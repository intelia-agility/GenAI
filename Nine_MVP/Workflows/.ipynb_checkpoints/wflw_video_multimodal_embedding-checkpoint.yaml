### This is the workflow to extract multimodal embeddings from video

main:
  #params: [input]

  steps:
    # Step 1: Initialize variables
    - init:
        assign:
            - PROJECT: ${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}
            - LOCATION: ${sys.get_env("GOOGLE_CLOUD_LOCATION")}
            - PROJECT_NUMBER : ${sys.get_env("GOOGLE_CLOUD_PROJECT_NUMBER") }
            - MM_MODEL: "multimodalembedding@001"
            - MM_METHOD: "predict"
            - MM_LLM_ENDPOINT: ${"https://" + LOCATION + "-aiplatform.googleapis.com" + "/v1/projects/" + PROJECT + "/locations/" + LOCATION + "/publishers/google/models/" + MM_MODEL+":"+MM_METHOD}
 
            - LST_OUTPUT: []
            - SOURCE_BUCKET: "raw_nine_files"  # ${sys.get_env("SOURCE_BUCKET_NAME")}
            - DESTINATION_BUCKET: "artifacts-nine-quality-test-embeddings"
            - MEDIA_TYPES: ["video/mp4"]   
            - FUNC_GET_VIDEO_DURATION_ENDPOINT: ${"https://getvideodurationservice-"+PROJECT_NUMBER+".us-central1.run.app/get-video-duration"}
            - SOURCE_VIDEO_FOLDER: "vlt_video_extract/OTHERS"
            - SEGMENT_LENGTH: 120
            - NO_OF_CONCURRENT_EXECUSTIONS: 10
            #- API_VIDEO_PER_SECOND: 5
            - SLEEP_BETWEEN_VIDEOS: 120 # ${int(NO_OF_CONCURRENT_EXECUSTIONS) / int(API_VIDEO_PER_SECOND)}
            - SLEEP_BETWEEN_SEGMENTS: 30
            - MULTIMODAL_EMBEDDING_FOLDER: "video_multimodal_embedding_fldr_out" #main folder name 
            - MULTIMODAL_EMBEDDING_FOLDER_JOB: ${"video_multimodal_embedding_"+  time.format( sys.now())} #this execution folder name
            - OUTPUT_FILE_NAME: ${MULTIMODAL_EMBEDDING_FOLDER+"/"+MULTIMODAL_EMBEDDING_FOLDER_JOB+"/"+"video_multimodal_embeddings.json"}
            - OUTPUT_DIRECTORY: ${"gs://"+DESTINATION_BUCKET+"/"+OUTPUT_FILE_NAME}  

    # Step 2: List objects in the GCS bucket
    - list_files:
        call: googleapis.storage.v1.objects.list
        args:
          bucket: ${SOURCE_BUCKET}
          prefix: ${SOURCE_VIDEO_FOLDER}
        result: list_result

    - log_list_files:
            call: sys.log
            args:
                text: "List Of files Loaded From GCP Storage"

  
    # Step 3: Filter only videos    
    - filter_medias:
        steps:
          - assignList:
              assign:
                  - media_types: ${MEDIA_TYPES}
                  - filetered_files: []
          - loopList:
              for:
                  value: item
                  in: ${list_result.items}
                  steps:
                      - check_matching: 
                          switch:                        
                            - condition: ${item.contentType in media_types}  
                              steps:
                                        - add_matching_item_to_filetered_list:
                                            assign:                                             
                                                - video_uri: ${"gs://"+SOURCE_BUCKET+"/"+item.name} 
                                                - video_uri_map: {"gcs_uri": "${video_uri}", "mime_type": "${item.contentType}"}                                    
                                                - item: ${map.merge(item, video_uri_map)}                                               
                                                - filetered_files: ${list.concat(filetered_files,item)}
    
  
    - log_filter_medias:
            call: sys.log
            args:
                text: ${"Medias Are Filtered-" + string(len(filetered_files))}

    # Step 4: extract video embeddings                             
    - extract_video_mm_embeddings:
        parallel:
            shared: [LST_OUTPUT]
            concurrency_limit: ${NO_OF_CONCURRENT_EXECUSTIONS}
            for:
                value: item
                in: ${filetered_files}
                steps:
                    #Step 5: Get video duration
                    - get_video_duration:
                        call: http.post
                        args:
                            url: ${FUNC_GET_VIDEO_DURATION_ENDPOINT}
                            headers:
                                Content-Type: "application/json"
                            body:
                                url: ${item.gcs_uri}

                        result:  video_duration_result
                        
                    #Step 6: Initialize vars
                    - set_start_offeset:
                        assign:
                            - prev: 0
                            - segment_length: ${SEGMENT_LENGTH}
                            - video_duration: ${video_duration_result.body.duration}
                            - video_gcs_uri: ${item.gcs_uri}

                    #Step 7: Loop over segments and call multimodal embeddings for each
                    - loop_over_video_segments:
                        steps:
                            #Step 7-1: initialize loop variables 
                            - init_vars:
                                assign:                                  
                                      - startOffset: ${prev}
                                      - endOffset:  ${prev+segment_length}
                            #Step 7-2: If end offset is exceeding video duration, set it to video duration
                            - check_endOffset:
                                 switch:
                                    - condition: ${endOffset >video_duration}
                                      steps:
                                            - set_endoffset_to_max_duration:  
                                                assign:
                                                    - endOffset : ${video_duration}

                            #Step 7-3: Call multimodal embedding
                            - ask_llm:
                                call: http.post
                                args:
                                    url: ${MM_LLM_ENDPOINT}
                                    auth:
                                        type: OAuth2
                                    body:
                                         "instances": [
                                                    {
                                                        "video": {
                                                         mimeType:  "${item.mime_type}",
                                                        "gcsUri": "${item.gcs_uri}" ,
                                                        videoSegmentConfig: {
                                                            "intervalSec": "${segment_length}",
                                                            "startOffsetSec": "${startOffset}",
                                                            "endOffsetSec": "${endOffset}"

                                                            }
                                                        }

                                                     } ]
 
                                    
                                result: llm_response

                            # Step 7-4: Add result to the output
                            - add_to_output:
                                    assign:                                    
                                        - output:  {
                                                    "intervalSec": "${segment_length}",
                                                    "startOffsetSec": "${startOffset}",
                                                    "endOffsetSec": "${endOffset}",
                                                    "duration": "${video_duration}",
                                                    "gcs_uri": "${item.gcs_uri}",                                         
                                                    "llm_response": "${llm_response.body}"
                                                     }
                                        - LST_OUTPUT: ${list.concat(LST_OUTPUT,output)}
                                   
                            # Step 7-5: Initialize vars to move to next segment
                            - assign_vars_move_next_segment:  
                                    assign:                                
                                      - prev: ${endOffset}

                            # Step 7-6: Check if there is any further segments left, if yes loop again 
                            - check_endOffset_move_next_segment:
                                 switch:
                                    - condition: ${endOffset <video_duration}
                                      next: loop_over_video_segments

                            # Step 7-7: We can not constantly call the enpoint, wait after each call
                            - wait_between_segments:
                                    call: sys.sleep
                                    args:
                                        seconds: ${SLEEP_BETWEEN_SEGMENTS}

                    - log_move_to_next_video:
                            call: sys.log
                            args:
                               text: ${"Embedding Is Calculated For - " + video_gcs_uri} 

                     # Step 8: We can not constantly call the enpoint, wait after each call
                    - wait_between_videos:
                            call: sys.sleep
                            args:
                                seconds: ${SLEEP_BETWEEN_VIDEOS}
                              

    
    # Step 9: Write the output into GCS
    - write_to_gcs:
        call: http.post
        args:
            url: ${"https://storage.googleapis.com/upload/storage/v1/b/" + DESTINATION_BUCKET + "/o"}
            auth:
                type: OAuth2
            query:
                name: ${OUTPUT_FILE_NAME}
            body:
                 {"items": "${LST_OUTPUT}"}
        
    # Step 10: Return output
    - return_result:
        return: [ {"status": "SUCCESS", "output_content": "${LST_OUTPUT}", "output_directory": "${OUTPUT_DIRECTORY}" }]
   
 