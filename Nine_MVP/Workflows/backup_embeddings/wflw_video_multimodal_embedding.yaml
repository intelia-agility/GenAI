### This is the workflow to extract multimodal embeddings from video

main:
  #params: [input]

  steps:
    # Step 1: Initialize variables
    - init:
        assign:
            - PROJECT: ${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}
            - LOCATION: ${sys.get_env("GOOGLE_CLOUD_LOCATION")}
            - PROJECT_NUMBER : ${sys.get_env("GOOGLE_CLOUD_PROJECT_NUMBER") }
            - MM_MODEL: "multimodalembedding@001"
            - MM_METHOD: "predict"
            - MM_LLM_ENDPOINT: ${"https://" + LOCATION + "-aiplatform.googleapis.com" + "/v1/projects/" + PROJECT + "/locations/" + LOCATION + "/publishers/google/models/" + MM_MODEL+":"+MM_METHOD}
 
          
            - SOURCE_BUCKET: ${sys.get_env("VAR_SOURCE_BUCKET")}
            - DESTINATION_BUCKET: ${sys.get_env("VAR_DESTINATION_BUCKET")}
            - MEDIA_TYPES: "video/mp4" #comma separated string   
            - FUNC_GET_VIDEO_DURATION_ENDPOINT: ${"https://getvideodurationservice-"+PROJECT_NUMBER+".us-central1.run.app/get-video-duration"}
            - SOURCE_VIDEO_FOLDER: "vlt_video_extract/OTHERS"
            - SEGMENT_LENGTH: 120
            - VIDEO_INTERVALS : 120
            - NO_OF_CONCURRENT_EXECUSTIONS: 10
            #- API_VIDEO_PER_SECOND: 5
            - SLEEP_BETWEEN_VIDEOS: 10 # ${int(NO_OF_CONCURRENT_EXECUSTIONS) / int(API_VIDEO_PER_SECOND)}
            - SLEEP_BETWEEN_SEGMENTS: 30
            - MULTIMODAL_EMBEDDING_FOLDER: "video_multimodal_embedding_fldr_out" #main folder name 
            - MULTIMODAL_EMBEDDING_FOLDER_JOB: ${"video_multimodal_embedding_"+  time.format( sys.now())} #this execution folder name
            - OUTPUT_FILE_NAME: "video_multimodal_embeddings"
            - OUTPUT_DIRECTORY: ${"gs://"+DESTINATION_BUCKET+"/"+MULTIMODAL_EMBEDDING_FOLDER+"/"+MULTIMODAL_EMBEDDING_FOLDER_JOB}  

            - METADATA_DATASET: "vlt_media_multimodal_embeddings_prelanding"
            - METADATA_TABLE: "vlt_video_metadata"
            - VIDEO_TABLE: "vlt_video_multimodal_embeddings"
            #- METADATA_ERROR_TABLE: "vlt_image_error_metadata"
            - FUNC_LOAD_MEDIA_METADATA: ${"https://"+LOCATION+"-"+PROJECT+".cloudfunctions.net/func_generate_media_metadata"}
            - OUTPUT_TABLE: ${METADATA_DATASET+"."+VIDEO_TABLE}
            - BATCH_OUTPUT: []


  #Step 1: Load media metadata into  big query table
    - load_media_metadata:
        call: http.post
        args:
            url: ${FUNC_LOAD_MEDIA_METADATA}
            query:
                name: "LOAD METADATA"            
                project_id: ${PROJECT}
                dataset: ${METADATA_DATASET}
                table: ${METADATA_TABLE}  # for video we separate metadata table and landing table
                video_landing_table: ${VIDEO_TABLE} 
                region:  ${LOCATION}
                source_bucket:  ${SOURCE_BUCKET}  
                source_folder:  ${SOURCE_VIDEO_FOLDER}  
                media_types:  ${MEDIA_TYPES}                 
              
        result:  metadata_load_result

    #Step 2: Check if data is loaded into bigquery successfully
    # exit the workflow and return failure even if one load job is faile
    - check_bigquery_load:
        for:
           value: job_id
           in: ${metadata_load_result.body.jobs}
           steps:
                 #Step 3: Get job state
                - get_bigquery_load_job_status:
                    call:  googleapis.bigquery.v2.jobs.get 
                    args:
                        jobId: ${job_id}
                        projectId: ${PROJECT}
                        location : ${LOCATION}     
                    result: load_job_result
                
                 # Step 4: check the if load is done sucessfully for all jobs, otherwise exit
                - checkIfLoadDone: 
                        switch:
                              - condition: ${load_job_result.status.state=="DONE" and "errors" in load_job_result.status}
                                steps:
                                    - return_load_failure:
                                        assign:
                                            - out_result:
                                                output_table: ""
                                                state: "BIGQUERY LOAD FAILED- CHECK THE LOGS"                                          
                                            - BATCH_OUTPUT: ${list.concat(BATCH_OUTPUT,out_result)}
                                    - exit:
                                        return: ${BATCH_OUTPUT}

                              - condition:  ${load_job_result.status.state in ["PENDING", "RUNNING"] and  not( "errors" in load_job_result.status)}
                                steps:
                                    - bg_load_wait:
                                        call: sys.sleep
                                        args:
                                            seconds: 30
                                        next: get_bigquery_load_job_status                                 
    
    - log_chunking:
        call: sys.log
        args:
          text: ${"Media Metadata Is Loaded - " + "Count of Created Tables "+ string(metadata_load_result.body.count_of_tables)}



    #Step 3: Get media count
    - get_media_count:
        call:  googleapis.bigquery.v2.jobs.query
        args:
          projectId: ${PROJECT}
          body:
            query: ${"SELECT COUNT(*) AS media_count FROM `"+METADATA_DATASET+"."+METADATA_TABLE+"` LIMIT 1"}
            useLegacySql: false
        result: media_count_response

    #Step 4: Get media count
    - set_media_count:
        assign:
            - media_count: ${int(media_count_response.rows[0].f[0]["v"])-1}

    - log_media:
        call: sys.log
        args:
          text: ${"Media Count Loaded - " +  string(media_count+1)}


    #Step 5: Check media count. exit if no media
    - checkIfNoMedia: 
        switch:
            - condition: ${media_count<0}
              steps:
                    - exitNoMedia:
                        return: "No Media Found- Check The Media Folder"


    
   #Step 6: Extract image multimodal embeddings
    - extract_video_mm_embeddings:
        parallel:
            concurrency_limit: ${NO_OF_CONCURRENT_EXECUSTIONS}
            for:
                value: idx
                range: ${[0, media_count]}    
              
                steps:
                    #Step 6-1: Set vars
                    - init_mdeia_metadata:
                        assign:
                            - metadata_map: {}

                    #Step 6-2: Get media info feom bigquery
                    - get_media_from_bq:
                            call:  googleapis.bigquery.v2.jobs.query
                            args:
                                projectId: ${PROJECT}
                                body:
                                    query: ${"SELECT name,mime_type,gcs_uri,media_name FROM `"+METADATA_DATASET+"."+METADATA_TABLE+"` WHERE idx="+idx+" LIMIT 1"}                      
                                    useLegacySql: false
                            result: bq_response 

                    - log_mediaInfoLoad:
                            call: sys.log
                            args:
                               text: ${"Media Info Loaded - "}

                    #Step 6-3: Set metadata info for current media
                    - set_metadata:
                            for: 
                                value: field
                                index: filed_idx
                                in: ${bq_response.schema.fields}
                                steps:
                                    - set_media_metadata:
                                            assign:
                                                - val: ${bq_response.rows[0].f[filed_idx]["v"]}
                                                - media_map: {"${field.name}" : "${val}"}
                                                - metadata_map:  ${map.merge(metadata_map, media_map)} 

                   
                    - log_mediaMetadataInfo:
                            call: sys.log
                            args:
                               text: ${"Media Metadata Is Set- "+metadata_map.media_name}  

                     #Step 6-4: Get video duration
                    - get_video_duration:
                        call: http.post
                        args:
                            url: ${FUNC_GET_VIDEO_DURATION_ENDPOINT}
                            headers:
                                Content-Type: "application/json"
                            body:
                                url: ${metadata_map.gcs_uri}

                        result:  video_duration_result

                    - log_video_duration:
                            call: sys.log
                            args:
                               text: ${"Video Duration Is Calcuated- "+metadata_map.media_name +"-"+ string(video_duration_result.body.duration)}  

                    #Step 6-7: Initialize vars
                    - set_vars_for_video_loop:
                        assign:
                            - prev: 0
                            - video_duration: ${math.floor(video_duration_result.body.duration)}                    

                    #Step 7: Loop over segments and call multimodal embeddings for each
                    - loop_over_video_segments:
                        steps:
                            #Step 7-1: initialize loop variables 
                            - init_vars:
                                assign:                                  
                                      - startOffset: ${prev}
                                      - endOffset:  ${prev+SEGMENT_LENGTH}

                            #Step 7-2: If end offset is exceeding video duration, set it to video duration
                            - check_endOffset:
                                 switch:
                                    - condition: ${endOffset >video_duration}
                                      steps:
                                            - set_endoffset_to_max_duration:  
                                                assign:
                                                    - endOffset : ${video_duration}

                            #Step 7-3: Set metadata info for current aegment
                            - generate_multimodal_embeding:
                                try:
                                    steps:
                                        #Step 7-3-1: Call multimodal embedding
                                        - ask_llm:
                                                call: http.post
                                                args:
                                                    url: ${MM_LLM_ENDPOINT}
                                                    auth:
                                                        type: OAuth2
                                                    body:
                                                        "instances": [
                                                                        {
                                                                            "video": {
                                                                                    mimeType:  "${metadata_map.mime_type}",
                                                                                    "gcsUri": "${metadata_map.gcs_uri}" ,
                                                                                    videoSegmentConfig: {
                                                                                        "intervalSec": "${VIDEO_INTERVALS}",
                                                                                        "startOffsetSec": "${startOffset}",
                                                                                        "endOffsetSec": "${endOffset}"

                                                                                        }
                                                                            }

                                                                        } ]
                                                result: llm_response

                                        - log_llm:
                                                call: sys.log
                                                args:
                                                    text: ${"Embedding Call Finished "+metadata_map.media_name +"- From"+ string(startOffset) + " to "+ string(endOffset)   }

                                        # Step 7-3-2: Write the output into GCS
                                        - write_to_gcs:
                                                call: http.post
                                                args:
                                                    url: ${"https://storage.googleapis.com/upload/storage/v1/b/" + DESTINATION_BUCKET + "/o"}
                                                    auth:
                                                            type: OAuth2
                                                    query:
                                                            name: ${MULTIMODAL_EMBEDDING_FOLDER+"/"+MULTIMODAL_EMBEDDING_FOLDER_JOB+"/"+metadata_map.media_name+"/"+OUTPUT_FILE_NAME +".json"}                                   
                                                    body:
                                                            {"intervalSec": "${VIDEO_INTERVALS}",
                                                            "startOffsetSec": "${startOffset}",
                                                            "endOffsetSec": "${endOffset}",
                                                            "duration": "${video_duration}",
                                                            "gcs_uri": "${metadata_map.gcs_uri}",                                         
                                                            "llm_response": "${llm_response.body}"
                                                           }


                                        - log_wrtite_to_gcs:
                                                call: sys.log
                                                args:
                                                    text: ${"Data Is Written In to GCS For- " + metadata_map.media_name +"- From"+ string(startOffset) + " to "+ string(endOffset)} 

                                        # Step 7-3-3: Init variables to write into bq
                                        - create_prediction_response:
                                                assign:  
                                                    - execution_time: "${time.format(sys.now())}"
                                                    - predictions:  "${llm_response.body}"
        
                                        # Step 7-3-4: Set record to insert write the output into bq as well                                    
                                        - set_row_to_insert:
                                            assign:                                         
                                                - bigquery_row:
                                                    gcs_uri: ${metadata_map.gcs_uri}
                                                    mime_type:  ${metadata_map.mime_type}
                                                    name: ${metadata_map.name}
                                                    media_name: ${metadata_map.media_name}
                                                    predictions: ${json.encode_to_string(predictions)}
                                                    time: "${time.format(sys.now())}"
                                                    start_offset: ${startOffset}
                                                    end_offset: ${endOffset}

                                        # Step 7-3-5: Write the output into bq as well
                                        - load_data_into_bq:
                                            call: googleapis.bigquery.v2.tabledata.insertAll
                                            args:
                                                datasetId:  ${METADATA_DATASET}
                                                projectId: ${PROJECT}
                                                tableId: ${VIDEO_TABLE} 
                                                body:                                                    
                                                    rows:
                                                        json: ${bigquery_row}
                                            result: insertResult

                                                
                                        - log_wrtite_to_bq:
                                                call: sys.log
                                                args:
                                                    text: ${"Data Is Written In to Bigquery Table - " + VIDEO_TABLE +"-"+metadata_map.media_name+"- From"+ string(startOffset) + " to "+ string(endOffset)} 

                                except:
                                    as: e
                                    steps:
                                        
                                            - logerror:
                                                    call: sys.log
                                                    args:
                                                        text: ${e}

                                            - create_error_response:
                                                assign: 
                                                    - execution_time: "${time.format(sys.now())}"
                                                    - error: ${e}

                                            # # Step 7-4: Set record to write the errors into bq as well
                                            - set_error_row_to_insert:
                                                assign:                                         
                                                    - bigquery_row:
                                                        gcs_uri: ${metadata_map.gcs_uri}
                                                        mime_type:  ${metadata_map.mime_type}
                                                        name: ${metadata_map.name}
                                                        media_name: ${metadata_map.media_name}                                                        
                                                        time: "${time.format(sys.now())}"
                                                        start_offset: ${startOffset}
                                                        end_offset: ${endOffset}
                                                        error: ${json.encode_to_string(error)}
                                                    
                                            # # Step 7-5: Write the errors into bq as well
                                            - load_errors_into_bq:
                                                call: googleapis.bigquery.v2.tabledata.insertAll
                                                args:
                                                    datasetId:  ${METADATA_DATASET}
                                                    projectId: ${PROJECT}
                                                    tableId: ${VIDEO_TABLE} 
                                                    body:                                                    
                                                        rows:
                                                            json: ${bigquery_row}
                                                result: insertResult
                                                
                                            - log_wrtite_error_to_bq:
                                                    call: sys.log
                                                    args:
                                                        text: ${"Error Is Logged In to Bigquery Table - " + VIDEO_TABLE +"-"+metadata_map.media_name+"- From"+ string(startOffset) + " to "+ string(endOffset)}
                                   
                            # Step 7-5: Initialize vars to move to next segment
                            - assign_vars_move_next_segment:  
                                    assign:                                
                                      - prev: ${endOffset}

                            # Step 7-6: Check if there is any further segments left, if yes loop again 
                            - check_endOffset_move_next_segment:
                                 switch:
                                    - condition: ${endOffset <video_duration}
                                      next: loop_over_video_segments

                            # Step 7-7: We can not constantly call the enpoint, wait after each call
                            - wait_between_segments:
                                    call: sys.sleep
                                    args:
                                        seconds: ${SLEEP_BETWEEN_SEGMENTS}

                    - log_move_to_next_video:
                            call: sys.log
                            args:
                                text: ${"Embedding Is Calculated For - " + metadata_map.media_name}                     

                     # Step 8: We can not constantly call the enpoint, wait after each call
                    - wait_between_images:
                            call: sys.sleep
                            args:
                                seconds: ${SLEEP_BETWEEN_VIDEOS}

    # Step 9: Return output
    - return_result:
        return: [ {"status": "SUCCESS", "output_directory": "${OUTPUT_DIRECTORY}", "output_table":"${OUTPUT_TABLE}" }]

 