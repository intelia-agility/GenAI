### This is the workflow to extract multimodal embeddings from images using biqquery ML

main:
  #params: [input]

  steps:
    # Step 1: Initialize variables
    - init:
        assign:
            - PROJECT: ${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}
            - LOCATION: ${sys.get_env("GOOGLE_CLOUD_LOCATION")}
         
            - MM_MODEL: "multimodalembedding@001" 
            - MM_BQ_REMOTE_ID: "vlt_multimodal_endpoint" 
            - MODEL_NAME: "vlt_model_media_multimodal_embeddings"
            - MEDIA_TYPES: "image/jpeg,image/png" #comma separated string 
        
            - METADATA_DATASET: "vlt_media_multimodal_embeddings_prelanding"
            - METADATA_TABLE: "vlt_image_metadata_bq" 
            - IMAGE_MULTIMODAL_EMBEDDING_TABLE: "vlt_image_multimodal_embeddings_bq" 
            - OUTPUT_TABLE: ${METADATA_DATASET+"."+METADATA_TABLE}

            - SOURCE_BUCKET: ${sys.get_env("VAR_SOURCE_BUCKET")}           
            - SOURCE_IMAGE_FOLDER: "2023/1/a"
            - BATCH_SIZE: 10000 #shouldnt be more that 25000 limit

    # Step 1: Create Dataset
    - create_dataset:
        call:  googleapis.bigquery.v2.jobs.query
        args:
          projectId: ${PROJECT}
          body:
            query: ${" CREATE SCHEMA IF NOT EXISTS " +METADATA_DATASET }
            useLegacySql: false
        result: model_creation_response


     # Step 2: Create Model
    - create_multimodal_model:
        call:  googleapis.bigquery.v2.jobs.query
        args:
          projectId: ${PROJECT}
          body:
            query: ${" CREATE OR REPLACE MODEL `"+METADATA_DATASET+"."+MODEL_NAME+"` REMOTE WITH CONNECTION `"+LOCATION+"."+MM_BQ_REMOTE_ID+"` OPTIONS(endpoint = '"+MM_MODEL+"');"}
            useLegacySql: false
        result: model_creation_response
 

    - log_model_build:
        call: sys.log
        args:
          text: ${"Multimodal Model Created - " }

           
    # Step 3: Create external table
    - createExternalTable:
        call: googleapis.bigquery.v2.jobs.insert
        args:
          projectId:  ${PROJECT}
          body:
            configuration:
              query:
                query: ${ 
                  "CREATE OR REPLACE EXTERNAL TABLE `"+METADATA_DATASET+"."+METADATA_TABLE+"`"+
                  " WITH CONNECTION `"+LOCATION+"."+MM_BQ_REMOTE_ID+"`"+
                  " OPTIONS ( "+
                    " object_metadata = 'SIMPLE', "+
                    " uris = ['gs://"+SOURCE_BUCKET+"/"+SOURCE_IMAGE_FOLDER+"/*'])" }
                useLegacySql: false
              
        result: queryJob
    
    # Step 4: Get the job status
    - get_bigquery_load_job_status:
            call:  googleapis.bigquery.v2.jobs.get 
            args:
                jobId: ${queryJob.jobReference.jobId}
                projectId: ${PROJECT}
                location : ${LOCATION}     
            result: load_job_result

    # Step 5: Check if job is done
    - checkIfLoadDone: 
            switch:
                    - condition: ${load_job_result.status.state=="DONE" and "errors" in load_job_result.status}
                      steps:
                            - return_load_failure:
                                   assign:
                                        - out_result:
                                                output_table: ""
                                                state: "BIGQUERY LOAD FAILED- CHECK THE LOGS"                                         
                                       
                            - exit:
                                    return: ${out_result}

                    - condition:  ${load_job_result.status.state in ["PENDING", "RUNNING"] and  not( "errors" in load_job_result.status)}
                      steps:
                            - bg_load_wait:
                                call: sys.sleep
                                args:
                                    seconds: 30
                                next: get_bigquery_load_job_status  

    - log_media_load:
        call: sys.log
        args:
          text: ${"Media Metadata Object Table Loaded - " }
          
    #Step 6: Get media count
    - get_media_count:
        call:  googleapis.bigquery.v2.jobs.query
        args:
          projectId: ${PROJECT}
          body:
            query: ${"SELECT COUNT(*) AS media_count FROM `"+METADATA_DATASET+"."+METADATA_TABLE+"` LIMIT 1"}
            useLegacySql: false
        result: media_count_response

    #Step 7: set media count
    - set_media_count:
        assign:
            - media_count: ${int(media_count_response.rows[0].f[0]["v"])}

    - log_media:
        call: sys.log
        args:
          text: ${"Media Count Loaded - " +  string(media_count)}

    
    #Step 8: Check media count. exit if no media
    - checkIfNoMedia: 
        switch:
            - condition: ${media_count<=0}
              steps:
                    - exitNoMedia:
                        return: "No Media Found- Check The Media Folder"   

    #Step 9: Inititalize variables for the batch
    - initialize:
        assign:         
          - offset: 0
          - limit: ${BATCH_SIZE}
          - query: ${"CREATE OR REPLACE TABLE "+ "`"+METADATA_DATASET+"."+IMAGE_MULTIMODAL_EMBEDDING_TABLE+"` AS "}

    #Step 10: Fetch the rows in batches and calculate multimodal embeddings
    - fetchRows:
        steps:

            #Step 10-1: Extract Multimodal embeddings
            - extract_multimodal_embeddings:
                call: googleapis.bigquery.v2.jobs.insert
                args:
                    projectId:   ${PROJECT}
                    body:
                        configuration:
                            query:
                                query:  ${query+ " SELECT *  FROM  ML.GENERATE_EMBEDDING ( MODEL" +"`"+ METADATA_DATASET+"."+MODEL_NAME+"`,"+
                                            " ( SELECT *  FROM `"+METADATA_DATASET+"."+METADATA_TABLE+"` LIMIT " +string(limit) +" OFFSET "+ string(offset) +"))"}
                                useLegacySql: false              
                result: queryJob 

            #Step 10-2: Get batch status     
            - get_multimodal_embeddings_batch_status:
                    call:  googleapis.bigquery.v2.jobs.get 
                    args:
                        jobId: ${queryJob.jobReference.jobId}
                        projectId: ${PROJECT}
                        location : ${LOCATION}     
                    result: load_job_result

            # Step 10-3: check the if embeddings are extracted successfully
            # in the case of failure, exit
            - checkIfBatchDone: 
                    switch:
                            - condition: ${load_job_result.status.state=="DONE" and "errors" in load_job_result.status}
                              steps:
                                    - set_embedding_failure:
                                        assign:
                                                - failure_message:
                                                        output_table: ""
                                                        state: "Image Multimodal Embeddings Batch Failed- CHECK THE LOGS"                                         
                                            
                                    - exit_embedding:
                                            return: ${failure_message}

                            - condition:  ${load_job_result.status.state in ["PENDING", "RUNNING"] and  not( "errors" in load_job_result.status)}
                              steps:
                                    - bg_embedding_wait:
                                        call: sys.sleep
                                        args:
                                            seconds: 30
                                        next: get_multimodal_embeddings_batch_status  

            - log_batch_execution:
                call: sys.log
                args:
                    text: ${"Batch Finished - " +string(limit) + " Loaded From "+string(offset) +" " }

            # Step 10-4: Set the variables for fetching next batch
            - updateOffset:
                 assign:
                    - offset: ${offset + limit}

            # Step 10-5: Set the query to Insert into instead of create table
            - update_query:
                assign:
                   - query: ${" INSERT INTO "+ "`"+METADATA_DATASET+"."+IMAGE_MULTIMODAL_EMBEDDING_TABLE+"` " }

            #Step 10-6: Get media count for next batch
            - get_next_batch:
                call:  googleapis.bigquery.v2.jobs.query
                args:
                    projectId: ${PROJECT}
                    body:
                        query: ${" SELECT COUNT(*) media_count FROM (SELECT 1 FROM `"+
                                 METADATA_DATASET+"."+METADATA_TABLE+"` LIMIT " +string(limit) +" OFFSET "+ string(offset) +")"}
                        useLegacySql: false
                result: media_count_response


            #Step 10-7: set media count for next batch
            - set_count_for_next_batch_check:
                assign:
                     - media_count: ${int(media_count_response.rows[0].f[0]["v"])}
                  
            #Step 10-8: check if there are more records
            # if yes, loop again
            - check_if_more_batch:
                    switch:
                        - condition: ${media_count>0}
                          next: fetchRows 
    - return_result:
         return: {"status": "SUCCESS", "output_dataset": "${METADATA_DATASET}", "output_table":"${IMAGE_MULTIMODAL_EMBEDDING_TABLE}"}

                


