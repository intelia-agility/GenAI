{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "026458de-69fd-44c8-8da1-8086a0214a23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from langchain_google_community import BigQueryLoader\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "#from langchain.llms import VertexAI as langchain_vertexai\n",
    "from langchain_google_vertexai import VertexAI as langchain_vertexai\n",
    "from langchain import PromptTemplate\n",
    "from pathlib import Path as p\n",
    "import pandas as pd\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n",
    "\n",
    "\n",
    "vertex_llm_text = langchain_vertexai(model_name=\"gemini-1.5-pro-002\")\n",
    "generative_multimodal_model= GenerativeModel(\"gemini-1.5-pro-002\")\n",
    "\n",
    "\n",
    "def estimate_token_length(text, model=\"gpt2\"):\n",
    "    \"\"\"Estimates the token length of a given text using a specified model.\n",
    "\n",
    "      Args:\n",
    "        text: The input text.\n",
    "        model: The model to use for tokenization (default: \"gpt2\").\n",
    "\n",
    "      Returns:\n",
    "        The estimated number of tokens.\n",
    "      \"\"\"\n",
    "\n",
    "  \n",
    "    enc = tiktoken.get_encoding(model)  \n",
    "\n",
    "    # Tokenize the text and count tokens\n",
    "    tokens = enc.encode(text)\n",
    "    token_count = len(tokens)\n",
    "    return token_count\n",
    "\n",
    "def get_data(source_query_str: str=None,metadata_columns: str=None,page_content_columns: str=None, project_id: str=None , return_text: bool=True):\n",
    "    \n",
    "    \"\"\"Load data from big query\n",
    "\n",
    "      Args:\n",
    "        str source_query_str:  The query string to fetch the data from bigquery\n",
    "        list[str] metadata_columns:  list of metadata column names\n",
    "        list[str] page_content_columns:  list of content column names  \n",
    "        str project_id: project id\n",
    "        bool return_text: returns the content columns description\n",
    "      Returns:\n",
    "          list[langchain_core.documents.base.Document] documents: langchain documents\n",
    "          \n",
    "      \"\"\"\n",
    "    \n",
    "    loader = BigQueryLoader(\n",
    "            query=source_query_str, project=project_id, metadata_columns=metadata_columns, page_content_columns=page_content_columns\n",
    "        )\n",
    "    documents = []\n",
    "    all_texts=[]\n",
    "    documents.extend(loader.load())\n",
    "    if return_text:  \n",
    "         all_texts=[doc.page_content.replace('description:',\"\",1) for doc in documents]\n",
    "        \n",
    "    return documents, '\\n'.join(all_texts)\n",
    "    \n",
    " \n",
    "def summarize_docs(documents: list[object],question_prompt_template: str=\"\", refine_prompt_template: str=\"\" ,is_token_limit_exceeded: bool=False ):\n",
    "    \n",
    "    \"\"\"summarizes the input documents\n",
    "\n",
    "      Args:\n",
    "        list[object] documents:  list of langchain documents\n",
    "        str question_prompt_template:  string question prompt template. \n",
    "        str refine_prompt_template:  string refine prompt template in the case that we need to use refine method\n",
    "        bool is_token_limit_exceeded:  boolean indicating wheather or not the token limit is exceeded.\n",
    "      Returns:\n",
    "         dict : summary result\n",
    "         \n",
    "      \"\"\"\n",
    "       \n",
    "    question_prompt = PromptTemplate(template=question_prompt_template, input_variables=[\"text\"]) \n",
    "    \n",
    "    if not is_token_limit_exceeded:        \n",
    "        #if the token limit is in the context window range, use a stuffing method for summary\n",
    "        chain = load_summarize_chain(vertex_llm_text, chain_type=\"stuff\", \n",
    "                                     prompt=question_prompt)\n",
    "        \n",
    "    else:     \n",
    "        #otherwise use a refine summarization method\n",
    "        refine_prompt = PromptTemplate(input_variables=[\"existing_answer\", \"text\"], template=refine_prompt_template)\n",
    "              \n",
    "        chain = load_summarize_chain(\n",
    "            vertex_llm_text,\n",
    "            chain_type=\"refine\",\n",
    "            question_prompt=question_prompt,\n",
    "            refine_prompt=refine_prompt,\n",
    "            return_intermediate_steps=True,\n",
    "          )\n",
    "        \n",
    "    return chain.invoke(documents)\n",
    "\n",
    "def  get_query_string (assets: str=\"\"):\n",
    "    \"\"\"set query string \n",
    "      Args:         \n",
    "        str assets:  comma separated string of all requested assets     \n",
    "      Returns:\n",
    "         str source_query_str : string query for loading data from biquery\n",
    "         \n",
    "      \"\"\"\n",
    "     #source_query_str=f\"select distinct combined_id,unique_id,content, chunk, trim(concat(ifnull(headline,''), CHR(10),  description)) as description from `nine-quality-test.vlt_media_embeddings_integration.vlt_all_media_content_text_embeddings` where asset_id in {assets} order by unique_id, chunk asc \"\n",
    "    source_query_str= f\"\"\"SELECT          asset_id,                  \n",
    "                    STRING_AGG(description, '\\\\n' ) \n",
    "                    OVER (PARTITION BY asset_id ORDER BY ifnull(startOffset_seconds,0) ASC , chunk ASC) AS full_description,\n",
    "                    IDX\n",
    "              FROM (\n",
    "                    SELECT  asset_id,startOffset_seconds, CHUNK, \n",
    "                    CASE WHEN chunk=0 \n",
    "                         THEN TRIM(CONCAT(IFNULL(headline,''), CHR(10),  description))  \n",
    "                         ELSE description \n",
    "                    END AS description,\n",
    "                    ROW_NUMBER() OVER (PARTITION BY asset_id ORDER BY startOffset_seconds desc) AS IDX,\n",
    "                    FROM `vlt_media_embeddings_integration.vlt_all_media_content_text_embeddings` where asset_id in ({assets})\n",
    "             )\n",
    "           WHERE IDX=1\n",
    "        \"\"\"\n",
    "    return source_query_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "c848aa6f-839e-440b-9927-0e67ae92e070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def  get_query_string (assets: str=\"\"):\n",
    "    \"\"\"set query string \n",
    "      Args:         \n",
    "        str assets:  comma separated string of all requested assets     \n",
    "      Returns:\n",
    "         str source_query_str : string query for loading data from biquery\n",
    "         \n",
    "      \"\"\"\n",
    "     #source_query_str=f\"select distinct combined_id,unique_id,content, chunk, trim(concat(ifnull(headline,''), CHR(10),  description)) as description from `nine-quality-test.vlt_media_embeddings_integration.vlt_all_media_content_text_embeddings` where asset_id in {assets} order by unique_id, chunk asc \"\n",
    "    source_query_str= f\"\"\"SELECT          asset_id,                  \n",
    "                    STRING_AGG(description, '\\\\n' ) \n",
    "                    OVER (PARTITION BY asset_id ORDER BY ifnull(startOffset_seconds,0) ASC , chunk ASC) AS full_description,\n",
    "                    IDX\n",
    "              FROM (\n",
    "                    SELECT  asset_id,startOffset_seconds, CHUNK, \n",
    "                    CASE WHEN chunk=0 \n",
    "                         THEN TRIM(CONCAT(IFNULL(headline,''), CHR(10),  description))  \n",
    "                         ELSE description \n",
    "                    END AS description,\n",
    "                    ROW_NUMBER() OVER (PARTITION BY asset_id ORDER BY startOffset_seconds desc) AS IDX,\n",
    "                    FROM `vlt_media_embeddings_integration.vlt_all_media_content_text_embeddings` where asset_id in ({assets})\n",
    "             )\n",
    "           WHERE IDX=1\n",
    "        \"\"\"\n",
    "    return source_query_str\n",
    "    \n",
    "def get_prompt(action_type: str=\"\",platform: str=\"\",persona_text: str=\"\", input_text:str=\"\", Language:str=\"\"):\n",
    "    \n",
    "    \"\"\"set prompt according to the requested action\n",
    "      Args:         \n",
    "        str action_type:  the type of action needs to be done\n",
    "        str platform: platform name for off platform posts \n",
    "        str persona_text: for persona based summaries \n",
    "      Returns:\n",
    "         str question_prompt_template : the main prompt for the given action \n",
    "         str refine_prompt_template:  the second level prompt for refinement, in the case that the context is too long, we have to use refinement method.\n",
    "         \n",
    "      \"\"\"\n",
    " \n",
    "    question_prompt_template=\"\"\n",
    "    refine_prompt_template=\"\"\n",
    "    \n",
    "    if action_type==\"Summary\" or action_type==\"Summary_Persona\":\n",
    "            #this is the main prompt for summary\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide a summary of the following text\"\"\"+persona_text+\"\"\". Your result must be detailed and at least 2 paragraphs. \n",
    "                When summarizing, directly dive into the narrative or descriptions from the text without using introductory phrases like 'In this passage'. \n",
    "                Directly address the main events, characters, and themes, encapsulating the essence and significant details from the text in a flowing narrative. \n",
    "                The goal is to present a unified view of the content, continuing the story seamlessly as if the passage naturally progresses into the summary.\n",
    "\n",
    "                TEXT: {text}\n",
    "                SUMMARY:\n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final summary. Your task is to combine and refine these summaries into a final, comprehensive summary that covers all key events, characters, themes, and details.\\n\"\n",
    "                \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing summary\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original summary\"\n",
    "                \"If the context isn't useful, return the original summary.\"\n",
    "            )\n",
    "    elif action_type==\"HeadLine\":  \n",
    "\n",
    "        #this is the main prompt for headline\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide a one line headline of the following text. \n",
    "\n",
    "                TEXT: {text}\n",
    "                HEADLINE:\n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final headline. Your task is to combine and refine these headlines into a final, comprehensive headline that covers all details.\\n\"\n",
    "                \"We have provided an existing headline up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing headline\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original headline\"\n",
    "                \"If the context isn't useful, return the original headline.\"\n",
    "            )\n",
    "    elif action_type==\"OffPlatformPost\"  and platform=='Twitter':\n",
    "               #this is the main prompt for social media post\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide a tweet that that’s catchy, concise, and fits within 280 characters. Make sure to highlight the key message, and encourage engagement with a question or call to action.\n",
    "\n",
    "                TEXT: {text}\n",
    "                Tweet: \n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final tweet. Your task is to combine and refine these tweets into a final, comprehensive tweet that covers all details, is catchy, concise, fits within 280 characters, and encourage engagement with a question or call to action.\\n\"\n",
    "                \"We have provided an existing tweet up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing tweet\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original tweet\"\n",
    "                \"If the context isn't useful, return the original tweet.\"\n",
    "            )\n",
    "    elif action_type==\"OffPlatformPost\" and platform=='Instagram':         \n",
    "            #this is the main prompt for social media post\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide  into an engaging Instagram post. Craft a short, attention-grabbing caption that highlights the main point. Use emojis to make it lively, and end with a question or call to action to spark conversation in the comments.\n",
    "\n",
    "                TEXT: {text}\n",
    "                Instagram Post: \n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final tweet. Your task is to combine and refine these Instagram posts into a final, comprehensive post that covers all details, crafts a short, attention-grabbing caption that highlights the main point. Use emojis to make it lively, and end with a question or call to action to spark conversation in the comments.\\n\"\n",
    "                \"We have provided an existing post up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing post\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original post\"\n",
    "                \"If the context isn't useful, return the original post.\"\n",
    "            )\n",
    "    elif action_type==\"Translation\":\n",
    "            print('******************')\n",
    "            #this is the main prompt for social media post\n",
    "            question_prompt_template = f\"\"\"Translate the following text into {Language}.  Make sure to preserve the meaning, tone, and style of the original text, while ensuring it is natural and fluent in {Language}.\n",
    "            Text:\\n \n",
    "              {input_text}\\n\n",
    "            Only provide a single response.\n",
    "            \"\"\"\n",
    "      \n",
    "            \n",
    "    return question_prompt_template,refine_prompt_template\n",
    "\n",
    "def get_summary(assets:str=\"\",action_type:str=\"\",platform:str=\"\",persona_text:str=\"\",project_id:str=\"\",context_window_limit: int=2000000):\n",
    "    \n",
    "    \"\"\"get summary according to the action type requested\n",
    "      Args:         \n",
    "        str assets:  comma separate string including all assets\n",
    "        str action_type: requested action\n",
    "        str persona_text: for persona based summaries \n",
    "        str platform: for off platform based posts\n",
    "        str project_id: project id\n",
    "        int context_window_limit: context window limit for the llm model\n",
    "      Returns:\n",
    "         str :output summary \n",
    "      \"\"\"\n",
    "    \n",
    "    #set query string\n",
    "    source_query_str= get_query_string(assets)\n",
    "    \n",
    "    #set prompts\n",
    "    question_prompt_template, refine_prompt_template=get_prompt(action_type=action_type,platform=platform,persona_text=persona_text)\n",
    "    \n",
    "    #set metadata and content columns\n",
    "    metadata_columns=[\"asset_id\"]\n",
    "    page_content_columns=[\"full_description\"]\n",
    "    \n",
    "    #load data from biqquery\n",
    "    documents,all_texts=get_data(source_query_str=source_query_str,metadata_columns=metadata_columns,page_content_columns=page_content_columns, project_id=project_id,return_text=True)\n",
    "\n",
    "    # Estimate the token length\n",
    "    estimated_token_length = estimate_token_length(all_texts,'cl100k_base') #cl100k_base\n",
    "    \n",
    "    message=\"\"\n",
    "    is_token_limit_exceeded=False\n",
    "    if estimated_token_length > context_window_limit:\n",
    "      message=\"Your text is too long for the Gemini 1.5 Pro context window. We are trying to chunk and return the result.\"\n",
    "      is_token_limit_exceeded=True\n",
    "      summary=summarize_docs(documents=documents,question_prompt_template=question_prompt_template,refine_prompt_template=refine_prompt_template,is_token_limit_exceeded=is_token_limit_exceeded )\n",
    "\n",
    "    else:\n",
    "      message=\"Your text fits within the Gemini 1.5 Pro context window.\"\n",
    "      summary=summarize_docs(documents=documents,question_prompt_template=question_prompt_template,is_token_limit_exceeded=is_token_limit_exceeded )\n",
    "        \n",
    "    return summary[\"output_text\"]\n",
    "\n",
    "def get_translation(action_type: str=\"\",input_text: str=\"\",Language:str=\"\"):\n",
    "    \n",
    "    \"\"\" get translation according to the requested language\n",
    "      Args:         \n",
    "        str input_text:  text to be translated\n",
    "        str Language: destination language\n",
    "      \n",
    "      Returns:\n",
    "         str : translated document \n",
    "      \"\"\"\n",
    " \n",
    "    \n",
    "    #set prompts\n",
    "    question_prompt_template, _=get_prompt(action_type=action_type,input_text=input_text,Language=Language)\n",
    "    \n",
    "    generation_config= GenerationConfig(temperature=0.2, max_output_tokens=8192) \n",
    "    safety_settings=  {\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        }\n",
    "\n",
    "    model_input=[question_prompt_template]\n",
    "        \n",
    "    response = generative_multimodal_model.generate_content(\n",
    "        model_input,\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings, \n",
    "        \n",
    "    )\n",
    "    \n",
    "    result=\"\"\n",
    "    try:\n",
    "        result=response.text\n",
    "    except:\n",
    "        result=\"No translation can be provided.\"\n",
    "        \n",
    " \n",
    "    return result\n",
    " \n",
    "        \n",
    "def func_generate_content(request):\n",
    "    \n",
    "    # Set the Gemini 1.5 Pro context window limit\n",
    "    context_window_limit = 2000000\n",
    "    project_id = \"nine-quality-test\"  # @param {type:\"string\"}\n",
    "    REGION = \"us-central1\"  # @param {type:\"string\"}\n",
    "    assets=\"p5d2tw,p5e9zq,p5e49l\" #comma separated asset_ids  \n",
    "    \n",
    "    assets= ','.join([ \"'\"+ id.strip()+\"'\" for id in assets.split(',')])\n",
    "    action_type=\"Translation\" # could be Summary, Summary_Persona, HeadLine, OffPlatformPost, Translation\n",
    "    persona=\"10-year-old\"\n",
    "    text=\"\"\"\n",
    "    Disney+ has lots of cool shows!  There are funny shows like *Abbott Elementary*, which is about teachers at a school in Philadelphia.  There's also *The Americans*, a show about Russian spies pretending to be a regular family.  *Andor* is like *Star Wars* but for grown-ups.  *Arrested Development* is a hilarious show about a crazy family. *Atlanta* is about two cousins, one a rapper and the other his manager, and what it's like to be Black in America. *The Bear* is about a fancy chef who takes over his family's sandwich shop.  *Bob's Burgers* is a cartoon about a family who runs a burger restaurant. And for something really fun, there's *Buffy the Vampire Slayer*, about a girl who fights vampires! *Desperate Housewives* is about a group of women and all the secrets they keep. *Homeland* is about a CIA agent with mental health challenges.\n",
    "\n",
    "There are also shows with lots of episodes like *How I Met Your Mother*, which is about a group of friends. *Loki* from the Marvel movies has his own show. *Lost* is about people trapped on a strange island.  *Mrs. America* tells the true story of the fight for women's rights. *The Muppet Show* is a classic with puppets! *NYPD Blue* is about police officers in New York City.  *One Mississippi* is a sad but funny show about a woman who goes home to take care of her sick mom.  *Only Murders in the Building* is about three friends who investigate a murder. *The People v. O.J. Simpson* tells the story of a famous trial. *Pose* shows the lives of drag queens in the 1980s.  There are so many shows to watch on Disney+!\n",
    "\n",
    "\n",
    "Curtis Sittenfeld's new book, *Romantic Comedy*, is about Sally, a writer for a comedy show like *Saturday Night Live*.  Sally makes fun of how average-looking guys often date beautiful women. She writes a joke skit about it called \"The Danny Horst Rule\". Then Sally meets a handsome pop star named Noah, and she starts to like him.  But Sally doesn't think Noah could ever like her back.  The book is about whether they'll end up together. Sally is a feminist who wants to write romantic comedies that are smart and funny. She and Noah bond over their work, but Sally hides her true feelings.  She's afraid to be vulnerable because a coworker once hurt her feelings. The book also shows what it's like to work at a comedy show.\n",
    "    \"\"\"\n",
    "    Language=\"Chineese\"\n",
    "    #text='How are you?'\n",
    "    \n",
    "    persona_text=\"\"\n",
    "    if action_type==\"Summary_Persona\" and persona==\"\":\n",
    "        return \"Error- Please set the persona\"    \n",
    "    else:\n",
    "         persona_text=f\" so that a {persona} can understand it. Use simple words and short sentences\"\n",
    "    \n",
    "    platform=\"Twitter\" # could be Twitter, Instagram or \"\" if OffPlatformPost is not selected\n",
    "    if action_type==\"OffPlatformPost\" and platform==\"\":\n",
    "         return \"Error- Please set the platform\"\n",
    "        \n",
    "    if action_type==\"Translation\" and (text==\"\" or Language==\"\"):\n",
    "        return \"Error- Please set the input text to translate and destination language\"\n",
    "        \n",
    "  \n",
    "    #get summary\n",
    "    if action_type!=\"Translation\":\n",
    "        if action_type==\"OffPlatformPost\":\n",
    "            result=\"Instagram Post:\\n\"+get_summary(assets =assets,action_type=action_type,platform='Instagram',\n",
    "                           persona_text=persona_text,project_id=project_id,context_window_limit=context_window_limit)\n",
    "\n",
    "            \n",
    "            result=result+\"\\nTwitter Post:\\n\"+get_summary(assets =assets,action_type=action_type,platform='Twitter',\n",
    "                           persona_text=persona_text,project_id=project_id,context_window_limit=context_window_limit)\n",
    "           \n",
    "        else:\n",
    "            result=get_summary(assets =assets,action_type=action_type,platform=\"\",\n",
    "                           persona_text=persona_text,project_id=project_id,context_window_limit=context_window_limit)\n",
    "    else:\n",
    "        result=get_translation(action_type=action_type,input_text=text,Language=Language )\n",
    "        \n",
    "      \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "34736324-932f-4aec-953a-3f4d1e16e44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************\n",
      "Translate the following text into Chineese.  Make sure to preserve the meaning, tone, and style of the original text, while ensuring it is natural and fluent in Chineese.\n",
      "            Text:\n",
      " \n",
      "              \n",
      "    Disney+ has lots of cool shows!  There are funny shows like *Abbott Elementary*, which is about teachers at a school in Philadelphia.  There's also *The Americans*, a show about Russian spies pretending to be a regular family.  *Andor* is like *Star Wars* but for grown-ups.  *Arrested Development* is a hilarious show about a crazy family. *Atlanta* is about two cousins, one a rapper and the other his manager, and what it's like to be Black in America. *The Bear* is about a fancy chef who takes over his family's sandwich shop.  *Bob's Burgers* is a cartoon about a family who runs a burger restaurant. And for something really fun, there's *Buffy the Vampire Slayer*, about a girl who fights vampires! *Desperate Housewives* is about a group of women and all the secrets they keep. *Homeland* is about a CIA agent with mental health challenges.\n",
      "\n",
      "There are also shows with lots of episodes like *How I Met Your Mother*, which is about a group of friends. *Loki* from the Marvel movies has his own show. *Lost* is about people trapped on a strange island.  *Mrs. America* tells the true story of the fight for women's rights. *The Muppet Show* is a classic with puppets! *NYPD Blue* is about police officers in New York City.  *One Mississippi* is a sad but funny show about a woman who goes home to take care of her sick mom.  *Only Murders in the Building* is about three friends who investigate a murder. *The People v. O.J. Simpson* tells the story of a famous trial. *Pose* shows the lives of drag queens in the 1980s.  There are so many shows to watch on Disney+!\n",
      "\n",
      "\n",
      "Curtis Sittenfeld's new book, *Romantic Comedy*, is about Sally, a writer for a comedy show like *Saturday Night Live*.  Sally makes fun of how average-looking guys often date beautiful women. She writes a joke skit about it called \"The Danny Horst Rule\". Then Sally meets a handsome pop star named Noah, and she starts to like him.  But Sally doesn't think Noah could ever like her back.  The book is about whether they'll end up together. Sally is a feminist who wants to write romantic comedies that are smart and funny. She and Noah bond over their work, but Sally hides her true feelings.  She's afraid to be vulnerable because a coworker once hurt her feelings. The book also shows what it's like to work at a comedy show.\n",
      "    \n",
      "\n",
      "            Only provide a single response.\n",
      "            \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Disney+ 上的精彩节目可真多！喜欢喜剧的话，有像《小学风云 (Abbott Elementary)》这样的剧集，讲述的是费城一所学校的老师们的故事。还有《美国谍梦 (The Americans)》，讲的是一对伪装成普通家庭的俄罗斯间谍。喜欢《星球大战》？那《安多 (Andor)》是面向成人的星战剧集。《发展受阻 (Arrested Development)》则讲述了一个疯狂家庭的爆笑故事。《亚特兰大 (Atlanta)》聚焦于一对表兄弟，一个是说唱歌手，另一个是他的经纪人，展现了美国黑人的生活。《大熊餐厅 (The Bear)》讲述了一位高级厨师接手家族三明治店的故事。《开心汉堡店 (Bob's Burgers)》是一部关于经营汉堡餐厅的家庭的动画片。想要更有趣的？那就来看《吸血鬼猎人巴菲 (Buffy the Vampire Slayer)》吧，讲述了一个女孩对抗吸血鬼的故事！《绝望的主妇 (Desperate Housewives)》围绕一群女人和她们保守的秘密展开。《国土安全 (Homeland)》则讲述了一位患有精神疾病的中央情报局特工的故事。\\n\\nDisney+ 也有许多长篇剧集，例如讲述一群朋友故事的《老爸老妈浪漫史 (How I Met Your Mother)》。漫威电影中的洛基 (Loki) 也有了自己的独立剧集。《迷失 (Lost)》讲述了一群人被困在一个神秘岛屿上的故事。《美国夫人 (Mrs. America)》讲述了为争取女性权利而奋斗的真实故事。《布偶秀 (The Muppet Show)》是经典的木偶剧！《纽约重案组 (NYPD Blue)》讲述了纽约市警察的故事。《密西西比轶事 (One Mississippi)》是一个悲伤又有趣的剧集，讲述了一个女人回家照顾生病母亲的故事。《公寓楼里的谋杀案 (Only Murders in the Building)》讲述了三个朋友调查谋杀案的故事。《辛普森杀妻案 (The People v. O.J. Simpson)》讲述了一个著名的审判故事。《姿态 (Pose)》展现了20世纪80年代变装皇后们的生活。Disney+ 上的节目真是应有尽有！\\n\\n\\n柯蒂斯·希滕菲尔德的新书《浪漫喜剧 (Romantic Comedy)》讲述了莎莉的故事，她是类似《周六夜现场 (Saturday Night Live)》的喜剧节目的编剧。莎莉经常拿长相普通的男人和美女约会这件事开玩笑，她还为此写了一个名为“丹尼·霍斯特法则”的搞笑短剧。后来，莎莉遇到了一位名叫诺亚的英俊流行歌星，并开始喜欢上他。但莎莉认为诺亚不可能喜欢她。这本书讲述了他们最终是否会在一起的故事。莎莉是一位女权主义者，她想创作既聪明又有趣的浪漫喜剧。她和诺亚因为工作而建立了联系，但莎莉隐藏了她的真实感受。她害怕变得脆弱，因为一位同事曾经伤害过她的感情。这本书也展现了在喜剧节目工作的幕后故事。\\n\""
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary=func_generate_content('')\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "5daaca38-331e-4203-9e09-b27b502106d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "دیزنی‌پلاس کلی سریال جذاب داره! سریال‌های طنز مثل «مدرسه ابتدایی ابوت» (Abbott Elementary) که درباره معلم‌های یه مدرسه تو فیلادلفیاست.  سریال «آمریکایی‌ها» (The Americans) هم هست که درباره جاسوس‌های روسی‌ایه که وانمود می‌کنن یه خانواده معمولی هستن. «آندور» (Andor) مثل «جنگ ستارگان» می‌مونه ولی برای بزرگسال‌ها ساخته شده. «دستگیری توسعه» (Arrested Development) یه سریال خیلی خنده‌دار درباره یه خانواده دیوونه‌ست. «آتلانتا» (Atlanta) درباره دو پسرعمو هست، یکی رپر و اون یکی مدیر برنامه‌هاش، و نشون می‌ده که سیاه‌پوست بودن تو آمریکا چه معنی‌ای داره. «خرس» (The Bear) درباره یه سرآشپز حرفه‌ای هست که ساندویچ‌فروشی خانوادگی‌شون رو به عهده می‌گیره. «باب برگرها» (Bob's Burgers) یه کارتون درباره یه خانواده‌ست که یه برگر فروشی دارن. و برای یه چیز خیلی سرگرم‌کننده، «بافی، قاتل خون‌آشام‌ها» (Buffy the Vampire Slayer) هست، درباره یه دختری که با خون‌آشام‌ها می‌جنگه! «زنان خانه‌دار ناامید» (Desperate Housewives) درباره یه گروه از زن‌ها و همه رازهایی هست که دارن. «میهن» (Homeland) درباره یه مأمور سیا با مشکلات روحی و روانی هست.\n",
      "\n",
      "همچنین سریال‌هایی با کلی قسمت مثل «چطور با مادرتون آشنا شدم» (How I Met Your Mother) که درباره یه گروه از دوست‌هاست. «لوکی» (Loki) از فیلم‌های مارول سریال خودش رو داره. «گمشدگان» (Lost) درباره آدم‌هایی هست که تو یه جزیره عجیب گیر افتادن. «خانم آمریکا» (Mrs. America) داستان واقعی مبارزه برای حقوق زنان رو روایت می‌کنه. «نمایش ماپت‌ها» (The Muppet Show) یه سریال کلاسیک با عروسک‌هاست! «نیویورک آبی» (NYPD Blue) درباره افسرهای پلیس تو شهر نیویورکه. «یک می‌سی‌سی‌پی» (One Mississippi) یه سریال غمگین ولی خنده‌دار درباره یه زنی هست که برای مراقبت از مادرش که بیمار هست به خونه برمی‌گرده. «فقط قتل‌های داخل ساختمان» (Only Murders in the Building) درباره سه دوست هست که یه قتل رو بررسی می‌کنن. «مردم علیه او. جی. سیمپسون» (The People v. O.J. Simpson) داستان یه دادگاه معروف رو تعریف می‌کنه. «ژست» (Pose) زندگی درگ کوئین‌ها (drag queens) رو تو دهه ۱۹۸۰ نشون می‌ده. کلی سریال برای تماشا تو دیزنی‌پلاس هست!\n",
      "\n",
      "\n",
      "کتاب جدید کورتیس سیتنفیلد، «کمدی رمانتیک» (Romantic Comedy)، درباره سالی هست، یه نویسنده برای یه برنامه کمدی مثل «پخش زنده شنبه شب» (Saturday Night Live). سالی مردهایی رو که قیافه معمولی دارن و اغلب با زن‌های زیبا قرار می‌ذارن، مسخره می‌کنه. اون یه طرح طنز درباره این موضوع می‌نویسه به اسم «قانون دنی هورست». بعد سالی با یه ستاره پاپ خوش‌قیافه به اسم نوح آشنا می‌شه و ازش خوشش میاد. اما سالی فکر نمی‌کنه که نوح بتونه از اون خوشش بیاد. کتاب درباره اینه که آیا اونا در نهایت با همدیگه خواهند بود یا نه. سالی یه فمینیست هست که می‌خواد کمدی‌های رمانتیکی بنویسه که هوشمندانه و خنده‌دار باشن. اون و نوح سر کارشون با هم صمیمی می‌شن، اما سالی احساسات واقعیش رو پنهان می‌کنه. اون از آسیب‌پذیر بودن می‌ترسه چون یه همکار قبلاً احساساتش رو جریحه‌دار کرده. کتاب همچنین نشون می‌ده که کار کردن تو یه برنامه کمدی چه جوریه.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "43d2f1c6-7d5d-490a-ad6c-b82226747c97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'حال شما چطور است؟ (haal-e shoma chetor ast?)\\n'"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part, SafetySetting\n",
    " \n",
    " \n",
    "def generate():\n",
    "    vertexai.init(project=\"nine-quality-test\", location=\"us-central1\")\n",
    "    model = GenerativeModel(\n",
    "        \"gemini-1.5-pro-002\",\n",
    "    )\n",
    "    responses = model.generate_content(\n",
    "        [text1],\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings,\n",
    "        stream=True,\n",
    "    )\n",
    "    result=\"\"\n",
    "    for response in responses:\n",
    "        result=result+response.text\n",
    "    return result\n",
    " \n",
    "text1 = \"\"\"Translate the following text into Persian. Make sure to preserve the meaning, tone, and style of the original text, while ensuring it is natural and fluent in Persian.\n",
    "Text:how are you\n",
    " \n",
    "Only provide a single response\"\"\"\n",
    " \n",
    "generation_config = {\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"temperature\": 1,\n",
    "    \"top_p\": 0.95,\n",
    "}\n",
    " \n",
    "safety_settings = [\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "]\n",
    " \n",
    "r=generate()\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "46c35f1e-a804-4de8-b99e-f0f6bb539d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************\n",
      "Translate the following text into Persian.  Make sure to preserve the meaning, tone, and style of the original text, while ensuring it is natural and fluent in Persian.\n",
      "            Text:\n",
      " \n",
      "              how are you\n",
      "\n",
      "            Only provide a single response.\n",
      "            \n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"\\330\\255\\330\\247\\331\\204 \\330\\264\\331\\205\\330\\247 \\332\\206\\330\\267\\331\\210\\330\\261 \\330\\247\\330\\263\\330\\252\\330\\237\\n\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.13206623494625092\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.11757202446460724\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.01590641401708126\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.06097523868083954\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.05340331420302391\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.08882041275501251\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.05582325905561447\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.10970578342676163\n",
      "  }\n",
      "  avg_logprobs: -0.06424553053719657\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 55\n",
      "  candidates_token_count: 7\n",
      "  total_token_count: 62\n",
      "}\n",
      "model_version: \"gemini-1.5-pro-002\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result=get_translation(action_type='Translation',input_text=\"how are you\",Language='Persian' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "413c2b7e-a9d6-4788-a527-5f7651dcce76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidates {\n",
       "  content {\n",
       "    role: \"model\"\n",
       "    parts {\n",
       "      text: \"The most common and natural way to say \\\"how are you\\\" in Persian is:\\n\\n**\\330\\255\\330\\247\\331\\204\\330\\252 \\332\\206\\330\\267\\331\\210\\330\\261\\331\\207\\330\\237** (Haalet chetore?) -  Informal, similar to \\\"How\\'s it going?\\\"\\n\\nOther options, depending on the level of formality and the region, include:\\n\\n* **\\330\\255\\330\\247\\331\\204 \\330\\264\\331\\205\\330\\247 \\332\\206\\330\\267\\331\\210\\330\\261 \\330\\247\\330\\263\\330\\252\\330\\237** (Haale shoma chetor ast?) - Formal\\n* **\\332\\206\\330\\267\\331\\210\\330\\261\\333\\214\\330\\237** (Chetori?) - Very informal, like \\\"What\\'s up?\\\"\\n* **\\330\\256\\331\\210\\330\\250\\333\\214\\330\\237** (Khoobi?) - Literally \\\"Are you good?\\\", informal\\n\\n\\nSo, depending on the context you want to convey, choose the most appropriate option.  For a simple \\\"how are you,\\\"  **\\330\\255\\330\\247\\331\\204\\330\\252 \\332\\206\\330\\267\\331\\210\\330\\261\\331\\207\\330\\237** is a good choice.\\n\"\n",
       "    }\n",
       "  }\n",
       "  finish_reason: STOP\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HATE_SPEECH\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.07807836681604385\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.05834592133760452\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.013636830262839794\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.05184546485543251\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HARASSMENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.05582325905561447\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.03410044312477112\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.04084572568535805\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.04603387415409088\n",
       "  }\n",
       "  avg_logprobs: -0.08926623700612998\n",
       "}\n",
       "usage_metadata {\n",
       "  prompt_token_count: 47\n",
       "  candidates_token_count: 166\n",
       "  total_token_count: 213\n",
       "}\n",
       "model_version: \"gemini-1.5-pro-002\""
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8ad8d0fa-8ddf-41f9-9256-4f7ea37fef33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disney+ offers a diverse range of adult programming, from comedies like *Abbott Elementary*, *Arrested Development*, and *Bob's Burgers* to adventures like *How I Met Your Mother* and *The Muppet Show*.  For more intense viewing, the platform boasts thrillers such as *The Americans*, *Andor*, and *Buffy the Vampire Slayer*,  mysteries like *Lost* and *Only Murders in the Building*, and suspenseful dramas like *Homeland*.  Disney+ also delves into real-world issues with shows like *Mrs. America*, *The People v. O.J. Simpson*, and *Pose*. While the platform offers lighter fare like the novel-based show \"Romantic Comedy,\" exploring relationships and the entertainment industry,  it's worth noting that the realities of that industry, particularly regarding toxic work environments and abusive power dynamics, are explored in Maureen Ryan's book \"Burn It Down,\" which exposes systemic issues behind the scenes of shows like *Lost* and even *Saturday Night Live*, highlighting a stark contrast to the romanticized version often portrayed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd70c31-5ea8-4531-aa37-7c0744a1162b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
