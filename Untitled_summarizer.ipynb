{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "026458de-69fd-44c8-8da1-8086a0214a23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from langchain_google_community import BigQueryLoader\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "#from langchain.llms import VertexAI as langchain_vertexai\n",
    "from langchain_google_vertexai import VertexAI as langchain_vertexai\n",
    "from langchain import PromptTemplate\n",
    "from pathlib import Path as p\n",
    "import pandas as pd\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n",
    "\n",
    "\n",
    "vertex_llm_text = langchain_vertexai(model_name=\"gemini-1.5-pro-002\")\n",
    "generative_multimodal_model= GenerativeModel(\"gemini-1.5-pro-002\")\n",
    "\n",
    "\n",
    "def estimate_token_length(text, model=\"gpt2\"):\n",
    "    \"\"\"Estimates the token length of a given text using a specified model.\n",
    "\n",
    "      Args:\n",
    "        text: The input text.\n",
    "        model: The model to use for tokenization (default: \"gpt2\").\n",
    "\n",
    "      Returns:\n",
    "        The estimated number of tokens.\n",
    "      \"\"\"\n",
    "\n",
    "  \n",
    "    enc = tiktoken.get_encoding(model)  \n",
    "\n",
    "    # Tokenize the text and count tokens\n",
    "    tokens = enc.encode(text)\n",
    "    token_count = len(tokens)\n",
    "    return token_count\n",
    "\n",
    "def get_data(source_query_str: str=None,metadata_columns: str=None,page_content_columns: str=None, project_id: str=None , return_text: bool=True):\n",
    "    \n",
    "    \"\"\"Load data from big query\n",
    "\n",
    "      Args:\n",
    "        str source_query_str:  The query string to fetch the data from bigquery\n",
    "        list[str] metadata_columns:  list of metadata column names\n",
    "        list[str] page_content_columns:  list of content column names  \n",
    "        str project_id: project id\n",
    "        bool return_text: returns the content columns description\n",
    "      Returns:\n",
    "          list[langchain_core.documents.base.Document] documents: langchain documents\n",
    "          \n",
    "      \"\"\"\n",
    "    \n",
    "    loader = BigQueryLoader(\n",
    "            query=source_query_str, project=project_id, metadata_columns=metadata_columns, page_content_columns=page_content_columns\n",
    "        )\n",
    "    documents = []\n",
    "    all_texts=[]\n",
    "    documents.extend(loader.load())\n",
    "    if return_text:  \n",
    "         all_texts=[doc.page_content.replace('description:',\"\",1) for doc in documents]\n",
    "        \n",
    "    return documents, '\\n'.join(all_texts)\n",
    "    \n",
    " \n",
    "def summarize_docs(documents: list[object],question_prompt_template: str=\"\", refine_prompt_template: str=\"\" ,is_token_limit_exceeded: bool=False ):\n",
    "    \n",
    "    \"\"\"summarizes the input documents\n",
    "\n",
    "      Args:\n",
    "        list[object] documents:  list of langchain documents\n",
    "        str question_prompt_template:  string question prompt template. \n",
    "        str refine_prompt_template:  string refine prompt template in the case that we need to use refine method\n",
    "        bool is_token_limit_exceeded:  boolean indicating wheather or not the token limit is exceeded.\n",
    "      Returns:\n",
    "         dict : summary result\n",
    "         \n",
    "      \"\"\"\n",
    "       \n",
    "    question_prompt = PromptTemplate(template=question_prompt_template, input_variables=[\"text\"]) \n",
    "    \n",
    "    if not is_token_limit_exceeded:        \n",
    "        #if the token limit is in the context window range, use a stuffing method for summary\n",
    "        chain = load_summarize_chain(vertex_llm_text, chain_type=\"stuff\", \n",
    "                                     prompt=question_prompt)\n",
    "        \n",
    "    else:     \n",
    "        #otherwise use a refine summarization method\n",
    "        refine_prompt = PromptTemplate(input_variables=[\"existing_answer\", \"text\"], template=refine_prompt_template)\n",
    "              \n",
    "        chain = load_summarize_chain(\n",
    "            vertex_llm_text,\n",
    "            chain_type=\"refine\",\n",
    "            question_prompt=question_prompt,\n",
    "            refine_prompt=refine_prompt,\n",
    "            return_intermediate_steps=True,\n",
    "          )\n",
    "        \n",
    "    return chain.invoke(documents)\n",
    "\n",
    "def  get_query_string (assets: str=\"\"):\n",
    "    \"\"\"set query string \n",
    "      Args:         \n",
    "        str assets:  comma separated string of all requested assets     \n",
    "      Returns:\n",
    "         str source_query_str : string query for loading data from biquery\n",
    "         \n",
    "      \"\"\"\n",
    "     #source_query_str=f\"select distinct combined_id,unique_id,content, chunk, trim(concat(ifnull(headline,''), CHR(10),  description)) as description from `nine-quality-test.vlt_media_embeddings_integration.vlt_all_media_content_text_embeddings` where asset_id in {assets} order by unique_id, chunk asc \"\n",
    "    source_query_str= f\"\"\"SELECT          asset_id,                  \n",
    "                    STRING_AGG(description, '\\\\n' ) \n",
    "                    OVER (PARTITION BY asset_id ORDER BY ifnull(startOffset_seconds,0) ASC , chunk ASC) AS full_description,\n",
    "                    IDX\n",
    "              FROM (\n",
    "                    SELECT  asset_id,startOffset_seconds, CHUNK, \n",
    "                    CASE WHEN chunk=0 \n",
    "                         THEN TRIM(CONCAT(IFNULL(headline,''), CHR(10),  description))  \n",
    "                         ELSE description \n",
    "                    END AS description,\n",
    "                    ROW_NUMBER() OVER (PARTITION BY asset_id ORDER BY startOffset_seconds desc) AS IDX,\n",
    "                    FROM `vlt_media_embeddings_integration.vlt_all_media_content_text_embeddings` where asset_id in ({assets})\n",
    "             )\n",
    "           WHERE IDX=1\n",
    "        \"\"\"\n",
    "    return source_query_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "c848aa6f-839e-440b-9927-0e67ae92e070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def  get_query_string (assets: str=\"\"):\n",
    "    \"\"\"set query string \n",
    "      Args:         \n",
    "        str assets:  comma separated string of all requested assets     \n",
    "      Returns:\n",
    "         str source_query_str : string query for loading data from biquery\n",
    "         \n",
    "      \"\"\"\n",
    "     #source_query_str=f\"select distinct combined_id,unique_id,content, chunk, trim(concat(ifnull(headline,''), CHR(10),  description)) as description from `nine-quality-test.vlt_media_embeddings_integration.vlt_all_media_content_text_embeddings` where asset_id in {assets} order by unique_id, chunk asc \"\n",
    "    source_query_str= f\"\"\"SELECT          asset_id,                  \n",
    "                    STRING_AGG(description, '\\\\n' ) \n",
    "                    OVER (PARTITION BY asset_id ORDER BY ifnull(startOffset_seconds,0) ASC , chunk ASC) AS full_description,\n",
    "                    IDX\n",
    "              FROM (\n",
    "                    SELECT  asset_id,startOffset_seconds, CHUNK, \n",
    "                    CASE WHEN chunk=0 \n",
    "                         THEN TRIM(CONCAT(IFNULL(headline,''), CHR(10),  description))  \n",
    "                         ELSE description \n",
    "                    END AS description,\n",
    "                    ROW_NUMBER() OVER (PARTITION BY asset_id ORDER BY startOffset_seconds desc) AS IDX,\n",
    "                    FROM `vlt_media_embeddings_integration.vlt_all_media_content_text_embeddings` where asset_id in ({assets})\n",
    "             )\n",
    "           WHERE IDX=1\n",
    "        \"\"\"\n",
    "    return source_query_str\n",
    "    \n",
    "def get_prompt(action_type: str=\"\",platform: str=\"\",persona_text: str=\"\", input_text:str=\"\", Language:str=\"\"):\n",
    "    \n",
    "    \"\"\"set prompt according to the requested action\n",
    "      Args:         \n",
    "        str action_type:  the type of action needs to be done\n",
    "        str platform: platform name for off platform posts \n",
    "        str persona_text: for persona based summaries \n",
    "      Returns:\n",
    "         str question_prompt_template : the main prompt for the given action \n",
    "         str refine_prompt_template:  the second level prompt for refinement, in the case that the context is too long, we have to use refinement method.\n",
    "         \n",
    "      \"\"\"\n",
    " \n",
    "    question_prompt_template=\"\"\n",
    "    refine_prompt_template=\"\"\n",
    "    \n",
    "    if action_type==\"Summary\" or action_type==\"Summary_Persona\":\n",
    "            #this is the main prompt for summary\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide a summary of the following text\"\"\"+persona_text+\"\"\". Your result must be detailed and at least 2 paragraphs. \n",
    "                When summarizing, directly dive into the narrative or descriptions from the text without using introductory phrases like 'In this passage'. \n",
    "                Directly address the main events, characters, and themes, encapsulating the essence and significant details from the text in a flowing narrative. \n",
    "                The goal is to present a unified view of the content, continuing the story seamlessly as if the passage naturally progresses into the summary.\n",
    "\n",
    "                TEXT: {text}\n",
    "                SUMMARY:\n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final summary. Your task is to combine and refine these summaries into a final, comprehensive summary that covers all key events, characters, themes, and details.\\n\"\n",
    "                \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing summary\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original summary\"\n",
    "                \"If the context isn't useful, return the original summary.\"\n",
    "            )\n",
    "    elif action_type==\"HeadLine\":  \n",
    "\n",
    "        #this is the main prompt for headline\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide a one line headline of the following text. \n",
    "\n",
    "                TEXT: {text}\n",
    "                HEADLINE:\n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final headline. Your task is to combine and refine these headlines into a final, comprehensive headline that covers all details.\\n\"\n",
    "                \"We have provided an existing headline up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing headline\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original headline\"\n",
    "                \"If the context isn't useful, return the original headline.\"\n",
    "            )\n",
    "    elif action_type==\"OffPlatformPost\"  and platform=='Twitter':\n",
    "               #this is the main prompt for social media post\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide a tweet that that’s catchy, concise, and fits within 280 characters. Make sure to highlight the key message, and encourage engagement with a question or call to action.\n",
    "\n",
    "                TEXT: {text}\n",
    "                Tweet: \n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final tweet. Your task is to combine and refine these tweets into a final, comprehensive tweet that covers all details, is catchy, concise, fits within 280 characters, and encourage engagement with a question or call to action.\\n\"\n",
    "                \"We have provided an existing tweet up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing tweet\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original tweet\"\n",
    "                \"If the context isn't useful, return the original tweet.\"\n",
    "            )\n",
    "    elif action_type==\"OffPlatformPost\" and platform=='Instagram':         \n",
    "            #this is the main prompt for social media post\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide  into an engaging Instagram post. Craft a short, attention-grabbing caption that highlights the main point. Use emojis to make it lively, and end with a question or call to action to spark conversation in the comments.\n",
    "\n",
    "                TEXT: {text}\n",
    "                Instagram Post: \n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final tweet. Your task is to combine and refine these Instagram posts into a final, comprehensive post that covers all details, crafts a short, attention-grabbing caption that highlights the main point. Use emojis to make it lively, and end with a question or call to action to spark conversation in the comments.\\n\"\n",
    "                \"We have provided an existing post up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing post\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original post\"\n",
    "                \"If the context isn't useful, return the original post.\"\n",
    "            )\n",
    "    elif action_type==\"Translation\":\n",
    "            print('******************')\n",
    "            #this is the main prompt for social media post\n",
    "            question_prompt_template = f\"\"\"Translate the following text into {Language}.  Make sure to preserve the meaning, tone, and style of the original text, while ensuring it is natural and fluent in {Language}.\n",
    "            Text:\\n \n",
    "              {input_text}\\n\n",
    "            Only provide a single response.\n",
    "            \"\"\"\n",
    "      \n",
    "            \n",
    "    return question_prompt_template,refine_prompt_template\n",
    "\n",
    "def get_summary(assets:str=\"\",action_type:str=\"\",platform:str=\"\",persona_text:str=\"\",project_id:str=\"\",context_window_limit: int=2000000):\n",
    "    \n",
    "    \"\"\"get summary according to the action type requested\n",
    "      Args:         \n",
    "        str assets:  comma separate string including all assets\n",
    "        str action_type: requested action\n",
    "        str persona_text: for persona based summaries \n",
    "        str platform: for off platform based posts\n",
    "        str project_id: project id\n",
    "        int context_window_limit: context window limit for the llm model\n",
    "      Returns:\n",
    "         str :output summary \n",
    "      \"\"\"\n",
    "    \n",
    "    #set query string\n",
    "    source_query_str= get_query_string(assets)\n",
    "    \n",
    "    #set prompts\n",
    "    question_prompt_template, refine_prompt_template=get_prompt(action_type=action_type,platform=platform,persona_text=persona_text)\n",
    "    \n",
    "    #set metadata and content columns\n",
    "    metadata_columns=[\"asset_id\"]\n",
    "    page_content_columns=[\"full_description\"]\n",
    "    \n",
    "    #load data from biqquery\n",
    "    documents,all_texts=get_data(source_query_str=source_query_str,metadata_columns=metadata_columns,page_content_columns=page_content_columns, project_id=project_id,return_text=True)\n",
    "\n",
    "    # Estimate the token length\n",
    "    estimated_token_length = estimate_token_length(all_texts,'cl100k_base') #cl100k_base\n",
    "    \n",
    "    message=\"\"\n",
    "    is_token_limit_exceeded=False\n",
    "    if estimated_token_length > context_window_limit:\n",
    "      message=\"Your text is too long for the Gemini 1.5 Pro context window. We are trying to chunk and return the result.\"\n",
    "      is_token_limit_exceeded=True\n",
    "      summary=summarize_docs(documents=documents,question_prompt_template=question_prompt_template,refine_prompt_template=refine_prompt_template,is_token_limit_exceeded=is_token_limit_exceeded )\n",
    "\n",
    "    else:\n",
    "      message=\"Your text fits within the Gemini 1.5 Pro context window.\"\n",
    "      summary=summarize_docs(documents=documents,question_prompt_template=question_prompt_template,is_token_limit_exceeded=is_token_limit_exceeded )\n",
    "        \n",
    "    return summary[\"output_text\"]\n",
    "\n",
    "def get_translation(action_type: str=\"\",input_text: str=\"\",Language:str=\"\"):\n",
    "    \n",
    "    \"\"\" get translation according to the requested language\n",
    "      Args:         \n",
    "        str input_text:  text to be translated\n",
    "        str Language: destination language\n",
    "      \n",
    "      Returns:\n",
    "         str : translated document \n",
    "      \"\"\"\n",
    " \n",
    "    \n",
    "    #set prompts\n",
    "    question_prompt_template, _=get_prompt(action_type=action_type,input_text=input_text,Language=Language)\n",
    "     \n",
    "    generation_config= GenerationConfig(temperature=1, max_output_tokens=8192) \n",
    "    safety_settings=  {\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        }\n",
    "\n",
    "    model_input=[question_prompt_template]\n",
    "        \n",
    "    response = generative_multimodal_model.generate_content(\n",
    "        model_input,\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings, \n",
    "        \n",
    "    )\n",
    "    \n",
    "    result=\"\"\n",
    "    try:\n",
    "        result=response.text\n",
    "    except:\n",
    "        result=\"No translation can be provided.\"\n",
    "        \n",
    " \n",
    "    return result\n",
    " \n",
    "        \n",
    "def func_generate_content(request):\n",
    "    \n",
    "    # Set the Gemini 1.5 Pro context window limit\n",
    "    context_window_limit = 2000000\n",
    "    project_id = \"nine-quality-test\"  # @param {type:\"string\"}\n",
    "    REGION = \"us-central1\"  # @param {type:\"string\"}\n",
    "    assets=\"p5d2tw,p5e9zq,p5e49l\" #comma separated asset_ids  \n",
    "    \n",
    "    assets= ','.join([ \"'\"+ id.strip()+\"'\" for id in assets.split(',')])\n",
    "    action_type=\"Translation\" # could be Summary, Summary_Persona, HeadLine, OffPlatformPost, Translation\n",
    "    persona=\"10-year-old\"\n",
    "    text=\"\"\"\n",
    "    Disney+ has lots of cool shows!  There are funny shows like *Abbott Elementary*, which is about teachers at a school in Philadelphia.  There's also *The Americans*, a show about Russian spies pretending to be a regular family.  *Andor* is like *Star Wars* but for grown-ups.  *Arrested Development* is a hilarious show about a crazy family. *Atlanta* is about two cousins, one a rapper and the other his manager, and what it's like to be Black in America. *The Bear* is about a fancy chef who takes over his family's sandwich shop.  *Bob's Burgers* is a cartoon about a family who runs a burger restaurant. And for something really fun, there's *Buffy the Vampire Slayer*, about a girl who fights vampires! *Desperate Housewives* is about a group of women and all the secrets they keep. *Homeland* is about a CIA agent with mental health challenges.\n",
    "\n",
    "There are also shows with lots of episodes like *How I Met Your Mother*, which is about a group of friends. *Loki* from the Marvel movies has his own show. *Lost* is about people trapped on a strange island.  *Mrs. America* tells the true story of the fight for women's rights. *The Muppet Show* is a classic with puppets! *NYPD Blue* is about police officers in New York City.  *One Mississippi* is a sad but funny show about a woman who goes home to take care of her sick mom.  *Only Murders in the Building* is about three friends who investigate a murder. *The People v. O.J. Simpson* tells the story of a famous trial. *Pose* shows the lives of drag queens in the 1980s.  There are so many shows to watch on Disney+!\n",
    "\n",
    "\n",
    "Curtis Sittenfeld's new book, *Romantic Comedy*, is about Sally, a writer for a comedy show like *Saturday Night Live*.  Sally makes fun of how average-looking guys often date beautiful women. She writes a joke skit about it called \"The Danny Horst Rule\". Then Sally meets a handsome pop star named Noah, and she starts to like him.  But Sally doesn't think Noah could ever like her back.  The book is about whether they'll end up together. Sally is a feminist who wants to write romantic comedies that are smart and funny. She and Noah bond over their work, but Sally hides her true feelings.  She's afraid to be vulnerable because a coworker once hurt her feelings. The book also shows what it's like to work at a comedy show.\n",
    "    \"\"\"\n",
    "    Language=\"Persian\"\n",
    "    #text='How are you?'\n",
    "    \n",
    "    persona_text=\"\"\n",
    "    if action_type==\"Summary_Persona\" and persona==\"\":\n",
    "        return \"Error- Please set the persona\"    \n",
    "    else:\n",
    "         persona_text=f\" so that a {persona} can understand it. Use simple words and short sentences\"\n",
    "    \n",
    "    platform=\"Twitter\" # could be Twitter, Instagram or \"\" if OffPlatformPost is not selected\n",
    "    if action_type==\"OffPlatformPost\" and platform==\"\":\n",
    "         return \"Error- Please set the platform\"\n",
    "        \n",
    "    if action_type==\"Translation\" and (text==\"\" or Language==\"\"):\n",
    "        return \"Error- Please set the input text to translate and destination language\"\n",
    "        \n",
    "  \n",
    "    #get summary\n",
    "    if action_type!=\"Translation\":\n",
    "        if action_type==\"OffPlatformPost\":\n",
    "            result=\"Instagram Post:\\n\"+get_summary(assets =assets,action_type=action_type,platform='Instagram',\n",
    "                           persona_text=persona_text,project_id=project_id,context_window_limit=context_window_limit)\n",
    "\n",
    "            \n",
    "            result=result+\"\\nTwitter Post:\\n\"+get_summary(assets =assets,action_type=action_type,platform='Twitter',\n",
    "                           persona_text=persona_text,project_id=project_id,context_window_limit=context_window_limit)\n",
    "           \n",
    "        else:\n",
    "            result=get_summary(assets =assets,action_type=action_type,platform=\"\",\n",
    "                           persona_text=persona_text,project_id=project_id,context_window_limit=context_window_limit)\n",
    "    else:\n",
    "        result=get_translation(action_type=action_type,input_text=text,Language=Language )\n",
    "        \n",
    "      \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "34736324-932f-4aec-953a-3f4d1e16e44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************\n",
      "دیزنی‌پلاس کلی سریال جذاب داره! سریال‌های خحالی مثل *Abbott Elementary* که درباره معلم‌های یه مدرسه تو فیلادلفیاست.  *The Americans* هم هست، سریالی درباره جاسوس‌های روسی که وانمود می‌کنن یه خانواده معمولی هستن. *Andor* مثل *Star Wars* می‌مونه اما برای بزرگسال‌ها. *Arrested Development* یه سریال خیلی خنده‌دار درباره یه خانواده دیوونه‌ست. *Atlanta* درباره دو پسرعمو هست، یکی رپر و اون یکی مدیربرنامه‌هاش، و نشون می‌ده که سیاه‌پوست بودن تو آمریکا چه معنی‌ای داره.  *The Bear* درباره یه سرآشپز درجه یکه که ساندویچ‌فروشی خانوادگی‌شون رو به عهده می‌گیره. *Bob's Burgers* یه کارتون درباره یه خانواده‌ست که یه رستوران همبرگر دارن. و برای یه چیز خیلی سرگرم‌کننده، *Buffy the Vampire Slayer* رو داریم، درباره یه دختری که با خون‌آشام‌ها می‌جنگه! *Desperate Housewives* درباره یه گروه از زن‌ها و همه رازهایی هست که دارن. *Homeland* درباره یه مأمور CIA با مشکلات روحی و روانیه.\n",
      "\n",
      "کلی سریال با تعداد قسمت‌های زیاد هم هست مثل *How I Met Your Mother* که درباره یه گروه از دوست‌هاست. *Loki* از فیلم‌های مارول سریال اختصاصی خودش رو داره. *Lost* درباره آدم‌هایی هست که تو یه جزیره عجیب گیر افتادن. *Mrs. America* داستان واقعی مبارزه برای حقوق زنان رو تعریف می‌کنه. *The Muppet Show* یه سریال کلاسیک با عروسک‌هاست! *NYPD Blue* درباره افسرهای پلیس تو نیویورک سیتی هست. *One Mississippi* یه سریال غمگین اما خنده‌دار درباره زنیه که برای مراقبت از مادربیمارش به خونه برمی‌گرده. *Only Murders in the Building* درباره سه دوستی هست که یه قتل رو بررسی می‌کنن.  *The People v. O.J. Simpson* داستان یه دادگاه معروف رو تعریف می‌کنه.  *Pose* زندگی درگ کوئین‌ها (ملکه‌های درگ) رو تو دهه ۱۹۸۰ نشون می‌ده. کلی سریال برای تماشا تو دیزنی‌پلاس هست!\n",
      "\n",
      "\n",
      "کتاب جدید Curtis Sittenfeld، *Romantic Comedy*، درباره سالی هست، نویسنده یه برنامه کمدی مثل *Saturday Night Live*. سالی مردهایی که قیافه معمولی دارن و اغلب با زن‌های زیبا قرار می‌ذارن رو دست می‌اندازه.  اون یه نمایش کمدی کوتاه درباره این موضوع می‌نویسه به اسم \"قانون دنی هورست\". بعد سالی با یه ستاره موسیقی پاپ خوش‌قیافه به اسم نوآ آشنا می‌شه و ازش خوشش میاد. اما سالی فکر نمی‌کنه نوآ بتونه از اون خوشش بیاد.  کتاب درباره اینه که آیا اونا در نهایت با همدیگه می‌شن یا نه.  سالی یه فمینیسته که می‌خواد کمدی رمانتیک بنویسه که هم هوشمندانه باشه هم خنده‌دار.  اون و نوآ سر کارشون با هم صمیمی می‌شن، اما سالی احساسات واقعیش رو پنهان می‌کنه.  اون می‌ترسه آسیب‌پذیر باشه چون یه همکار قبلاً احساساتش رو جرحه‌دار کرده.  کتاب همچنین نشون می‌ده که کار کردن تو یه برنامه کمدی چه‌طوریه.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary=func_generate_content('')\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "43d2f1c6-7d5d-490a-ad6c-b82226747c97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'حال شما چطور است؟ (haal-e shoma chetor ast?)\\n'"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part, SafetySetting\n",
    " \n",
    " \n",
    "def generate():\n",
    "    vertexai.init(project=\"nine-quality-test\", location=\"us-central1\")\n",
    "    model = GenerativeModel(\n",
    "        \"gemini-1.5-pro-002\",\n",
    "    )\n",
    "    responses = model.generate_content(\n",
    "        [text1],\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings,\n",
    "        stream=True,\n",
    "    )\n",
    "    result=\"\"\n",
    "    for response in responses:\n",
    "        result=result+response.text\n",
    "    return result\n",
    " \n",
    "text1 = \"\"\"Translate the following text into Persian. Make sure to preserve the meaning, tone, and style of the original text, while ensuring it is natural and fluent in Persian.\n",
    "Text:how are you\n",
    " \n",
    "Only provide a single response\"\"\"\n",
    " \n",
    "generation_config = {\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"temperature\": 1,\n",
    "    \"top_p\": 0.95,\n",
    "}\n",
    " \n",
    "safety_settings = [\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "]\n",
    " \n",
    "r=generate()\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "46c35f1e-a804-4de8-b99e-f0f6bb539d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************\n",
      "Translate the following text into Persian.  Make sure to preserve the meaning, tone, and style of the original text, while ensuring it is natural and fluent in Persian.\n",
      "            Text:\n",
      " \n",
      "              how are you\n",
      "\n",
      "            Only provide a single response.\n",
      "            \n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"\\330\\255\\330\\247\\331\\204 \\330\\264\\331\\205\\330\\247 \\332\\206\\330\\267\\331\\210\\330\\261 \\330\\247\\330\\263\\330\\252\\330\\237\\n\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.13206623494625092\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.11757202446460724\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.01590641401708126\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.06097523868083954\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.05340331420302391\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.08882041275501251\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.05582325905561447\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.10970578342676163\n",
      "  }\n",
      "  avg_logprobs: -0.06424553053719657\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 55\n",
      "  candidates_token_count: 7\n",
      "  total_token_count: 62\n",
      "}\n",
      "model_version: \"gemini-1.5-pro-002\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result=get_translation(action_type='Translation',input_text=\"how are you\",Language='Persian' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "413c2b7e-a9d6-4788-a527-5f7651dcce76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidates {\n",
       "  content {\n",
       "    role: \"model\"\n",
       "    parts {\n",
       "      text: \"The most common and natural way to say \\\"how are you\\\" in Persian is:\\n\\n**\\330\\255\\330\\247\\331\\204\\330\\252 \\332\\206\\330\\267\\331\\210\\330\\261\\331\\207\\330\\237** (Haalet chetore?) -  Informal, similar to \\\"How\\'s it going?\\\"\\n\\nOther options, depending on the level of formality and the region, include:\\n\\n* **\\330\\255\\330\\247\\331\\204 \\330\\264\\331\\205\\330\\247 \\332\\206\\330\\267\\331\\210\\330\\261 \\330\\247\\330\\263\\330\\252\\330\\237** (Haale shoma chetor ast?) - Formal\\n* **\\332\\206\\330\\267\\331\\210\\330\\261\\333\\214\\330\\237** (Chetori?) - Very informal, like \\\"What\\'s up?\\\"\\n* **\\330\\256\\331\\210\\330\\250\\333\\214\\330\\237** (Khoobi?) - Literally \\\"Are you good?\\\", informal\\n\\n\\nSo, depending on the context you want to convey, choose the most appropriate option.  For a simple \\\"how are you,\\\"  **\\330\\255\\330\\247\\331\\204\\330\\252 \\332\\206\\330\\267\\331\\210\\330\\261\\331\\207\\330\\237** is a good choice.\\n\"\n",
       "    }\n",
       "  }\n",
       "  finish_reason: STOP\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HATE_SPEECH\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.07807836681604385\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.05834592133760452\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.013636830262839794\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.05184546485543251\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HARASSMENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.05582325905561447\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.03410044312477112\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.04084572568535805\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.04603387415409088\n",
       "  }\n",
       "  avg_logprobs: -0.08926623700612998\n",
       "}\n",
       "usage_metadata {\n",
       "  prompt_token_count: 47\n",
       "  candidates_token_count: 166\n",
       "  total_token_count: 213\n",
       "}\n",
       "model_version: \"gemini-1.5-pro-002\""
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8ad8d0fa-8ddf-41f9-9256-4f7ea37fef33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disney+ offers a diverse range of adult programming, from comedies like *Abbott Elementary*, *Arrested Development*, and *Bob's Burgers* to adventures like *How I Met Your Mother* and *The Muppet Show*.  For more intense viewing, the platform boasts thrillers such as *The Americans*, *Andor*, and *Buffy the Vampire Slayer*,  mysteries like *Lost* and *Only Murders in the Building*, and suspenseful dramas like *Homeland*.  Disney+ also delves into real-world issues with shows like *Mrs. America*, *The People v. O.J. Simpson*, and *Pose*. While the platform offers lighter fare like the novel-based show \"Romantic Comedy,\" exploring relationships and the entertainment industry,  it's worth noting that the realities of that industry, particularly regarding toxic work environments and abusive power dynamics, are explored in Maureen Ryan's book \"Burn It Down,\" which exposes systemic issues behind the scenes of shows like *Lost* and even *Saturday Night Live*, highlighting a stark contrast to the romanticized version often portrayed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd70c31-5ea8-4531-aa37-7c0744a1162b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
