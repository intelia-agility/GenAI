{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "267fab21-d152-4ab1-8769-be85bfe0d7b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LLM Evaluation \n",
    "\n",
    "This code uses llm as a judge to compare the generated content by two different llm models\n",
    "    \n",
    "<b> llm as a judge using user provided metrics:<br>\n",
    "- multimodal content coverage comparisions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9830715c-0f3d-4cc1-b184-9f2512f71c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --user --quiet google-cloud-aiplatform[evaluation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1ab6b2b-8c59-4311-90df-5158cfaabd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import time\n",
    "import random\n",
    "from google.cloud import bigquery\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from LLM_PairWiseEval_cls import PairwiseEvaluationClient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c48cff-f90e-49bf-9b53-168c4d2553c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prepare Data Sample for Multimodal Coverage Comparisions\n",
    "The assumption is that the generated content is in the form of json including the fields that are requested from llm models to be extracted from the content.<br>\n",
    "Because we did not have data in our environment, we make some sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e00a83-6ab8-43b1-9771-9b3c374cc77b",
   "metadata": {},
   "source": [
    "# Sample User Prompt\n",
    "This is basically the prompt text that will be used to generate the content for each video segment or image during batch/online content generation.\n",
    "Here, we used this prompt to generate the content of a sample video from 600s to 900s using two different models 'gemini-1.5-pro-002', 'gemini-1.5-flash-002'. The generated content is recorded in json format in output_model1.txt and output_model2.txt files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fef82971-48ea-496b-ad1e-442c7aa88541",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start=600\n",
    "end=900\n",
    "schema=\"\"\"{\n",
    "    \"description\": \"A structured schema to represent detailed information from a video or text analysis\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"Category\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The category or general type of the content\"\n",
    "        },\n",
    "        \"DetailedDescriptionOfEventsAndConversations\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"A detailed textual description of the events and conversations in the content\"\n",
    "        },\n",
    "        \"BrandsCompanyNamesLogos\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"description\": \"A list of brands, company names, or logos appearing or mentioned in the content\"\n",
    "        },\n",
    "        \"KeyLocationsAndScenes\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"description\": \"A list of key locations and scenes appearing or mentioned in the content\"\n",
    "        },\n",
    "        \"KeyThemes\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"description\": \"A list of key themes discussed or portrayed in the content\"\n",
    "        },\n",
    "        \"PeopleAppearingAndMentioned\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"description\": \"A list of people who appear or are mentioned in the content\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\n",
    "        \"Category\",\n",
    "        \"DetailedDescriptionOfEventsAndConversations\",\n",
    "        \"BrandsCompanyNamesLogos\",\n",
    "        \"KeyLocationsAndScenes\",\n",
    "        \"KeyThemes\",\n",
    "        \"PeopleAppearingAndMentioned\"\n",
    "    ]\n",
    "}\"\"\"\n",
    "\n",
    "\n",
    "VAR_VIDEO_SEGMENT=f\"Your task is to provide a comprehensive description of this video from segment {start} seconds to {end} seconds.\\n\"\n",
    "VAR_INSTRUCTIONS= \"\"\"To complete the task you need to follow these steps:\\n\n",
    "                           No greetings, closing remarks, or additional comments. Begin immediately with the video analysis and provide only the requested information in the specified format.\\n\n",
    "                           Idenify all instances of visual product placement. Pay close attention to background details and items held by the characters. List each product placement with the following\n",
    "                            information: Brand name, product name (if applicable), and a brief description. Include information about product placement into the description generated for the video\\n\n",
    "                           Create a transcript of all the speeches, dialogs, narration.\\n\n",
    "                           Scrupulously examine each scene for any and all visible brand names, logos, and products. Even if a product appears briefly or in the background, it should be included.\\n\"\"\"\n",
    "\n",
    "VAR_CONSTRAINTS= \"\"\"Describe the video content objectively, avoiding any subjective opinions or assumptions.\\n\n",
    "                           Specify who is saying what. If a person talking can be seen, specify their name and/or occupation. If it is voice behind the scenes, then describe it as a narrator.\\n\n",
    "                           Be specific when describing. Include all the information that is shown or given.\\n\n",
    "                           Do not show timestamps.\\n\n",
    "                           If an unidentified person is shown in the video first, but then their name is mentioned later in the video, make sure to mention their name in the description from the start.\\n\n",
    "                           \"\"\"\n",
    "\n",
    "VAR_STRUCTURE= f\"\"\"Organize the description with the following properties, and give a valid json file with JSON schema.<JSONSchema>{json.dumps(schema)}</JSONSchema>:\n",
    "                       \\n**Category**\\n\n",
    "                       \\n**DetailedDescriptionOfEventsAndConversations**\\n\n",
    "                       \\n**BrandsCompanyNamesLogos**\\n\n",
    "                       \\n**KeyLocationsAndScenes**\\n\n",
    "                       \\n**KeyThemes**\\n\n",
    "                       \\n**PeopleAppearingAndMentioned**\\n \n",
    "                 \"\"\" \n",
    "\n",
    "VAR_CONDITIONS = \"\"\"Identify a video as one of these categories: News, TV Shows, Live Sport Events, News Analyses. \\n\n",
    "                       When describing the DetailedDescriptionOfEventsAndConversations, consider the following instructions for specific video types:\\n\n",
    "                       * **News:** Pay close attention to transitions, graphics, and on-screen text.\\n\n",
    "                       * **TV Shows:** Describe facial expressions, body language, appearances, and overall mood.\\n\n",
    "                       * **Live Sports Events:** Focus on key moments, like goals or fouls, and describe the overall flow and momentum of the game.\\n\n",
    "                       * **News Analyses:** Identify different perspectives, arguments, and supporting evidence.\\n\n",
    "                       Make sure to mention people's names in the DetailedDescriptionOfEventsAndConversations and in PeopleAppearingAndMentioned as well as any other information about them like their age, occupation, location, etc. \\n\"\"\"\n",
    "\n",
    "VAR_EXAMPLE = \"\"\"Follow this example for the format of the output:\\n\n",
    "              {\n",
    "                \"Category\": \"TV Show\",\n",
    "                \"DetailedDescriptionOfEventsAndConversations\": \"The video starts with a man sitting at a dining table, reading a letter. Two Fiji bottles are visible on the benchtop. He has short, light brown hair and a beard. His name is Harrison. The scene changes to Melissa. Melissa says: \\\"I'm Melissa, and I'm a hairdresser. I'm 41 years old, and I'm from Sydney.\\\"\",\n",
    "                \"BrandsCompanyNamesLogos\": [\"Lacoste\", \"Fiji\"],\n",
    "                \"KeyLocationsAndScenes\": [\"Apartment\"],\n",
    "                \"KeyThemes\": [\"Marriage\"],\n",
    "                \"PeopleAppearingAndMentioned\": [\n",
    "                \"Harrison, 32, Builder, NSW\",\n",
    "                \"Melissa, 41, Hairdresser, NSW\"\n",
    "                ]\n",
    "            }\n",
    "               \"\"\"\n",
    "  \n",
    "    \n",
    "video_description_prompt=VAR_VIDEO_SEGMENT+VAR_INSTRUCTIONS+VAR_CONSTRAINTS+VAR_STRUCTURE+VAR_CONDITIONS+VAR_EXAMPLE\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00eb83a4-070a-48f2-947a-379fc1ca24fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load pre-executed predictions\n",
    "with open('output_model1.txt', 'r') as file:\n",
    "    response1 = json.dumps(json.load(file))\n",
    "with open('output_model2.txt', 'r') as file:\n",
    "    response2 = json.dumps(json.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba94562a-04cd-4e79-82d7-debbdc5dfe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create one comparision sample\n",
    "generated_response = [\n",
    "    response1,\n",
    "    response2\n",
    "]\n",
    "llm_models=['gemini-1.5-pro-002', 'gemini-1.5-flash-002']\n",
    "\n",
    "items= pd.DataFrame(\n",
    "    {   'asset_id':\"MAAT2024_1_A_HBB.mp4\",\n",
    "        \"prompt_text_A\": video_description_prompt, #this should be set with the prompt_text when doing batch generation for model -A\n",
    "        \"prompt_text_B\": video_description_prompt, #this should be set with the prompt_text when doing batch generation for model -B\n",
    "        \"fileUri\":'gs://raw_nine_files/vlt_video_extract/MAAT/MAAT2024_1_A_HBB.mp4' , #this should be set to file uri when doing batch generation\n",
    "        \"description_A\": response1, #this should be set the generated content when doing batch generation for model-A\n",
    "        \"description_B\": response2, #this should be set the generated content when doing batch generation for model-B\n",
    "     \n",
    "        \"asset_type\": 'video/mp4', #this should be set to asset_type/mime_type when doing batch generation\n",
    "        \"startOffset_seconds\":[int(start)],\n",
    "        \"endOffset_seconds\":[int(end)],\n",
    "        \"modelVersion_A\":llm_models[0],#this should be set the model-A name\n",
    "        \"modelVersion_B\":llm_models[1],#this should be set the model-B name\n",
    "\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c79b54-df1a-476b-a000-5d74293e2497",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_A=\"Describe this image in detail. Identify any text, brands or company logos, locations and key themes. If there is a famous person like politician, celebrity or athlete, indicate their name and describe what they are famous for. Organize the description in the following format: \\n**DetailedDescription**\\n \\n**BrandsCompanyNamesLogos**\\n \\n**KeyLocations**\\n \\n**KeyThemes**\\n \\n**PeopleAppearing**\\n If you are not sure about any info, please do not make it up. No greetings, closing remarks, or additional comments.\"\n",
    "response_A=\"**DetailedDescription**\\nEye-level close-up of what appears to be a formal press conference or bilateral meeting.  Two individuals are seated at a table, likely dignitaries or officials, given the setting and presence of flags and microphones. The person on the left wears a yellow and grey patterned dress and a traditional floral lei. She has grey hair and glasses. The person on the right, with short grey hair, wears a dark suit jacket and a similar floral lei.  They are both looking directly towards the camera, possibly addressing an audience. \\n\\n\\nThe table in front of them is white and holds two bottles of water, two small flags (Samoa and Australia), microphones with foam covers, a small bottle of hand sanitizer, and a document.  A centerpiece of pink, purple, and white flowers sits between the individuals. \\n\\n\\nThe backdrop consists of a dark, possibly wooden, wall with a textured or patterned design. Two large flags are prominently displayed behind the individuals, one appearing to be the flag of Samoa and the other the flag of Australia. The lighting is well-balanced, illuminating the subjects and the foreground elements while the background remains slightly darker.\\n\\n**BrandsCompanyNamesLogos**\\nNone\\n\\n**KeyLocations**\\nSamoa (flag present)\\nAustralia (flag present)\\n\\n**KeyThemes**\\nInternational relations/diplomacy\\nBilateral meeting/press conference\\nFormal occasion\\n\\n**PeopleAppearing**\\nFiame Naomi Mata'afa, Prime Minister of Samoa.\"\n",
    "\n",
    "prompt_B=\"Describe this image in detail. Identify any text, brands or company logos, locations and key themes. If there is a famous person like politician, celebrity or athlete, indicate their name and describe what they are famous for. Organize the description in the following format: \\n**DetailedDescription**\\n \\n**BrandsCompanyNamesLogos**\\n \\n**KeyLocations**\\n \\n**KeyThemes**\\n \\n**PeopleAppearing**\\n If you are not sure about any info, please do not make it up. No greetings, closing remarks, or additional comments.\"\n",
    "response_B=\"**DetailedDescription**\\nEye-level view of a scene that appears to be a political rally or public speaking event. \\n\\n\\nThe central figure is Donald Trump, standing on a stage with a large American flag draped across the front. He is wearing a dark suit, red tie, and his signature hairstyle. His hands are clasped in front of him, and he appears to be looking out at the crowd. \\n\\n\\nA person with a camera and stabilizer rig is positioned to the right of the frame, seemingly filming or photographing the event. \\n\\n\\nA crowd of people is visible behind a barrier in the background, many of whom are holding up cell phones, presumably taking pictures or videos. They appear to be engaged and focused on the stage. \\n\\n\\nThe sky is visible above, mostly clear with some light clouds. The lighting suggests it's daytime, likely in the late afternoon or early evening.\\n\\n\\n**BrandsCompanyNamesLogos**\\nThe Trump campaign slogan appears on a woman's tank top.\\n\\n**KeyLocations**\\nThe location appears to be an outdoor venue in the United States, possibly a fairground or open field, judging by the flat terrain and crowd barriers.\\n\\n\\n**KeyThemes**\\nPolitical rally, public speaking, presidential campaign\\n\\n\\n**PeopleAppearing**\\nDonald Trump, former President of the United States.\\n\"\n",
    "\n",
    "new_item=pd.DataFrame(\n",
    "   [ {   'asset_id':\"04ae4ae696419a0d23df328343bc5e893bb8b666.jpeg\",\n",
    "        \"prompt_text_A\": prompt_A, #this should be set with the prompt_text when doing batch generation for model -A\n",
    "        \"prompt_text_B\": prompt_B, #this should be set with the prompt_text when doing batch generation for model -B\n",
    "        \"fileUri\":'gs://nineshowcaseassets/IMAGES/04ae4ae696419a0d23df328343bc5e893bb8b666.jpeg' , #this should be set to file uri when doing batch generation\n",
    "        \"description_A\": response_A, #this should be set the generated content when doing batch generation for model-A\n",
    "        \"description_B\": response_B, #this should be set the generated content when doing batch generation for model-B     \n",
    "        \"asset_type\": 'image/jpeg', #this should be set to asset_type/mime_type when doing batch generation      \n",
    "        \"modelVersion_A\":'gemini-1.5-pro-002',#this should be set the model-A name\n",
    "        \"modelVersion_B\":'gemini-1.5-pro-002',#this should be set the model-B name\n",
    "\n",
    "    }]\n",
    ")\n",
    "\n",
    "items=pd.concat([items,new_item], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6763f141-a9d6-4f08-9584-661eda2d877b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>prompt_text_A</th>\n",
       "      <th>prompt_text_B</th>\n",
       "      <th>fileUri</th>\n",
       "      <th>description_A</th>\n",
       "      <th>description_B</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>startOffset_seconds</th>\n",
       "      <th>endOffset_seconds</th>\n",
       "      <th>modelVersion_A</th>\n",
       "      <th>modelVersion_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAAT2024_1_A_HBB.mp4</td>\n",
       "      <td>Your task is to provide a comprehensive descri...</td>\n",
       "      <td>Your task is to provide a comprehensive descri...</td>\n",
       "      <td>gs://raw_nine_files/vlt_video_extract/MAAT/MAA...</td>\n",
       "      <td>{\"Category\": \"TV Show\", \"DetailedDescriptionOf...</td>\n",
       "      <td>{\"Category\": \"TV Show\", \"DetailedDescriptionOf...</td>\n",
       "      <td>video/mp4</td>\n",
       "      <td>600.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>gemini-1.5-pro-002</td>\n",
       "      <td>gemini-1.5-flash-002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04ae4ae696419a0d23df328343bc5e893bb8b666.jpeg</td>\n",
       "      <td>Describe this image in detail. Identify any te...</td>\n",
       "      <td>Describe this image in detail. Identify any te...</td>\n",
       "      <td>gs://nineshowcaseassets/IMAGES/04ae4ae696419a0...</td>\n",
       "      <td>**DetailedDescription**\\nEye-level close-up of...</td>\n",
       "      <td>**DetailedDescription**\\nEye-level view of a s...</td>\n",
       "      <td>image/jpeg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gemini-1.5-pro-002</td>\n",
       "      <td>gemini-1.5-pro-002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        asset_id  \\\n",
       "0                           MAAT2024_1_A_HBB.mp4   \n",
       "0  04ae4ae696419a0d23df328343bc5e893bb8b666.jpeg   \n",
       "\n",
       "                                       prompt_text_A  \\\n",
       "0  Your task is to provide a comprehensive descri...   \n",
       "0  Describe this image in detail. Identify any te...   \n",
       "\n",
       "                                       prompt_text_B  \\\n",
       "0  Your task is to provide a comprehensive descri...   \n",
       "0  Describe this image in detail. Identify any te...   \n",
       "\n",
       "                                             fileUri  \\\n",
       "0  gs://raw_nine_files/vlt_video_extract/MAAT/MAA...   \n",
       "0  gs://nineshowcaseassets/IMAGES/04ae4ae696419a0...   \n",
       "\n",
       "                                       description_A  \\\n",
       "0  {\"Category\": \"TV Show\", \"DetailedDescriptionOf...   \n",
       "0  **DetailedDescription**\\nEye-level close-up of...   \n",
       "\n",
       "                                       description_B  asset_type  \\\n",
       "0  {\"Category\": \"TV Show\", \"DetailedDescriptionOf...   video/mp4   \n",
       "0  **DetailedDescription**\\nEye-level view of a s...  image/jpeg   \n",
       "\n",
       "   startOffset_seconds  endOffset_seconds      modelVersion_A  \\\n",
       "0                600.0              900.0  gemini-1.5-pro-002   \n",
       "0                  NaN                NaN  gemini-1.5-pro-002   \n",
       "\n",
       "         modelVersion_B  \n",
       "0  gemini-1.5-flash-002  \n",
       "0    gemini-1.5-pro-002  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1111a86d-aa54-4bde-9912-7a6ee1d0b8cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_name = \"content-generation-qa-quality\"\n",
    "file_path = 'PairWiseMultimodalContentEvaluationMetrics.json'\n",
    "\n",
    "# Open and load the JSON file\n",
    "with open(file_path, 'r') as file:\n",
    "    multimodal_eval_prompt_metrics = json.load(file)\n",
    "\n",
    "    \n",
    "video_multimodal_content_evaluation_metric_promopt =multimodal_eval_prompt_metrics['video_multimodal_content_evaluation_metric_promopt']\n",
    "image_multimodal_content_evaluation_metric_promopt= multimodal_eval_prompt_metrics['image_multimodal_content_evaluation_metric_promopt']\n",
    "\n",
    "multimodal_evaluation_promt={'video_prompt': video_multimodal_content_evaluation_metric_promopt,'image_prompt':image_multimodal_content_evaluation_metric_promopt}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "117dae90-26c7-4ed1-9424-463535f7d380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>prompt_text_A</th>\n",
       "      <th>prompt_text_B</th>\n",
       "      <th>fileUri</th>\n",
       "      <th>description_A</th>\n",
       "      <th>description_B</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>startOffset_seconds</th>\n",
       "      <th>endOffset_seconds</th>\n",
       "      <th>modelVersion_A</th>\n",
       "      <th>modelVersion_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAAT2024_1_A_HBB.mp4</td>\n",
       "      <td>Your task is to provide a comprehensive descri...</td>\n",
       "      <td>Your task is to provide a comprehensive descri...</td>\n",
       "      <td>gs://raw_nine_files/vlt_video_extract/MAAT/MAA...</td>\n",
       "      <td>{\"Category\": \"TV Show\", \"DetailedDescriptionOf...</td>\n",
       "      <td>{\"Category\": \"TV Show\", \"DetailedDescriptionOf...</td>\n",
       "      <td>video/mp4</td>\n",
       "      <td>600.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>gemini-1.5-pro-002</td>\n",
       "      <td>gemini-1.5-flash-002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04ae4ae696419a0d23df328343bc5e893bb8b666.jpeg</td>\n",
       "      <td>Describe this image in detail. Identify any te...</td>\n",
       "      <td>Describe this image in detail. Identify any te...</td>\n",
       "      <td>gs://nineshowcaseassets/IMAGES/04ae4ae696419a0...</td>\n",
       "      <td>**DetailedDescription**\\nEye-level close-up of...</td>\n",
       "      <td>**DetailedDescription**\\nEye-level view of a s...</td>\n",
       "      <td>image/jpeg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gemini-1.5-pro-002</td>\n",
       "      <td>gemini-1.5-pro-002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        asset_id  \\\n",
       "0                           MAAT2024_1_A_HBB.mp4   \n",
       "0  04ae4ae696419a0d23df328343bc5e893bb8b666.jpeg   \n",
       "\n",
       "                                       prompt_text_A  \\\n",
       "0  Your task is to provide a comprehensive descri...   \n",
       "0  Describe this image in detail. Identify any te...   \n",
       "\n",
       "                                       prompt_text_B  \\\n",
       "0  Your task is to provide a comprehensive descri...   \n",
       "0  Describe this image in detail. Identify any te...   \n",
       "\n",
       "                                             fileUri  \\\n",
       "0  gs://raw_nine_files/vlt_video_extract/MAAT/MAA...   \n",
       "0  gs://nineshowcaseassets/IMAGES/04ae4ae696419a0...   \n",
       "\n",
       "                                       description_A  \\\n",
       "0  {\"Category\": \"TV Show\", \"DetailedDescriptionOf...   \n",
       "0  **DetailedDescription**\\nEye-level close-up of...   \n",
       "\n",
       "                                       description_B  asset_type  \\\n",
       "0  {\"Category\": \"TV Show\", \"DetailedDescriptionOf...   video/mp4   \n",
       "0  **DetailedDescription**\\nEye-level view of a s...  image/jpeg   \n",
       "\n",
       "   startOffset_seconds  endOffset_seconds      modelVersion_A  \\\n",
       "0                600.0              900.0  gemini-1.5-pro-002   \n",
       "0                  NaN                NaN  gemini-1.5-pro-002   \n",
       "\n",
       "         modelVersion_B  \n",
       "0  gemini-1.5-flash-002  \n",
       "0    gemini-1.5-pro-002  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c7977db-579f-49c9-8e37-9917249cbd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nine-quality-test.vlt_eval_statistics_schema exists.\n",
      "Table nine-quality-test.vlt_eval_statistics_schema.vlt_pairwise_eval_statistics exists. Checking schema...\n",
      "Evaluations have successfully been loaded into nine-quality-test.vlt_eval_statistics_schema.vlt_pairwise_eval_statistics.\n"
     ]
    }
   ],
   "source": [
    "pairwise_evaluation_client=PairwiseEvaluationClient(project='nine-quality-test',\n",
    "                          location='us-central1',\n",
    "                          items=items,\n",
    "                          response_A_desc_column_name= \"description_A\",\n",
    "                          response_B_desc_column_name= \"description_B\",\n",
    "                          response_A_llm_model_column_name=\"modelVersion_A\",\n",
    "                          response_B_llm_model_column_name=\"modelVersion_B\",                        \n",
    "                         experiment_name=\"pairwise-evaluation-experiment\",    \n",
    "                         multimodal_evaluation_promt=multimodal_evaluation_promt, # prompt that will be used for video and image generated content evaluation comparisions\n",
    "                         response_A_userPrompt_column_name=\"prompt_text_A\", # name of the column in the 'items' data frame that includes user input prompt when generating content for model-A\n",
    "                         response_B_userPrompt_column_name=\"prompt_text_B\", # name of the column in the 'items' data frame that includes user input prompt when generating content for model-b\n",
    "                         response_media_column_metadata={'fileUri':'fileUri', 'startOffset':'startOffset_seconds','endOffset':'endOffset_seconds', 'mediaType':'asset_type'},   # name of metadata columns in the 'items' dataframe\n",
    "                         response_mediaType_column_name='asset_type'\n",
    "                             )\n",
    "evaluations=pairwise_evaluation_client.get_evaluations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b38f6d8f-361c-4d29-ad9b-6f64c0022ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_A</th>\n",
       "      <th>response_B</th>\n",
       "      <th>mediaType</th>\n",
       "      <th>multimodal_evaluation_promt</th>\n",
       "      <th>instruction_A</th>\n",
       "      <th>instruction_B</th>\n",
       "      <th>reference</th>\n",
       "      <th>response_A_llm_model</th>\n",
       "      <th>response_B_llm_model</th>\n",
       "      <th>run_experiment_name</th>\n",
       "      <th>...</th>\n",
       "      <th>detailed_description_of_events_and_conversations_score</th>\n",
       "      <th>detailed_description_of_events_and_conversations_explanation</th>\n",
       "      <th>brands_companynames_and_logos_score</th>\n",
       "      <th>brands_companynames_and_logos_explanation</th>\n",
       "      <th>keylocations_and_scenes_score</th>\n",
       "      <th>keylocations_and_scenes_explanation</th>\n",
       "      <th>key_themes_score</th>\n",
       "      <th>key_themes_explanation</th>\n",
       "      <th>people_appearing_and_mentioned_score</th>\n",
       "      <th>people_appearing_and_mentioned_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\"Category\": \"TV Show\", \"DetailedDescriptionOf...</td>\n",
       "      <td>{\"Category\": \"TV Show\", \"DetailedDescriptionOf...</td>\n",
       "      <td>video/mp4</td>\n",
       "      <td># Instruction\\nYou are an expert evaluator. Yo...</td>\n",
       "      <td>Your task is to provide a comprehensive descri...</td>\n",
       "      <td>Your task is to provide a comprehensive descri...</td>\n",
       "      <td>{\"fileuri\": \"gs://raw_nine_files/vlt_video_ext...</td>\n",
       "      <td>gemini-1.5-pro-002</td>\n",
       "      <td>gemini-1.5-flash-002</td>\n",
       "      <td>pairwise-evaluation-experiment-1d4257a8-fc36-4...</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Both models capture the main events of the vid...</td>\n",
       "      <td>1</td>\n",
       "      <td>Model A correctly identifies the Fiji water bo...</td>\n",
       "      <td>5</td>\n",
       "      <td>Both Models capture most of the key locations ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Both Models are almost similar in identifying ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Both models correctly identify most of the peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>**DetailedDescription**\\nEye-level close-up of...</td>\n",
       "      <td>**DetailedDescription**\\nEye-level view of a s...</td>\n",
       "      <td>image/jpeg</td>\n",
       "      <td># Instruction\\nYou are an expert evaluator. Yo...</td>\n",
       "      <td>Describe this image in detail. Identify any te...</td>\n",
       "      <td>Describe this image in detail. Identify any te...</td>\n",
       "      <td>{\"fileuri\": \"gs://nineshowcaseassets/IMAGES/04...</td>\n",
       "      <td>gemini-1.5-pro-002</td>\n",
       "      <td>gemini-1.5-pro-002</td>\n",
       "      <td>pairwise-evaluation-experiment-1d4257a8-fc36-4...</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Both models capture the main events of the vid...</td>\n",
       "      <td>1</td>\n",
       "      <td>Model A correctly identifies the Fiji water bo...</td>\n",
       "      <td>5</td>\n",
       "      <td>Both Models capture most of the key locations ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Both Models are almost similar in identifying ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Both models correctly identify most of the peo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          response_A  \\\n",
       "0  {\"Category\": \"TV Show\", \"DetailedDescriptionOf...   \n",
       "0  **DetailedDescription**\\nEye-level close-up of...   \n",
       "\n",
       "                                          response_B   mediaType  \\\n",
       "0  {\"Category\": \"TV Show\", \"DetailedDescriptionOf...   video/mp4   \n",
       "0  **DetailedDescription**\\nEye-level view of a s...  image/jpeg   \n",
       "\n",
       "                         multimodal_evaluation_promt  \\\n",
       "0  # Instruction\\nYou are an expert evaluator. Yo...   \n",
       "0  # Instruction\\nYou are an expert evaluator. Yo...   \n",
       "\n",
       "                                       instruction_A  \\\n",
       "0  Your task is to provide a comprehensive descri...   \n",
       "0  Describe this image in detail. Identify any te...   \n",
       "\n",
       "                                       instruction_B  \\\n",
       "0  Your task is to provide a comprehensive descri...   \n",
       "0  Describe this image in detail. Identify any te...   \n",
       "\n",
       "                                           reference response_A_llm_model  \\\n",
       "0  {\"fileuri\": \"gs://raw_nine_files/vlt_video_ext...   gemini-1.5-pro-002   \n",
       "0  {\"fileuri\": \"gs://nineshowcaseassets/IMAGES/04...   gemini-1.5-pro-002   \n",
       "\n",
       "   response_B_llm_model                                run_experiment_name  \\\n",
       "0  gemini-1.5-flash-002  pairwise-evaluation-experiment-1d4257a8-fc36-4...   \n",
       "0    gemini-1.5-pro-002  pairwise-evaluation-experiment-1d4257a8-fc36-4...   \n",
       "\n",
       "   ... detailed_description_of_events_and_conversations_score  \\\n",
       "0  ...                                                  5       \n",
       "0  ...                                                  5       \n",
       "\n",
       "   detailed_description_of_events_and_conversations_explanation  \\\n",
       "0  Both models capture the main events of the vid...              \n",
       "0  Both models capture the main events of the vid...              \n",
       "\n",
       "  brands_companynames_and_logos_score  \\\n",
       "0                                   1   \n",
       "0                                   1   \n",
       "\n",
       "           brands_companynames_and_logos_explanation  \\\n",
       "0  Model A correctly identifies the Fiji water bo...   \n",
       "0  Model A correctly identifies the Fiji water bo...   \n",
       "\n",
       "  keylocations_and_scenes_score  \\\n",
       "0                             5   \n",
       "0                             5   \n",
       "\n",
       "                 keylocations_and_scenes_explanation key_themes_score  \\\n",
       "0  Both Models capture most of the key locations ...                3   \n",
       "0  Both Models capture most of the key locations ...                3   \n",
       "\n",
       "                              key_themes_explanation  \\\n",
       "0  Both Models are almost similar in identifying ...   \n",
       "0  Both Models are almost similar in identifying ...   \n",
       "\n",
       "  people_appearing_and_mentioned_score  \\\n",
       "0                                    5   \n",
       "0                                    5   \n",
       "\n",
       "          people_appearing_and_mentioned_explanation  \n",
       "0  Both models correctly identify most of the peo...  \n",
       "0  Both models correctly identify most of the peo...  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45139015-84f9-4f9b-b6b9-14ebf408f8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Instruction\n",
      "You are an expert evaluator. Your task is to evaluate the quality of the responses generated by AI models. We will provide you with the user prompt, and AI-generated responses for model A and B, video and the segment for which this response is generated.\n",
      "You should first read the user input carefully for analyzing the task, then look into video segment, and then evaluate the quality of the responses based on the Criteria provided in the Evaluation section below.\n",
      "You will assign the response a rating following the Rating Rubric and Evaluation Steps. Give step-by-step explanations for your rating, and only choose ratings from the Rating Rubric.\n",
      "\n",
      "# Evaluation\n",
      "## Metric Definition\n",
      "You will be assessing coverage, which measures the ability to provide a detailed response based on the given video segment and requested properties.\n",
      "\n",
      "## Criteria\n",
      "Coverage: It is the quality of capturing all required detail for each requested property.\n",
      "In the context of video content capturing, it refers to the way that all the details of the following properties are captured and presented thoroughly:\n",
      "\n",
      "- Category\n",
      "- Detailed Description Of Events And Conversations\n",
      "- Brands, Company Names, and Logos\n",
      "- Key Locations And Scenes\n",
      "- Key Themes\n",
      "- People Appearing And Mentioned\n",
      "\n",
      "This AI-generated responses will be used for data retrieval. So, it has to be able to capture all the details of a scene. Rating rubric has to be calculated for each property separately.\n",
      "\n",
      "## Rating Rubric\n",
      "1: (Model A Perfectly Aligned) model A has perfectly captured the most accurate content but model B could not\n",
      "2: (Model B Perfectly Aligned) model B has perfectly captured the most accurate content but model A could not\n",
      "3: (Model A and B Aligned) both models could capture the content accurately\n",
      "4: (Model A and B Not Aligned) neither of two models could capture the content accurately\n",
      "5: (Model A and B Slightly Aligned- A is more accurate) Both models could capture the content partially but model A is more accurate\n",
      "6: (Model A and B Slightly Aligned- B is more accurate) Both models could capture the content partially but model B is more accurate\n",
      "\n",
      "## Evaluation Steps\n",
      "STEP 1: Assess User Instruction: Carefully read the user input prompt to understand the user's request and requested information.\n",
      "STEP 2: Analyze Video Segment: Examine the video segment for each requested property to make sure all the requested information is captured in detail.\n",
      "STEP 3: Evaluate Accuracy: For each requested property, check if the generated response correctly identifies the information and details described in the video segment.\n",
      "STEP 4: Identify Inconsistencies: For each requested property, look for any discrepancies or missed details between the video segment details and the captured information in the AI-generated responses. For example, if any information is missed, or not captured right for each property separately.\n",
      "STEP 5: Determine Score: Based on the previous steps, assign a score using the 1-6 rubric. Consider the severity of any inconsistencies and their potential impact on the data retrieval.\n",
      "\n",
      "## AI-generated response model A:\n",
      "{response_A}\n",
      "\n",
      "## AI-generated response model B:\n",
      "{response_B}\n"
     ]
    }
   ],
   "source": [
    "print(video_multimodal_content_evaluation_metric_promopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500c667f-5bc2-4290-91b2-a8240fdfeb2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
