{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd896aaf-29b5-43b2-aeb7-bedbd45a1198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "start=600\n",
    "end=900\n",
    "schema=\"\"\"{\n",
    "    \"description\": \"A structured schema to represent detailed information from a video or text analysis\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"Category\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The category or general type of the content\"\n",
    "        },\n",
    "        \"DetailedDescriptionOfEventsAndConversations\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"A detailed textual description of the events and conversations in the content\"\n",
    "        },\n",
    "        \"BrandsCompanyNamesLogos\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"description\": \"A list of brands, company names, or logos appearing or mentioned in the content\"\n",
    "        },\n",
    "        \"KeyLocationsAndScenes\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"description\": \"A list of key locations and scenes appearing or mentioned in the content\"\n",
    "        },\n",
    "        \"KeyThemes\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"description\": \"A list of key themes discussed or portrayed in the content\"\n",
    "        },\n",
    "        \"PeopleAppearingAndMentioned\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"description\": \"A list of people who appear or are mentioned in the content\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\n",
    "        \"Category\",\n",
    "        \"DetailedDescriptionOfEventsAndConversations\",\n",
    "        \"BrandsCompanyNamesLogos\",\n",
    "        \"KeyLocationsAndScenes\",\n",
    "        \"KeyThemes\",\n",
    "        \"PeopleAppearingAndMentioned\"\n",
    "    ]\n",
    "}\"\"\"\n",
    "\n",
    "\n",
    "VAR_VIDEO_SEGMENT=f\"Your task is to provide a comprehensive description of this video from segment {start} seconds to {end} seconds.\\n\"\n",
    "VAR_INSTRUCTIONS= \"\"\"To complete the task you need to follow these steps:\\n\n",
    "                           No greetings, closing remarks, or additional comments. Begin immediately with the video analysis and provide only the requested information in the specified format.\\n\n",
    "                           Idenify all instances of visual product placement. Pay close attention to background details and items held by the characters. List each product placement with the following\n",
    "                            information: Brand name, product name (if applicable), and a brief description. Include information about product placement into the description generated for the video\\n\n",
    "                           Create a transcript of all the speeches, dialogs, narration.\\n\n",
    "                           Scrupulously examine each scene for any and all visible brand names, logos, and products. Even if a product appears briefly or in the background, it should be included.\\n\"\"\"\n",
    "\n",
    "VAR_CONSTRAINTS= \"\"\"Describe the video content objectively, avoiding any subjective opinions or assumptions.\\n\n",
    "                           Specify who is saying what. If a person talking can be seen, specify their name and/or occupation. If it is voice behind the scenes, then describe it as a narrator.\\n\n",
    "                           Be specific when describing. Include all the information that is shown or given.\\n\n",
    "                           Do not show timestamps.\\n\n",
    "                           If an unidentified person is shown in the video first, but then their name is mentioned later in the video, make sure to mention their name in the description from the start.\\n\n",
    "                           \"\"\"\n",
    "\n",
    "VAR_STRUCTURE= f\"\"\"Organize the description with the following properties, and give a valid json file with JSON schema.<JSONSchema>{json.dumps(schema)}</JSONSchema>:\n",
    "                       \\n**Category**\\n\n",
    "                       \\n**DetailedDescriptionOfEventsAndConversations**\\n\n",
    "                       \\n**BrandsCompanyNamesLogos**\\n\n",
    "                       \\n**KeyLocationsAndScenes**\\n\n",
    "                       \\n**KeyThemes**\\n\n",
    "                       \\n**PeopleAppearingAndMentioned**\\n \n",
    "                 \"\"\" \n",
    "\n",
    "VAR_CONDITIONS = \"\"\"Identify a video as one of these categories: News, TV Shows, Live Sport Events, News Analyses. \\n\n",
    "                       When describing the DetailedDescriptionOfEventsAndConversations, consider the following instructions for specific video types:\\n\n",
    "                       * **News:** Pay close attention to transitions, graphics, and on-screen text.\\n\n",
    "                       * **TV Shows:** Describe facial expressions, body language, appearances, and overall mood.\\n\n",
    "                       * **Live Sports Events:** Focus on key moments, like goals or fouls, and describe the overall flow and momentum of the game.\\n\n",
    "                       * **News Analyses:** Identify different perspectives, arguments, and supporting evidence.\\n\n",
    "                       Make sure to mention people's names in the DetailedDescriptionOfEventsAndConversations and in PeopleAppearingAndMentioned as well as any other information about them like their age, occupation, location, etc. \\n\"\"\"\n",
    "\n",
    "VAR_EXAMPLE = \"\"\"Follow this example for the format of the output:\\n\n",
    "              {\n",
    "                \"Category\": \"TV Show\",\n",
    "                \"DetailedDescriptionOfEventsAndConversations\": \"The video starts with a man sitting at a dining table, reading a letter. Two Fiji bottles are visible on the benchtop. He has short, light brown hair and a beard. His name is Harrison. The scene changes to Melissa. Melissa says: \\\"I'm Melissa, and I'm a hairdresser. I'm 41 years old, and I'm from Sydney.\\\"\",\n",
    "                \"BrandsCompanyNamesLogos\": [\"Lacoste\", \"Fiji\"],\n",
    "                \"KeyLocationsAndScenes\": [\"Apartment\"],\n",
    "                \"KeyThemes\": [\"Marriage\"],\n",
    "                \"PeopleAppearingAndMentioned\": [\n",
    "                \"Harrison, 32, Builder, NSW\",\n",
    "                \"Melissa, 41, Hairdresser, NSW\"\n",
    "                ]\n",
    "            }\n",
    "               \"\"\"\n",
    "  \n",
    "    \n",
    "video_description_prompt=VAR_VIDEO_SEGMENT+VAR_INSTRUCTIONS+VAR_CONSTRAINTS+VAR_STRUCTURE+VAR_CONDITIONS+VAR_EXAMPLE\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37d6ef3c-2a1f-4dc6-98f7-d7d4e131c4d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import time\n",
    "import typing\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.protobuf import struct_pb2\n",
    "\n",
    "#libraries to generate image summaries\n",
    "from vertexai.vision_models import Video\n",
    "from vertexai.vision_models import VideoSegmentConfig\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.vision_models import Image as vision_model_Image\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part as GenerativeModelPart,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n",
    "from typing import Any, Dict, List, Literal, Optional, Union\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "contents= [{\n",
    "                                                                    \"role\": \"user\",\n",
    "                                                                    \"parts\": [\n",
    "                                                                        {\n",
    "                                                                    \n",
    "                                                                        \n",
    "                                                                        \"file_data\": {\n",
    "                                                                            \"mime_type\":  \"video/mp4\",\n",
    "                                                                            \"file_uri\": \"gs://raw_nine_files/vlt_video_extract/MAAT/MAAT2024_1_A_HBB.mp4\"\n",
    "                                                                        } \n",
    "                                                                         ,\n",
    "                                                                        \"video_metadata\": {\n",
    "                                                                                        \"start_offset\": {\n",
    "                                                                                        \"seconds\": start,\n",
    "                                                                                        \"nanos\": 0\n",
    "                                                                                        },\n",
    "                                                                                        \"end_offset\": {\n",
    "                                                                                        \"seconds\": end,\n",
    "                                                                                        \"nanos\": 0\n",
    "                                                                                        }\n",
    "                                                                                }\n",
    "\n",
    "                                                                        },\n",
    "                                                                        { \"text\": video_description_prompt }\n",
    "                                                                    ]\n",
    "                                                                    }\n",
    "                                                                ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f9bab4-a753-4fc0-aa4e-5122641129e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_multimodal_model= GenerativeModel(\"gemini-1.5-pro-002\")\n",
    "generation_config=GenerationConfig(temperature=1, top_k=40,top_p=0.95,max_output_tokens=8192)#, response_mime_type='application/json',\n",
    " \n",
    "safety_settings=  {\n",
    "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    }\n",
    "\n",
    "model_response = generative_multimodal_model.generate_content(\n",
    "                                    contents ,safety_settings=safety_settings,generation_config=generation_config,\n",
    "                                   )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "540e7dac-0b44-4612-b110-9c2474f3b76c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"Category\": \"TV Show\",\\n  \"DetailedDescriptionOfEventsAndConversations\": \"The video begins with Jayden, a 26-year-old professional kickboxer from Queensland, arriving at a gathering. He greets Tim, Richard, and John. Richard introduces himself to Jayden. Richard asks Jayden what he does for a living. Jayden says that kickboxing is his full-time job, training twice a day, six days a week. Jayden explains that he\\'s not what he appears to be, enjoying snuggles and back tickles when he\\'s not fighting. He adds that he\\'s a romantic and doesn\\'t have a specific type, looking for someone with a good heart. Lucinda, a 43-year-old MC and wedding celebrant from New South Wales, arrives at the same gathering, greeting the other women: Tori and Natasha. Lucinda says that she\\'s looking for a confident man, a great cook who is funny and generous of spirit. She unfolds a scroll, revealing her detailed list of desired qualities in a partner, including “handsome” and “spunky,” prompting laughter from her companions. The next scene shows Lucinda conversing with John Aiken. Lucinda says she wants someone who\\'s good with his clothes off, leading to a humorous exchange about “high-functioning erection.”  The scene shifts back to the gathering, where Lucinda discusses her ideal partner with Tori and Natasha. She mentions wanting someone well-established, secure, and confident without a big ego, while Tori expresses her desire for a nerdy guy. Lucinda notes Tori\\'s intellectual nature and need for a challenging partner.  The conversation then shifts to discussing what they\\'ve written on their lists, with Lucinda noting “purple” as the color of transcendence, eliciting laughter. Sara, a 29-year-old nutritionist from New South Wales, arrives. She expresses her hopes of walking down the aisle and meeting her future husband.  The video then cuts to another man arriving in a car at the same location. The Sydney skyline is visible in the background. The video then cuts to Sara, a 29-year-old nutritionist from New South Wales, arriving and meeting several other women. It ends with another male arrival at the party.\",\\n  \"BrandsCompanyNamesLogos\": [\"Fiji\"],\\n  \"KeyLocationsAndScenes\": [\"Sydney Harbour\", \"Gathering venue\", \"Boxing gym\", \"Beach\", \"Interview room\"],\\n  \"KeyThemes\": [\"Dating\", \"Marriage\", \"Relationships\", \"First impressions\", \"Expectations\"],\\n  \"PeopleAppearingAndMentioned\": [\\n    \"Jayden, 26, Professional kickboxer, Queensland\",\\n    \"Tim\",\\n    \"Richard\",\\n    \"John\",\\n    \"Lucinda, 43, MC and Wedding Celebrant, New South Wales\",\\n    \"John Aiken\",\\n    \"Tori\",\\n    \"Natasha\",\\n    \"Sara, 29, Nutritionist, New South Wales\"\\n  ]\\n}\\n```'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_response.candidates[0].content.parts[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33ad99d8-cf3f-4111-9b0b-f5a6c6ddd82a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"Category\": \"TV Show\",\n",
      "  \"DetailedDescriptionOfEventsAndConversations\": \"The video begins with Jayden, a 26-year-old professional kickboxer from Queensland, arriving at a gathering. He greets Tim, Richard, and John. Richard introduces himself to Jayden. Richard asks Jayden what he does for a living. Jayden says that kickboxing is his full-time job, training twice a day, six days a week. Jayden explains that he's not what he appears to be, enjoying snuggles and back tickles when he's not fighting. He adds that he's a romantic and doesn't have a specific type, looking for someone with a good heart. Lucinda, a 43-year-old MC and wedding celebrant from New South Wales, arrives at the same gathering, greeting the other women: Tori and Natasha. Lucinda says that she's looking for a confident man, a great cook who is funny and generous of spirit. She unfolds a scroll, revealing her detailed list of desired qualities in a partner, including “handsome” and “spunky,” prompting laughter from her companions. The next scene shows Lucinda conversing with John Aiken. Lucinda says she wants someone who's good with his clothes off, leading to a humorous exchange about “high-functioning erection.”  The scene shifts back to the gathering, where Lucinda discusses her ideal partner with Tori and Natasha. She mentions wanting someone well-established, secure, and confident without a big ego, while Tori expresses her desire for a nerdy guy. Lucinda notes Tori's intellectual nature and need for a challenging partner.  The conversation then shifts to discussing what they've written on their lists, with Lucinda noting “purple” as the color of transcendence, eliciting laughter. Sara, a 29-year-old nutritionist from New South Wales, arrives. She expresses her hopes of walking down the aisle and meeting her future husband.  The video then cuts to another man arriving in a car at the same location. The Sydney skyline is visible in the background. The video then cuts to Sara, a 29-year-old nutritionist from New South Wales, arriving and meeting several other women. It ends with another male arrival at the party.\",\n",
      "  \"BrandsCompanyNamesLogos\": [\"Fiji\"],\n",
      "  \"KeyLocationsAndScenes\": [\"Sydney Harbour\", \"Gathering venue\", \"Boxing gym\", \"Beach\", \"Interview room\"],\n",
      "  \"KeyThemes\": [\"Dating\", \"Marriage\", \"Relationships\", \"First impressions\", \"Expectations\"],\n",
      "  \"PeopleAppearingAndMentioned\": [\n",
      "    \"Jayden, 26, Professional kickboxer, Queensland\",\n",
      "    \"Tim\",\n",
      "    \"Richard\",\n",
      "    \"John\",\n",
      "    \"Lucinda, 43, MC and Wedding Celebrant, New South Wales\",\n",
      "    \"John Aiken\",\n",
      "    \"Tori\",\n",
      "    \"Natasha\",\n",
      "    \"Sara, 29, Nutritionist, New South Wales\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(model_response.candidates[0].content.parts[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "858ac693-7b31-4f18-b4c8-0e13aea00598",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Category': 'TV Show',\n",
       " 'DetailedDescriptionOfEventsAndConversations': \"The video begins with Jayden, a 26-year-old professional kickboxer from Queensland, arriving at a gathering. He greets Tim, Richard, and John. Richard introduces himself to Jayden. Richard asks Jayden what he does for a living. Jayden says that kickboxing is his full-time job, training twice a day, six days a week. Jayden explains that he's not what he appears to be, enjoying snuggles and back tickles when he's not fighting. He adds that he's a romantic and doesn't have a specific type, looking for someone with a good heart. Lucinda, a 43-year-old MC and wedding celebrant from New South Wales, arrives at the same gathering, greeting the other women: Tori and Natasha. Lucinda says that she's looking for a confident man, a great cook who is funny and generous of spirit. She unfolds a scroll, revealing her detailed list of desired qualities in a partner, including “handsome” and “spunky,” prompting laughter from her companions. The next scene shows Lucinda conversing with John Aiken. Lucinda says she wants someone who's good with his clothes off, leading to a humorous exchange about “high-functioning erection.”  The scene shifts back to the gathering, where Lucinda discusses her ideal partner with Tori and Natasha. She mentions wanting someone well-established, secure, and confident without a big ego, while Tori expresses her desire for a nerdy guy. Lucinda notes Tori's intellectual nature and need for a challenging partner.  The conversation then shifts to discussing what they've written on their lists, with Lucinda noting “purple” as the color of transcendence, eliciting laughter. Sara, a 29-year-old nutritionist from New South Wales, arrives. She expresses her hopes of walking down the aisle and meeting her future husband.  The video then cuts to another man arriving in a car at the same location. The Sydney skyline is visible in the background. The video then cuts to Sara, a 29-year-old nutritionist from New South Wales, arriving and meeting several other women. It ends with another male arrival at the party.\",\n",
       " 'BrandsCompanyNamesLogos': ['Fiji'],\n",
       " 'KeyLocationsAndScenes': ['Sydney Harbour',\n",
       "  'Gathering venue',\n",
       "  'Boxing gym',\n",
       "  'Beach',\n",
       "  'Interview room'],\n",
       " 'KeyThemes': ['Dating',\n",
       "  'Marriage',\n",
       "  'Relationships',\n",
       "  'First impressions',\n",
       "  'Expectations'],\n",
       " 'PeopleAppearingAndMentioned': ['Jayden, 26, Professional kickboxer, Queensland',\n",
       "  'Tim',\n",
       "  'Richard',\n",
       "  'John',\n",
       "  'Lucinda, 43, MC and Wedding Celebrant, New South Wales',\n",
       "  'John Aiken',\n",
       "  'Tori',\n",
       "  'Natasha',\n",
       "  'Sara, 29, Nutritionist, New South Wales']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Provided JSON string\n",
    "json_string =  model_response.candidates[0].content.parts[0].text.replace('```json','').replace('```','')\n",
    "# Convert JSON string to a Python dictionary\n",
    "parsed_json = json.loads(json_string, strict=False)\n",
    "\n",
    "parsed_json\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e29d010-37eb-4b5b-901e-e06818d0ba3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text has been successfully exported to output_model1.txt\n"
     ]
    }
   ],
   "source": [
    "# Define the text you want to write to the file\n",
    "text_to_export =json_string\n",
    "\n",
    "# Specify the file name\n",
    "file_name = \"output_model1.txt\"\n",
    "\n",
    "# Write the text to the file\n",
    "with open(file_name, \"w\") as file:\n",
    "    file.write(text_to_export)\n",
    "\n",
    "print(f\"The text has been successfully exported to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b86007e-9dd9-4141-954a-172f27517e69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text has been successfully exported to output_model_original_text1.txt\n"
     ]
    }
   ],
   "source": [
    "# Define the text you want to write to the file\n",
    "text_to_export =model_response.candidates[0].content.parts[0].text\n",
    "\n",
    "# Specify the file name\n",
    "file_name = \"output_model_original_text1.txt\"\n",
    "\n",
    "# Write the text to the file\n",
    "with open(file_name, \"w\") as file:\n",
    "    file.write(text_to_export)\n",
    "\n",
    "print(f\"The text has been successfully exported to {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f277e7-5efd-4264-b9de-6977cc53548d",
   "metadata": {},
   "source": [
    "### Lets test with another model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "15bf62a5-2e91-4df0-a659-ab0a6be6859c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lets change the model\n",
    "\n",
    "generative_multimodal_model= GenerativeModel(\"gemini-1.5-flash-002\")\n",
    "generation_config=GenerationConfig(temperature=1, top_k=40,top_p=0.95,max_output_tokens=8192 , response_mime_type='application/json')\n",
    " \n",
    "safety_settings=  {\n",
    "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    }\n",
    "\n",
    "model_response = generative_multimodal_model.generate_content(\n",
    "                                    contents ,safety_settings=safety_settings,generation_config=generation_config\n",
    "                                   )   \n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "09720c9b-5551-4e87-b569-51e15e6fed68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Category': 'TV Show',\n",
       " 'DetailedDescriptionOfEventsAndConversations': \"The video shows a group of men sitting on a couch in a modern, well-lit room with a city view at night. Jayden, a 26-year-old professional kickboxer from Queensland, enters and introduces himself. Richard comments on Jayden's striking character. Jayden shares that his full-time job is kickboxing, which surprises the others. The scene shifts to Jayden sitting in a boxing gym, talking about his work and softer side. He mentions wanting to have knockouts in front of a crowd. Back at the gathering, the men continue their conversation. Lucinda, a 43-year-old MC and wedding celebrant from New South Wales, arrives in a pink sparkly jacket and matching dress. She greets the other women present. Lucinda shares her thoughts on her ideal partner. The scene transitions to Lucinda sitting on a couch and reading a scroll with notes about the men. She laughs after reading the notes.\",\n",
       " 'BrandsCompanyNamesLogos': [],\n",
       " 'KeyLocationsAndScenes': ['Modern living room with city view',\n",
       "  'Boxing gym',\n",
       "  \"Lucinda's home\",\n",
       "  'Restaurant with city view'],\n",
       " 'KeyThemes': ['First impressions', 'Dating', 'Relationships', 'Personality'],\n",
       " 'PeopleAppearingAndMentioned': ['Jayden, 26, Professional kickboxer, QLD',\n",
       "  'Richard',\n",
       "  'Lucinda, 43, MC & Wedding Celebrant, NSW']}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Provided JSON string\n",
    "json_string =  model_response.candidates[0].content.parts[0].text.replace('```json','').replace('```','')\n",
    "# Convert JSON string to a Python dictionary\n",
    "parsed_json = json.loads(json_string, strict=False)\n",
    "\n",
    "parsed_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "340fd988-2413-433c-8522-467e35c13b5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Category': 'TV Show',\n",
       " 'DetailedDescriptionOfEventsAndConversations': \"The video shows a group of men sitting on a couch in a modern, well-lit room with a city view at night. Jayden, a 26-year-old professional kickboxer from Queensland, enters and introduces himself. Richard comments on Jayden's striking character. Jayden shares that his full-time job is kickboxing, which surprises the others. The scene shifts to Jayden sitting in a boxing gym, talking about his work and softer side. He mentions wanting to have knockouts in front of a crowd. Back at the gathering, the men continue their conversation. Lucinda, a 43-year-old MC and wedding celebrant from New South Wales, arrives in a pink sparkly jacket and matching dress. She greets the other women present. Lucinda shares her thoughts on her ideal partner. The scene transitions to Lucinda sitting on a couch and reading a scroll with notes about the men. She laughs after reading the notes.\",\n",
       " 'BrandsCompanyNamesLogos': [],\n",
       " 'KeyLocationsAndScenes': ['Modern living room with city view',\n",
       "  'Boxing gym',\n",
       "  \"Lucinda's home\",\n",
       "  'Restaurant with city view'],\n",
       " 'KeyThemes': ['First impressions', 'Dating', 'Relationships', 'Personality'],\n",
       " 'PeopleAppearingAndMentioned': ['Jayden, 26, Professional kickboxer, QLD',\n",
       "  'Richard',\n",
       "  'Lucinda, 43, MC & Wedding Celebrant, NSW']}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Provided JSON string\n",
    "json_string =  model_response.candidates[0].content.parts[0].text.replace('```json','').replace('```','')\n",
    "# Convert JSON string to a Python dictionary\n",
    "parsed_json = json.loads(json_string, strict=False)\n",
    "\n",
    "parsed_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b0209bdf-f7fd-4d3f-a1e4-eaa31098690d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text has been successfully exported to output_model2.txt\n"
     ]
    }
   ],
   "source": [
    "# Define the text you want to write to the file\n",
    "text_to_export =json_string\n",
    "\n",
    "# Specify the file name\n",
    "file_name = \"output_model2.txt\"\n",
    "\n",
    "# Write the text to the file\n",
    "with open(file_name, \"w\") as file:\n",
    "    file.write(text_to_export)\n",
    "\n",
    "print(f\"The text has been successfully exported to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "22d89106-df3d-4682-96bd-d858824566ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text has been successfully exported to output_model_original_text2.txt\n"
     ]
    }
   ],
   "source": [
    "# Define the text you want to write to the file\n",
    "text_to_export =model_response.candidates[0].content.parts[0].text\n",
    "\n",
    "# Specify the file name\n",
    "file_name = \"output_model_original_text2.txt\"\n",
    "\n",
    "# Write the text to the file\n",
    "with open(file_name, \"w\") as file:\n",
    "    file.write(text_to_export)\n",
    "\n",
    "print(f\"The text has been successfully exported to {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61570eb2-fa93-4eb3-8804-f2ed5237d253",
   "metadata": {},
   "source": [
    "### compare the result of the two model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f2189952-5897-4278-81c6-58da9e0bf361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('output_model1.txt', 'r') as file:\n",
    "    response1 = json.dumps(json.load(file))\n",
    "with open('output_model2.txt', 'r') as file:\n",
    "    response2 = json.dumps(json.load(file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "89944ead-82b1-4847-9045-fd0444dab06d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_autorater_response(metric_prompt: list) -> dict:\n",
    "    metric_response_schema = {\n",
    "        \"type\": \"OBJECT\",\n",
    "        \"properties\": {\n",
    "            \"score\": {\"type\": \"NUMBER\"},\n",
    "            \"explanation\": {\"type\": \"STRING\"},\n",
    "        },\n",
    "        \"required\": [\"score\", \"explanation\"],\n",
    "    }\n",
    "\n",
    "    autorater = GenerativeModel(\n",
    "        \"gemini-1.5-pro\",\n",
    "        generation_config=GenerationConfig(\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema=metric_response_schema,\n",
    "        ),\n",
    "        safety_settings={\n",
    "            HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    response = autorater.generate_content(metric_prompt)\n",
    "\n",
    "    response_json = {}\n",
    "\n",
    "    if response.candidates and len(response.candidates) > 0:\n",
    "        candidate = response.candidates[0]\n",
    "        if (\n",
    "            candidate.content\n",
    "            and candidate.content.parts\n",
    "            and len(candidate.content.parts) > 0\n",
    "        ):\n",
    "            part = candidate.content.parts[0]\n",
    "            if part.text:\n",
    "                response_json = json.loads(part.text)\n",
    "\n",
    "    return response_json\n",
    "\n",
    "def custom_coverage_fn(instance):\n",
    "\n",
    "    video_uri = instance[\"reference\"][\"video_uri\"]\n",
    "    video_metadata = instance[\"reference\"][\"video_metadata\"]\n",
    "    response = instance[\"response\"]\n",
    "\n",
    "    eval_instruction_template = \"\"\"\n",
    "  # Instruction\n",
    "  You are an expert evaluator. Your task is to evaluate the quality of the responses generated by AI models. We will provide you with the user prompt,  and an AI-generated responses, video and the segment (in seconds) for which this response is generated.\n",
    "  You should first read the user input carefully for analyzing the task, then look into video segment, and then evaluate the quality of the responses based on the Criteria provided in the Evaluation section below.\n",
    "  You will assign the response a rating following the Rating Rubric and Evaluation Steps. Give step by step explanations for your rating, and only choose ratings from the Rating Rubric.\n",
    "\n",
    "  # Evaluation\n",
    "  ## Metric Definition\n",
    "  You will be assessing coverage, which measures the ability to provide a detailed response based on a the given video segment and requested properties.\n",
    "  \n",
    "\n",
    "  ## Criteria\n",
    "  Coverage: It is the quality of capturing all required detail for each requested property.\n",
    "  In the context of video content capturing, it refers to the way that all the details of the following properties are captured and presented throughly:\n",
    "  \n",
    "  - Category \n",
    "  - Detailed Description Of Events And Conversations \n",
    "  - Brands,CompanyNames, and Logos \n",
    "  - KeyLocations And Scenes\" \n",
    "  - Key Themes \n",
    "  - People Appearing And Mentioned \n",
    "  \n",
    "  This AI-generated responses will be used for data retrieval. So, it has to be able to capture all the details of a scene.\n",
    "\n",
    "  ## Rating Rubric\n",
    "  5: (Perfectly Aligned) The details of the video segment is captured properly for all the requested properties thoroughly.\n",
    "  4: (Highly Aligned) The descriptions captured for each property generally supports the details in the video segment and can be used for data retrieval.\n",
    "  3: (Moderately Aligned) The descriptions captured for each property is captured well, but there might be minor inconsistencies or missed details, and the response is broadly relevant but not entirely specific.\n",
    "  2: (Poorly Aligned)  The descriptions captured for each property has significant inconsistencies with the video segment, raising doubts about the validity and quality of text to be usable for data retrieval.\n",
    "  1: (Misaligned) The descriptions captured for each property has major inconsistencies with the video segment and many information and details are missed casuing a very poor quality of text for data retrieval.\n",
    "\n",
    "  ## Evaluation Steps\n",
    "  STEP 1:  Assess User Instruction:  Carefully read the user input prompt to understand the user's request and requested information.\n",
    "  STEP 2:  Analyze Video Segment: Examine the video segment for each requested property to to make sure all the requested information are captured in detail.\n",
    "  STEP 3: Evaluate Accuracy:  For each requested property, Check if the generated response correctly identifies the information and details described in the video segment.\n",
    "  STEP 4:  Identify Inconsistencies: for each requested property, look for any discrepancies between the video segment details and the captured information in the AI-generated responses. For example, if any information is missed, or not captured right.\n",
    "  STEP 5:  Determine Overall Coverage: Based on the previous steps, assign a coverage score using the 1-5 rubric.  Consider the severity of any inconsistencies and their potential impact on the data retrieval.\n",
    "  \"\"\"\n",
    " \n",
    "    # generate the eval\n",
    "    evaluation_prompt = [\n",
    "        eval_instruction_template,       \n",
    "        \"VIDEO URI: \",\n",
    "        video_uri,\n",
    "        \"VIDEO METADATA: \",\n",
    "        video_metadata,\n",
    "        \"GENERATED RESPONSE: \",\n",
    "        response,\n",
    "    ]\n",
    "\n",
    "   \n",
    "    \n",
    "    evaluation_response = get_autorater_response(evaluation_prompt)\n",
    "    return {\n",
    "       \"custom_coverage\":  evaluation_response.get(\"score\", \"\"),\n",
    "         \"explanation\": evaluation_response.get(\"explanation\", \"\") \n",
    "    }\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1a7a32c9-7d05-41b4-b790-21456eae073a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "context = [\n",
    "    {\n",
    "        \"video_uri\": \"gs://raw_nine_files/vlt_video_extract/MAAT/MAAT2024_1_A_HBB.mp4\",\n",
    "        \"video_metadata\":json.dumps({\"start_offset\": {\"seconds\": start, \"nanos\": 0}, \"end_offset\": {\"seconds\": end, \"nanos\": 0}}, indent=2)\n",
    "    }\n",
    "]\n",
    "\n",
    "generated_response = [\n",
    "    response1,\n",
    "    response2\n",
    "]\n",
    "\n",
    "eval_dataset = pd.DataFrame(\n",
    "    {\n",
    "        \"instruction\": video_description_prompt,\n",
    "        \"context\":[None]*len(generated_response) ,\n",
    "        \"response\": generated_response,\n",
    "        \"reference\":context*len(generated_response) ,\n",
    "    \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb1712-d0df-466f-9f82-177db133b61b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "606fe947-aa69-4de5-b737-c1bd9ee24769",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your task is to provide a comprehensive descri...</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"Category\": \"TV Show\", \"DetailedDescriptionOf...</td>\n",
       "      <td>{'video_uri': 'gs://raw_nine_files/vlt_video_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Your task is to provide a comprehensive descri...</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"Category\": \"TV Show\", \"DetailedDescriptionOf...</td>\n",
       "      <td>{'video_uri': 'gs://raw_nine_files/vlt_video_e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction context  \\\n",
       "0  Your task is to provide a comprehensive descri...    None   \n",
       "1  Your task is to provide a comprehensive descri...    None   \n",
       "\n",
       "                                            response  \\\n",
       "0  {\"Category\": \"TV Show\", \"DetailedDescriptionOf...   \n",
       "1  {\"Category\": \"TV Show\", \"DetailedDescriptionOf...   \n",
       "\n",
       "                                           reference  \n",
       "0  {'video_uri': 'gs://raw_nine_files/vlt_video_e...  \n",
       "1  {'video_uri': 'gs://raw_nine_files/vlt_video_e...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "70f09b33-054f-42ec-9c52-f25ef5a7f1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.evaluation import CustomMetric, EvalTask\n",
    "\n",
    "custom_coverage_metric = CustomMetric(\n",
    "    name=\"custom_coverage\",\n",
    "    metric_function=custom_coverage_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2c5db688-953a-4c8a-9660-3f46c225d4b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = [custom_coverage_metric]\n",
    "\n",
    "experiment_name = \"eval-multimodal-metric\"\n",
    "\n",
    "eval_task = EvalTask(\n",
    "    dataset=eval_dataset,\n",
    "    metrics=metrics,\n",
    "    experiment=experiment_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7917ddd0-b06f-4dc9-be2c-00ac71cd821e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-c8b33bac-b7af-422d-82f3-848975e802de\" href=\"#view-view-vertex-resource-c8b33bac-b7af-422d-82f3-848975e802de\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-c8b33bac-b7af-422d-82f3-848975e802de');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/eval-multimodal-metric/runs?project=nine-quality-test');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/eval-multimodal-metric/runs?project=nine-quality-test', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/494586852359/locations/us-central1/metadataStores/default/contexts/eval-multimodal-metric-08e02d44-b9cc-40f8-8a73-af1fbe869fa8 to Experiment: eval-multimodal-metric\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-53d8bd08-8bd7-47a4-9a08-9e6009317f01\" href=\"#view-view-vertex-resource-53d8bd08-8bd7-47a4-9a08-9e6009317f01\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment Run</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-53d8bd08-8bd7-47a4-9a08-9e6009317f01');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/eval-multimodal-metric/runs/eval-multimodal-metric-08e02d44-b9cc-40f8-8a73-af1fbe869fa8?project=nine-quality-test');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/eval-multimodal-metric/runs/eval-multimodal-metric-08e02d44-b9cc-40f8-8a73-af1fbe869fa8?project=nine-quality-test', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics with a total of 2 Vertex Gen AI Evaluation Service API requests.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:07<00:00,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 2 metric requests are successfully computed.\n",
      "Evaluation Took:7.35588538297452 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = eval_task.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "789599ed-1332-462b-ba7d-d9cfeae1516b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Evaluation Results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Summary Metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_count</th>\n",
       "      <th>custom_coverage/mean</th>\n",
       "      <th>custom_coverage/std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_count  custom_coverage/mean  custom_coverage/std\n",
       "0        2.0                   2.0                  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Row-based Metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>custom_coverage/score</th>\n",
       "      <th>custom_coverage/explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your task is to provide a comprehensive descri...</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"Category\": \"TV Show\", \"DetailedDescriptionOf...</td>\n",
       "      <td>{'video_uri': 'gs://raw_nine_files/vlt_video_e...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The response captures some accurate details ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Your task is to provide a comprehensive descri...</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"Category\": \"TV Show\", \"DetailedDescriptionOf...</td>\n",
       "      <td>{'video_uri': 'gs://raw_nine_files/vlt_video_e...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The response captures some accurate details ab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction context  \\\n",
       "0  Your task is to provide a comprehensive descri...    None   \n",
       "1  Your task is to provide a comprehensive descri...    None   \n",
       "\n",
       "                                            response  \\\n",
       "0  {\"Category\": \"TV Show\", \"DetailedDescriptionOf...   \n",
       "1  {\"Category\": \"TV Show\", \"DetailedDescriptionOf...   \n",
       "\n",
       "                                           reference custom_coverage/score  \\\n",
       "0  {'video_uri': 'gs://raw_nine_files/vlt_video_e...                   2.0   \n",
       "1  {'video_uri': 'gs://raw_nine_files/vlt_video_e...                   2.0   \n",
       "\n",
       "                         custom_coverage/explanation  \n",
       "0  The response captures some accurate details ab...  \n",
       "1  The response captures some accurate details ab...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "response:{\"Category\": \"TV Show\", \"DetailedDescriptionOfEventsAndConversations\": \"The video shows a group of men sitting on a couch in a modern, well-lit room with a city view at night. Jayden, a 26-year-old professional kickboxer from Queensland, enters and introduces himself. Richard comments on Jayden's striking character. Jayden shares that his full-time job is kickboxing, which surprises the others. The scene shifts to Jayden sitting in a boxing gym, talking about his work and softer side. He mentions wanting to have knockouts in front of a crowd. Back at the gathering, the men continue their conversation. Lucinda, a 43-year-old MC and wedding celebrant from New South Wales, arrives in a pink sparkly jacket and matching dress. She greets the other women present. Lucinda shares her thoughts on her ideal partner. The scene transitions to Lucinda sitting on a couch and reading a scroll with notes about the men. She laughs after reading the notes.\", \"BrandsCompanyNamesLogos\": [], \"KeyLocationsAndScenes\": [\"Modern living room with city view\", \"Boxing gym\", \"Lucinda's home\", \"Restaurant with city view\"], \"KeyThemes\": [\"First impressions\", \"Dating\", \"Relationships\", \"Personality\"], \"PeopleAppearingAndMentioned\": [\"Jayden, 26, Professional kickboxer, QLD\", \"Richard\", \"Lucinda, 43, MC & Wedding Celebrant, NSW\"]}"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "custom_coverage/score:2.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "custom_coverage/explanation:The response captures some accurate details about the video segment, such as the introductions of Jayden and Lucinda and their professions. However, it misses or misrepresents other crucial information. For example, the video doesn't show Lucinda's home, and the detailed description doesn't accurately reflect the conversations happening. The 'Key Locations and Scenes' and 'Detailed Description of Events and Conversations' are poorly aligned with the actual video content."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title\n",
    "import json\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, Markdown, display\n",
    "\n",
    "logging.getLogger(\"urllib3.connectionpool\").setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "\n",
    "def display_eval_result(\n",
    "    eval_result: dict | object,\n",
    "    title: str | None = None,\n",
    "    metrics: list[str] | None = None,\n",
    ") -> None:\n",
    "    \"\"\"Display the evaluation results.\"\"\"\n",
    "    summary_metrics, metrics_table = (\n",
    "        eval_result.summary_metrics,\n",
    "        eval_result.metrics_table,\n",
    "    )\n",
    "\n",
    "    metrics_df = pd.DataFrame.from_dict(summary_metrics, orient=\"index\").T\n",
    "    if metrics:\n",
    "        metrics_df = metrics_df.filter(\n",
    "            [\n",
    "                metric\n",
    "                for metric in metrics_df.columns\n",
    "                if any(selected_metric in metric for selected_metric in metrics)\n",
    "            ]\n",
    "        )\n",
    "        metrics_table = metrics_table.filter(\n",
    "            [\n",
    "                metric\n",
    "                for metric in metrics_table.columns\n",
    "                if any(selected_metric in metric for selected_metric in metrics)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    if title:\n",
    "        # Display the title with Markdown for emphasis\n",
    "        display(Markdown(f\"## {title}\"))\n",
    "    # Display the summary metrics DataFrame\n",
    "    display(Markdown(\"### Summary Metrics\"))\n",
    "    display(metrics_df)\n",
    "    # Display the metrics table DataFrame\n",
    "    display(Markdown(\"### Row-based Metrics\"))\n",
    "    display(metrics_table)\n",
    "\n",
    "\n",
    "def display_explanations(\n",
    "    eval_result: dict | object, metrics: list[str] | None = None, n: int = 1\n",
    ") -> None:\n",
    "    \"\"\"Display the explanations.\"\"\"\n",
    "    style = \"white-space: pre-wrap; width: 1500px; overflow-x: auto;\"\n",
    "    metrics_table = eval_result.metrics_table\n",
    "    df = metrics_table.sample(n=n)\n",
    "\n",
    "    if metrics:\n",
    "        df = df.filter(\n",
    "            [\"response\", \"baseline_model_response\"]\n",
    "            + [\n",
    "                metric\n",
    "                for metric in df.columns\n",
    "                if any(selected_metric in metric for selected_metric in metrics)\n",
    "            ]\n",
    "        )\n",
    "    for index, row in df.iterrows():\n",
    "        for col in df.columns:\n",
    "            display(HTML(f\"{col}:{row[col]}\"))\n",
    "        display(HTML(\"\"))\n",
    "     \n",
    "    \n",
    "\n",
    "display_eval_result(eval_result, title=\"Evaluation Results\")\n",
    "display_explanations(eval_result, metrics=[\"custom_coverage\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "42ab16a1-3116-4fae-8e16-5f21287f3132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_result.metrics_table.to_csv('test20250117.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "789c0dca-8cb8-4815-b502-c4941854a2e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The response captures some accurate details about events and conversations, but it also includes information not present within the provided video segment. For example, the response mentions Jayden\\'s training regimen, Lucinda\\'s desire for a \"high-functioning erection,\" and Tori\\'s preference for a nerdy guy, none of which are depicted or discussed within the given timeframe. Additionally, some key details from the video are missing, such as the conversation about Sara wanting tattoos and how many people each of them are meeting.  The location identification is inaccurate, as the Sydney skyline is not visible in the video segment.  Also, there is no mention of Fiji water in the video. Lastly, while it accurately lists some individuals present, it omits several others who appear on screen. This mix of fabricated details and omission of existing information results in a poorly aligned response.',\n",
       " \"The response captures some accurate details about the video segment, such as the introductions of Jayden and Lucinda and their professions. However, it misses or misrepresents other crucial information. For example, the video doesn't show Lucinda's home, and the detailed description doesn't accurately reflect the conversations happening. The 'Key Locations and Scenes' and 'Detailed Description of Events and Conversations' are poorly aligned with the actual video content.\"]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result.metrics_table['custom_coverage/explanation'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "08f0866a-6b5d-4c04-a764-f9d0dbd110a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"Category\": \"TV Show\", \"DetailedDescriptionOfEventsAndConversations\": \"The video begins with Jayden, a 26-year-old professional kickboxer from Queensland, arriving at a gathering. He greets Tim, Richard, and John. Richard introduces himself to Jayden. Richard asks Jayden what he does for a living. Jayden says that kickboxing is his full-time job, training twice a day, six days a week. Jayden explains that he\\'s not what he appears to be, enjoying snuggles and back tickles when he\\'s not fighting. He adds that he\\'s a romantic and doesn\\'t have a specific type, looking for someone with a good heart. Lucinda, a 43-year-old MC and wedding celebrant from New South Wales, arrives at the same gathering, greeting the other women: Tori and Natasha. Lucinda says that she\\'s looking for a confident man, a great cook who is funny and generous of spirit. She unfolds a scroll, revealing her detailed list of desired qualities in a partner, including \\\\u201chandsome\\\\u201d and \\\\u201cspunky,\\\\u201d prompting laughter from her companions. The next scene shows Lucinda conversing with John Aiken. Lucinda says she wants someone who\\'s good with his clothes off, leading to a humorous exchange about \\\\u201chigh-functioning erection.\\\\u201d  The scene shifts back to the gathering, where Lucinda discusses her ideal partner with Tori and Natasha. She mentions wanting someone well-established, secure, and confident without a big ego, while Tori expresses her desire for a nerdy guy. Lucinda notes Tori\\'s intellectual nature and need for a challenging partner.  The conversation then shifts to discussing what they\\'ve written on their lists, with Lucinda noting \\\\u201cpurple\\\\u201d as the color of transcendence, eliciting laughter. Sara, a 29-year-old nutritionist from New South Wales, arrives. She expresses her hopes of walking down the aisle and meeting her future husband.  The video then cuts to another man arriving in a car at the same location. The Sydney skyline is visible in the background. The video then cuts to Sara, a 29-year-old nutritionist from New South Wales, arriving and meeting several other women. It ends with another male arrival at the party.\", \"BrandsCompanyNamesLogos\": [\"Fiji\"], \"KeyLocationsAndScenes\": [\"Sydney Harbour\", \"Gathering venue\", \"Boxing gym\", \"Beach\", \"Interview room\"], \"KeyThemes\": [\"Dating\", \"Marriage\", \"Relationships\", \"First impressions\", \"Expectations\"], \"PeopleAppearingAndMentioned\": [\"Jayden, 26, Professional kickboxer, Queensland\", \"Tim\", \"Richard\", \"John\", \"Lucinda, 43, MC and Wedding Celebrant, New South Wales\", \"John Aiken\", \"Tori\", \"Natasha\", \"Sara, 29, Nutritionist, New South Wales\"]}',\n",
       " '{\"Category\": \"TV Show\", \"DetailedDescriptionOfEventsAndConversations\": \"The video shows a group of men sitting on a couch in a modern, well-lit room with a city view at night. Jayden, a 26-year-old professional kickboxer from Queensland, enters and introduces himself. Richard comments on Jayden\\'s striking character. Jayden shares that his full-time job is kickboxing, which surprises the others. The scene shifts to Jayden sitting in a boxing gym, talking about his work and softer side. He mentions wanting to have knockouts in front of a crowd. Back at the gathering, the men continue their conversation. Lucinda, a 43-year-old MC and wedding celebrant from New South Wales, arrives in a pink sparkly jacket and matching dress. She greets the other women present. Lucinda shares her thoughts on her ideal partner. The scene transitions to Lucinda sitting on a couch and reading a scroll with notes about the men. She laughs after reading the notes.\", \"BrandsCompanyNamesLogos\": [], \"KeyLocationsAndScenes\": [\"Modern living room with city view\", \"Boxing gym\", \"Lucinda\\'s home\", \"Restaurant with city view\"], \"KeyThemes\": [\"First impressions\", \"Dating\", \"Relationships\", \"Personality\"], \"PeopleAppearingAndMentioned\": [\"Jayden, 26, Professional kickboxer, QLD\", \"Richard\", \"Lucinda, 43, MC & Wedding Celebrant, NSW\"]}']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result.metrics_table['response'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4a48ab-a203-4c91-a19b-ad53183ede17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
