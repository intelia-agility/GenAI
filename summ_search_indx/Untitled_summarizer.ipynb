{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71f2fea-6ba4-463d-8850-8518efa6b03d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import VertexAI as langchain_vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026458de-69fd-44c8-8da1-8086a0214a23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from langchain_google_community import BigQueryLoader\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "#from langchain.llms import VertexAI as langchain_vertexai\n",
    "from langchain_google_vertexai import VertexAI as langchain_vertexai\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pathlib import Path as p\n",
    "import pandas as pd\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n",
    "\n",
    "\n",
    "vertex_llm_text = langchain_vertexai(model_name=\"gemini-1.5-pro-002\")\n",
    "generative_multimodal_model= GenerativeModel(\"gemini-1.5-pro-002\")\n",
    "\n",
    "\n",
    "def estimate_token_length(text, model=\"gpt2\"):\n",
    "    \"\"\"Estimates the token length of a given text using a specified model.\n",
    "\n",
    "      Args:\n",
    "        text: The input text.\n",
    "        model: The model to use for tokenization (default: \"gpt2\").\n",
    "\n",
    "      Returns:\n",
    "        The estimated number of tokens.\n",
    "      \"\"\"\n",
    "\n",
    "  \n",
    "    enc = tiktoken.get_encoding(model)  \n",
    "\n",
    "    # Tokenize the text and count tokens\n",
    "    tokens = enc.encode(text)\n",
    "    token_count = len(tokens)\n",
    "    return token_count\n",
    "\n",
    "def get_data(source_query_str: str=None,metadata_columns: str=None,page_content_columns: str=None, project_id: str=None , return_text: bool=True):\n",
    "    \n",
    "    \"\"\"Load data from big query\n",
    "\n",
    "      Args:\n",
    "        str source_query_str:  The query string to fetch the data from bigquery\n",
    "        list[str] metadata_columns:  list of metadata column names\n",
    "        list[str] page_content_columns:  list of content column names  \n",
    "        str project_id: project id\n",
    "        bool return_text: returns the content columns description\n",
    "      Returns:\n",
    "          list[langchain_core.documents.base.Document] documents: langchain documents\n",
    "          \n",
    "      \"\"\"\n",
    "    \n",
    "    loader = BigQueryLoader(\n",
    "            query=source_query_str, project=project_id, metadata_columns=metadata_columns, page_content_columns=page_content_columns\n",
    "        )\n",
    "    documents = []\n",
    "    all_texts=[]\n",
    "    documents.extend(loader.load())\n",
    "    if return_text:  \n",
    "         all_texts=[doc.page_content.replace('description:',\"\",1) for doc in documents]\n",
    "        \n",
    "    return documents, '\\n'.join(all_texts)\n",
    "    \n",
    " \n",
    "def summarize_docs(documents: list[object],question_prompt_template: str=\"\", refine_prompt_template: str=\"\" ,is_token_limit_exceeded: bool=False ):\n",
    "    \n",
    "    \"\"\"summarizes the input documents\n",
    "\n",
    "      Args:\n",
    "        list[object] documents:  list of langchain documents\n",
    "        str question_prompt_template:  string question prompt template. \n",
    "        str refine_prompt_template:  string refine prompt template in the case that we need to use refine method\n",
    "        bool is_token_limit_exceeded:  boolean indicating wheather or not the token limit is exceeded.\n",
    "      Returns:\n",
    "         dict : summary result\n",
    "         \n",
    "      \"\"\"\n",
    "       \n",
    "    question_prompt = PromptTemplate(template=question_prompt_template, input_variables=[\"text\"]) \n",
    "    \n",
    "    if not is_token_limit_exceeded:        \n",
    "        #if the token limit is in the context window range, use a stuffing method for summary\n",
    "        chain = load_summarize_chain(vertex_llm_text, chain_type=\"stuff\", \n",
    "                                     prompt=question_prompt)\n",
    "        \n",
    "    else:     \n",
    "        #otherwise use a refine summarization method\n",
    "        refine_prompt = PromptTemplate(input_variables=[\"existing_answer\", \"text\"], template=refine_prompt_template)\n",
    "              \n",
    "        chain = load_summarize_chain(\n",
    "            vertex_llm_text,\n",
    "            chain_type=\"refine\",\n",
    "            question_prompt=question_prompt,\n",
    "            refine_prompt=refine_prompt,\n",
    "            return_intermediate_steps=True,\n",
    "          )\n",
    "        \n",
    "    return chain.invoke(documents)\n",
    "\n",
    "def  get_query_string (assets: str=\"\"):\n",
    "    \"\"\"set query string \n",
    "      Args:         \n",
    "        str assets:  comma separated string of all requested assets     \n",
    "      Returns:\n",
    "         str source_query_str : string query for loading data from biquery\n",
    "         \n",
    "      \"\"\"\n",
    "     #source_query_str=f\"select distinct combined_id,unique_id,content, chunk, trim(concat(ifnull(headline,''), CHR(10),  description)) as description from `nine-quality-test.vlt_media_embeddings_integration.vlt_all_media_content_text_embeddings` where asset_id in {assets} order by unique_id, chunk asc \"\n",
    "    source_query_str= f\"\"\"SELECT          asset_id,                  \n",
    "                    STRING_AGG(description, '\\\\n' ) \n",
    "                    OVER (PARTITION BY asset_id ORDER BY ifnull(startOffset_seconds,0) ASC , chunk ASC) AS full_description,\n",
    "                    IDX\n",
    "              FROM (\n",
    "                    SELECT  asset_id,startOffset_seconds, CHUNK, \n",
    "                    \n",
    "                    CASE WHEN chunk=0 \n",
    "                         THEN TRIM(CONCAT(IFNULL(headline,''), CHR(10),  description))  \n",
    "                         ELSE description \n",
    "                    END AS description,\n",
    "                    ROW_NUMBER() OVER (PARTITION BY asset_id ORDER BY startOffset_seconds desc, chunk desc) AS IDX,\n",
    "                    FROM `vlt_media_embeddings_integration.vlt_all_media_content_text_embeddings` where asset_id in ({assets})\n",
    "             )\n",
    "           WHERE IDX=1\n",
    "        \"\"\"\n",
    "    return source_query_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c848aa6f-839e-440b-9927-0e67ae92e070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def  get_query_string (assets: str=\"\"):\n",
    "    \"\"\"set query string \n",
    "      Args:         \n",
    "        str assets:  comma separated string of all requested assets     \n",
    "      Returns:\n",
    "         str source_query_str : string query for loading data from biquery\n",
    "         \n",
    "      \"\"\"\n",
    "     #source_query_str=f\"select distinct combined_id,unique_id,content, chunk, trim(concat(ifnull(headline,''), CHR(10),  description)) as description from `nine-quality-test.vlt_media_embeddings_integration.vlt_all_media_content_text_embeddings` where asset_id in {assets} order by unique_id, chunk asc \"\n",
    "    source_query_str= f\"\"\"SELECT          asset_id,                  \n",
    "                    STRING_AGG(description, '\\\\n' ) \n",
    "                    OVER (PARTITION BY asset_id ORDER BY ifnull(startOffset_seconds,0) ASC , chunk ASC) AS full_description,\n",
    "                    IDX\n",
    "              FROM (\n",
    "                    SELECT  asset_id,startOffset_seconds, CHUNK, \n",
    "                    CASE WHEN chunk=0 \n",
    "                         THEN TRIM(CONCAT(IFNULL(headline,''), CHR(10),  description))  \n",
    "                         ELSE description \n",
    "                    END AS description,\n",
    "                    ROW_NUMBER() OVER (PARTITION BY asset_id ORDER BY startOffset_seconds desc) AS IDX,\n",
    "                    FROM `vlt_media_embeddings_integration.vlt_all_media_content_text_embeddings` where asset_id in ({assets})\n",
    "             )\n",
    "           WHERE IDX=1\n",
    "        \"\"\"\n",
    "    return source_query_str\n",
    "    \n",
    "def get_prompt(action_type: str=\"\",platform: str=\"\",persona_text: str=\"\", input_text:str=\"\", Language:str=\"\"):\n",
    "    \n",
    "    \"\"\"set prompt according to the requested action\n",
    "      Args:         \n",
    "        str action_type:  the type of action needs to be done\n",
    "        str platform: platform name for off platform posts \n",
    "        str persona_text: for persona based summaries \n",
    "      Returns:\n",
    "         str question_prompt_template : the main prompt for the given action \n",
    "         str refine_prompt_template:  the second level prompt for refinement, in the case that the context is too long, we have to use refinement method.\n",
    "         \n",
    "      \"\"\"\n",
    " \n",
    "    question_prompt_template=\"\"\n",
    "    refine_prompt_template=\"\"\n",
    "    \n",
    "    if action_type==\"Summary\" or action_type==\"Summary_Persona\":\n",
    "            #this is the main prompt for summary\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide a summary of the following text\"\"\"+persona_text+\"\"\". Your result must be detailed and at least 2 paragraphs. \n",
    "                When summarizing, directly dive into the narrative or descriptions from the text without using introductory phrases like 'In this passage'. \n",
    "                Directly address the main events, characters, and themes, encapsulating the essence and significant details from the text in a flowing narrative. \n",
    "                The goal is to present a unified view of the content, continuing the story seamlessly as if the passage naturally progresses into the summary.\n",
    "\n",
    "                TEXT: {text}\n",
    "                SUMMARY:\n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final summary. Your task is to combine and refine these summaries into a final, comprehensive summary that covers all key events, characters, themes, and details.\\n\"\n",
    "                \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing summary\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original summary\"\n",
    "                \"If the context isn't useful, return the original summary.\"\n",
    "            )\n",
    "    elif action_type==\"HeadLine\":  \n",
    "\n",
    "        #this is the main prompt for headline\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide a one line headline of the following text. \n",
    "\n",
    "                TEXT: {text}\n",
    "                HEADLINE:\n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final headline. Your task is to combine and refine these headlines into a final, comprehensive headline that covers all details.\\n\"\n",
    "                \"We have provided an existing headline up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing headline\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original headline\"\n",
    "                \"If the context isn't useful, return the original headline.\"\n",
    "            )\n",
    "    elif action_type==\"OffPlatformPost\"  and platform=='Twitter':\n",
    "               #this is the main prompt for social media post\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide a tweet that that’s catchy, concise, and fits within 280 characters. Make sure to highlight the key message, and encourage engagement with a question or call to action.\n",
    "\n",
    "                TEXT: {text}\n",
    "                Tweet: \n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final tweet. Your task is to combine and refine these tweets into a final, comprehensive tweet that covers all details, is catchy, concise, fits within 280 characters, and encourage engagement with a question or call to action.\\n\"\n",
    "                \"We have provided an existing tweet up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing tweet\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original tweet\"\n",
    "                \"If the context isn't useful, return the original tweet.\"\n",
    "            )\n",
    "    elif action_type==\"OffPlatformPost\" and platform=='Instagram':         \n",
    "            #this is the main prompt for social media post\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide  into an engaging Instagram post. Craft a short, attention-grabbing caption that highlights the main point. Use emojis to make it lively, and end with a question or call to action to spark conversation in the comments.\n",
    "\n",
    "                TEXT: {text}\n",
    "                Instagram Post: \n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final tweet. Your task is to combine and refine these Instagram posts into a final, comprehensive post that covers all details, crafts a short, attention-grabbing caption that highlights the main point. Use emojis to make it lively, and end with a question or call to action to spark conversation in the comments.\\n\"\n",
    "                \"We have provided an existing post up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing post\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original post\"\n",
    "                \"If the context isn't useful, return the original post.\"\n",
    "            )\n",
    "    elif action_type==\"Translation\":\n",
    "            #this is the main prompt for social media post\n",
    "            question_prompt_template = f\"\"\"Translate the following text into {Language}.  Make sure to preserve the meaning, tone, and style of the original text, while ensuring it is natural and fluent in {Language}.\n",
    "            Text:\\n \n",
    "              {input_text}\\n\n",
    "            Only provide a single response.\n",
    "            \"\"\"\n",
    "      \n",
    "            \n",
    "    return question_prompt_template,refine_prompt_template\n",
    "\n",
    "def get_summary(assets:str=\"\",action_type:str=\"\",platform:str=\"\",persona_text:str=\"\",project_id:str=\"\",context_window_limit: int=2000000):\n",
    "    \n",
    "    \"\"\"get summary according to the action type requested\n",
    "      Args:         \n",
    "        str assets:  comma separate string including all assets\n",
    "        str action_type: requested action\n",
    "        str persona_text: for persona based summaries \n",
    "        str platform: for off platform based posts\n",
    "        str project_id: project id\n",
    "        int context_window_limit: context window limit for the llm model\n",
    "      Returns:\n",
    "         str :output summary \n",
    "      \"\"\"\n",
    "    \n",
    "    #set query string\n",
    "    source_query_str= get_query_string(assets)\n",
    "    \n",
    "    #set prompts\n",
    "    question_prompt_template, refine_prompt_template=get_prompt(action_type=action_type,platform=platform,persona_text=persona_text)\n",
    "    \n",
    "    #set metadata and content columns\n",
    "    metadata_columns=[\"asset_id\"]\n",
    "    page_content_columns=[\"full_description\"]\n",
    "    \n",
    "    #load data from biqquery\n",
    "    documents,all_texts=get_data(source_query_str=source_query_str,metadata_columns=metadata_columns,page_content_columns=page_content_columns, project_id=project_id,return_text=True)\n",
    "\n",
    "    # Estimate the token length\n",
    "    estimated_token_length = estimate_token_length(all_texts,'cl100k_base') #cl100k_base\n",
    "    \n",
    "    message=\"\"\n",
    "    is_token_limit_exceeded=False\n",
    "    if estimated_token_length > context_window_limit:\n",
    "      message=\"Your text is too long for the Gemini 1.5 Pro context window. We are trying to chunk and return the result.\"\n",
    "      is_token_limit_exceeded=True\n",
    "      summary=summarize_docs(documents=documents,question_prompt_template=question_prompt_template,refine_prompt_template=refine_prompt_template,is_token_limit_exceeded=is_token_limit_exceeded )\n",
    "\n",
    "    else:\n",
    "      message=\"Your text fits within the Gemini 1.5 Pro context window.\"\n",
    "      summary=summarize_docs(documents=documents,question_prompt_template=question_prompt_template,is_token_limit_exceeded=is_token_limit_exceeded )\n",
    "        \n",
    "    return summary[\"output_text\"]\n",
    "\n",
    "def get_translation(action_type: str=\"\",input_text: str=\"\",Language:str=\"\"):\n",
    "    \n",
    "    \"\"\" get translation according to the requested language\n",
    "      Args:         \n",
    "        str input_text:  text to be translated\n",
    "        str Language: destination language\n",
    "      \n",
    "      Returns:\n",
    "         str : translated document \n",
    "      \"\"\"\n",
    " \n",
    "    \n",
    "    #set prompts\n",
    "    question_prompt_template, _=get_prompt(action_type=action_type,input_text=input_text,Language=Language)\n",
    "     \n",
    "    generation_config= GenerationConfig(temperature=1, max_output_tokens=8192) \n",
    "    safety_settings=  {\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        }\n",
    "\n",
    "    model_input=[question_prompt_template]\n",
    "        \n",
    "    response = generative_multimodal_model.generate_content(\n",
    "        model_input,\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings, \n",
    "        \n",
    "    )\n",
    "    \n",
    "    result=\"\"\n",
    "    try:\n",
    "        result=response.text\n",
    "    except:\n",
    "        result=\"No translation can be provided.\"\n",
    "        \n",
    " \n",
    "    return result\n",
    " \n",
    "        \n",
    "def func_generate_content(request):\n",
    "    \n",
    "    # Set the Gemini 1.5 Pro context window limit\n",
    "    context_window_limit = 2000000\n",
    "    project_id = \"nine-quality-test\"  # @param {type:\"string\"}\n",
    "    REGION = \"us-central1\"  # @param {type:\"string\"}\n",
    "    assets=\"p5d2tw,p5e9zq,p5e49l\" #comma separated asset_ids  \n",
    "    \n",
    "    assets= ','.join([ \"'\"+ id.strip()+\"'\" for id in assets.split(',')])\n",
    "    action_type=\"Translation\" # could be Summary, Summary_Persona, HeadLine, OffPlatformPost, Translation\n",
    "    persona=\"10-year-old\"\n",
    "    text=\"\"\"\n",
    "    Disney+ has lots of cool shows!  There are funny shows like *Abbott Elementary*, which is about teachers at a school in Philadelphia.  There's also *The Americans*, a show about Russian spies pretending to be a regular family.  *Andor* is like *Star Wars* but for grown-ups.  *Arrested Development* is a hilarious show about a crazy family. *Atlanta* is about two cousins, one a rapper and the other his manager, and what it's like to be Black in America. *The Bear* is about a fancy chef who takes over his family's sandwich shop.  *Bob's Burgers* is a cartoon about a family who runs a burger restaurant. And for something really fun, there's *Buffy the Vampire Slayer*, about a girl who fights vampires! *Desperate Housewives* is about a group of women and all the secrets they keep. *Homeland* is about a CIA agent with mental health challenges.\n",
    "\n",
    "There are also shows with lots of episodes like *How I Met Your Mother*, which is about a group of friends. *Loki* from the Marvel movies has his own show. *Lost* is about people trapped on a strange island.  *Mrs. America* tells the true story of the fight for women's rights. *The Muppet Show* is a classic with puppets! *NYPD Blue* is about police officers in New York City.  *One Mississippi* is a sad but funny show about a woman who goes home to take care of her sick mom.  *Only Murders in the Building* is about three friends who investigate a murder. *The People v. O.J. Simpson* tells the story of a famous trial. *Pose* shows the lives of drag queens in the 1980s.  There are so many shows to watch on Disney+!\n",
    "\n",
    "\n",
    "Curtis Sittenfeld's new book, *Romantic Comedy*, is about Sally, a writer for a comedy show like *Saturday Night Live*.  Sally makes fun of how average-looking guys often date beautiful women. She writes a joke skit about it called \"The Danny Horst Rule\". Then Sally meets a handsome pop star named Noah, and she starts to like him.  But Sally doesn't think Noah could ever like her back.  The book is about whether they'll end up together. Sally is a feminist who wants to write romantic comedies that are smart and funny. She and Noah bond over their work, but Sally hides her true feelings.  She's afraid to be vulnerable because a coworker once hurt her feelings. The book also shows what it's like to work at a comedy show.\n",
    "    \"\"\"\n",
    "    Language=\"Persian\"\n",
    "    #text='How are you?'\n",
    "    \n",
    "    persona_text=\"\"\n",
    "    if action_type==\"Summary_Persona\" and persona==\"\":\n",
    "        return \"Error- Please set the persona\"    \n",
    "    else:\n",
    "         persona_text=f\" so that a {persona} can understand it. Use simple words and short sentences\"\n",
    "    \n",
    "    platform=\"Twitter\" # could be Twitter, Instagram or \"\" if OffPlatformPost is not selected\n",
    "    if action_type==\"OffPlatformPost\" and platform==\"\":\n",
    "         return \"Error- Please set the platform\"\n",
    "        \n",
    "    if action_type==\"Translation\" and (text==\"\" or Language==\"\"):\n",
    "        return \"Error- Please set the input text to translate and destination language\"\n",
    "        \n",
    "  \n",
    "    #get summary\n",
    "    if action_type!=\"Translation\":\n",
    "        if action_type==\"OffPlatformPost\":\n",
    "            result=\"Instagram Post:\\n\"+get_summary(assets =assets,action_type=action_type,platform='Instagram',\n",
    "                           persona_text=persona_text,project_id=project_id,context_window_limit=context_window_limit)\n",
    "\n",
    "            \n",
    "            result=result+\"\\nTwitter Post:\\n\"+get_summary(assets =assets,action_type=action_type,platform='Twitter',\n",
    "                           persona_text=persona_text,project_id=project_id,context_window_limit=context_window_limit)\n",
    "           \n",
    "        else:\n",
    "            result=get_summary(assets =assets,action_type=action_type,platform=\"\",\n",
    "                           persona_text=persona_text,project_id=project_id,context_window_limit=context_window_limit)\n",
    "    else:\n",
    "        result=get_translation(action_type=action_type,input_text=text,Language=Language )\n",
    "        \n",
    "      \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34736324-932f-4aec-953a-3f4d1e16e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=func_generate_content('')\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d2f1c6-7d5d-490a-ad6c-b82226747c97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part, SafetySetting\n",
    " \n",
    " \n",
    "def generate():\n",
    "    vertexai.init(project=\"nine-quality-test\", location=\"us-central1\")\n",
    "    model = GenerativeModel(\n",
    "        \"gemini-1.5-pro-002\",\n",
    "    )\n",
    "    responses = model.generate_content(\n",
    "        [text1],\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings,\n",
    "        stream=True,\n",
    "    )\n",
    "    result=\"\"\n",
    "    for response in responses:\n",
    "        result=result+response.text\n",
    "    return result\n",
    " \n",
    "text1 = \"\"\"Translate the following text into Persian. Make sure to preserve the meaning, tone, and style of the original text, while ensuring it is natural and fluent in Persian.\n",
    "Text:how are you\n",
    " \n",
    "Only provide a single response\"\"\"\n",
    " \n",
    "generation_config = {\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"temperature\": 1,\n",
    "    \"top_p\": 0.95,\n",
    "}\n",
    " \n",
    "safety_settings = [\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "]\n",
    " \n",
    "r=generate()\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c35f1e-a804-4de8-b99e-f0f6bb539d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=get_translation(action_type='Translation',input_text=\"how are you\",Language='Persian' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1cd70c31-5ea8-4531-aa37-7c0744a1162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions_framework\n",
    "import tiktoken\n",
    "from langchain_google_community import BigQueryLoader\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import pandas as pd\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n",
    "from langchain_google_vertexai import VertexAI as langchain_vertexai\n",
    "from vertexai.generative_models._generative_models import SafetySettingsType\n",
    "import vertexai\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "from google.cloud import bigquery\n",
    "\n",
    "\n",
    "def estimate_token_length(text, model=\"gpt2\"):\n",
    "    \"\"\"Estimates the token length of a given text using a specified model.\n",
    "\n",
    "      Args:\n",
    "        text: The input text.\n",
    "        model: The model to use for tokenization (default: \"gpt2\").\n",
    "\n",
    "      Returns:\n",
    "        The estimated number of tokens.\n",
    "      \"\"\"\n",
    "\n",
    "  \n",
    "    enc = tiktoken.get_encoding(model)  \n",
    "\n",
    "    # Tokenize the text and count tokens\n",
    "    tokens = enc.encode(text)\n",
    "    token_count = len(tokens)\n",
    "    return token_count\n",
    "\n",
    "def get_data(source_query_str: str=None,metadata_columns: str=None,page_content_columns: str=None, project_id: str=None , return_text: bool=True):\n",
    "    \n",
    "    \"\"\"Load data from big query\n",
    "\n",
    "      Args:\n",
    "        str source_query_str:  The query string to fetch the data from bigquery\n",
    "        list[str] metadata_columns:  list of metadata column names\n",
    "        list[str] page_content_columns:  list of content column names  \n",
    "        str project_id: project id\n",
    "        bool return_text: returns the content columns description\n",
    "      Returns:\n",
    "          list[langchain_core.documents.base.Document] documents: langchain documents\n",
    "          \n",
    "      \"\"\"\n",
    "    \n",
    "    loader = BigQueryLoader(\n",
    "            query=source_query_str, project=project_id, metadata_columns=metadata_columns, page_content_columns=page_content_columns\n",
    "        )\n",
    "    documents = []\n",
    "    all_texts=[]\n",
    "    documents.extend(loader.load())\n",
    "    if return_text:  \n",
    "         all_texts=[doc.page_content.replace('full_description:',\"\",1) for doc in documents]\n",
    " \n",
    "        \n",
    "    return documents, '\\n'.join(all_texts)\n",
    "    \n",
    " \n",
    "def summarize_docs(documents: list[object],question_prompt_template: str=\"\", refine_prompt_template: str=\"\" ,is_token_limit_exceeded: bool=False ,model: object=None):\n",
    "    \n",
    "    \"\"\"summarizes the input documents\n",
    "\n",
    "      Args:\n",
    "        list[object] documents:  list of langchain documents\n",
    "        str question_prompt_template:  string question prompt template. \n",
    "        str refine_prompt_template:  string refine prompt template in the case that we need to use refine method\n",
    "        bool is_token_limit_exceeded:  boolean indicating wheather or not the token limit is exceeded.\n",
    "      Returns:\n",
    "         dict : summary result\n",
    "         \n",
    "      \"\"\"\n",
    "       \n",
    "    \n",
    "    question_prompt = PromptTemplate(template=question_prompt_template, input_variables=[\"text\"]) \n",
    "\n",
    "    if not is_token_limit_exceeded:        \n",
    "        #if the token limit is in the context window range, use a stuffing method for summary\n",
    "        chain = load_summarize_chain(model, chain_type=\"stuff\", \n",
    "                                     prompt=question_prompt)\n",
    "        \n",
    "    else:     \n",
    "        #otherwise use a refine summarization method\n",
    "        refine_prompt = PromptTemplate(input_variables=[\"existing_answer\", \"text\"], template=refine_prompt_template)\n",
    "              \n",
    "        chain = load_summarize_chain(\n",
    "            model,\n",
    "            chain_type=\"refine\",\n",
    "            question_prompt=question_prompt,\n",
    "            refine_prompt=refine_prompt,\n",
    "            return_intermediate_steps=True,\n",
    "          )\n",
    "        \n",
    "    return chain.invoke(documents)\n",
    "\n",
    "def  get_query_string (assets: str=\"\"):\n",
    "    \"\"\"set query string \n",
    "      Args:         \n",
    "        str assets:  comma separated string of all requested assets     \n",
    "      Returns:\n",
    "         str source_query_str : string query for loading data from biquery\n",
    "         \n",
    "      \"\"\"\n",
    "    # source_query_str= f\"\"\"SELECT          asset_id,                  \n",
    "    #                 STRING_AGG(description, '\\\\n' ) \n",
    "    #                 OVER (PARTITION BY asset_id ORDER BY ifnull(startOffset_seconds,0) ASC , chunk ASC) AS full_description,\n",
    "    #                 IDX\n",
    "    #           FROM (\n",
    "    #                 SELECT  asset_id,startOffset_seconds, CHUNK, \n",
    "    #                 CASE WHEN chunk=0 \n",
    "    #                      THEN TRIM(CONCAT(IFNULL(headline,''), CHR(10),  description))  \n",
    "    #                      ELSE description \n",
    "    #                 END AS description,\n",
    "    #                 ROW_NUMBER() OVER (PARTITION BY asset_id ORDER BY startOffset_seconds desc, chunk desc) AS IDX,\n",
    "    #                 FROM `vlt_media_embeddings_integration.vlt_all_media_content_text_embeddings` where asset_id in ({assets})\n",
    "    #          )\n",
    "    #        WHERE IDX=1\n",
    "    #     \"\"\"\n",
    "    source_query_str= f\"\"\"\n",
    "     SELECT * FROM (\n",
    "        SELECT          asset_id,                  \n",
    "                    STRING_AGG(description, '\\\\n' ) \n",
    "                     OVER (PARTITION BY asset_id ORDER BY ifnull(startOffset_seconds,0) ASC , IFNULL(endOffset_seconds,0) ASC ) AS full_description,\n",
    "                    ROW_NUMBER() OVER (PARTITION BY asset_id ORDER BY startOffset_seconds desc,endOffset_seconds desc) AS IDX,\n",
    "              FROM (\n",
    "                    SELECT * FROM \n",
    "                    (\n",
    "                        SELECT  distinct asset_id,startOffset_seconds,endOffset_seconds,\n",
    "                        TRIM(CONCAT(IFNULL(headline,''), CHR(10),  description))  description,\n",
    "                        ROW_NUMBER() OVER (PARTITION BY asset_id,startOffset_seconds ORDER BY startOffset_seconds desc, chunk desc) AS IDX,\n",
    "                        FROM `vlt_media_embeddings_integration.vlt_all_media_content_text_embeddings` where asset_id in ({assets})\n",
    "                      )\n",
    "                      WHERE IDX=1\n",
    "             )\n",
    "          )\n",
    "           WHERE IDX=1\n",
    "        \"\"\"\n",
    "    #print(source_query_str)\n",
    "    return source_query_str\n",
    "\n",
    "def get_prompt(action_type: str=\"\",platform: str=\"\",persona_text: str=\"\", input_text:str=\"\", Language:str=\"\"):\n",
    "    \n",
    "    \"\"\"set prompt according to the requested action\n",
    "      Args:         \n",
    "        str action_type:  the type of action needs to be done\n",
    "        str platform: platform name for off platform posts \n",
    "        str persona_text: for persona based summaries \n",
    "      Returns:\n",
    "         str question_prompt_template : the main prompt for the given action \n",
    "         str refine_prompt_template:  the second level prompt for refinement, in the case that the context is too long, we have to use refinement method.\n",
    "         \n",
    "      \"\"\"\n",
    " \n",
    "    question_prompt_template=\"\"\n",
    "    refine_prompt_template=\"\"\n",
    "    \n",
    "    if action_type==\"Summary\" or action_type==\"Summary_Persona\":\n",
    "            #this is the main prompt for summary\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide a summary of the following text\"\"\"+persona_text+\"\"\". Your result must be detailed and at least 2 paragraphs. \n",
    "                When summarizing, directly dive into the narrative or descriptions from the text without using introductory phrases like 'In this passage'. \n",
    "                Directly address the main events, characters, and themes, encapsulating the essence and significant details from the text in a flowing narrative. \n",
    "                The goal is to present a unified view of the content, continuing the story seamlessly as if the passage naturally progresses into the summary.\n",
    "                If different parts of texts look unrelevant, give a symmary of each text in 1 paragraph separately.\n",
    "\n",
    "                TEXT: {text}\n",
    "                SUMMARY:\n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final summary. Your task is to combine and refine these summaries into a final, comprehensive summary that covers all key events, characters, themes, and details.\\n\"\n",
    "                \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing summary\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original summary\"\n",
    "                \"If the context isn't useful, return the original summary and add the summary of the new context in a separate paragraph.\"\n",
    "            )\n",
    "    elif action_type==\"HeadLine\":  \n",
    "\n",
    "        #this is the main prompt for headline\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide a one line headline of the following text. \n",
    "\n",
    "                TEXT: {text}\n",
    "                HEADLINE:\n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final headline. Your task is to combine and refine these headlines into a final, comprehensive headline that covers all details.\\n\"\n",
    "                \"We have provided an existing headline up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing headline\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original headline\"\n",
    "                \"If the context isn't useful, return the original headline and add the headline of the new context in a separate line.\"\n",
    "            )\n",
    "    elif action_type==\"OffPlatformPost\"  and platform=='Twitter':\n",
    "               #this is the main prompt for social media post\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide a tweet that that’s catchy, concise, and fits within 280 characters. Make sure to highlight the key message, and encourage engagement with a question or call to action.\n",
    "\n",
    "                TEXT: {text}\n",
    "                Tweet: \n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final tweet. Your task is to combine and refine these tweets into a final, comprehensive tweet that covers all details, is catchy, concise, fits within 280 characters, and encourage engagement with a question or call to action.\\n\"\n",
    "                \"We have provided an existing tweet up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing tweet\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original tweet\"\n",
    "                \"If the context isn't useful, return the original tweet.\"\n",
    "            )\n",
    "    elif action_type==\"OffPlatformPost\" and platform=='Instagram':         \n",
    "            #this is the main prompt for social media post\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide  into an engaging Instagram post. Craft a short, attention-grabbing caption that highlights the main point. Use emojis to make it lively, and end with a question or call to action to spark conversation in the comments.\n",
    "\n",
    "                TEXT: {text}\n",
    "                Instagram Post: \n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final tweet. Your task is to combine and refine these Instagram posts into a final, comprehensive post that covers all details, crafts a short, attention-grabbing caption that highlights the main point. Use emojis to make it lively, and end with a question or call to action to spark conversation in the comments.\\n\"\n",
    "                \"We have provided an existing post up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing post\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original post\"\n",
    "                \"If the context isn't useful, return the original post.\"\n",
    "            )\n",
    "    elif action_type==\"Translation\":\n",
    "            #this is the main prompt for social media post\n",
    "            question_prompt_template = f\"\"\"Translate the following text into {Language}.  Make sure to preserve the meaning, tone, and style of the original text, while ensuring it is natural and fluent in {Language}.\n",
    "            Text:\\n \n",
    "              {input_text}\\n\n",
    "            Only provide a single response.\n",
    "            \"\"\"   \n",
    "    elif action_type==\"TrailerScript\":\n",
    "        \n",
    "            #this is the main prompt for summary\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given a summary of episode. Provide a trailer script that will run for between 2 and 3 minutes.\n",
    "\n",
    "                TEXT: {text}\n",
    "                Trailer Script:\n",
    "            \"\"\"\n",
    " \n",
    "            refine_prompt_template = \"\"\n",
    "    \n",
    "    elif action_type==\"KeyClips\":\n",
    "        \n",
    "            #this is the main prompt for summary\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given a summary of episode. Identify the key clips in this episode and provide a title and summary of each clip along with the time line.\n",
    "\n",
    "                TEXT: {text}\n",
    "                Key Clips:\n",
    "            \"\"\"\n",
    " \n",
    "            refine_prompt_template = \"\"\n",
    "\n",
    "    return question_prompt_template,refine_prompt_template\n",
    "\n",
    "def get_summary(assets:str=\"\",action_type:str=\"\",platform:str=\"\",persona_text:str=\"\",project_id:str=\"\",context_window_limit: int=2000000, model: object=None):\n",
    "    \n",
    "    \"\"\"get summary according to the action type requested\n",
    "      Args:         \n",
    "        str assets:  comma separate string including all assets\n",
    "        str action_type: requested action\n",
    "        str persona_text: for persona based summaries \n",
    "        str platform: for off platform based posts\n",
    "        str project_id: project id\n",
    "        int context_window_limit: context window limit for the llm model\n",
    "      Returns:\n",
    "         str :output summary \n",
    "      \"\"\"\n",
    "    \n",
    "    #set query string\n",
    "    source_query_str= get_query_string(assets)\n",
    "    \n",
    "    #set prompts\n",
    "    question_prompt_template, refine_prompt_template=get_prompt(action_type=action_type,platform=platform,persona_text=persona_text)\n",
    "    \n",
    "    #set metadata and content columns\n",
    "    metadata_columns=[\"asset_id\"]\n",
    "    page_content_columns=[\"full_description\"]\n",
    "    \n",
    "    #load data from biqquery\n",
    "    documents,all_texts=get_data(source_query_str=source_query_str,metadata_columns=metadata_columns,page_content_columns=page_content_columns, project_id=project_id,return_text=True)\n",
    "\n",
    "    #print(all_texts)\n",
    "    # Estimate the token length\n",
    "    estimated_token_length = estimate_token_length(all_texts,'cl100k_base') #cl100k_base\n",
    "    \n",
    "    message=\"\"\n",
    "    is_token_limit_exceeded=False\n",
    "    if estimated_token_length > context_window_limit:\n",
    "      message=\"Your text is too long for the Gemini 1.5 Pro context window. We are trying to chunk and return the result.\"\n",
    "      is_token_limit_exceeded=True\n",
    "      summary=summarize_docs(documents=documents,question_prompt_template=question_prompt_template,refine_prompt_template=refine_prompt_template,is_token_limit_exceeded=is_token_limit_exceeded ,model=model)\n",
    "\n",
    "    else:\n",
    "      message=\"Your text fits within the Gemini 1.5 Pro context window.\"\n",
    "      summary=summarize_docs(documents=documents,question_prompt_template=question_prompt_template,is_token_limit_exceeded=is_token_limit_exceeded,model=model )\n",
    " \n",
    "  \n",
    "    return summary[\"output_text\"]\n",
    "\n",
    "def get_translation(action_type: str=\"\",input_text: str=\"\",Language:str=\"\", model: object=None):\n",
    "    \n",
    "    \"\"\" get translation according to the requested language\n",
    "      Args:         \n",
    "        str input_text:  text to be translated\n",
    "        str Language: destination language\n",
    "      \n",
    "      Returns:\n",
    "         str : translated document \n",
    "      \"\"\"\n",
    " \n",
    "    \n",
    "    #set prompts\n",
    "    question_prompt_template, _=get_prompt(action_type=action_type,input_text=input_text,Language=Language)\n",
    "    generation_config= GenerationConfig(temperature=0.2, max_output_tokens=8192) \n",
    "    safety_settings=  {\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        }\n",
    "\n",
    "    model_input=[question_prompt_template]\n",
    "        \n",
    "    response = model.generate_content(\n",
    "        model_input,\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings, )\n",
    "    \n",
    "    result=\"\"\n",
    "    try:\n",
    "        result=response.text\n",
    "    except Exception as e:\n",
    "        result=str(e)\n",
    "\n",
    "    return result\n",
    " \n",
    "    \n",
    "\n",
    "\n",
    "def log_data(result,error,request,elapsed_time,project_id):\n",
    "    \"\"\"\n",
    "      Log the search result into bigquery\n",
    "    Args:\n",
    "       List[dict]  result: the result of search\n",
    "       str error: the error message\n",
    "       dict request: the request sent\n",
    "       float elapsed_time: the time taken for the search result to be generated\n",
    "       str project_id: project id\n",
    "    \"\"\"\n",
    "    rows_to_insert=[] \n",
    "    rows_to_insert.append(\n",
    "                                {  \"search_date\":  datetime.now().isoformat() ,\n",
    "                                    \"request\":request,\n",
    "                                    \"response\":   result  , \n",
    "                                    \"error\":  error,\n",
    "                                    \"elapsed_time\":elapsed_time ,\n",
    "                                    \"API\": \"content_generation\"\n",
    "                                  \n",
    "                                    }\n",
    "                                            )   \n",
    "\n",
    "    #create table new if does not exist\n",
    "    # Load configuration from config.json\n",
    "    with open('config.json') as config_file:\n",
    "         config = json.load(config_file)\n",
    "\n",
    "    table=config['log_table']\n",
    "    dataset_id=config['log_dataset']\n",
    "    #push the data into the table\n",
    "    table_id = f\"{project_id}.{dataset_id}.{table}\"\n",
    "    client = bigquery.Client(project_id)\n",
    "    dataset  = client.dataset(dataset_id)\n",
    "    table = dataset.table(table)\n",
    "\n",
    "    #send a big query streaming insert job- dont need to wait for the job to finish\n",
    "    job = client.load_table_from_json(rows_to_insert, table) \n",
    "\n",
    "def func_generate_content(request):\n",
    "    \n",
    "    \"\"\"\n",
    "    Cloud Function entry point. This function handles the incoming request, \n",
    "    performs content generation according to the given action\n",
    "    \"\"\"\n",
    "\n",
    "    # Parse the incoming request to extract text or image file\n",
    "    request_json = request.get_json(silent=True)   \n",
    "    project_id = request_json.get('project')  \n",
    "    location = request_json.get('region')  \n",
    "    action_type = request_json.get('action_type') # could be Summary, Summary_Persona, HeadLine, OffPlatformPost, Translation\n",
    "    \n",
    "\n",
    "    if \"asset_ids\" in request_json:\n",
    "        assets = request_json.get('asset_ids') #comma separated assets\n",
    "    else:\n",
    "        assets=\"\"\n",
    "\n",
    "        \n",
    "    if \"persona\" in request_json:\n",
    "       persona = request_json.get('persona')   #persona filter\n",
    "    else:\n",
    "        persona=\"\"\n",
    "    \n",
    "    if action_type==\"Summary_Persona\" and persona==\"\":\n",
    "        return \"Error- Persona must be set\"  \n",
    "\n",
    "    if \"input_text\" in request_json: \n",
    "       input_text = request_json.get('input_text')   #input text for translation\n",
    "    else:\n",
    "        input_text=\"\"\n",
    "\n",
    "    if action_type==\"Translation\" and input_text==\"\":\n",
    "        return \"Error- Provide input text for translation\"\n",
    "\n",
    "    if \"language\" in request_json: \n",
    "       Language = request_json.get('language')   #input text for translation\n",
    "    else:\n",
    "        Language=\"Chineese\"\n",
    "\n",
    "    if action_type==\"Translation\" and Language==\"\":\n",
    "        return \"Error- Provide destination language for translation\"\n",
    "        \n",
    "          # Load configuration from config.json\n",
    "    with open('config.json') as config_file:\n",
    "         config = json.load(config_file)\n",
    "\n",
    "   # Set the Gemini 1.5 Pro context window limit\n",
    "    context_window_limit=int(config['context_window_limit']) \n",
    "    model_name=config['model_name'] \n",
    "\n",
    "    #Init vertex ai\n",
    "    vertexai.init(project=project_id, location=location )\n",
    "   \n",
    "\n",
    "    #set assets for search\n",
    "    if assets.strip() !=\"\":\n",
    "        assets= ','.join([ \"'\"+ id.strip()+\"'\" for id in assets.split(',')])\n",
    "    else:\n",
    "        assets=\"\"\n",
    "\n",
    "   #Set persona text    \n",
    "    persona_text=\"\"\n",
    "    if action_type==\"Summary_Persona\" and persona==\"\":\n",
    "        return \"Error- Please set the persona\"    \n",
    "    else:\n",
    "         persona_text=f\" so that a {persona} can understand it. Use simple words and short sentences\"\n",
    "\n",
    "    error=\"\" \n",
    "    start_time = time.time()     \n",
    "    #generate content according to the requested action\n",
    "    try:\n",
    "        if action_type!=\"Translation\":\n",
    "            #generate other content according to the requested action\n",
    "            vertex_llm_text = langchain_vertexai(model_name=model_name)\n",
    "           \n",
    "            if action_type==\"OffPlatformPost\": #for OffPlatformPost, create both Twitter and Instagram posts\n",
    "                result=\"Instagram Post:\\n\"+get_summary(assets =assets,action_type=action_type,platform='Instagram',\n",
    "                            persona_text=persona_text,project_id=project_id,context_window_limit=context_window_limit,model=vertex_llm_text)\n",
    "\n",
    "                \n",
    "                result=result+\"\\nTwitter Post:\\n\"+get_summary(assets =assets,action_type=action_type,platform='Twitter',\n",
    "                            persona_text=persona_text,project_id=project_id,context_window_limit=context_window_limit,model=vertex_llm_text)\n",
    "            \n",
    "            else:           \n",
    "                result=get_summary(assets =assets,action_type=action_type,platform=\"\",\n",
    "                            persona_text=persona_text,project_id=project_id,context_window_limit=context_window_limit,model=vertex_llm_text)\n",
    "        else:\n",
    "            #generate trannlation\n",
    "            generative_multimodal_model= GenerativeModel(model_name)\n",
    "            result=get_translation(action_type=action_type,input_text=input_text,Language=Language, model= generative_multimodal_model)\n",
    "    \n",
    "    except Exception as e:\n",
    "        result=\"Error- Service is not available or content generation has faced an issue:\\n\"+str(e)\n",
    "        error=result\n",
    "\n",
    "    end_time = time.time()\n",
    "    # Calculate the elapsed time\n",
    "    elapsed_time = end_time - start_time\n",
    "    #record the search log\n",
    "    log_data(result,error,request_json,elapsed_time,project_id)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ba953ede-84f9-468a-bc8a-8e713f25a5e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from unittest.mock import Mock\n",
    "import json\n",
    "\n",
    "\n",
    "#vlt_video_extract_SIXTY_MINUTES_60MI23_14_A_HBB.mp4\n",
    "data={\"asset_ids\":\"vlt_video_extract_NINE_NEWS_SYD-NINE_NNNT23_101_A.mp4\", \n",
    "\"project\":\"nine-quality-test\",\n",
    "\"region\":\"us-central1\",\n",
    "\"action_type\":\"TrailerScript\"  \n",
    "       }\n",
    " \n",
    "# Simulating an HTTP request with the mock object\n",
    "mock_request = Mock()\n",
    "mock_request.get_json.return_value = data  # Mock the get_json method to return your data\n",
    "\n",
    "\n",
    "x=func_generate_content(mock_request)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87795546-ba28-4464-bef7-b2dc308a7835",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 1==1:\n",
    "    #set query string\n",
    "    assets=\"'p5d1x4','p5dx0h','p5duot','a4e57c915b48502be148d6fcb08944efa22d2107.jpeg','3466295218ab26efc1739b775d21453a5f1a819b.jpeg','03245688ac9a7dd651797170992af7d8421ae2c2.jpeg','vlt_video_extract_SIXTY_MINUTES_60MI23_10_A_HBB.mp4','vlt_video_extract_NINE_NEWS_SYD-NINE_NNNT23_101_A.mp4'\"\n",
    "    source_query_str= get_query_string(assets)\n",
    "    \n",
    "    #set prompts\n",
    "    question_prompt_template, refine_prompt_template=get_prompt(action_type='HeadLine',platform='',persona_text='')\n",
    "    \n",
    "    #set metadata and content columns\n",
    "    metadata_columns=[\"asset_id\"]\n",
    "    page_content_columns=[\"full_description\"]\n",
    "    \n",
    "    #load data from biqquery\n",
    "    documents,all_texts=get_data(source_query_str=source_query_str,metadata_columns=metadata_columns,page_content_columns=page_content_columns, project_id='nine-quality-test',return_text=True)\n",
    "    print(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5b486b37-152d-4db9-b8e2-5ca5289b0ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions_framework\n",
    "import tiktoken\n",
    "from langchain_google_community import BigQueryLoader\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import pandas as pd\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n",
    "from langchain_google_vertexai import VertexAI as langchain_vertexai\n",
    "from vertexai.generative_models._generative_models import SafetySettingsType\n",
    "import vertexai\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "from google.cloud import bigquery\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "def estimate_token_length(text, model=\"gpt2\"):\n",
    "    \"\"\"Estimates the token length of a given text using a specified model.\n",
    "\n",
    "      Args:\n",
    "        text: The input text.\n",
    "        model: The model to use for tokenization (default: \"gpt2\").\n",
    "\n",
    "      Returns:\n",
    "        The estimated number of tokens.\n",
    "      \"\"\"\n",
    "\n",
    "  \n",
    "    enc = tiktoken.get_encoding(model)  \n",
    "\n",
    "    # Tokenize the text and count tokens\n",
    "    tokens = enc.encode(text)\n",
    "    token_count = len(tokens)\n",
    "    return token_count\n",
    "\n",
    "def get_data(source_query_str: str=None,metadata_columns: str=None,page_content_columns: str=None, project_id: str=None , return_text: bool=True):\n",
    "    \n",
    "    \"\"\"Load data from big query\n",
    "\n",
    "      Args:\n",
    "        str source_query_str:  The query string to fetch the data from bigquery\n",
    "        list[str] metadata_columns:  list of metadata column names\n",
    "        list[str] page_content_columns:  list of content column names  \n",
    "        str project_id: project id\n",
    "        bool return_text: returns the content columns description\n",
    "      Returns:\n",
    "          list[langchain_core.documents.base.Document] documents: langchain documents\n",
    "          \n",
    "      \"\"\"\n",
    "    \n",
    "    loader = BigQueryLoader(\n",
    "            query=source_query_str, project=project_id, metadata_columns=metadata_columns, page_content_columns=page_content_columns\n",
    "        )\n",
    "    documents = []\n",
    "    all_texts=[]\n",
    "    documents.extend(loader.load())\n",
    "    if return_text:  \n",
    "         all_texts=[doc.page_content.replace('full_description:',\"\",1) for doc in documents]\n",
    "        \n",
    "    return documents, '\\n'.join(all_texts)\n",
    "    \n",
    " \n",
    "def summarize_docs(documents: list[object],question_prompt_template: str=\"\", refine_prompt_template: str=\"\" ,is_token_limit_exceeded: bool=False ,model: object=None):\n",
    "    \n",
    "    \"\"\"summarizes the input documents\n",
    "\n",
    "      Args:\n",
    "        list[object] documents:  list of langchain documents\n",
    "        str question_prompt_template:  string question prompt template. \n",
    "        str refine_prompt_template:  string refine prompt template in the case that we need to use refine method\n",
    "        bool is_token_limit_exceeded:  boolean indicating wheather or not the token limit is exceeded.\n",
    "      Returns:\n",
    "         dict : summary result\n",
    "         \n",
    "      \"\"\"\n",
    "       \n",
    "    \n",
    "    question_prompt = PromptTemplate(template=question_prompt_template, input_variables=[\"text\"]) \n",
    "\n",
    "    if not is_token_limit_exceeded:        \n",
    "        #if the token limit is in the context window range, use a stuffing method for summary\n",
    "        chain = load_summarize_chain(model, chain_type=\"stuff\", \n",
    "                                     prompt=question_prompt)\n",
    "        \n",
    "    else:     \n",
    "        #otherwise use a refine summarization method\n",
    "        refine_prompt = PromptTemplate(input_variables=[\"existing_answer\", \"text\"], template=refine_prompt_template)\n",
    "              \n",
    "        chain = load_summarize_chain(\n",
    "            model,\n",
    "            chain_type=\"refine\",\n",
    "            question_prompt=question_prompt,\n",
    "            refine_prompt=refine_prompt,\n",
    "            return_intermediate_steps=True,\n",
    "          )\n",
    "        \n",
    "    return chain.invoke(documents)\n",
    "\n",
    "def  get_query_string (assets: str=\"\", video: bool=False ):\n",
    "    \"\"\"set query string \n",
    "      Args:         \n",
    "        str assets:  comma separated string of all requested assets     \n",
    "      Returns:\n",
    "         str source_query_str : string query for loading data from biquery\n",
    "         \n",
    "      \"\"\"\n",
    "    desc=\"\"\n",
    "    if video:\n",
    "        #desc= \"STRING_AGG(CONCAT ('\\n', CONCAT(' to ', startOffset_seconds,endOffset_seconds), description), '\\\\n' ) \"\n",
    "        desc=\"STRING_AGG(CONCAT (' ', CONCAT( 'Video details from offset ', startOffset_seconds,' seconds to ',endOffset_seconds,' seconds: ', '\\\\n'), description), '\\\\n' ) \"        \n",
    "    else:\n",
    "        desc=\"STRING_AGG(description, '\\\\n' )\"\n",
    "        \n",
    "    source_query_str= f\"\"\"\n",
    "     SELECT * FROM (\n",
    "        SELECT      asset_id, \n",
    "                    fileUri,  \n",
    "                    asset_type,               \n",
    "                   {desc} \n",
    "                     OVER (PARTITION BY asset_id ORDER BY ifnull(startOffset_seconds,0) ASC , IFNULL(endOffset_seconds,0) ASC ) AS full_description,\n",
    "                    ROW_NUMBER() OVER (PARTITION BY asset_id ORDER BY startOffset_seconds desc,endOffset_seconds desc) AS IDX,\n",
    "              FROM (\n",
    "                    SELECT * FROM \n",
    "                    (\n",
    "                        SELECT  distinct asset_id,startOffset_seconds,endOffset_seconds,fileUri,  \n",
    "                        asset_type,\n",
    "                        TRIM(CONCAT(IFNULL(headline,''), CHR(10),  description))  description,\n",
    "                        ROW_NUMBER() OVER (PARTITION BY asset_id,startOffset_seconds ORDER BY startOffset_seconds desc, chunk desc) AS IDX,\n",
    "                        FROM `vlt_media_embeddings_integration.vlt_all_media_content_text_embeddings` where asset_id in ({assets})\n",
    "                      )\n",
    "                      WHERE IDX=1\n",
    "             )\n",
    "          )\n",
    "           WHERE IDX=1\n",
    "        \"\"\"\n",
    "    print(source_query_str)\n",
    "    return source_query_str\n",
    "\n",
    "def get_prompt(action_type: str=\"\",platform: str=\"\",persona_text: str=\"\", input_text:str=\"\", Language:str=\"\"):\n",
    "    \n",
    "    \"\"\"set prompt according to the requested action\n",
    "      Args:         \n",
    "        str action_type:  the type of action needs to be done\n",
    "        str platform: platform name for off platform posts \n",
    "        str persona_text: for persona based summaries \n",
    "      Returns:\n",
    "         str question_prompt_template : the main prompt for the given action \n",
    "         str refine_prompt_template:  the second level prompt for refinement, in the case that the context is too long, we have to use refinement method.\n",
    "         \n",
    "      \"\"\"\n",
    "    #print(action_type)\n",
    "    question_prompt_template=\"\"\n",
    "    refine_prompt_template=\"\"\n",
    "    \n",
    "    if action_type==\"Summary\" or action_type==\"Summary_Persona\":\n",
    "            #this is the main prompt for summary\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide a summary of the following text\"\"\"+persona_text+\"\"\". Your result must be detailed and at least 2 paragraphs. \n",
    "                When summarizing, directly dive into the narrative or descriptions from the text without using introductory phrases like 'In this passage'. \n",
    "                Directly address the main events, characters, and themes, encapsulating the essence and significant details from the text in a flowing narrative. \n",
    "                The goal is to present a unified view of the content, continuing the story seamlessly as if the passage naturally progresses into the summary.\n",
    "                If different parts of texts look unrelevant, give a symmary of each text in 1 paragraph separately.\n",
    "\n",
    "                TEXT: {text}\n",
    "                SUMMARY:\n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final summary. Your task is to combine and refine these summaries into a final, comprehensive summary that covers all key events, characters, themes, and details.\\n\"\n",
    "                \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing summary\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original summary\"\n",
    "                \"If the context isn't useful, return the original summary and add the summary of the new context in a separate paragraph.\"\n",
    "            )\n",
    "    elif action_type==\"HeadLine\":  \n",
    "\n",
    "        #this is the main prompt for headline\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide a one line headline of the following text. \n",
    "\n",
    "                TEXT: {text}\n",
    "                HEADLINE:\n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final headline. Your task is to combine and refine these headlines into a final, comprehensive headline that covers all details.\\n\"\n",
    "                \"We have provided an existing headline up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing headline\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original headline\"\n",
    "                \"If the context isn't useful, return the original headline.\"\n",
    "            )\n",
    "    elif action_type==\"OffPlatformPost\"  and platform=='Twitter':\n",
    "               #this is the main prompt for social media post\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide a tweet that that’s catchy, concise, and fits within 280 characters. Make sure to highlight the key message, and encourage engagement with a question or call to action.\n",
    "\n",
    "                TEXT: {text}\n",
    "                Tweet: \n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final tweet. Your task is to combine and refine these tweets into a final, comprehensive tweet that covers all details, is catchy, concise, fits within 280 characters, and encourage engagement with a question or call to action.\\n\"\n",
    "                \"We have provided an existing tweet up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing tweet\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original tweet\"\n",
    "                \"If the context isn't useful, return the original tweet.\"\n",
    "            )\n",
    "    elif action_type==\"OffPlatformPost\" and platform=='Instagram':         \n",
    "            #this is the main prompt for social media post\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide  into an engaging Instagram post. Craft a short, attention-grabbing caption that highlights the main point. Use emojis to make it lively, and end with a question or call to action to spark conversation in the comments.\n",
    "\n",
    "                TEXT: {text}\n",
    "                Instagram Post: \n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final tweet. Your task is to combine and refine these Instagram posts into a final, comprehensive post that covers all details, crafts a short, attention-grabbing caption that highlights the main point. Use emojis to make it lively, and end with a question or call to action to spark conversation in the comments.\\n\"\n",
    "                \"We have provided an existing post up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing post\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original post\"\n",
    "                \"If the context isn't useful, return the original post.\"\n",
    "            )\n",
    "    elif action_type==\"Translation\":\n",
    "            #this is the main prompt for social media post\n",
    "            question_prompt_template = f\"\"\"Translate the following text into {Language}.  Make sure to preserve the meaning, tone, and style of the original text, while ensuring it is natural and fluent in {Language}. \n",
    "            Text:\\n \n",
    "              {input_text}\\n\n",
    "            Only provide a single response and do not add any openning or closing comment to the translated result.\n",
    "            \"\"\"  \n",
    "    elif action_type==\"trailer-script\":\n",
    "        \n",
    "            #this is the main prompt for summary\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given a summary of episode. Provide a trailer script that will run for between 2 and 3 minutes.\n",
    "\n",
    "                TEXT: {text}\n",
    "                Trailer Script:\n",
    "            \"\"\"\n",
    " \n",
    "            refine_prompt_template = \"\"\n",
    "    \n",
    "    elif action_type==\"key-clips\":\n",
    "            # question_prompt_template = \"\"\"\n",
    "            #     You will be given a video episode. Identify the key clips in this episode and provide a title and summary of each clip along with their time line. Do not add any openning or closing comment to the result.\n",
    "            # \"\"\" \n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given a summary of different segments of a video episode. These descriptions are not broken into specific stories, and a single story may run across multiple segments. Identify the key clips in the entire video and provide timelines in seconds based on when they appear. For each clip, provide a timeline, title and summary.\n",
    "      \n",
    "                TEXT: {text}\n",
    "                Key Clips:\n",
    "            \"\"\"\n",
    "            refine_prompt_template = \"\"        \n",
    "            \n",
    "    return question_prompt_template,refine_prompt_template\n",
    "\n",
    "def get_summary(assets:str=\"\",action_type:str=\"\",platform:str=\"\",persona_text:str=\"\",project_id:str=\"\",context_window_limit: int=2000000, model: object=None):\n",
    "    \n",
    "    \"\"\"get summary according to the action type requested\n",
    "      Args:         \n",
    "        str assets:  comma separate string including all assets\n",
    "        str action_type: requested action\n",
    "        str persona_text: for persona based summaries \n",
    "        str platform: for off platform based posts\n",
    "        str project_id: project id\n",
    "        int context_window_limit: context window limit for the llm model\n",
    "      Returns:\n",
    "         str :output summary \n",
    "      \"\"\"\n",
    "    \n",
    "    #set query string\n",
    "    #if action type is key-clips, set the video to True. This will add video segments to descriptins\n",
    "    if action_type==\"key-clips\":\n",
    "       video=True\n",
    "    else:\n",
    "        video=False\n",
    "    source_query_str= get_query_string(assets,video=video)\n",
    "    \n",
    "    #set prompts\n",
    "    question_prompt_template, refine_prompt_template=get_prompt(action_type=action_type,platform=platform,persona_text=persona_text)\n",
    "    \n",
    "    #set metadata and content columns\n",
    "    metadata_columns=[\"asset_id\"]\n",
    "    page_content_columns=[\"full_description\"]\n",
    "    \n",
    "    #load data from biqquery\n",
    "    documents,all_texts=get_data(source_query_str=source_query_str,metadata_columns=metadata_columns,page_content_columns=page_content_columns, project_id=project_id,return_text=True)\n",
    "    print(documents)\n",
    "    # Estimate the token length\n",
    "    estimated_token_length = estimate_token_length(all_texts,'cl100k_base') #cl100k_base\n",
    "    \n",
    "    message=\"\"\n",
    "    is_token_limit_exceeded=False\n",
    "    if estimated_token_length > context_window_limit:\n",
    "      message=\"Your text is too long for the Gemini 1.5 Pro context window. We are trying to chunk and return the result.\"\n",
    "      is_token_limit_exceeded=True\n",
    "      summary=summarize_docs(documents=documents,question_prompt_template=question_prompt_template,refine_prompt_template=refine_prompt_template,is_token_limit_exceeded=is_token_limit_exceeded ,model=model)\n",
    "\n",
    "    else:\n",
    "      message=\"Your text fits within the Gemini 1.5 Pro context window.\"\n",
    "      summary=summarize_docs(documents=documents,question_prompt_template=question_prompt_template,is_token_limit_exceeded=is_token_limit_exceeded,model=model )\n",
    " \n",
    "    return summary[\"output_text\"]\n",
    "\n",
    "def get_translation(assets: str=\"\", action_type: str=\"\",input_text: str=\"\",Language:str=\"\", model: object=None, project_id: str=\"\"):\n",
    "    \n",
    "    \"\"\" get translation according to the requested language\n",
    "      Args:         \n",
    "        str input_text:  text to be translated\n",
    "        str Language: destination language\n",
    "        str assets: comma separated assets if input text is not given\n",
    "        str project_id: project id \n",
    "        object model: generative AI model\n",
    "      \n",
    "      Returns:\n",
    "         str : translated document \n",
    "      \"\"\"\n",
    " \n",
    "    if input_text==\"\" and assets==\"\":\n",
    "        return \"No text is provided for translation- Please provide asset ids or text\"\n",
    "\n",
    "    elif input_text==\"\" and assets!=\"\":\n",
    "        #set query string\n",
    "        source_query_str= get_query_string(assets)\n",
    "\n",
    "        #set metadata and content columns\n",
    "        metadata_columns=[\"asset_id\"]\n",
    "        page_content_columns=[\"full_description\"]\n",
    "        \n",
    "        #load data from biqquery\n",
    "        _,input_text=get_data(source_query_str=source_query_str,metadata_columns=metadata_columns,page_content_columns=page_content_columns, project_id=project_id,return_text=True)\n",
    "\n",
    " \n",
    "    #set prompts and other configs\n",
    "    question_prompt_template, _=get_prompt(action_type=action_type,input_text=input_text,Language=Language)\n",
    "    generation_config= GenerationConfig(temperature=0.2, max_output_tokens=8192) \n",
    "    safety_settings=  {\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        }\n",
    "\n",
    "    model_input=[question_prompt_template]\n",
    "        \n",
    "    attempt = 0\n",
    "    max_retries=3\n",
    "    result=\"\"\n",
    "    #use exponential backoff to prevent direct failure in the case of exhaustion of end point\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            response = model.generate_content(\n",
    "                        model_input,\n",
    "                        generation_config=generation_config,\n",
    "                        safety_settings=safety_settings, )\n",
    "            attempt=max_retries \n",
    "            try:         \n",
    "                result=response.text     \n",
    "            except Exception as e:\n",
    "                result=str(e)\n",
    "        except Exception as e:\n",
    "            attempt += 1\n",
    "            backoff_delay = min(2 ** attempt + random.uniform(0, 1), 32)  # Exponential backoff with jitter\n",
    "            print(f\"Attempt {attempt} failed with error {e}. Retrying in {backoff_delay:.2f} seconds...\")\n",
    "            time.sleep(backoff_delay)  # Wait before retrying  \n",
    "    return result\n",
    " \n",
    "def get_VideoClips(assets: str=\"\", action_type: str=\"\", model: object=None, project_id: str=\"\", use_content: bool=True):\n",
    "    \n",
    "    \"\"\" get key clips for a given video\n",
    "      Args:         \n",
    "        \n",
    "        object model: generative AI model\n",
    "        str assets: comma separated assets if input text is not given\n",
    "        str project_id: project id \n",
    "        bool use_content: a flag that identifies wheather to use video object or its content for generating clips\n",
    "      \n",
    "      Returns:\n",
    "         str : key video clips\n",
    "      \"\"\"\n",
    " \n",
    "    if assets==\"\":\n",
    "        return \"No asset is provided for generating video clips- Please provide asset id\"\n",
    "\n",
    "    \n",
    "    #set query string\n",
    "    source_query_str= get_query_string(assets, video=True )\n",
    "    \n",
    "    #set metadata and content columns\n",
    "    metadata_columns=[\"asset_id\", \"fileUri\", \"asset_type\"]\n",
    "    page_content_columns=[\"full_description\"]\n",
    "        \n",
    "    #load data from biqquery\n",
    "    documents,_=get_data(source_query_str=source_query_str,metadata_columns=metadata_columns,page_content_columns=page_content_columns, project_id=project_id,return_text=True)\n",
    "    \n",
    "    \n",
    "    #set video file and mime_type\n",
    "    video_file=documents[0].metadata[\"fileUri\"]\n",
    "    mime_type=documents[0].metadata[\"asset_type\"]\n",
    "    \n",
    "    #set prompts and other configs\n",
    "    question_prompt_template, _=get_prompt(action_type=action_type)\n",
    "    generation_config= GenerationConfig(temperature=0.2, max_output_tokens=8192) \n",
    "    safety_settings=  {\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        }\n",
    "  \n",
    "    model_input=[Part.from_uri(video_file,mime_type=mime_type),\n",
    "                           question_prompt_template,]  \n",
    "\n",
    "\n",
    "    attempt = 0\n",
    "    max_retries=3\n",
    "    result=\"\"\n",
    "    #use exponential backoff to prevent direct failure in the case of exhaustion of end point\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "         \n",
    "            response = model.generate_content(\n",
    "                        model_input,\n",
    "                        generation_config=generation_config,\n",
    "                        safety_settings=safety_settings, )           \n",
    "            attempt=max_retries\n",
    "            print(response)\n",
    "            try:         \n",
    "                result=response.text     \n",
    "            except Exception as e:\n",
    "                result=str(e)\n",
    "        \n",
    "        except Exception as e:\n",
    "            attempt += 1\n",
    "            backoff_delay = min(2 ** attempt + random.uniform(0, 1), 32)  # Exponential backoff with jitter\n",
    "            print(f\"Attempt {attempt} failed with error {e}. Retrying in {backoff_delay:.2f} seconds...\")\n",
    "            time.sleep(backoff_delay)  # Wait before retrying\n",
    "            \n",
    "    return result  \n",
    "\n",
    "\n",
    "def log_data(result,error,request,elapsed_time,project_id):\n",
    "    \"\"\"\n",
    "      Log the search result into bigquery\n",
    "    Args:\n",
    "       List[dict]  result: the result of search\n",
    "       str error: the error message\n",
    "       dict request: the request sent\n",
    "       float elapsed_time: the time taken for the search result to be generated\n",
    "       str project_id: project id\n",
    "    \"\"\"\n",
    "    rows_to_insert=[] \n",
    "    rows_to_insert.append(\n",
    "                                {  \"search_date\":  datetime.now().isoformat() ,\n",
    "                                    \"request\":request,\n",
    "                                    \"response\":   result  , \n",
    "                                    \"error\":  error,\n",
    "                                    \"elapsed_time\":elapsed_time ,\n",
    "                                    \"API\": \"Content Generation\"\n",
    "                                  \n",
    "                                    }\n",
    "                                            )   \n",
    "\n",
    "    #create table new if does not exist\n",
    "    # Load configuration from config.json\n",
    "    with open('config.json') as config_file:\n",
    "         config = json.load(config_file)\n",
    "\n",
    "    table=config['log_table']\n",
    "    dataset_id=config['log_dataset']\n",
    "    #push the data into the table\n",
    "    table_id = f\"{project_id}.{dataset_id}.{table}\"\n",
    "    client = bigquery.Client(project_id)\n",
    "    dataset  = client.dataset(dataset_id)\n",
    "    table = dataset.table(table)\n",
    "\n",
    "    #send a big query streaming insert job- dont need to wait for the job to finish\n",
    "    job = client.load_table_from_json(rows_to_insert, table) \n",
    "\n",
    "def func_generate_content(request):\n",
    "    \n",
    "    \"\"\"\n",
    "    Cloud Function entry point. This function handles the incoming request, \n",
    "    performs content generation according to the given action\n",
    "    \"\"\"\n",
    "\n",
    "    # Parse the incoming request to extract text or image file\n",
    "    request_json = request.get_json(silent=True)   \n",
    "    project_id = request_json.get('project')  \n",
    "    location = request_json.get('region')  \n",
    "    action_type = request_json.get('action_type') # could be Summary, Summary_Persona, HeadLine, OffPlatformPost, Translation, trailer-script, key-clips\n",
    "    \n",
    "    \n",
    "    #print(request_json)\n",
    "    \n",
    "    if \"asset_ids\" in request_json:\n",
    "        assets = request_json.get('asset_ids') #comma separated assets\n",
    "    else:\n",
    "        assets=\"\"\n",
    "\n",
    "        \n",
    "    # if \"persona\" in request_json:\n",
    "    #    persona = request_json.get('persona')   #persona filter\n",
    "    # else:\n",
    "    #     persona=\"\"\n",
    "    persona=\"\"\n",
    "    if action_type==\"Summary_Persona_5year\":\n",
    "        persona=\"5-year old\"\n",
    "        action_type=\"Summary_Persona\"\n",
    "\n",
    "    if action_type==\"Summary_Persona_highschool\":\n",
    "        persona=\"high school student\"\n",
    "        action_type=\"Summary_Persona\" \n",
    "\n",
    "    if \"input_text\" in request_json: \n",
    "       input_text = request_json.get('input_text')   #input text for translation\n",
    "    else:\n",
    "        input_text=\"\"\n",
    "   \n",
    "\n",
    "    # if action_type==\"Translation\" and input_text==\"\":\n",
    "    #     return \"Error- Provide input text for translation\"\n",
    "\n",
    "    if \"language\" in request_json: \n",
    "       Language = request_json.get('language')   #input text for translation\n",
    "    else:\n",
    "        Language=\"Chineese\"\n",
    "\n",
    "    # if action_type==\"Translation\" and Language==\"\":\n",
    "    #     return \"Error- Provide destination language for translation\"\n",
    "        \n",
    "          # Load configuration from config.json\n",
    "    with open('config.json') as config_file:\n",
    "         config = json.load(config_file)\n",
    "\n",
    "   # Set the Gemini 1.5 Pro context window limit\n",
    "    context_window_limit=int(config['context_window_limit']) \n",
    "    # general model name: for most of the scenarios we use Gemini Pro\n",
    "    model_name=config['model_name'] \n",
    "    #video clips model name: to generate video clips we use Gemini Flash because of speed of response\n",
    "    video_clips_model_name=config[\"video_clips_model_name\"]\n",
    "\n",
    "    #Init vertex ai\n",
    "    vertexai.init(project=project_id, location=location )\n",
    "   \n",
    "\n",
    "    #set assets for search\n",
    "    if assets.strip() !=\"\":\n",
    "        assets= ','.join([ \"'\"+ id.strip()+\"'\" for id in assets.split(',')])\n",
    "    else:\n",
    "        assets=\"\"\n",
    "\n",
    "   #Set persona text    \n",
    "    persona_text=\"\"\n",
    "    if action_type==\"Summary_Persona\" and persona==\"\":\n",
    "        return \"Error- Please set the persona\"    \n",
    "    else:\n",
    "         persona_text=f\" so that a {persona} can understand it. Use simple words and short sentences\"\n",
    "\n",
    "  \n",
    "    error=\"\" \n",
    "    start_time = time.time()     \n",
    "    #generate content according to the requested action\n",
    "    try:\n",
    "        if action_type in (\"Summary_Persona\", \"Summary\",\"HeadLine\", \"OffPlatformPost\",\"trailer-script\" ):\n",
    "            print('***')\n",
    "            #generate other content according to the requested action\n",
    "            vertex_llm_text = langchain_vertexai(model_name=model_name)\n",
    "           \n",
    "            if action_type==\"OffPlatformPost\": #for OffPlatformPost, create both Twitter and Instagram posts\n",
    "                result=\"Instagram Post:\\n\"+get_summary(assets =assets,action_type=action_type,platform='Instagram',\n",
    "                            persona_text=persona_text,project_id=project_id,context_window_limit=context_window_limit,model=vertex_llm_text)\n",
    "\n",
    "                \n",
    "                result=result+\"\\nTwitter Post:\\n\"+get_summary(assets =assets,action_type=action_type,platform='Twitter',\n",
    "                            persona_text=persona_text,project_id=project_id,context_window_limit=context_window_limit,model=vertex_llm_text)\n",
    "            \n",
    "            else:           \n",
    "                result=get_summary(assets =assets,action_type=action_type,platform=\"\",\n",
    "                            persona_text=persona_text,project_id=project_id,context_window_limit=context_window_limit,model=vertex_llm_text)\n",
    "        elif action_type==\"Translation\" :\n",
    "            #generate trannlation\n",
    "            generative_multimodal_model= GenerativeModel(model_name)\n",
    "            result=get_translation(assets=assets,action_type=action_type,input_text=input_text,Language=Language, model= generative_multimodal_model, project_id=project_id)\n",
    "        \n",
    "        elif action_type==\"key-clips\" : \n",
    "            #generate key video clips\n",
    "            video_clips_model_name='gemini-1.5-pro-001'\n",
    "            generative_multimodal_model= GenerativeModel(video_clips_model_name)\n",
    "            result=get_VideoClips(assets=assets,action_type=action_type, model= generative_multimodal_model, project_id=project_id)\n",
    "        \n",
    "    \n",
    "    except Exception as e:\n",
    "        result=\"Error- Service is not available or content generation has faced an issue:\\n\"+str(e)\n",
    "        error=result\n",
    "\n",
    "    end_time = time.time()\n",
    "    # Calculate the elapsed time\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(elapsed_time)\n",
    "    #record the search log\n",
    "    log_data(result,error,request_json,elapsed_time,project_id)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a80147a1-b7c4-4ebd-91ae-baa93e67f04e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     SELECT * FROM (\n",
      "        SELECT      asset_id, \n",
      "                    fileUri,  \n",
      "                    asset_type,               \n",
      "                   STRING_AGG(CONCAT (' ', CONCAT( 'Video details from offset ', startOffset_seconds,' seconds to ',endOffset_seconds,' seconds: ', '\\n'), description), '\\n' )  \n",
      "                     OVER (PARTITION BY asset_id ORDER BY ifnull(startOffset_seconds,0) ASC , IFNULL(endOffset_seconds,0) ASC ) AS full_description,\n",
      "                    ROW_NUMBER() OVER (PARTITION BY asset_id ORDER BY startOffset_seconds desc,endOffset_seconds desc) AS IDX,\n",
      "              FROM (\n",
      "                    SELECT * FROM \n",
      "                    (\n",
      "                        SELECT  distinct asset_id,startOffset_seconds,endOffset_seconds,fileUri,  \n",
      "                        asset_type,\n",
      "                        TRIM(CONCAT(IFNULL(headline,''), CHR(10),  description))  description,\n",
      "                        ROW_NUMBER() OVER (PARTITION BY asset_id,startOffset_seconds ORDER BY startOffset_seconds desc, chunk desc) AS IDX,\n",
      "                        FROM `vlt_media_embeddings_integration.vlt_all_media_content_text_embeddings` where asset_id in ('vlt_video_extract_MAAT_Full_MAAT2023_10_A_HBB.mp4')\n",
      "                      )\n",
      "                      WHERE IDX=1\n",
      "             )\n",
      "          )\n",
      "           WHERE IDX=1\n",
      "        \n",
      "Attempt 1 failed with error 500 Internal error encountered.. Retrying in 2.41 seconds...\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"Sure, here are the key clips from the video:\\n\\n| Timestamp | Title | Summary |\\n|---|---|---|\\n| 0:01-0:22 | Shannon\\'s Confession | Shannon confessed to the experts that he was intimate with his ex a week before coming to the experiment. The experts were shocked and said that he would not be there if they had known. |\\n| 0:22-0:28 | Bronte and Harrison\\'s Decision | At the commitment ceremony, Bronte wrote \\\"stay\\\" and Harrison wrote \\\"leave.\\\" Bronte was blindsided by Harrison\\'s decision. |\\n| 0:29-0:55 | Josh and Melissa\\'s Marriage | Josh and Melissa are having trouble in their marriage. Melissa is frustrated with Josh\\'s lack of effort and feels like she is the only one trying. |\\n| 0:56-1:17 | Adam\\'s Accusations | Adam is accused of flirting with Claire and saying that he would go home with her if Janelle left. Janelle is confused and upset by these accusations. |\\n| 1:18-1:46 | Jesse\\'s Anxiety | Jesse is feeling anxious about his recent behavior and the repercussions on the group. He is also feeling guilty about his connection with Claire during confessions week. |\\n| 1:47-2:28 | Bronte and Harrison\\'s Fight | Bronte and Harrison are fighting about Harrison\\'s decision to write \\\"leave\\\" at the commitment ceremony. Bronte feels like Harrison is gaslighting her and putting words in her mouth. Harrison feels like Bronte is playing the victim and blaming him for everything. |\\n| 2:29-3:00 | Janelle\\'s Decision | Janelle decides to stay with Adam despite the accusations against him. She feels like he is being honest with her and wants to focus on their relationship. |\\n| 3:01-3:59 | Alessandra\\'s Intimacy Workshop | Alessandra hosts an intimacy workshop for the brides and grooms. She talks about the importance of intimacy and how it can help to build a strong foundation for a long-lasting relationship. |\\n| 4:00-4:27 | Ollie\\'s Date | Ollie plans a romantic date for Tahnee to recreate their Fijian honeymoon. Tahnee is impressed with Ollie\\'s effort and they have a good time. |\\n| 4:28-4:59 | Harrison\\'s Date | Harrison plans a romantic date for Bronte, but she is not interested. She feels like he is trying to make himself look good and is not genuinely interested in her. |\\n| 5:00-5:59 | Josh and Melissa\\'s Intimacy Issues | Josh and Melissa are still having trouble with intimacy. Melissa feels like Josh is not putting in enough effort and is not interested in connecting with her on an emotional level. Josh feels like Melissa is putting too much pressure on him and is not giving him enough space. |\\n| 6:00-6:59 | Jesse and Claire\\'s Intimacy | Jesse and Claire are starting to connect on a deeper level. They are both enjoying the intimacy week tasks and are feeling more comfortable with each other. |\\n| 7:00-7:59 | Josh and Melissa\\'s Argument | Josh and Melissa have a big argument about their lack of intimacy. Melissa feels like Josh is not meeting her halfway and is not trying to make things work. Josh feels like Melissa is being too demanding and is not giving him enough space. |\\n| 8:00-8:59 | Bronte and Harrison\\'s Date | Harrison plans a date for Bronte, but she is not interested in going. She feels like he is gaslighting her and is not being genuine. Harrison feels like Bronte is being difficult and is not giving him a chance. |\\n| 9:00-9:59 | Josh and Melissa\\'s Breakfast | Josh and Melissa have an awkward breakfast together. They are both still upset about their fight the night before and are not communicating well. |\\n| 10:00-10:59 | Dan and Sandy\\'s Date | Dan plans a romantic date for Sandy at an Italian restaurant. Sandy is impressed with Dan\\'s effort and they have a good time. |\\n| 11:00-11:59 | Bronte and Harrison\\'s Confrontation | Bronte confronts Harrison about his behavior. She feels like he is gaslighting her and is not being honest with her. Harrison feels like Bronte is being dramatic and is overreacting. |\\n| 12:00-14:00 | Jesse\\'s Apology | Jesse apologizes to Adam and Janelle for his behavior at the commitment ceremony. He says that he was jealous and insecure, but that he is committed to making things right with Claire. |\\n| 14:01-14:59 | Harrison\\'s Plan | Harrison plans a date for Bronte, but she rejects his offer. Harrison feels like Bronte is not giving him a chance and is being unfair. |\\n| 15:00-16:59 | Alessandra\\'s Intimacy Challenge | Alessandra sets the grooms a challenge to plan a romantic and intimate date for their wives. The grooms are excited to take on the challenge and are looking forward to showing their wives a good time. |\\n| 17:00-19:59 | Intimacy Week Dates | The grooms plan their dates for their wives. Ollie recreates their Fijian honeymoon for Tahnee, Dan takes Sandy to an Italian restaurant, and Adam gives Janelle a pamper night. |\\n| 20:00-20:59 | Alessandra\\'s Advice | Alessandra gives the grooms advice on how to be more romantic and intimate with their wives. She also talks about the importance of communication and trust in a relationship. |\\n| 21:00-21:59 | The Grooms\\' Reactions | The grooms react to Alessandra\\'s advice. Some of them are receptive to her suggestions, while others are more resistant. |\\n\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.068359375\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.11572265625\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.07177734375\n",
      "    severity: HARM_SEVERITY_LOW\n",
      "    severity_score: 0.2158203125\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.23828125\n",
      "    severity: HARM_SEVERITY_LOW\n",
      "    severity_score: 0.2021484375\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: HIGH\n",
      "    probability_score: 0.8828125\n",
      "    severity: HARM_SEVERITY_HIGH\n",
      "    severity_score: 0.9765625\n",
      "  }\n",
      "  avg_logprobs: -0.1790624470471247\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 1186572\n",
      "  candidates_token_count: 1314\n",
      "  total_token_count: 1187886\n",
      "}\n",
      "model_version: \"gemini-1.5-pro-001\"\n",
      "\n",
      "281.6890776157379\n"
     ]
    }
   ],
   "source": [
    "from unittest.mock import Mock\n",
    "import json\n",
    "\n",
    "#\"vlt_video_extract_NINE_NEWS_SYD-NINE_NNNT23_101_A.mp4\", \n",
    "#vlt_video_extract_SIXTY_MINUTES_60MI23_14_A_HBB.mp4\n",
    "data={\"asset_ids\":\"vlt_video_extract_MAAT_Full_MAAT2023_10_A_HBB.mp4\",\n",
    "\"project\":\"nine-quality-test\",\n",
    "\"region\":\"us-central1\",\n",
    "\"action_type\":\"key-clips\"  \n",
    "       }\n",
    " \n",
    "# Simulating an HTTP request with the mock object\n",
    "mock_request = Mock()\n",
    "mock_request.get_json.return_value = data  # Mock the get_json method to return your data\n",
    "\n",
    "\n",
    "x=func_generate_content(mock_request)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c5767e75-ae28-4bde-b2e5-a266529e2f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here are the key clips from the video:\n",
      "\n",
      "| Timestamp | Title | Summary |\n",
      "|---|---|---|\n",
      "| 0:01-0:22 | Shannon's Confession | Shannon confessed to the experts that he was intimate with his ex a week before coming to the experiment. The experts were shocked and said that he would not be there if they had known. |\n",
      "| 0:22-0:28 | Bronte and Harrison's Decision | At the commitment ceremony, Bronte wrote \"stay\" and Harrison wrote \"leave.\" Bronte was blindsided by Harrison's decision. |\n",
      "| 0:29-0:55 | Josh and Melissa's Marriage | Josh and Melissa are having trouble in their marriage. Melissa is frustrated with Josh's lack of effort and feels like she is the only one trying. |\n",
      "| 0:56-1:17 | Adam's Accusations | Adam is accused of flirting with Claire and saying that he would go home with her if Janelle left. Janelle is confused and upset by these accusations. |\n",
      "| 1:18-1:46 | Jesse's Anxiety | Jesse is feeling anxious about his recent behavior and the repercussions on the group. He is also feeling guilty about his connection with Claire during confessions week. |\n",
      "| 1:47-2:28 | Bronte and Harrison's Fight | Bronte and Harrison are fighting about Harrison's decision to write \"leave\" at the commitment ceremony. Bronte feels like Harrison is gaslighting her and putting words in her mouth. Harrison feels like Bronte is playing the victim and blaming him for everything. |\n",
      "| 2:29-3:00 | Janelle's Decision | Janelle decides to stay with Adam despite the accusations against him. She feels like he is being honest with her and wants to focus on their relationship. |\n",
      "| 3:01-3:59 | Alessandra's Intimacy Workshop | Alessandra hosts an intimacy workshop for the brides and grooms. She talks about the importance of intimacy and how it can help to build a strong foundation for a long-lasting relationship. |\n",
      "| 4:00-4:27 | Ollie's Date | Ollie plans a romantic date for Tahnee to recreate their Fijian honeymoon. Tahnee is impressed with Ollie's effort and they have a good time. |\n",
      "| 4:28-4:59 | Harrison's Date | Harrison plans a romantic date for Bronte, but she is not interested. She feels like he is trying to make himself look good and is not genuinely interested in her. |\n",
      "| 5:00-5:59 | Josh and Melissa's Intimacy Issues | Josh and Melissa are still having trouble with intimacy. Melissa feels like Josh is not putting in enough effort and is not interested in connecting with her on an emotional level. Josh feels like Melissa is putting too much pressure on him and is not giving him enough space. |\n",
      "| 6:00-6:59 | Jesse and Claire's Intimacy | Jesse and Claire are starting to connect on a deeper level. They are both enjoying the intimacy week tasks and are feeling more comfortable with each other. |\n",
      "| 7:00-7:59 | Josh and Melissa's Argument | Josh and Melissa have a big argument about their lack of intimacy. Melissa feels like Josh is not meeting her halfway and is not trying to make things work. Josh feels like Melissa is being too demanding and is not giving him enough space. |\n",
      "| 8:00-8:59 | Bronte and Harrison's Date | Harrison plans a date for Bronte, but she is not interested in going. She feels like he is gaslighting her and is not being genuine. Harrison feels like Bronte is being difficult and is not giving him a chance. |\n",
      "| 9:00-9:59 | Josh and Melissa's Breakfast | Josh and Melissa have an awkward breakfast together. They are both still upset about their fight the night before and are not communicating well. |\n",
      "| 10:00-10:59 | Dan and Sandy's Date | Dan plans a romantic date for Sandy at an Italian restaurant. Sandy is impressed with Dan's effort and they have a good time. |\n",
      "| 11:00-11:59 | Bronte and Harrison's Confrontation | Bronte confronts Harrison about his behavior. She feels like he is gaslighting her and is not being honest with her. Harrison feels like Bronte is being dramatic and is overreacting. |\n",
      "| 12:00-14:00 | Jesse's Apology | Jesse apologizes to Adam and Janelle for his behavior at the commitment ceremony. He says that he was jealous and insecure, but that he is committed to making things right with Claire. |\n",
      "| 14:01-14:59 | Harrison's Plan | Harrison plans a date for Bronte, but she rejects his offer. Harrison feels like Bronte is not giving him a chance and is being unfair. |\n",
      "| 15:00-16:59 | Alessandra's Intimacy Challenge | Alessandra sets the grooms a challenge to plan a romantic and intimate date for their wives. The grooms are excited to take on the challenge and are looking forward to showing their wives a good time. |\n",
      "| 17:00-19:59 | Intimacy Week Dates | The grooms plan their dates for their wives. Ollie recreates their Fijian honeymoon for Tahnee, Dan takes Sandy to an Italian restaurant, and Adam gives Janelle a pamper night. |\n",
      "| 20:00-20:59 | Alessandra's Advice | Alessandra gives the grooms advice on how to be more romantic and intimate with their wives. She also talks about the importance of communication and trust in a relationship. |\n",
      "| 21:00-21:59 | The Grooms' Reactions | The grooms react to Alessandra's advice. Some of them are receptive to her suggestions, while others are more resistant. |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "52e7a785-c497-45fc-8601-664268915a6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text='Video details from offset 0 seconds to 600 seconds: \\nHere\\'s a detailed description of the video you provided:\\n\\n**Category**\\nReality TV Show\\n\\n**DetailedDescriptionOfEventsAndConversations**\\n\\nThe video begins with a night scene of a dark building with lit windows. The scene transitions to a \"Previously on\" segment, recapping events from a reality show, likely \"Married at First Sight.\"\\n\\nThe first scene shows a man and woman sitting on a green couch, engaged in a serious conversation. A woman with blonde hair and silver earrings, possibly a relationship expert, questions the man about being intimate with his ex a week before joining the experiment. The man, appearing slightly uncomfortable, confirms this. Other participants react with surprise and shock.\\n\\nThe scene shifts to a commitment ceremony, a pivotal event in the show. The narrator describes it as the newlyweds\\' first commitment ceremony. A woman in a green dress reveals her decision to \"stay\" in the experiment, while her male partner chooses to \"leave.\" This unexpected turn of events leads to emotional reactions, particularly from the woman.\\n\\nThe focus then moves to another couple, where a woman named Alessandra is credited with helping Melissa and Josh rekindle intimacy in their relationship. The experts suggest that Melissa and Josh can learn from each other to build a strong emotional connection and a fulfilling sex life.\\n\\nThe next scene highlights a confrontation between a couple. The man, Jesse, is accused of overreacting to cheating allegations. He admits that the experiment has brought out the worst in him. Jesse chooses to \"leave,\" while his partner, Claire, opts to \"stay.\" This decision leads to Jesse\\'s departure from the show.\\n\\nThe segment transitions to \"Alessandra\\'s Intimacy Week,\" showcasing various couples engaging in intimate activities like massages, pillow fights, and playful interactions. The atmosphere is lighthearted and sensual.\\n\\nHowever, the mood shifts again as Jesse confesses to having jealousy issues. He admits to overreacting and expresses regret for his actions. The scene shows him hugging Claire, suggesting a reconciliation.\\n\\nThe narrative then turns to another couple facing challenges. Harrison accuses Bronte of gaslighting him. Bronte appears upset and frustrated by the accusations. The scene highlights the tension and conflict in their relationship.\\n\\nThe focus returns to Melissa and Josh, whose marriage is on the rocks. Melissa criticizes Josh\\'s inability to love, leading to an emotional breakdown from Josh. He expresses doubt about continuing in the experiment.\\n\\nThe show\\'s title card, \"Married at First Sight,\" appears, followed by a scenic view of Sydney\\'s skyline and harbor. The scene then shifts to a modern apartment building, where the couples are shown navigating the aftermath of the commitment ceremony.\\n\\nSome couples, like Harrison and Bronte, and Lyndall and Cameron, are shown enjoying a peaceful morning, making coffee and engaging in light conversation. However, the tension from the previous night\\'s events is palpable in other couples\\' interactions.\\n\\nJanelle and Adam discuss the revelations from the commitment ceremony, particularly Shannon\\'s confession about still loving his ex. Janelle expresses shock and surprise at this revelation.\\n\\nThe focus shifts back to Shannon and Caitlin. Shannon expresses his desire to win Caitlin back and focus on their relationship. He acknowledges his past mistakes and emphasizes his commitment to Caitlin.\\n\\nThe segment then revisits the accusations made against Adam. Janelle expresses confusion and questions the truth behind the allegations. Adam denies the accusations and emphasizes his commitment to Janelle.\\n\\nThe scene moves to Jesse and Claire, who are still living separately. Jesse expresses anxiety about his recent behavior and its impact on the group. Claire reflects on Jesse\\'s decision to leave and his admission about his jealousy. She expresses a desire for Jesse to step up and make things right.\\n\\nThe final scene shows Melissa and Josh attempting to move forward after their difficult conversation. Melissa expresses excitement about intimacy week and initiates a conversation about sex. Josh appears receptive to her efforts.\\n\\n**BrandsCompanyNamesLogos**\\n\\n* Tommy Hilfiger logo on a sweatshirt\\n* Lacoste logo on a t-shirt\\n* Louis Vuitton logo on a purse\\n* New Era logo on a baseball cap\\n* Raiders logo on a sweatshirt\\n* Bulls logo on a baseball cap\\n\\n**KeyLocationsAndScenes**\\n\\n* Dark building with lit windows (likely the apartment complex where the participants live)\\n* Commitment ceremony set (a formal space with couches and lighting)\\n* Various apartment interiors (showcasing the couples\\' living spaces)\\n* Sydney skyline and harbor (establishing shot)\\n* Modern apartment building exterior (establishing shot)\\n\\n**KeyThemes**\\n\\n* Commitment and trust in relationships\\n* Communication and conflict resolution\\n* Jealousy and insecurity\\n* Intimacy and emotional connection\\n* The challenges of a social experiment\\n\\n**PeopleAppearingAndMentioned**\\n\\n* Shannon (Personal Trainer, VIC, 30)\\n* Caitlin\\n* Jesse (Marriage Celebrant, WA, 30)\\n* Claire (Kindergarten Assistant, VIC, 31)\\n* Alessandra\\n* Melissa (Hairdresser, NSW, 41)\\n* Josh\\n* Harrison\\n* Bronte\\n* Adam\\n* Janelle (Beauty Influencer, WA, 28)\\n* Lyndall\\n* Cameron\\n\\n\\nLet me know if you have any other questions.\\n Video details from offset 600 seconds to 1200 seconds: \\nHere is a detailed description of the video from seconds 600 to 1200, following your requested format:\\n\\n**Category**\\n\\nReality TV Show\\n\\n**DetailedDescriptionOfEventsAndConversations**\\n\\nThe video clip begins with a scene of a woman, Melissa, and a man, Josh, having breakfast. Melissa is wearing a navy blue pajama top with pink trim and monogrammed initials \"MMS\" on the pocket. Josh is wearing a black t-shirt with a graphic design. Melissa expresses her disappointment with the lack of intimacy in her relationship with Josh during what she had anticipated to be \"intimacy week.\" She mentions they mostly talk about toast. Josh makes toast with peanut butter. Melissa reflects on Josh\\'s efforts to get to know her, acknowledging his awareness of her dislike for sourdough bread. She hopes these small gestures are his way of initiating intimacy. They eat breakfast separately, Melissa on the couch and Josh at the dining table. Josh drinks chocolate milk from a carton labeled \"OAK.\" Melissa contemplates how she can meet Josh halfway in their relationship.\\n\\nThe scene transitions to Bronte sitting on a balcony, feeling blindsided by Harrison\\'s decision to write \"leave\" at the commitment ceremony. The next scene shows Harrison and Bronte sitting on separate couches during a therapy session. Harrison explains his decision to write \"leave,\" citing their prolonged separation as a reason why he doesn\\'t consider their situation a relationship. Bronte expresses confusion and frustration, mentioning a text message from Harrison before the commitment ceremony where he stated he wasn\\'t going anywhere. She accuses him of blindsiding her and changing his mind without giving her time to process.\\n\\nThe scene shifts to Harrison entering their apartment, looking for Bronte. He finds her on the balcony. Bronte, wearing a white cropped top, green cargo pants, and sunglasses, confronts Harrison about his decision to write \"leave.\" She shows him a text message on her phone where he said he wasn\\'t leaving. Harrison denies saying \"I\\'m not leaving,\" claiming she\\'s twisting his words and gaslighting him. Bronte insists he did say it and becomes increasingly upset. She accuses him of being a narcissist and storms off. Harrison expresses frustration with Bronte\\'s behavior, calling her disingenuous and accusing her of playing the victim. He states he won\\'t tolerate her inaccurate accusations and blames her for constantly blaming him for everything.\\n\\nBronte is shown crying on the couch, expressing hurt and frustration with Harrison\\'s inability to listen. She accuses him of trying to portray himself as perfect and putting words in her mouth. She repeats her accusation of gaslighting. The scene ends with Bronte walking away, saying she\\'s done and leaving. Harrison stands in the kitchen, frustrated and upset.\\n\\nThe video then transitions to a promotional segment about \"intimacy week,\" highlighting the challenges and opportunities for the newlyweds to explore intimate aspects of their relationships. Alessandra, a clinical sexologist, is introduced as the expert guiding the couples through this phase. Several couples are shown receiving invitations for a workshop. Janelle and Adam, Claire and Jesse, and Bronte and Harrison are among the couples shown reading their invitations.\\n\\nAlessandra explains the purpose of the workshops, emphasizing the importance of intimacy beyond just sex. She plans to host separate workshops for the brides and grooms to create a safe space for open exploration of different aspects of intimacy. The scene shows the brides arriving at the workshop, greeted by Alessandra. Alessandra acknowledges the apprehension surrounding \"intimacy week,\" clarifying that it\\'s not just about sex but about building a strong foundation for lasting relationships. She reveals goodie bags for the participants. The scene ends with the brides reacting with excitement and curiosity to the contents of the goodie bags.\\n\\n\\n**BrandsCompanyNamesLogos**\\n\\n* OAK (chocolate milk carton)\\n* New Era (baseball cap)\\n* Lacoste (t-shirt logo)\\n* Louis Vuitton (purse)\\n\\n\\n**KeyLocationsAndScenes**\\n\\n* Apartment kitchen and living area (Melissa and Josh\\'s apartment)\\n* Apartment balcony (Bronte and Harrison\\'s apartment)\\n* Therapy session room (Harrison and Bronte)\\n* Skye Suites Sydney (exterior shot)\\n* City street with brick buildings\\n* Sydney Opera House and Harbour Bridge\\n* Workshop venue (interior with couches and brick walls)\\n\\n\\n**KeyThemes**\\n\\n* Intimacy and communication in relationships\\n* Misunderstandings and conflict\\n* Accusations of gaslighting and manipulation\\n* Importance of emotional connection\\n* Exploration of sexuality\\n\\n\\n**PeopleAppearingAndMentioned**\\n\\n* Melissa\\n* Josh\\n* Bronte\\n* Harrison\\n* Alessandra Rampolla (Clinical Sexologist)\\n* Janelle\\n* Adam\\n* Claire\\n* Jesse\\n* Tahnee\\n Video details from offset 1200 seconds to 1800 seconds: \\nHere\\'s a detailed description of the video from 12:00 to 18:00, following your requested format:\\n\\n**Category**\\n\\nReality TV Show\\n\\n**DetailedDescriptionOfEventsAndConversations**\\n\\nThe scene opens with Alessandra, a sexologist, leading a workshop on intimacy with a group of women. Alessandra holds a pink sex toy, initiating a conversation about its use and the associated taboos. A woman in a peach-colored t-shirt expresses that her Mormon upbringing makes the topic of sex toys particularly sensitive for her. Alessandra reassures her that it\\'s something she can overcome, emphasizing that it\\'s her body and her right to explore her sexuality fully.\\n\\nThe scene shifts to two women on a couch, one in a mustard-yellow top and the other in an orange shirt. The woman in yellow expresses her reluctance to use sex toys, fearing it might set her partner up for failure. Alessandra interjects, suggesting a different perspective: that using sex toys is like a party, and the partner is invited to join in the fun. She emphasizes that sex toys don\\'t replace a partner\\'s role in providing pleasure, but can add variety and intensity to the experience.\\n\\nAlessandra then addresses the group, highlighting the importance of how one treats and speaks to their partner, and how that contributes to their partner\\'s feelings. She encourages the women to try the items in their \"goodie boxes.\" The scene cuts to the women laughing and reacting to the suggestion.\\n\\nThe scene changes to a wider shot of the room, showing the women seated on a couch, and Alessandra sitting in a chair facing them. Three men enter the room and take seats on a separate couch. Alessandra welcomes them and asks if they\\'re nervous. One of the men responds that he\\'s looking forward to the session.\\n\\nAlessandra then asks the men about the best places to touch women to turn them on. They suggest the collarbone, neck, and thighs. Alessandra prompts them further, leading them to the heart and, finally, emphasizing the importance of treating and speaking to women in a way that makes them feel good. She encourages the men to try the items in their goodie boxes.\\n\\nThe scene shifts to a man with long hair and tattoos, sitting on a bed. He expresses his admiration for Alessandra\\'s confidence in discussing intimate topics. He recalls a conversation with Alessandra where they discussed the taboo nature of such conversations, and how Alessandra\\'s openness encouraged him to talk about it.\\n\\nAlessandra asks the men about their feelings on sex toys. Some express enthusiasm, while one man states he\\'s never needed an accessory. Alessandra challenges his perspective, suggesting that sex toys can enhance pleasure and expand the range of sensations one can experience. She clarifies that sex doesn\\'t always have to involve penetration, and that all erogenous zones are valid.\\n\\nThe scene cuts to a man in a white t-shirt, who says he\\'s never needed an accessory. Alessandra responds humorously, pointing out that nobody \"needs\" a toy, just as one doesn\\'t need utensils to eat steak. She encourages them to expand their possibilities for experiencing sensations.\\n\\nThe scene shifts to a man in a red baseball cap, standing in a kitchen. He\\'s looking at his phone, reading a text message from Bronte that says \"No thanks.\" The scene then cuts to a city street at night, then to a man and woman sitting on a couch, discussing intimacy. The woman expresses frustration with the man\\'s apparent difficulty with intimacy. The man appears distressed and unsure if he can continue with the experiment.\\n\\nThe scene changes to a man with long hair and a chain necklace, sitting on a bed. He reflects on Alessandra\\'s workshop, describing himself as a sponge soaking up information. He expresses the need for more time to process everything he\\'s learned.\\n\\nAlessandra addresses the group again, acknowledging that they\\'ve only scratched the surface of the topic. She introduces a challenge for the men: to plan the perfect romantic and intimate date for their partners. She emphasizes that the date doesn\\'t have to be sexual, but should be intimate and erotic.\\n\\nThe scene cuts to various men planning their dates, using laptops and making notes. One man searches online for romantic date ideas. Another plans to recreate his Fijian honeymoon for his wife.\\n\\nThe scene ends with Ollie, wearing a lei, preparing a romantic surprise for his wife, Tania. He decorates their apartment with tropical-themed items and prepares coconut drinks. He expresses his excitement for the date and his hope that it will strengthen their connection.\\n\\n**BrandsCompanyNamesLogos**\\n\\nLacoste (logo on shirts)\\n\\n\\n**KeyLocationsAndScenes**\\n\\n* Workshop room with a green painting on the wall\\n* Couch with two women\\n* Wider shot of the room with two couches and a group of women and men\\n* Bedroom with an orange bedspread\\n* Kitchen with wooden cabinets\\n* City street at night\\n* Living room with a beige couch and framed pictures on the wall\\n* Apartment with a brown couch, a glass table, and a wooden room divider\\n* Bedroom with a blue bedspread and a wooden closet\\n* Apartment decorated with tropical-themed items\\n* Beach in Fiji\\n* Kitchen with a white countertop and a sink\\n\\n**KeyThemes**\\n\\n* Intimacy and communication in relationships\\n* Exploring sexuality and overcoming taboos\\n* The role of sex toys in relationships\\n* Planning romantic and intimate dates\\n* Reflecting on past experiences and strengthening connections\\n\\n**PeopleAppearingAndMentioned**\\n\\n* Alessandra (sexologist)\\n* Woman in peach-colored t-shirt (Mormon background)\\n* Woman in mustard-yellow top\\n* Woman in orange shirt\\n* Man with long hair and tattoos (Jesse)\\n* Man in white t-shirt (Josh)\\n* Man in red baseball cap (Harrison)\\n* Bronte (mentioned in text message)\\n* Ollie (planning a date for Tania)\\n* Tania (Ollie\\'s wife)\\n* Sandy (mentioned in conversation)\\n Video details from offset 1800 seconds to 2400 seconds: \\nSure, here is a detailed description of the video from 1800 seconds to 2400 seconds.\\n\\n**Category**\\n\\nTV Show\\n\\n**DetailedDescriptionOfEventsAndConversations**\\n\\nThe video begins with Tahnee, a 27-year-old PR manager from New South Wales, expressing her delight at the transformation of her apartment into a Fiji beach setting. Her partner, Ollie, has orchestrated this surprise, recreating their honeymoon destination. Tahnee is touched by Ollie\\'s thoughtfulness and appreciates his effort to create a special and intimate experience. They share drinks, take photos, and enjoy the recreated beach atmosphere.\\n\\nThe scene then shifts to Darling Harbour, where Dan, a 42-year-old digital business owner from Queensland, is on a date with Sandy, a 36-year-old dental hygienist from Victoria. Dan has chosen an Italian restaurant, a cuisine they both enjoyed during their honeymoon. They discuss their preferences and share a meal, enjoying each other\\'s company. Sandy compliments Dan on his intelligence and open-mindedness, qualities she values. Dan, in turn, praises Sandy\\'s loyalty and expresses feeling safe with her. Sandy admits that she\\'s never been in a serious relationship before and finds talking about deep things with Dan a new and impressive experience. She feels that she\\'s getting to know him better and appreciates his openness.\\n\\nNext, the focus shifts to Harrison, a 32-year-old builder from New South Wales, who is planning a date for Bronte. He searches for date ideas online, considering a stroll around Barangaroo Reserve and a picnic. He sends Bronte a text message inviting her on the date, but she declines. Harrison expresses his frustration, pointing out that he\\'s making an effort and that Bronte had previously expressed a desire to work on their relationship. He feels that Bronte\\'s words and actions are contradictory. Despite her rejection, Harrison decides to proceed with the date plans, hoping she\\'ll change her mind.\\n\\nThe scene transitions to Adam, a 35-year-old entrepreneur from Queensland, who is preparing a pampering night for Janelle. He sets up a romantic atmosphere with flowers, chocolates, champagne, and nail polish. He blindfolds Janelle and leads her to the surprise. Janelle is delighted and expresses her appreciation for Adam\\'s gesture. Adam apologizes for the difficulties they faced during the commitment ceremony and expresses his appreciation for Janelle and his commitment to their relationship. He gives Janelle a foot massage, and they share a moment of connection and laughter.\\n\\nFinally, Jesse, a 30-year-old marriage celebrant from Western Australia, is planning a date for Claire. He wants to keep things simple and close to home, aiming for a relaxed and enjoyable experience. He invites Claire over, and she is surprised and pleased by his effort. They set up a bowling game using water bottles and a crumpled ball of aluminum foil. They share a meal and drinks, and Claire expresses her appreciation for Jesse\\'s creativity. She asks Jesse if he feels forced to be there, and he assures her that he\\'s there for a reason and wants to learn more about her. Claire acknowledges that it\\'s difficult for Jesse to express his vulnerability, but she appreciates his effort. She feels that the conversation has brought them closer and is optimistic about their future.\\n\\n**BrandsCompanyNamesLogos**\\n\\n* Google (search engine)\\n* The Urban List (website)\\n* Hungry by Nature (website)\\n* Casa (restaurant name)\\n* Macquarie (building name)\\n* Lacoste (logo on Harrison\\'s shirt)\\n* New Era (logo on Harrison\\'s cap)\\n* Skye (building name)\\n* Bronte & Harrison (sign)\\n* Janelle & Adam (sign)\\n* Lindt (chocolate brand)\\n* Claire & Jesse (sign)\\n* Boss (store name)\\n* Grace (store name)\\n* Prosecco (wine brand)\\n\\n**KeyLocationsAndScenes**\\n\\n* Tahnee and Ollie\\'s apartment, transformed into a Fiji beach setting\\n* Darling Harbour, Italian restaurant\\n* Harrison and Bronte\\'s apartment\\n* Adam and Janelle\\'s apartment\\n* Jesse and Claire\\'s apartment\\n\\n**KeyThemes**\\n\\n* Romance and intimacy\\n* Thoughtfulness and effort in relationships\\n* Communication and vulnerability\\n* Challenges and growth in relationships\\n\\n**PeopleAppearingAndMentioned**\\n\\n* Tahnee, 27, PR manager, NSW\\n* Ollie\\n* Dan, 42, digital business owner, QLD\\n* Sandy, 36, dental hygienist, VIC\\n* Harrison, 32, builder, NSW\\n* Bronte\\n* Adam, 35, entrepreneur, QLD\\n* Janelle\\n* Jesse, 30, marriage celebrant, WA\\n* Claire\\n* Alessandro (mentioned)\\n Video details from offset 2400 seconds to 3000 seconds: \\nSure, here is a detailed description of the video from period 2400 seconds (40:00) to 3000 seconds (50:00) following the format you requested.\\n\\n**Category**\\nTV Show\\n\\n**DetailedDescriptionOfEventsAndConversations**\\n\\nThe scene opens with Claire and Jesse sitting at a table in a kitchen area. Claire, with long brown hair and gold hoop earrings, wears a black short-sleeved top and khaki pants. Jesse, with a man bun and tattoos on his arms, wears a dark blue short-sleeved top and white pants. They have a charcuterie board, crackers, and two glasses of a yellow drink in front of them. A bottle of Prosecco sits near the glasses. Claire tells Jesse that the door is metaphorically open for him to return, but shut for safety purposes. She smiles and tells him to let her know if he decides to return, and they will be happy to have him. Jesse smiles and nods.\\n\\nThe scene cuts to Jesse sitting on a bed with an orange pillow behind him. He says that his and Claire\\'s connection has taken a healthy step in the right direction after tonight.\\n\\nThe scene cuts back to Claire and Jesse in the kitchen area. Claire is now wearing a beige, fuzzy cardigan. She throws a crumpled ball of paper at some empty plastic water bottles set up like bowling pins in the hallway outside the kitchen. She knocks them all down. Jesse laughs and covers his face with his hands. Claire runs back into the kitchen and celebrates. She then runs out into the hallway again and throws her arms up in victory. Jesse continues to laugh. Claire returns to the kitchen and hugs Jesse. She tells him that she is sure he is good at something in life, but bowling is not one of them. They hug again.\\n\\nThe scene cuts to a shot of the Sydney Opera House at sunset. Then, it shows a street in Sydney at night, with cars driving by. A sign for Skye Suites is shown.\\n\\nThe scene cuts to Bronte sitting on a bed in a hotel room. She wears a black long-sleeved top, olive green cargo pants, and a white headband. She says that Harrison sent her a message about a date, and she wonders what would make him think that she would want to spend more than two seconds with him. She calls him a gaslighter and a liar, and says that she stormed down and told him she was done. She wonders why he would still plan a date, just to make himself look good. She says that Harrison does whatever he wants. She says she feels awful and that she came into the suite with high hopes, but has been constantly let down by Harrison. She says it is really disappointing. A producer asks her what she thinks Harrison would have done for her. She replies that he would have wined and dined someone on the coastline. She wipes a tear from her eye.\\n\\nThe scene cuts to a framed photo of Harrison and his wife on their wedding day. Harrison, wearing a blue suit and tie, stands next to his wife, who wears a white wedding dress and holds a bouquet of white flowers. A hand holding a glass of wine is seen in front of the photo.\\n\\nThe scene cuts to a view of the Sydney skyline at night. A boat moves across the water. Then, Harrison is shown sitting on a bench by the water. He wears a white Tommy Jeans sweatshirt, light blue jeans, and a red baseball cap. He says that he asked Bronte out and she said no. He takes a sip of wine from a wine glass. He says that he wanted to go last night, but at Bronte\\'s request, he stayed and is here doing the work. He says that Bronte is not there. He says that he made the commitment to stay there another week and work on the relationship, and he is going to do that with or without Bronte. A framed photo of Harrison and his wife is shown again. A producer asks him if he feels awkward being on the date on his own. He replies that he does not mind, he has his wife with him. He says that people come from all over Sydney to chill there. He says that it has honestly been one of the best dates he has had in a long time. They have done everything he wanted to do. He asks the producer if they are hungry. The producer replies that they are. Harrison says that he feels like he and his wife have shared a lot and been intimate, and had fun tonight. He asks if the producer had fun. The producer replies yes. He says he is going to get some dinner. He walks away, carrying the framed photo.\\n\\nThe scene cuts to the Married at First Sight logo. Then, a view of the Sydney skyline during the day is shown. Cars are shown stopped at a red light. The Skye Suites sign is shown again. A sign on a door reads \"Melissa & Josh.\" A framed photo of Melissa and Josh on their wedding day is shown. Josh, wearing a black suit, stands next to Melissa, who wears a white wedding dress and holds a bouquet of flowers.\\n\\nJosh and Melissa are sitting on a couch. Melissa wears a white t-shirt and black pants. Josh wears a black t-shirt and jeans. Josh tells Melissa to close her eyes. He counts down from three, then reveals a Lego set. Melissa is excited and hugs Josh. She says it is the best Lego ever. Josh says it is Thor\\'s hammer. Melissa says that there are going to be a lot of Thor\\'s hammer jokes. She says it is so thoughtful, like something from everyone. She says that Josh gets a tick.\\n\\nMelissa says that there was feedback yesterday from Alessandra about making an effort. Josh says that he is very hopeful that Melissa can see the effort he is trying to show. Melissa asks Josh about his childhood and if he built Lego growing up. Josh says that they were outside kids, and his parents would have dinner parties. He says that they were the cheeky kids that would sneak downstairs to see what the adults were doing, and all the kids would come to their house and have snacks because his parents owned a supermarket. Melissa is surprised. Josh says that he didn\\'t think she would be that talkative. Melissa says that when she would get in trouble, she would say it was her twin sister. Josh asks if they were ever in the same class. Melissa replies that they were, but then they had to separate them because they talked too much. Josh laughs. Melissa says that she didn\\'t think he would be that talkative. Josh says that it was a great conversation. He says that if he had known that Lego was going to bring them closer together, he probably would have reached into his Lego inventory at home a lot sooner in their relationship. He says that they can see it is starting to take shape. Melissa asks if he is talking about their relationship. Josh replies no. Melissa laughs. She says that this is a really good activity. Josh says that he doesn\\'t feel like a sex object today. He says that he actually feels like they are bonding and talking about their childhoods, which they haven\\'t done the entire time they have been together. Melissa says that when she was a twin, she never knew what it was like to be lonely because she always had someone there. Josh says that is nice. Melissa says that when she would get in trouble, she would say it was her twin sister. Josh asks if they were ever in the same class. Melissa replies that they were, then they had to be separated because they talked too much. Josh laughs. Melissa says that you can see how that happens. Josh says that he didn\\'t think she would be that talkative. Melissa says that it\\'s like intimacy week, but it keeps going the way that it\\'s going. She hopes they can rip open their goody bags and have some fun together.\\n\\nThe scene cuts to a view of the Sydney skyline. A brick building with arched windows is shown.\\n\\nAlessandra, wearing a blue dress, knocks on a door with a sign that reads \"Claire & Jesse.\" Claire, wearing a pink t-shirt and black shorts, opens the door. Alessandra enters and hugs Claire. Claire calls Jesse on the phone and tells him that Alessandra is there and asks if he can come down. Jesse says that he is reading the Kama Sutra book that Alessandra gave them. Claire laughs and tells him that speaking of Alessandra, she is there and asks if he can come down. Jesse says wow and asks her to give him a second. Claire says she will see him soon and hangs up. Alessandra says that is amazing. Claire says that she is excited but a little bit nervous. Alessandra says good, that means this means something to her. Claire says that of course it does.\\n\\nThe scene cuts to Alessandra, wearing a brown shirt, sitting in a room with a blurred background. She says that for Claire and Jesse, the experiment has been very challenging so far. They have had to negotiate a lot of obstacles, but it is encouraging to see that they have started to repair their relationship. She hopes the exercises will help them this week.\\n\\nA framed photo of Lyndall and Cameron on their wedding day is shown. Lyndall wears a white wedding dress and holds a bouquet of flowers. Cameron wears a red suit.\\n\\nAlessandra, Claire, and Jesse are sitting in a living room. Alessandra, wearing a blue dress, sits in a chair. Claire and Jesse sit on a brown couch. Alessandra tells them that coming into this week, she thinks it is clear to both of them that the intent is not necessarily to push anything to happen between them, but to build connection. She says her idea for them is to go back to basics and start from the very beginning and see if they can build a space of trust and a space of safety. She asks if they are ready. Claire and Jesse say okay. Alessandra tells them to get up and stand in front of one another, facing each other. She tells them to step forward, hug, and put their arms around each other. She tells them to get their knees closer together. She tells them to simply feel their heartbeats and see what that is like.\\n\\nJesse says that hugging Claire like that was a little bit like, \"Oh, this is really, really nice.\" He says he is not used to that, but standing there for a few minutes, he could feel himself becoming more and more relaxed. He says it was a touching moment and he would like to do more hugging like that with Claire.\\n\\n\\n**BrandsCompanyNamesLogos**\\n\\n* Prosecco\\n* Gucci (belt buckle)\\n* Skye Suites\\n* Tommy Jeans\\n* New Era (baseball cap)\\n* New York Yankees (baseball cap logo)\\n* Lacoste\\n* Lego\\n\\n**KeyLocationsAndScenes**\\n\\n* Kitchen area with a table and chairs\\n* Bedroom with an orange pillow\\n* Hallway with empty water bottles set up like bowling pins\\n* Sydney Opera House\\n* Sydney street at night\\n* Hotel room with a bed\\n* Coastline at night\\n* Restaurant\\n* Living room with a couch and coffee table\\n\\n**KeyThemes**\\n\\n* Relationship building and connection\\n* Trust and safety in relationships\\n* Vulnerability and intimacy\\n* Communication and effort in relationships\\n\\n**PeopleAppearingAndMentioned**\\n\\n* Claire\\n* Jesse\\n* Bronte\\n* Harrison\\n* Alessandra Rampolla (Clinical Sexologist)\\n* Melissa\\n* Josh\\n Video details from offset 3000 seconds to 3600 seconds: \\nThe video starts with Claire, a 31-year-old kindergarten assistant from Victoria, recalling a moment of intimacy with Jesse. She describes how their relationship progressed from initial awkwardness to a comfortable and natural connection. She reminisces about their wedding day, recalling the spark she felt when she first saw Jesse at the altar. The video then shows flashbacks of their wedding ceremony, highlighting their joy and laughter.\\n\\nThe scene shifts back to the present, with Claire expressing gratitude for the universe for bringing them together. Alessandra, a relationship expert, observes their interaction and comments on the relaxed atmosphere between Claire and Jesse, suggesting they are no longer at war with each other and can be themselves.\\n\\nJesse is then shown walking down a hallway at night, mentioning his plan to visit Janelle and Adam. The video then cuts to a scene with Melissa and Josh, where Melissa expresses her frustration with Josh\\'s lack of intimacy. She complains about his lack of affection and physical touch, contrasting it with her past relationships. Josh listens to her concerns and acknowledges her feelings.\\n\\nThe video transitions to a montage of couples exploring the contents of goodie bags provided by Alessandra. The bags contain various items related to intimacy, including sex toys and lubricants. Claire humorously comments on the potential reactions of the sound crew to the noises from the devices.\\n\\nThe video then shows several couples using the items from the goodie bags. Tahnee, a 27-year-old PR manager from New South Wales, and Ollie are shown using a vibrator, with Tahnee expressing her satisfaction with the experience. Another couple, Harrison and Bronte, are shown using various items from the bag, with Bronte expressing her amusement and Harrison playfully suggesting selling some of the items online.\\n\\nThe scene shifts back to Josh and Melissa in bed. Melissa expresses her dissatisfaction with Josh\\'s lack of cuddling and kissing, stating that it makes her feel uncomfortable and insecure in their relationship. Josh listens to her concerns and acknowledges her feelings.\\n\\nThe video ends with Jesse visiting Janelle and Adam, offering them a peace offering of champagne and chocolates. Janelle and Adam accept his apology, and Jesse expresses his relief and happiness at their reconciliation.\\n\\n**Brands, Company Names, or Logos:**\\n\\n* The Roommate by Rosie Danan (book)\\n* I Am Pilgrim by Terry Hayes (book)\\n* The Nowhere Child by Christian White (book)\\n* Harley Davidson (logo on Claire\\'s t-shirt)\\n* Breville (coffee machine)\\n* Mr. Sex Wax (product)\\n* New York Yankees (logo on Adam\\'s cap)\\n* Skye Suites (hotel)\\n\\n**People Mentioned:**\\n\\n* Claire\\n* Jesse\\n* Alessandra\\n* Janelle\\n* Adam\\n* Melissa\\n* Josh\\n* Harrison\\n* Bronte\\n* Tahnee\\n* Ollie\\n* Dan\\n* Sandy\\n\\n**Key Locations:**\\n\\n* Claire and Jesse\\'s apartment\\n* Janelle and Adam\\'s apartment\\n* Harrison and Bronte\\'s apartment\\n* Tahnee and Ollie\\'s apartment\\n* Josh and Melissa\\'s apartment\\n* Skye Suites hotel\\n* Sydney, Australia (cityscape shots)\\n\\n\\nThis detailed description provides a comprehensive overview of the video\\'s content, key themes, individuals involved, and any notable brands or locations featured. It adheres to the prompt\\'s request for a 4000-word description without adding any extra text or interpretation.\\n Video details from offset 3600 seconds to 4022 seconds: \\n**Category**\\nReality TV Show\\n\\n**DetailedDescriptionOfEventsAndConversations**\\n\\nThe scene opens with a view of a curved hallway in a modern building. Two figures, a man and a woman, are visible in a doorway on the upper level. The woman, Claire, 31, a kindergarten assistant from Victoria, appears in a close-up shot. She recounts a recent interaction with Jesse, who came to her door to say goodnight. Claire expresses her appreciation for this gesture, finding it \"really, really sweet.\" She shares that she\\'s \"feeling off\" after the day\\'s events.\\n\\nThe scene transitions to Claire standing at her apartment door, talking to Jesse. Jesse, with his hair tied back in a bun, smiles and asks Claire if she had a good day. Claire replies affirmatively, and Jesse echoes her sentiment. Claire expresses her happiness at seeing Jesse take advice from Alyssa and Sandra, feeling more connected to him as a result. She believes they are on a better path.\\n\\nClaire thanks Jesse for coming to say goodnight, calling it \"sweet.\" Jesse responds, \"That\\'s okay.\" Claire suggests a \"melting one\" (hug), and they embrace warmly. The scene briefly returns to the curved hallway, then back to Claire and Jesse hugging. Claire expresses her anticipation for sharing the space with Jesse again in a more harmonious way. She mentions a full moon and her intention to charge her crystals, aiming to return with \"happy, friendly, fun energy\" for the next day. She reiterates her thanks to Jesse for his goodnight visit.\\n\\nThe scene cuts to a shot of a building at night, with the name \"SKYE\" illuminated on its side. Then, a door sign reading \"MELISSA & JOSH\" is shown. Inside the apartment, a framed wedding photo of Melissa and Josh is displayed on a nightstand. Melissa and Josh are sitting on a couch, discussing their differing views on intimacy. Melissa expresses concern about the lack of intimacy in their relationship, stating that it\\'s a significant part of how she loves. She feels they don\\'t have any intimacy and it scares her.\\n\\nMelissa emphasizes that she feels \"a hundred million billion trillion percent\" that Josh has an intimacy issue. She feels confused and like she\\'s walking on eggshells when she talks to him. She points out that Josh complains about wanting an emotional connection, but he doesn\\'t let her in. She demands to know how he shows intimacy without sex, questioning how they can move past this issue.\\n\\nJosh asks if he\\'s supposed to wake up every day, have sex with Melissa, and comment on how good the day is. Melissa retorts that he has a problem with intimacy and doesn\\'t know how to \"crack it.\" She asserts that Josh does know how to \"crack it\" and that when someone is strong, he runs away. Melissa reiterates that she\\'s living and dating him, and it\\'s uncomfortable because he doesn\\'t kiss or touch. She expresses her confusion about what\\'s wrong.\\n\\nMelissa repeats that Josh can have sex but doesn\\'t know how to love. She doesn\\'t know how to break through his barriers. Josh covers his face with his hands in frustration. Melissa continues, saying that he has a problem with intimacy and that she\\'s too much for him. Josh agrees that she\\'s too much for him. Melissa stands up and walks over to a shelf, continuing to express her frustration. She says she\\'s speaking her truth for every woman in the world and that Josh has a problem with someone getting close to him. She says he either locks up or walks away when she tries to get close, creating a barrier between them.\\n\\nJosh says he doesn\\'t know what to do. He expresses feeling horrible about Melissa repeatedly saying these things to him. He says a relationship is more than physicality, but Melissa only sees it that way. He says all he ever wanted with Melissa was a deep conversation to get to know her better. He accuses Melissa of lacking depth and only understanding sex. Melissa interjects, saying that\\'s not true. Josh says he\\'s blown away by Melissa\\'s words and that it\\'s not all about sex for him. Melissa says that Josh\\'s statement is far from the truth and that it hurts her.\\n\\nMelissa suggests that perhaps her girlfriends were right and that Josh isn\\'t enough for her, that they saw the writing on the wall. Josh says he\\'s giving so much to be there but doesn\\'t know what he\\'s doing it for. Melissa says that Josh has a problem with intimacy and that she’s too much for him, that he doesn’t know what to do. She says that he’s a big man but he locks up or walks away when she tries to get intimate. She asks if it demasculinizes him and if it bothers him that she likes intimacy more than he does. She asks if he can’t keep up.\\n\\nJosh says he doesn’t know if he can be in the experiment anymore. He sarcastically repeats the encouragement he received to get married, saying it would be fun. The scene transitions to Josh shirtless in bed with Melissa, then to Duncan shirtless in bed with Alyssa. Alyssa sips wine and says intimacy week continues. Duncan kisses Alyssa. The scene transitions to Duncan and Caitlin at a candlelit dinner table. Caitlin reads a note from Duncan. The scene transitions to Harrison and Bronte sitting on a couch, holding hands. Bronte says she feels connected to Harrison. The scene transitions to Lyndall and Cameron sitting on a couch. Lyndall says that when the relationship becomes a priority to Cameron, he should let her know. The scene transitions to Alyssa and Duncan kissing on a bed, then to Harrison and Bronte kissing on a bed. The scene transitions to Harrison and Bronte sitting on a couch, talking. Harrison says he doesn’t know if he can be in the experiment anymore.\\n\\n**BrandsCompanyNamesLogos**\\n\\nCalvin Klein (underwear)\\nNine Network Australia\\nRed Arrow Studios\\nMarried At First Sight\\n\\n**KeyLocationsAndScenes**\\n\\nCurved hallway in a modern building\\nClaire\\'s apartment\\nSkye Suites Sydney\\nMelissa and Josh\\'s apartment\\nLyndall and Cameron\\'s apartment\\nAlyssa and Duncan\\'s apartment\\nHarrison and Bronte\\'s apartment\\n\\n**KeyThemes**\\n\\nIntimacy issues in relationships\\nCommunication challenges\\nEmotional connection versus physical intimacy\\nFrustration and doubt in relationships\\nThe pressures of a social experiment\\n\\n**PeopleAppearingAndMentioned**\\n\\nClaire\\nJesse\\nMelissa\\nJosh\\nAlyssa\\nDuncan\\nCaitlin\\nHarrison\\nBronte\\nLyndall\\nCameron\\nSandra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "44655903-a7b6-4a70-b472-95a35b711db9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     SELECT * FROM (\n",
      "        SELECT      asset_id, \n",
      "                    fileUri,  \n",
      "                    asset_type,               \n",
      "                   STRING_AGG(CONCAT (' ', CONCAT( 'Video details from offset ', startOffset_seconds,' seconds to ',endOffset_seconds,' seconds: ', '\\n'), description), '\\n' )  \n",
      "                     OVER (PARTITION BY asset_id ORDER BY ifnull(startOffset_seconds,0) ASC , IFNULL(endOffset_seconds,0) ASC ) AS full_description,\n",
      "                    ROW_NUMBER() OVER (PARTITION BY asset_id ORDER BY startOffset_seconds desc,endOffset_seconds desc) AS IDX,\n",
      "              FROM (\n",
      "                    SELECT * FROM \n",
      "                    (\n",
      "                        SELECT  distinct asset_id,startOffset_seconds,endOffset_seconds,fileUri,  \n",
      "                        asset_type,\n",
      "                        TRIM(CONCAT(IFNULL(headline,''), CHR(10),  description))  description,\n",
      "                        ROW_NUMBER() OVER (PARTITION BY asset_id,startOffset_seconds ORDER BY startOffset_seconds desc, chunk desc) AS IDX,\n",
      "                        FROM `vlt_media_embeddings_integration.vlt_all_media_content_text_embeddings` where asset_id in ('p5d1x4','p5dx0h','p5duot','a4e57c915b48502be148d6fcb08944efa22d2107.jpeg','3466295218ab26efc1739b775d21453a5f1a819b.jpeg','03245688ac9a7dd651797170992af7d8421ae2c2.jpeg','vlt_video_extract_SIXTY_MINUTES_60MI23_10_A_HBB.mp4','vlt_video_extract_NINE_NEWS_SYD-NINE_NNNT23_101_A.mp4')\n",
      "                      )\n",
      "                      WHERE IDX=1\n",
      "             )\n",
      "          )\n",
      "           WHERE IDX=1\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "\n",
    "if 1==1:\n",
    "    #set query string\n",
    "    source_query_str= get_query_string(assets,video=True)\n",
    "\n",
    "    #set metadata and content columns\n",
    "    metadata_columns=[\"asset_id\"]\n",
    "    page_content_columns=[\"full_description\"]\n",
    "    project_id='nine-quality-test'\n",
    "    #load data from biqquery\n",
    "    _,input_text=get_data(source_query_str=source_query_str,metadata_columns=metadata_columns,page_content_columns=page_content_columns, project_id=project_id,return_text=True)\n",
    "\n",
    "    question_prompt_template = f\"\"\"\n",
    "                You will be given a summary of a video episode. Your task is to identify only the key clips in the entire video, which represent the most significant or noteworthy moments, such as major events, highlights, or important conversations. Do **not** summarize every two-minute segment. Only include clips that are important or stand out. \n",
    "                If require, merge different time lines of the video into a single clip to only represent key highlights.\n",
    "                For each clip, provide the followings:\n",
    "               \n",
    "                1. Clip Number (e.g., Clip 1, Clip 2, etc.)\n",
    "                2. Title (a brief name or title for the clip)\n",
    "                3. Timeline (the start and end time of the clip in minutes)\n",
    "                4. Summary (a brief summary or description of the clip)\n",
    "\n",
    "                Do not add any opening or closing comment to the result.\n",
    "      \n",
    "                TEXT: {input_text}\n",
    "                Key Clips:\n",
    "            \"\"\"\n",
    "    generation_config= GenerationConfig(temperature=0.2, max_output_tokens=8192) \n",
    "    safety_settings=  {\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        }\n",
    "\n",
    "    model_input=[question_prompt_template]\n",
    "        \n",
    "    attempt = 0\n",
    "    max_retries=3\n",
    "    result=\"\"\n",
    "    #use exponential backoff to prevent direct failure in the case of exhaustion of end point\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            response = model.generate_content(\n",
    "                        model_input,\n",
    "                        generation_config=generation_config,\n",
    "                        safety_settings=safety_settings, )\n",
    "            attempt=max_retries \n",
    "            try:         \n",
    "                result=response.text     \n",
    "            except Exception as e:\n",
    "                result=str(e)\n",
    "        except Exception as e:\n",
    "            attempt += 1\n",
    "            backoff_delay = min(2 ** attempt + random.uniform(0, 1), 32)  # Exponential backoff with jitter\n",
    "            print(f\"Attempt {attempt} failed with error {e}. Retrying in {backoff_delay:.2f} seconds...\")\n",
    "            time.sleep(backoff_delay)  # Wait before retrying  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0c4ca692-b2fc-4d04-8ff1-1742f3387538",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Clip 1**\n",
      "**Title:** Ariarne's Difficult Birth and Early Fight for Life\n",
      "**Timeline:** 0:03 - 0:05\n",
      "**Summary:**  Footage of Ariarne's perilous birth and her parents' fear, highlighting her innate fighting spirit.\n",
      "\n",
      "**Clip 2**\n",
      "**Title:**  Chasing the Olympic Dream: Family Sacrifice and Relocation\n",
      "**Timeline:** 0:08 - 0:12\n",
      "**Summary:** The Titmus family discusses the difficult decision to leave Tasmania for Queensland to support Ariarne's swimming ambitions.\n",
      "\n",
      "**Clip 3**\n",
      "**Title:**  Forging a Champion: Dean Boxall's Transformative Coaching\n",
      "**Timeline:** 0:13 - 0:20\n",
      "**Summary:**  Dean Boxall's coaching methods and the rigorous training that transformed Ariarne into an Olympic champion.  Includes the 16-second deficit to Ledecky and how they closed the gap.\n",
      "\n",
      "**Clip 4**\n",
      "**Title:** Triumph Over Ledecky: Olympic Gold in Tokyo\n",
      "**Timeline:** 0:20 - 0:22\n",
      "**Summary:** Ariarne's victory over Katie Ledecky in the 400m freestyle, capturing her emotions and the significance of the win.\n",
      "\n",
      "**Clip 5**\n",
      "**Title:** The Falwell Scandal: Pool Boy, Power, and Hypocrisy\n",
      "**Timeline:** 1:25 - 2:00\n",
      "**Summary:** Introduction to the story of Giancarlo Granda, the Falwells, and the unfolding scandal involving sex, religion, and politics.  Includes Granda's initial encounter with Becki Falwell.\n",
      "\n",
      "**Clip 6**\n",
      "**Title:**  Falwell's Downfall and Becki's Response\n",
      "**Timeline:** 2:20 - 2:35\n",
      "**Summary:** Jerry Falwell Jr.'s resignation and Becki Falwell's recorded phone conversation where she discusses Christianity, sin, and being held to a different standard.\n",
      "\n",
      "**Clip 7**\n",
      "**Title:** Granda's Reflection and Aftermath\n",
      "**Timeline:** 2:38 - 2:40\n",
      "**Summary:** Giancarlo Granda's reflections on the ordeal, expressing regret but also pride in exposing corruption.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e6dd721f-e436-408f-bc53-15f5a5ff6021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 1==1:\n",
    "  \n",
    "    generation_config= GenerationConfig(temperature=0.2, max_output_tokens=8192) \n",
    "    safety_settings=  {\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        }\n",
    "\n",
    "    model_input=[question_prompt_template]\n",
    "        \n",
    "    attempt = 0\n",
    "    max_retries=3\n",
    "    result=\"\"\n",
    "    #use exponential backoff to prevent direct failure in the case of exhaustion of end point\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            response = model.generate_content(\n",
    "                        model_input,\n",
    "                        generation_config=generation_config,\n",
    "                        safety_settings=safety_settings, )\n",
    "            attempt=max_retries \n",
    "            try:         \n",
    "                result=response.text     \n",
    "            except Exception as e:\n",
    "                result=str(e)\n",
    "        except Exception as e:\n",
    "            attempt += 1\n",
    "            backoff_delay = min(2 ** attempt + random.uniform(0, 1), 32)  # Exponential backoff with jitter\n",
    "            print(f\"Attempt {attempt} failed with error {e}. Retrying in {backoff_delay:.2f} seconds...\")\n",
    "            time.sleep(backoff_delay)  # Wait before retrying  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9251d023-7bc3-4f99-9511-88cb1baeae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions_framework\n",
    "import tiktoken\n",
    "from langchain_google_community import BigQueryLoader\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import pandas as pd\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n",
    "from langchain_google_vertexai import VertexAI as langchain_vertexai\n",
    "from vertexai.generative_models._generative_models import SafetySettingsType\n",
    "import vertexai\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "from google.cloud import bigquery\n",
    "\n",
    "\n",
    "\n",
    "def estimate_token_length(text, model=\"gpt2\"):\n",
    "    \"\"\"Estimates the token length of a given text using a specified model.\n",
    "\n",
    "      Args:\n",
    "        text: The input text.\n",
    "        model: The model to use for tokenization (default: \"gpt2\").\n",
    "\n",
    "      Returns:\n",
    "        The estimated number of tokens.\n",
    "      \"\"\"\n",
    "\n",
    "  \n",
    "    enc = tiktoken.get_encoding(model)  \n",
    "\n",
    "    # Tokenize the text and count tokens\n",
    "    tokens = enc.encode(text)\n",
    "    token_count = len(tokens)\n",
    "    return token_count\n",
    "\n",
    "def get_data(source_query_str: str=None,metadata_columns: str=None,page_content_columns: str=None, project_id: str=None , return_text: bool=True):\n",
    "    \n",
    "    \"\"\"Load data from big query\n",
    "\n",
    "      Args:\n",
    "        str source_query_str:  The query string to fetch the data from bigquery\n",
    "        list[str] metadata_columns:  list of metadata column names\n",
    "        list[str] page_content_columns:  list of content column names  \n",
    "        str project_id: project id\n",
    "        bool return_text: returns the content columns description\n",
    "      Returns:\n",
    "          list[langchain_core.documents.base.Document] documents: langchain documents\n",
    "          \n",
    "      \"\"\"\n",
    "    \n",
    "    loader = BigQueryLoader(\n",
    "            query=source_query_str, project=project_id, metadata_columns=metadata_columns, page_content_columns=page_content_columns\n",
    "        )\n",
    "    documents = []\n",
    "    all_texts=[]\n",
    "    documents.extend(loader.load())\n",
    "    if return_text:  \n",
    "         all_texts=[doc.page_content.replace('full_description:',\"\",1) for doc in documents]\n",
    "        \n",
    "    return documents, '\\n'.join(all_texts)\n",
    "    \n",
    " \n",
    "def summarize_docs(documents: list[object],question_prompt_template: str=\"\", refine_prompt_template: str=\"\" ,is_token_limit_exceeded: bool=False ,model: object=None):\n",
    "    \n",
    "    \"\"\"summarizes the input documents\n",
    "\n",
    "      Args:\n",
    "        list[object] documents:  list of langchain documents\n",
    "        str question_prompt_template:  string question prompt template. \n",
    "        str refine_prompt_template:  string refine prompt template in the case that we need to use refine method\n",
    "        bool is_token_limit_exceeded:  boolean indicating wheather or not the token limit is exceeded.\n",
    "      Returns:\n",
    "         dict : summary result\n",
    "         \n",
    "      \"\"\"\n",
    "       \n",
    "    \n",
    "    question_prompt = PromptTemplate(template=question_prompt_template, input_variables=[\"text\"]) \n",
    "\n",
    "    if not is_token_limit_exceeded:        \n",
    "        #if the token limit is in the context window range, use a stuffing method for summary\n",
    "        chain = load_summarize_chain(model, chain_type=\"stuff\", \n",
    "                                     prompt=question_prompt)\n",
    "        \n",
    "    else:     \n",
    "        #otherwise use a refine summarization method\n",
    "        refine_prompt = PromptTemplate(input_variables=[\"existing_answer\", \"text\"], template=refine_prompt_template)\n",
    "              \n",
    "        chain = load_summarize_chain(\n",
    "            model,\n",
    "            chain_type=\"refine\",\n",
    "            question_prompt=question_prompt,\n",
    "            refine_prompt=refine_prompt,\n",
    "            return_intermediate_steps=True,\n",
    "          )\n",
    "        \n",
    "    return chain.invoke(documents)\n",
    "\n",
    "\n",
    "def  get_query_string (assets: str=\"\", video: bool=False ):\n",
    "    \"\"\"set query string \n",
    "      Args:         \n",
    "        str assets:  comma separated string of all requested assets     \n",
    "      Returns:\n",
    "         str source_query_str : string query for loading data from biquery\n",
    "         \n",
    "      \"\"\"\n",
    "    desc=\"\"\n",
    "    if video:\n",
    "        #desc= \"STRING_AGG(CONCAT ('\\n', CONCAT(' to ', startOffset_seconds,endOffset_seconds), description), '\\\\n' ) \"\n",
    "        desc=\"STRING_AGG(CONCAT (' ', CONCAT( 'Video details from offset ', startOffset_seconds,' seconds to ',endOffset_seconds,' seconds: ', '\\\\n'), description), '\\\\n' ) \"        \n",
    "    else:\n",
    "        desc=\"STRING_AGG(description, '\\\\n' )\"\n",
    "        \n",
    "    source_query_str= f\"\"\"\n",
    "     SELECT * FROM (\n",
    "        SELECT      asset_id, \n",
    "                    fileUri,  \n",
    "                    asset_type,               \n",
    "                   {desc} \n",
    "                     OVER (PARTITION BY asset_id ORDER BY ifnull(startOffset_seconds,0) ASC , IFNULL(endOffset_seconds,0) ASC ) AS full_description,\n",
    "                    ROW_NUMBER() OVER (PARTITION BY asset_id ORDER BY startOffset_seconds desc,endOffset_seconds desc) AS IDX,\n",
    "              FROM (\n",
    "                    SELECT * FROM \n",
    "                    (\n",
    "                        SELECT  distinct asset_id,startOffset_seconds,endOffset_seconds,fileUri,  \n",
    "                        asset_type,\n",
    "                        TRIM(CONCAT(IFNULL(headline,''), CHR(10),  description))  description,\n",
    "                        ROW_NUMBER() OVER (PARTITION BY asset_id,startOffset_seconds ORDER BY startOffset_seconds desc, chunk desc) AS IDX,\n",
    "                        FROM `vlt_media_embeddings_integration.vlt_all_media_content_text_embeddings` where asset_id in ({assets})\n",
    "                      )\n",
    "                      WHERE IDX=1\n",
    "             )\n",
    "          )\n",
    "           WHERE IDX=1\n",
    "        \"\"\"\n",
    "    #print(source_query_str)\n",
    "    return source_query_str\n",
    "\n",
    "def get_prompt(action_type: str=\"\",platform: str=\"\",persona_text: str=\"\", input_text:str=\"\", Language:str=\"\"):\n",
    "    \n",
    "    \"\"\"set prompt according to the requested action\n",
    "      Args:         \n",
    "        str action_type:  the type of action needs to be done\n",
    "        str platform: platform name for off platform posts \n",
    "        str persona_text: for persona based summaries \n",
    "      Returns:\n",
    "         str question_prompt_template : the main prompt for the given action \n",
    "         str refine_prompt_template:  the second level prompt for refinement, in the case that the context is too long, we have to use refinement method.\n",
    "         \n",
    "      \"\"\"\n",
    "    #print(action_type)\n",
    "    question_prompt_template=\"\"\n",
    "    refine_prompt_template=\"\"\n",
    "    \n",
    "    if action_type==\"Summary\" or action_type==\"Summary_Persona\":\n",
    "            #this is the main prompt for summary\n",
    "            #   If different parts of texts look unrelevant, give a symmary of each text in 1 paragraph separately.\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide a summary of the following text\"\"\"+persona_text+\"\"\". Your result must be detailed and at least 2 paragraphs. \n",
    "                When summarizing, directly dive into the narrative or descriptions from the text without using introductory phrases like 'In this passage'. \n",
    "                Directly address the main events, characters, and themes, encapsulating the essence and significant details from the text in a flowing narrative. \n",
    "                The goal is to present a unified view of the content, continuing the story seamlessly as if the passage naturally progresses into the summary.\n",
    "            \n",
    "                TEXT: {text}\n",
    "                SUMMARY:\n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final summary. Your task is to combine and refine these summaries into a final, comprehensive summary that covers all key events, characters, themes, and details.\\n\"\n",
    "                \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing summary\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original summary\"\n",
    "                \"If the context isn't useful, return the original summary and add the summary of the new context in a separate paragraph.\"\n",
    "            )\n",
    "    elif action_type==\"HeadLine\":  \n",
    "\n",
    "        #this is the main prompt for headline\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide a one line headline of the following text. \n",
    "\n",
    "                TEXT: {text}\n",
    "                HEADLINE:\n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final headline. Your task is to combine and refine these headlines into a final, comprehensive headline that covers all details.\\n\"\n",
    "                \"We have provided an existing headline up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing headline\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original headline\"\n",
    "                \"If the context isn't useful, return the original headline.\"\n",
    "            )\n",
    "    elif action_type==\"OffPlatformPost\"  and platform=='Twitter':\n",
    "               #this is the main prompt for social media post\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide a tweet that that’s catchy, concise, and fits within 280 characters. Make sure to highlight the key message, and encourage engagement with a question or call to action.\n",
    "\n",
    "                TEXT: {text}\n",
    "                Tweet: \n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final tweet. Your task is to combine and refine these tweets into a final, comprehensive tweet that covers all details, is catchy, concise, fits within 280 characters, and encourage engagement with a question or call to action.\\n\"\n",
    "                \"We have provided an existing tweet up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing tweet\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original tweet\"\n",
    "                \"If the context isn't useful, return the original tweet.\"\n",
    "            )\n",
    "    elif action_type==\"OffPlatformPost\" and platform=='Instagram':         \n",
    "            #this is the main prompt for social media post\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given different parts of texts. Provide  into an engaging Instagram post. Craft a short, attention-grabbing caption that highlights the main point. Use emojis to make it lively, and end with a question or call to action to spark conversation in the comments.\n",
    "\n",
    "                TEXT: {text}\n",
    "                Instagram Post: \n",
    "            \"\"\"\n",
    "\n",
    "            refine_prompt_template = (\n",
    "                \"Your job is to produce a final tweet. Your task is to combine and refine these Instagram posts into a final, comprehensive post that covers all details, crafts a short, attention-grabbing caption that highlights the main point. Use emojis to make it lively, and end with a question or call to action to spark conversation in the comments.\\n\"\n",
    "                \"We have provided an existing post up to a certain point: {existing_answer}\\n\"\n",
    "                \"We have the opportunity to refine the existing post\"\n",
    "                \"(only if needed) with some more context below.\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------------\\n\"\n",
    "                \"Given the new context, refine the original post\"\n",
    "                \"If the context isn't useful, return the original post.\"\n",
    "            )\n",
    "    elif action_type==\"Translation\":\n",
    "            #this is the main prompt for social media post\n",
    "            question_prompt_template = f\"\"\"Translate the following text into {Language}.  Make sure to preserve the meaning, tone, and style of the original text, while ensuring it is natural and fluent in {Language}.\n",
    "            Text:\\n \n",
    "              {input_text}\\n\n",
    "            Only provide a single response.\n",
    "            \"\"\"  \n",
    "    elif action_type==\"trailer-script\":\n",
    "        \n",
    "            #this is the main prompt for summary\n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given a summary of episode. Provide a trailer script that will run for between 2 and 3 minutes.\n",
    "\n",
    "                TEXT: {text}\n",
    "                Trailer Script:\n",
    "            \"\"\"\n",
    " \n",
    "            refine_prompt_template = \"\"\n",
    "    \n",
    "    elif action_type==\"key-clips\":\n",
    "            # question_prompt_template = \"\"\"\n",
    "            #     You will be given a video episode. Identify the key clips in this episode and provide a title and summary of each clip along with their time line. Do not add any openning or closing comment to the result.\n",
    "            # \"\"\" \n",
    "            question_prompt_template = \"\"\"\n",
    "                You will be given a summary of a video episode. Your task is to identify only the key clips in the entire video, which represent the most significant or noteworthy moments, such as major events, highlights, or important conversations. Do **not** summarize every two-minute segment. Only include clips that are important or stand out. \n",
    "                Feel free to merge multiple segments into a single clip summary, and aim for clips of between 5 and 15 minute times.\n",
    "                For each clip, provide the followings:\n",
    "               \n",
    "                1. Clip Number (e.g., Clip 1, Clip 2, etc.)\n",
    "                2. Title (a brief name or title for the clip)\n",
    "                3. Timeline (the start and end time of the clip in minutes)\n",
    "                4. Summary (a brief summary or description of the clip)\n",
    "\n",
    "                Do not add any opening or closing comment to the result. Organize the description in the following format: \n",
    "                \\n<<<--Clip Number-->>>\\n \n",
    "                \\n**Title:**\\n \n",
    "                \\n**Timeline (minutes):**\\n \n",
    "                \\n**Summary:**\\n  \n",
    "                \n",
    "\n",
    "                TEXT: {text}\n",
    "                Key Clips:\n",
    "            \"\"\"\n",
    "            refine_prompt_template = \"\"          \n",
    "                   \n",
    "            \n",
    "    return question_prompt_template,refine_prompt_template\n",
    "\n",
    "def get_summary(assets:str=\"\",action_type:str=\"\",platform:str=\"\",persona_text:str=\"\",project_id:str=\"\",context_window_limit: int=2000000, model: object=None):\n",
    "    \n",
    "    \"\"\"get summary according to the action type requested\n",
    "      Args:         \n",
    "        str assets:  comma separate string including all assets\n",
    "        str action_type: requested action\n",
    "        str persona_text: for persona based summaries \n",
    "        str platform: for off platform based posts\n",
    "        str project_id: project id\n",
    "        int context_window_limit: context window limit for the llm model\n",
    "      Returns:\n",
    "         str :output summary \n",
    "      \"\"\"\n",
    "    \n",
    "    #set query string\n",
    "    if action_type==\"key-clips\":\n",
    "       video=True\n",
    "    else:\n",
    "        video=False\n",
    "\n",
    "    source_query_str= get_query_string(assets, video=video)\n",
    "    \n",
    "    #set prompts\n",
    "    question_prompt_template, refine_prompt_template=get_prompt(action_type=action_type,platform=platform,persona_text=persona_text)\n",
    "    \n",
    "    #set metadata and content columns\n",
    "    metadata_columns=[\"asset_id\"]\n",
    "    page_content_columns=[\"full_description\"]\n",
    "    \n",
    "    #load data from biqquery\n",
    "    documents,all_texts=get_data(source_query_str=source_query_str,metadata_columns=metadata_columns,page_content_columns=page_content_columns, project_id=project_id,return_text=True)\n",
    "    \n",
    "    \n",
    "    # Estimate the token length\n",
    "    estimated_token_length = estimate_token_length(all_texts,'cl100k_base') #cl100k_base\n",
    "    \n",
    "    message=\"\"\n",
    "    is_token_limit_exceeded=False\n",
    "    if estimated_token_length > context_window_limit:\n",
    "      message=\"Your text is too long for the Gemini 1.5 Pro context window. We are trying to chunk and return the result.\"\n",
    "      is_token_limit_exceeded=True\n",
    "      summary=summarize_docs(documents=documents,question_prompt_template=question_prompt_template,refine_prompt_template=refine_prompt_template,is_token_limit_exceeded=is_token_limit_exceeded ,model=model)\n",
    "\n",
    "    else:\n",
    "      message=\"Your text fits within the Gemini 1.5 Pro context window.\"\n",
    "      summary=summarize_docs(documents=documents,question_prompt_template=question_prompt_template,is_token_limit_exceeded=is_token_limit_exceeded,model=model )\n",
    " \n",
    "    return summary[\"output_text\"]\n",
    "\n",
    "def get_translation(assets: str=\"\", action_type: str=\"\",input_text: str=\"\",Language:str=\"\", model: object=None, project_id: str=\"\"):\n",
    "    \n",
    "    \"\"\" get translation according to the requested language\n",
    "      Args:         \n",
    "        str input_text:  text to be translated\n",
    "        str Language: destination language\n",
    "        str assets: comma separated assets if input text is not given\n",
    "        str project_id: project id \n",
    "      \n",
    "      Returns:\n",
    "         str : translated document \n",
    "      \"\"\"\n",
    " \n",
    "    if input_text==\"\" and assets==\"\":\n",
    "        return \"No text is provided for translation- Please provide asset ids or text\"\n",
    "\n",
    "    elif input_text==\"\" and assets!=\"\":\n",
    "        #set query string\n",
    "        source_query_str= get_query_string(assets)\n",
    "\n",
    "        #set metadata and content columns\n",
    "        metadata_columns=[\"asset_id\"]\n",
    "        page_content_columns=[\"full_description\"]\n",
    "        \n",
    "        #load data from biqquery\n",
    "        _,input_text=get_data(source_query_str=source_query_str,metadata_columns=metadata_columns,page_content_columns=page_content_columns, project_id=project_id,return_text=True)\n",
    "\n",
    " \n",
    "    #set prompts\n",
    "    question_prompt_template, _=get_prompt(action_type=action_type,input_text=input_text,Language=Language)\n",
    "    generation_config= GenerationConfig(temperature=0.2, max_output_tokens=8192) \n",
    "    safety_settings=  {\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        }\n",
    "\n",
    "    model_input=[question_prompt_template]\n",
    "        \n",
    "    response = model.generate_content(\n",
    "        model_input,\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings, )\n",
    "    \n",
    "    result=\"\"\n",
    "    try:\n",
    "        result=response.text\n",
    "    except Exception as e:\n",
    "        result=str(e)\n",
    "\n",
    "    return result\n",
    " \n",
    "    \n",
    "def get_VideoClips(assets: str=\"\", action_type: str=\"\", model: object=None, project_id: str=\"\", use_content: bool=True):\n",
    "    \n",
    "    \"\"\" get key clips for a given video\n",
    "      Args:         \n",
    "        \n",
    "        object model: generative AI model\n",
    "        str assets: comma separated assets if input text is not given\n",
    "        str project_id: project id \n",
    "        bool use_content: a flag that identifies wheather to use video object or its content for generating clips\n",
    "      \n",
    "      Returns:\n",
    "         str : key video clips\n",
    "      \"\"\"\n",
    " \n",
    "    if assets==\"\":\n",
    "        return \"No asset is provided for generating video clips- Please provide asset id\"\n",
    "\n",
    "    \n",
    "    #set query string\n",
    "    source_query_str= get_query_string(assets, video=True )\n",
    "    \n",
    "    #set metadata and content columns\n",
    "    metadata_columns=[\"asset_id\", \"fileUri\", \"asset_type\"]\n",
    "    page_content_columns=[\"full_description\"]\n",
    "        \n",
    "    #load data from biqquery\n",
    "    documents,_=get_data(source_query_str=source_query_str,metadata_columns=metadata_columns,page_content_columns=page_content_columns, project_id=project_id,return_text=True)\n",
    "    \n",
    "    \n",
    "    #set video file and mime_type\n",
    "    video_file=documents[0].metadata[\"fileUri\"]\n",
    "    mime_type=documents[0].metadata[\"asset_type\"]\n",
    "    \n",
    "    #set prompts and other configs\n",
    "    question_prompt_template, _=get_prompt(action_type=action_type)\n",
    "    \n",
    "    generation_config= GenerationConfig(temperature=0.2, max_output_tokens=8192) \n",
    "    safety_settings=  {\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        }\n",
    "  \n",
    "    model_input=[Part.from_uri(video_file,mime_type=mime_type),\n",
    "                           question_prompt_template,]  \n",
    "\n",
    "\n",
    "    attempt = 0\n",
    "    max_retries=3\n",
    "    result=\"\"\n",
    "    #use exponential backoff to prevent direct failure in the case of exhaustion of end point\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "         \n",
    "            response = model.generate_content(\n",
    "                        model_input,\n",
    "                        generation_config=generation_config,\n",
    "                        safety_settings=safety_settings, )           \n",
    "            attempt=max_retries\n",
    "            print(response)\n",
    "            try:         \n",
    "                result=response.text     \n",
    "            except Exception as e:\n",
    "                result=str(e)\n",
    "        \n",
    "        except Exception as e:\n",
    "            attempt += 1\n",
    "            backoff_delay = min(2 ** attempt + random.uniform(0, 1), 32)  # Exponential backoff with jitter\n",
    "            print(f\"Attempt {attempt} failed with error {e}. Retrying in {backoff_delay:.2f} seconds...\")\n",
    "            time.sleep(backoff_delay)  # Wait before retrying\n",
    "            \n",
    "    return result \n",
    "\n",
    "def log_data(result,error,request,elapsed_time,project_id):\n",
    "    \"\"\"\n",
    "      Log the search result into bigquery\n",
    "    Args:\n",
    "       List[dict]  result: the result of search\n",
    "       str error: the error message\n",
    "       dict request: the request sent\n",
    "       float elapsed_time: the time taken for the search result to be generated\n",
    "       str project_id: project id\n",
    "    \"\"\"\n",
    "    rows_to_insert=[] \n",
    "    rows_to_insert.append(\n",
    "                                {  \"search_date\":  datetime.now().isoformat() ,\n",
    "                                    \"request\":request,\n",
    "                                    \"response\":   result  , \n",
    "                                    \"error\":  error,\n",
    "                                    \"elapsed_time\":elapsed_time ,\n",
    "                                    \"API\": \"Content Generation\"\n",
    "                                  \n",
    "                                    }\n",
    "                                            )   \n",
    "\n",
    "    #create table new if does not exist\n",
    "    # Load configuration from config.json\n",
    "    with open('config.json') as config_file:\n",
    "         config = json.load(config_file)\n",
    "\n",
    "    table=config['log_table']\n",
    "    dataset_id=config['log_dataset']\n",
    "    #push the data into the table\n",
    "    table_id = f\"{project_id}.{dataset_id}.{table}\"\n",
    "    client = bigquery.Client(project_id)\n",
    "    dataset  = client.dataset(dataset_id)\n",
    "    table = dataset.table(table)\n",
    "\n",
    "    #send a big query streaming insert job- dont need to wait for the job to finish\n",
    "    job = client.load_table_from_json(rows_to_insert, table) \n",
    "\n",
    "def func_generate_content(request):\n",
    "    \n",
    "    \"\"\"\n",
    "    Cloud Function entry point. This function handles the incoming request, \n",
    "    performs content generation according to the given action\n",
    "    \"\"\"\n",
    "\n",
    "    # Parse the incoming request to extract text or image file\n",
    "    request_json = request.get_json(silent=True)   \n",
    "    project_id = request_json.get('project')  \n",
    "    location = request_json.get('region')  \n",
    "    action_type = request_json.get('action_type') # could be Summary, Summary_Persona, HeadLine, OffPlatformPost, Translation\n",
    "    \n",
    "    #print(request_json)\n",
    "    \n",
    "    if \"asset_ids\" in request_json:\n",
    "        assets = request_json.get('asset_ids') #comma separated assets\n",
    "    else:\n",
    "        assets=\"\"\n",
    "\n",
    "        \n",
    "    # if \"persona\" in request_json:\n",
    "    #    persona = request_json.get('persona')   #persona filter\n",
    "    # else:\n",
    "    #     persona=\"\"\n",
    "    persona=\"\"\n",
    "    if action_type==\"Summary_Persona_5year\":\n",
    "        persona=\"5-year old\"\n",
    "        action_type=\"Summary_Persona\"\n",
    "\n",
    "    if action_type==\"Summary_Persona_highschool\":\n",
    "        persona=\"high school student\"\n",
    "        action_type=\"Summary_Persona\" \n",
    "\n",
    "    if \"input_text\" in request_json: \n",
    "       input_text = request_json.get('input_text')   #input text for translation\n",
    "    else:\n",
    "        input_text=\"\"\n",
    "   \n",
    "\n",
    "    # if action_type==\"Translation\" and input_text==\"\":\n",
    "    #     return \"Error- Provide input text for translation\"\n",
    "\n",
    "    if \"language\" in request_json: \n",
    "       Language = request_json.get('language')   #input text for translation\n",
    "    else:\n",
    "        Language=\"Chineese\"\n",
    "\n",
    "    # if action_type==\"Translation\" and Language==\"\":\n",
    "    #     return \"Error- Provide destination language for translation\"\n",
    "        \n",
    "          # Load configuration from config.json\n",
    "    with open('config.json') as config_file:\n",
    "         config = json.load(config_file)\n",
    "\n",
    "   # Set the Gemini 1.5 Pro context window limit\n",
    "    context_window_limit=int(config['context_window_limit']) \n",
    "    model_name=config['model_name'] \n",
    "\n",
    "    #Init vertex ai\n",
    "    vertexai.init(project=project_id, location=location )\n",
    "   \n",
    "\n",
    "    #set assets for search\n",
    "    if assets.strip() !=\"\":\n",
    "        assets= ','.join([ \"'\"+ id.strip()+\"'\" for id in assets.split(',')])\n",
    "    else:\n",
    "        assets=\"\"\n",
    "\n",
    "   #Set persona text    \n",
    "    persona_text=\"\"\n",
    "    if action_type==\"Summary_Persona\" and persona==\"\":\n",
    "        return \"Error- Please set the persona\"    \n",
    "    else:\n",
    "         persona_text=f\" so that a {persona} can understand it. Use simple words and short sentences\"\n",
    "\n",
    "  \n",
    "    error=\"\" \n",
    "    start_time = time.time()     \n",
    "    #generate content according to the requested action\n",
    "    try:\n",
    "        if action_type in (\"Summary_Persona\", \"Summary\",\"HeadLine\", \"OffPlatformPost\",\"trailer-script\"):#,\"key-clips\"):\n",
    "            #generate other content according to the requested action\n",
    "            vertex_llm_text = langchain_vertexai(model_name=model_name)\n",
    "           \n",
    "            if action_type==\"OffPlatformPost\": #for OffPlatformPost, create both Twitter and Instagram posts\n",
    "                result=\"Instagram Post:\\n\"+get_summary(assets =assets,action_type=action_type,platform='Instagram',\n",
    "                            persona_text=persona_text,project_id=project_id,context_window_limit=context_window_limit,model=vertex_llm_text)\n",
    "\n",
    "                \n",
    "                result=result+\"\\nTwitter Post:\\n\"+get_summary(assets =assets,action_type=action_type,platform='Twitter',\n",
    "                            persona_text=persona_text,project_id=project_id,context_window_limit=context_window_limit,model=vertex_llm_text)\n",
    "            \n",
    "            else:           \n",
    "                result=get_summary(assets =assets,action_type=action_type,platform=\"\",\n",
    "                            persona_text=persona_text,project_id=project_id,context_window_limit=context_window_limit,model=vertex_llm_text)\n",
    "        elif action_type==\"Translation\" :\n",
    "            #generate trannlation\n",
    "            generative_multimodal_model= GenerativeModel(model_name)\n",
    "            result=get_translation(assets=assets,action_type=action_type,input_text=input_text,Language=Language, model= generative_multimodal_model, project_id=project_id)\n",
    "\n",
    "        elif action_type==\"key-clips\" : \n",
    "            #generate key video clips\n",
    "            video_clips_model_name='gemini-1.5-pro-001'\n",
    "            generative_multimodal_model= GenerativeModel(video_clips_model_name)\n",
    "            result=get_VideoClips(assets=assets,action_type=action_type, model= generative_multimodal_model, project_id=project_id)\n",
    "            \n",
    "    except Exception as e:\n",
    "        result=\"Error- Service is not available or content generation has faced an issue:\\n\"+str(e)\n",
    "        error=result\n",
    "\n",
    "  \n",
    "    end_time = time.time()\n",
    "    # Calculate the elapsed time\n",
    "    elapsed_time = end_time - start_time\n",
    "    #record the search log\n",
    "    log_data(result,error,request_json,elapsed_time,project_id)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70a69c-19f8-49b2-a5f4-cc1e7816bc8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
