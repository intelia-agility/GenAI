{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab31c62-609f-4913-ad5c-9a79f902dfbc",
   "metadata": {},
   "source": [
    "### reference\n",
    "https://partner.cloudskillsboost.google/course_templates/948/video/485086"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b0aa0-abf0-4336-9e78-c20546c04c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade --user google-cloud-aiplatform umap-learn tqdm pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9db04d67-94f0-4953-ac89-bb5778263971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part as GenerativeModelPart,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n",
    "\n",
    "text_embedding_model = TextEmbeddingModel.from_pretrained(\"text-embedding-004\")\n",
    "model = GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ce33910-1baa-440f-873a-79ff2346f3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intelia ethos</td>\n",
       "      <td>\\t\\n#delightthecustomer\\n\\nOur customers' succ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Migrating Data from Legacy Enterprise Data War...</td>\n",
       "      <td>Migrating data from a legacy on-prem data ware...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data is at our core. It's what we're passionat...</td>\n",
       "      <td>intelia was founded in 2018, with a desire to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intelia has a unique technology partner ecosys...</td>\n",
       "      <td>In an increasingly fast-paced and competitive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>? Celebrating Excellence at intelia! ?</td>\n",
       "      <td>ast night, we came together as hashtag#onetrib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Direnc Uysal's linked-in post</td>\n",
       "      <td>Amidst the excitement surrounding Generative A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>intelia's post on 22rd december</td>\n",
       "      <td>As 2024 comes to a close, the intelia hashtag#...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                      intelia ethos   \n",
       "1  Migrating Data from Legacy Enterprise Data War...   \n",
       "2  Data is at our core. It's what we're passionat...   \n",
       "3  intelia has a unique technology partner ecosys...   \n",
       "4             ? Celebrating Excellence at intelia! ?   \n",
       "5                      Direnc Uysal's linked-in post   \n",
       "6                    intelia's post on 22rd december   \n",
       "\n",
       "                                             content  \n",
       "0  \\t\\n#delightthecustomer\\n\\nOur customers' succ...  \n",
       "1  Migrating data from a legacy on-prem data ware...  \n",
       "2  intelia was founded in 2018, with a desire to ...  \n",
       "3  In an increasingly fast-paced and competitive ...  \n",
       "4  ast night, we came together as hashtag#onetrib...  \n",
       "5  Amidst the excitement surrounding Generative A...  \n",
       "6  As 2024 comes to a close, the intelia hashtag#...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('testdata.csv',encoding='latin1')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4310a25-66e8-45b5-b6eb-5f0b9eca48e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import tempfile, shutil\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "from google.cloud import bigquery \n",
    "import os \n",
    "import gcsfs\n",
    "import pandas as pd\n",
    "\n",
    "def upload_file(request_file : tempfile,dest_bucket_name:str =None,request_file_folder: str =None,request_file_prefix: str =None, version: int=0, request_file_post_fix : str=\"\"):\n",
    "\n",
    "    \"\"\"upload file into gcs\n",
    "   \n",
    "        Args:\n",
    "            tempfile request_file: request file\n",
    "            str dest_bucket_name:  name of destination bucket\n",
    "            str request_file_folder: name of the destination folder name to write files to\n",
    "            list request_file_prefix: prefix of request file name\n",
    "          \n",
    "    \"\"\"\n",
    "\n",
    "    temp=request_file\n",
    "    client = storage.Client()\n",
    "    # Extract name to the temp file\n",
    "    temp_file = \"\".join([str(temp.name)])\n",
    "    # Uploading the temp image file to the bucket\n",
    "    dest_filename = f\"{request_file_folder}/\"+request_file_prefix+'_'+request_file_post_fix+'_'+str(version)+\".json\" \n",
    "    dest_bucket = client.get_bucket(dest_bucket_name)\n",
    "    dest_blob = dest_bucket.blob(dest_filename)\n",
    "    dest_blob.upload_from_filename(temp_file)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c9ea7f8-589b-4bc0-8d44-f3ab4383c15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intelia ethos</td>\n",
       "      <td>\\t\\n#delightthecustomer\\n\\nOur customers' succ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Migrating Data from Legacy Enterprise Data War...</td>\n",
       "      <td>Migrating data from a legacy on-prem data ware...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data is at our core. It's what we're passionat...</td>\n",
       "      <td>intelia was founded in 2018, with a desire to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intelia has a unique technology partner ecosys...</td>\n",
       "      <td>In an increasingly fast-paced and competitive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>? Celebrating Excellence at intelia! ?</td>\n",
       "      <td>ast night, we came together as hashtag#onetrib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Direnc Uysal's linked-in post</td>\n",
       "      <td>Amidst the excitement surrounding Generative A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>intelia's post on 22rd december</td>\n",
       "      <td>As 2024 comes to a close, the intelia hashtag#...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                      intelia ethos   \n",
       "1  Migrating Data from Legacy Enterprise Data War...   \n",
       "2  Data is at our core. It's what we're passionat...   \n",
       "3  intelia has a unique technology partner ecosys...   \n",
       "4             ? Celebrating Excellence at intelia! ?   \n",
       "5                      Direnc Uysal's linked-in post   \n",
       "6                    intelia's post on 22rd december   \n",
       "\n",
       "                                             content  \n",
       "0  \\t\\n#delightthecustomer\\n\\nOur customers' succ...  \n",
       "1  Migrating data from a legacy on-prem data ware...  \n",
       "2  intelia was founded in 2018, with a desire to ...  \n",
       "3  In an increasingly fast-paced and competitive ...  \n",
       "4  ast night, we came together as hashtag#onetrib...  \n",
       "5  Amidst the excitement surrounding Generative A...  \n",
       "6  As 2024 comes to a close, the intelia hashtag#...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "522a7ade-f64d-48fb-8cdf-8e76a74c0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=True) \n",
    "rf= open(request_file.name, \"a\") \n",
    "\n",
    "for idx,row in data.iterrows():\n",
    "    data_items=[ json.dumps( {  \"_id\": idx,\n",
    "                                \"title\":row['title'],\n",
    "                                 \"text\":row['content']                                          \n",
    "                               }\n",
    "                               )  +\"\\n\"\n",
    "                ]\n",
    "\n",
    "    rf.writelines(data_items)\n",
    "    rf.flush()\n",
    "upload_file(rf,dest_bucket_name='vlt_search_and_contet_output',request_file_folder='finetunning',request_file_prefix='fine_tuning_intelia_sample', version=0, request_file_post_fix ='0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "349d2d00-c38f-4f41-a0c0-6864670396b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries(model, title, text):\n",
    "\n",
    "    prompt = (f'You are a human being who is tasked with extracting some questions from a given text.\\n'\n",
    "    f'Think throughly when reading this text including both title and content. Think of questions may people ask to know more about a data consultancy called Intelia.\\n'\n",
    "    f'Suggest 1 to 5 short questions and 2-3 labels or short expressions that are important to ask when people want to explore who Intelia is and what it does. These expressions or questions should be optimized for fine tuning a text embedding model.\\n'    \n",
    "    f'Output each response on a separate line divided by a newline.\\n'\n",
    "    f'Here is the text:\\n'\n",
    "    f'\"title\": {title}\\n'\n",
    "    f'\"content\":{text}')\n",
    "    \n",
    "    responses = model.generate_content(prompt, stream=False)\n",
    "    return responses.text.split('\\n')\n",
    "\n",
    "\n",
    "def get_autorater_response(llm_model: str=\"gemini-1.5-pro\", title=\"\", text=\"\", query=\"\") -> dict:\n",
    "        \n",
    "        \"\"\"Extract evaluation metric on a AI-generated content using a AI-as-judge approach\n",
    "        \n",
    "        Args:\n",
    "        list metric_prompt: the input metric prompt parameters\n",
    "        str llm_model: evaluation model\n",
    "\n",
    "        Returns:\n",
    "        dict response_json: the evaluated metric in json format\n",
    "        \"\"\"\n",
    "            \n",
    "        # set evaluation metric schema\n",
    "        metric_response_schema = {\n",
    "            \"type\": \"OBJECT\",\n",
    "            \"properties\": {\n",
    "                \"score\": {\"type\": \"NUMBER\"},\n",
    "                \"explanation\": {\"type\": \"STRING\"},\n",
    "            },\n",
    "            \"required\": [\"score\", \"explanation\"],\n",
    "        }     \n",
    "        #define a generative model as an autorator\n",
    "        autorater = GenerativeModel(\n",
    "            llm_model,\n",
    "            generation_config=GenerationConfig(\n",
    "                response_mime_type=\"application/json\",\n",
    "                response_schema=metric_response_schema,\n",
    "            ),\n",
    "            safety_settings={\n",
    "                HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        metric_prompt=  (f'You are a human being who is tasked with finding the answer of a given question within an aricle.\\n'\n",
    "                        f'Read the given question and analyse the given artcile to see if you can find the answer to the question within this aricle.\\n'\n",
    "                        f'Use this rating rubric to give a relevancy score for your analysis:\\n'\n",
    "                        f'\"Rating Rubric:\\n'\n",
    "                        f'0: No relevancy. The document has no connection to the question. It lacks relevant keywords, topics, or context. \\n'\n",
    "                        f'1: Low Relevance. The document contains some keywords but does not provide meaningful information related to the question. The context is weak or unrelated. \\n'\n",
    "                        f'2: Moderate Relevance. The document partially addresses the question but lacks completeness, clarity, or depth. It may require inference to extract an answer.\\n'\n",
    "                        f'3\tHigh Relevance. The document directly and clearly answers the question with specific, well-aligned information. Strong contextual alignment.\\n'\n",
    "\n",
    "                        f'Question:\\n'\n",
    "                        f'{query}\\n'                      \n",
    "                        f'Article:\\n'                    \n",
    "                        f'\"title\": {title}\\n'\n",
    "                        f'\"content\":{text}')\n",
    "    \n",
    "        #generate the rating metrics as per requested measures and metric in the prompt\n",
    "        response = autorater.generate_content([metric_prompt])\n",
    "\n",
    "        response_json = {}\n",
    "\n",
    "        if response.candidates and len(response.candidates) > 0:\n",
    "            candidate = response.candidates[0]\n",
    "            if (\n",
    "                candidate.content\n",
    "                and candidate.content.parts\n",
    "                and len(candidate.content.parts) > 0\n",
    "            ):\n",
    "                part = candidate.content.parts[0]\n",
    "                if part.text:\n",
    "                    response_json = json.loads(part.text)\n",
    "\n",
    "        return response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa7ed000-cd88-44f9-be97-66cffe40569b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"What is Intelia's core philosophy and how does it impact their approach to customer success?\", '', 'How does Intelia balance its focus on customer delight with the well-being of its employees?', '', 'What specific actions does Intelia take to foster a passionate and enjoyable work environment?', '', 'How does Intelia leverage diversity and collaboration to achieve its goals?', '', 'What sets Intelia apart from other data consultancies in the market?']\n",
      "\n",
      "['## Questions about Intelia:', '', '1. **What specific types of data migrations does Intelia specialize in?**', '', '2. **Does Intelia offer end-to-end data migration services, including planning, execution, and post-migration support?**', '', '3. **What cloud platforms is Intelia most experienced with and certified in?**', '', '4. **Can Intelia provide case studies or examples of successful data migration projects they have completed?**', '', \"5. **What is Intelia's pricing model for data migration services?**\"]\n",
      "\n",
      "['## Intelia: Key Questions', '', '1. **What specific data-driven opportunities does Intelia help its clients unlock?** ', '2. **Beyond data analysis, what other services does Intelia provide to its clients?**', \"3. **Can you elaborate on Intelia's unique approach to data consultancy?**\", '4. **How does Intelia tailor its services to address the specific challenges of each client?**', '5. **What are some examples of successful projects Intelia has completed for its clients?** ', '']\n",
      "\n",
      "['What types of businesses does Intelia typically work with?', 'What makes Intelia different from other cloud data platform providers?', \"How does Snowflake's cloud-first architecture benefit businesses?\", 'How can Intelia assist with planning a cloud or multi-cloud strategy? ', 'How does Intelia help clients focus on business value rather than data warehousing complexity']\n",
      "\n",
      "['## Questions about Intelia:', '', '1. What specific data consultancy services does Intelia offer?', '2. What kind of impact does Intelia make for its customers?', '3. How does Intelia foster a culture of innovation and excellence within its team?', \"4. What are Intelia's plans for the future, especially in the context of the evolving AI and data landscape?\", \"5. What are some examples of projects or achievements that demonstrate Intelia's expertise and success? \", '']\n",
      "\n",
      "['1. What specific data governance services does Intelia offer to help businesses succeed with their machine learning solutions? ', '2. How does Intelia ensure compliance and facilitate collaboration when implementing data governance strategies?', '3. Can Intelia provide examples of how they have helped businesses improve their data management and avoid the need for significant changes down the line?', '4. What are the key benefits of partnering with Intelia for data governance, particularly in the context of Generative AI adoption?', '5. Does Intelia offer tailored solutions for different industries or specific data-driven challenges? ', '']\n",
      "\n",
      "['- What services does Intelia provide?', \"- What are some of Intelia's major accomplishments in 2024?\", \"- What are some of Intelia's core values?\", \"- What are Intelia's goals for 2025?\", '- What is the meaning of the hashtag \"#onetribe\"?']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generated_queries=[]\n",
    "request_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=True) \n",
    "rf= open(request_file.name, \"a\") \n",
    "\n",
    "for idx,row in data.iterrows():\n",
    "    queries=generate_queries(model, row['title'], row['content']) \n",
    "    print(queries)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1b69b7da-870a-46d5-b1fd-5ed244397cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1=[\"What is Intelia's core philosophy and how does it impact their approach to customer success?\",  'How does Intelia balance its focus on customer delight with the well-being of its employees?',  'What specific actions does Intelia take to foster a passionate and enjoyable work environment?',  'How does Intelia leverage diversity and collaboration to achieve its goals?',  'What sets Intelia apart from other data consultancies in the market?']\n",
    "\n",
    "q2=['## Questions about Intelia:',  '1. **What specific types of data migrations does Intelia specialize in?**',  '2. **Does Intelia offer end-to-end data migration services, including planning, execution, and post-migration support?**',  '3. **What cloud platforms is Intelia most experienced with and certified in?**',  '4. **Can Intelia provide case studies or examples of successful data migration projects they have completed?**',  \"5. **What is Intelia's pricing model for data migration services?**\"]\n",
    "\n",
    "q3=['## Intelia: Key Questions',  '1. **What specific data-driven opportunities does Intelia help its clients unlock?** ', '2. **Beyond data analysis, what other services does Intelia provide to its clients?**', \"3. **Can you elaborate on Intelia's unique approach to data consultancy?**\", '4. **How does Intelia tailor its services to address the specific challenges of each client?**', '5. **What are some examples of successful projects Intelia has completed for its clients?** ']\n",
    "\n",
    "q4=['What types of businesses does Intelia typically work with?', 'What makes Intelia different from other cloud data platform providers?', \"How does Snowflake's cloud-first architecture benefit businesses?\", 'How can Intelia assist with planning a cloud or multi-cloud strategy? ', 'How does Intelia help clients focus on business value rather than data warehousing complexity']\n",
    "\n",
    "q5=['## Questions about Intelia:',  '1. What specific data consultancy services does Intelia offer?', '2. What kind of impact does Intelia make for its customers?', '3. How does Intelia foster a culture of innovation and excellence within its team?', \"4. What are Intelia's plans for the future, especially in the context of the evolving AI and data landscape?\", \"5. What are some examples of projects or achievements that demonstrate Intelia's expertise and success? \"]\n",
    "\n",
    "q6=['1. What specific data governance services does Intelia offer to help businesses succeed with their machine learning solutions? ', '2. How does Intelia ensure compliance and facilitate collaboration when implementing data governance strategies?', '3. Can Intelia provide examples of how they have helped businesses improve their data management and avoid the need for significant changes down the line?', '4. What are the key benefits of partnering with Intelia for data governance, particularly in the context of Generative AI adoption?', '5. Does Intelia offer tailored solutions for different industries or specific data-driven challenges? ', '']\n",
    "\n",
    "q7=['- What services does Intelia provide?', \"- What are some of Intelia's major accomplishments in 2024?\", \"- What are some of Intelia's core values?\", \"- What are Intelia's goals for 2025?\", '- What is the meaning of the hashtag \"#onetribe\"?']\n",
    "\n",
    "queries=q1+q2+q3+q4+q5+q6+q7\n",
    "\n",
    "qid=0\n",
    "for query in queries:\n",
    "        if query!=\"\":\n",
    "            generated_queries=[ json.dumps( {  \"_id\": qid,  \n",
    "                                               \"text\":query                                      \n",
    "                                         }\n",
    "                                       )  +\"\\n\"\n",
    "                        ]\n",
    "        \n",
    "            rf.writelines(generated_queries)\n",
    "            rf.flush()\n",
    "            qid +=1\n",
    "\n",
    "upload_file(rf,dest_bucket_name='vlt_search_and_contet_output',request_file_folder='finetunning',request_file_prefix='fine_tuning_query_sample', version=0, request_file_post_fix ='0')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ec8fb2d8-4c72-4e9f-a1bc-0dd9ad1a639b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n",
      "gemini-1.5-pro\n"
     ]
    },
    {
     "ename": "ServiceUnavailable",
     "evalue": "503 502:Bad Gateway",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:65\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    270\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_interceptor.py:332\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interceptor\u001b[38;5;241m.\u001b[39mintercept_unary_unary(\n\u001b[1;32m    330\u001b[0m     continuation, client_call_details, request\n\u001b[1;32m    331\u001b[0m )\n\u001b[0;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, call\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_channel.py:440\u001b[0m, in \u001b[0;36m_InactiveRpcError.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See grpc.Future.result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_channel.py:1198\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1192\u001b[0m (\n\u001b[1;32m   1193\u001b[0m     state,\n\u001b[1;32m   1194\u001b[0m     call,\n\u001b[1;32m   1195\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1196\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1197\u001b[0m )\n\u001b[0;32m-> 1198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"502:Bad Gateway\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"502:Bad Gateway\", grpc_status:14, created_time:\"2025-02-01T12:40:13.985828595+00:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx,row \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m----> 5\u001b[0m         r\u001b[38;5;241m=\u001b[39m\u001b[43mget_autorater_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      6\u001b[0m         relevancy\u001b[38;5;241m.\u001b[39mappend([qid,idx,r\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\n",
      "Cell \u001b[0;32mIn[76], line 69\u001b[0m, in \u001b[0;36mget_autorater_response\u001b[0;34m(llm_model, title, text, query)\u001b[0m\n\u001b[1;32m     53\u001b[0m metric_prompt\u001b[38;5;241m=\u001b[39m  (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou are a human being who is tasked with finding the answer of a given question within an aricle.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     54\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRead the given question and analyse the given artcile to see if you can find the answer to the question within this aricle.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     55\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse this rating rubric to give a relevancy score for your analysis:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     66\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#generate the rating metrics as per requested measures and metric in the prompt\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mautorater\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric_prompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m response_json \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcandidates \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response\u001b[38;5;241m.\u001b[39mcandidates) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py:695\u001b[0m, in \u001b[0;36m_GenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content_streaming(\n\u001b[1;32m    687\u001b[0m         contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    688\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py:820\u001b[0m, in \u001b[0;36m_GenerativeModel._generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates content.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m \n\u001b[1;32m    795\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;124;03m    A single GenerationResponse object\u001b[39;00m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    812\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m    813\u001b[0m     contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    814\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    818\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    819\u001b[0m )\n\u001b[0;32m--> 820\u001b[0m gapic_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_response(gapic_response)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform_v1beta1/services/prediction_service/client.py:2348\u001b[0m, in \u001b[0;36mPredictionServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   2347\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2348\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2355\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:113\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     metadata\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata)\n\u001b[1;32m    111\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metadata\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:67\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m: 503 502:Bad Gateway"
     ]
    }
   ],
   "source": [
    "qid=0\n",
    "relevancy=[]\n",
    "\n",
    "import time\n",
    "\n",
    "try:\n",
    "    for query in queries:\n",
    "        for idx,row in data.iterrows():\n",
    "            r=get_autorater_response(title=row['title'], text=row['content'], query=query) \n",
    "            relevancy.append([qid,idx,r.get(\"score\", \"\")])\n",
    "            time.sleep(2)\n",
    "        qid=qid+1\n",
    "except:\n",
    "    print(qid)\n",
    "\n",
    "\n",
    "# Create DataFrame with column names\n",
    "df = pd.DataFrame(data, columns=[\"ID\", \"Name\", \"Age\"])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "    query-id  corpus-id   score\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c51e53f-f481-4c07-bf21-ed0c9d70335a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
