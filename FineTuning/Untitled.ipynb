{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab31c62-609f-4913-ad5c-9a79f902dfbc",
   "metadata": {},
   "source": [
    "### reference\n",
    "https://partner.cloudskillsboost.google/course_templates/948/video/485086"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b0aa0-abf0-4336-9e78-c20546c04c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade --user google-cloud-aiplatform umap-learn tqdm pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9db04d67-94f0-4953-ac89-bb5778263971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part as GenerativeModelPart,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5ce33910-1baa-440f-873a-79ff2346f3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intelia ethos</td>\n",
       "      <td>\\t\\n#delightthecustomer\\n\\nOur customers' succ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Migrating Data from Legacy Enterprise Data War...</td>\n",
       "      <td>Migrating data from a legacy on-prem data ware...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data is at our core. It's what we're passionat...</td>\n",
       "      <td>intelia was founded in 2018, with a desire to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intelia has a unique technology partner ecosys...</td>\n",
       "      <td>In an increasingly fast-paced and competitive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>? Celebrating Excellence at intelia! ?</td>\n",
       "      <td>ast night, we came together as hashtag#onetrib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Direnc Uysal's linked-in post</td>\n",
       "      <td>Amidst the excitement surrounding Generative A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>intelia's post on 22rd december</td>\n",
       "      <td>As 2024 comes to a close, the intelia hashtag#...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                      intelia ethos   \n",
       "1  Migrating Data from Legacy Enterprise Data War...   \n",
       "2  Data is at our core. It's what we're passionat...   \n",
       "3  intelia has a unique technology partner ecosys...   \n",
       "4             ? Celebrating Excellence at intelia! ?   \n",
       "5                      Direnc Uysal's linked-in post   \n",
       "6                    intelia's post on 22rd december   \n",
       "\n",
       "                                             content  \n",
       "0  \\t\\n#delightthecustomer\\n\\nOur customers' succ...  \n",
       "1  Migrating data from a legacy on-prem data ware...  \n",
       "2  intelia was founded in 2018, with a desire to ...  \n",
       "3  In an increasingly fast-paced and competitive ...  \n",
       "4  ast night, we came together as hashtag#onetrib...  \n",
       "5  Amidst the excitement surrounding Generative A...  \n",
       "6  As 2024 comes to a close, the intelia hashtag#...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('testdata.csv',encoding='latin1')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e4310a25-66e8-45b5-b6eb-5f0b9eca48e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import tempfile, shutil\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "from google.cloud import bigquery \n",
    "import os \n",
    "import gcsfs\n",
    "import pandas as pd\n",
    "\n",
    "def upload_file(request_file : tempfile,dest_bucket_name:str =None,request_file_folder: str =None,request_file_prefix: str =None, version: int=0, request_file_post_fix : str=\"\"):\n",
    "\n",
    "    \"\"\"upload file into gcs\n",
    "   \n",
    "        Args:\n",
    "            tempfile request_file: request file\n",
    "            str dest_bucket_name:  name of destination bucket\n",
    "            str request_file_folder: name of the destination folder name to write files to\n",
    "            list request_file_prefix: prefix of request file name\n",
    "          \n",
    "    \"\"\"\n",
    "\n",
    "    temp=request_file\n",
    "    client = storage.Client()\n",
    "    # Extract name to the temp file\n",
    "    temp_file = \"\".join([str(temp.name)])\n",
    "    # Uploading the temp image file to the bucket\n",
    "    dest_filename = f\"{request_file_folder}/\"+request_file_prefix+'_'+request_file_post_fix+'_'+str(version)+\".json\" \n",
    "    dest_bucket = client.get_bucket(dest_bucket_name)\n",
    "    dest_blob = dest_bucket.blob(dest_filename)\n",
    "    dest_blob.upload_from_filename(temp_file)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "522a7ade-f64d-48fb-8cdf-8e76a74c0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=True) \n",
    "rf= open(request_file.name, \"a\") \n",
    "\n",
    "for idx,row in data.iterrows():\n",
    "    data_items=[ json.dumps( {  \"_id\": idx,\n",
    "                                \"title\":row['title'],\n",
    "                                 \"text\":row['content']                                          \n",
    "                               }\n",
    "                               )  +\"\\n\"\n",
    "                ]\n",
    "\n",
    "    rf.writelines(data_items)\n",
    "    rf.flush()\n",
    "upload_file(rf,dest_bucket_name='vlt_search_and_contet_output',request_file_folder='finetunning',request_file_prefix='fine_tuning_intelia_sample', version=0, request_file_post_fix ='0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "349d2d00-c38f-4f41-a0c0-6864670396b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries(model=\"gemini-1.5-pro\", title=\"\", text=\"\"):\n",
    "\n",
    "        metric_prompt = (f'You are an expert who is tasked with extracting some questions from a given article.\\n'\n",
    "        f'Think throughly when reading this article including both title and content. Think of questions may people may ask to know more about a data consultancy called Intelia.\\n'\n",
    "        f'Suggest 1 to 2 short questions that are important to ask when people want to explore who Intelia is and what it does.\\n'\n",
    "        f' Also suggest 1-2 labels or short expressions that are related to this articleor highlight them.\\n'\n",
    "        f' These expressions or questions should be optimized for fine tuning a text embedding model.\\n'    \n",
    "        f'Output each response on a separate line divided by a newline.\\n'\n",
    "        f'Here is the article:\\n'\n",
    "        f'\"title\": {title}\\n'\n",
    "        f'\"content\":{text}')\n",
    "\n",
    "        # set evaluation metric schema\n",
    "        metric_response_schema = {\n",
    "            \"type\": \"OBJECT\",\n",
    "            \"properties\": {\n",
    "                \"question_expression\": {\n",
    "                    \"type\": \"ARRAY\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"OBJECT\",\n",
    "                        \"properties\": {\n",
    "                            \"query_expression\": {\"type\": \"STRING\"},\n",
    "                            \"answer\": {\"type\": \"STRING\"}\n",
    "                        },\n",
    "                        \"required\": [\"query_expression\",\"answer\"]\n",
    "                    }\n",
    "                } \n",
    "            },\n",
    "            \"required\": [\"question_expression\"],\n",
    "        }\n",
    "    \n",
    "      \n",
    "        #define a generative model as an autorator\n",
    "  \n",
    "  \n",
    "        autorater = GenerativeModel(\n",
    "            model,\n",
    "            generation_config=GenerationConfig(\n",
    "                response_mime_type=\"application/json\",\n",
    "                response_schema=metric_response_schema,\n",
    "            ),\n",
    "            safety_settings={\n",
    "                HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            },\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "    \n",
    "        #generate the rating metrics as per requested measures and metric in the prompt\n",
    "        response = autorater.generate_content([metric_prompt])\n",
    "\n",
    "        response_json = {}\n",
    "\n",
    "        if response.candidates and len(response.candidates) > 0:\n",
    "            candidate = response.candidates[0]\n",
    "            if (\n",
    "                candidate.content\n",
    "                and candidate.content.parts\n",
    "                and len(candidate.content.parts) > 0\n",
    "            ):\n",
    "                part = candidate.content.parts[0]\n",
    "                if part.text:\n",
    "                    response_json = json.loads(part.text)\n",
    "\n",
    "        return response_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0c30cc03-17e7-4ab8-951d-6290e430436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autorater_response(llm_model: str=\"gemini-1.5-pro\", title=\"\", text=\"\", query=\"\") -> dict:\n",
    "        \n",
    "        \"\"\"Extract evaluation metric on a AI-generated content using a AI-as-judge approach\n",
    "        \n",
    "        Args:\n",
    "        list metric_prompt: the input metric prompt parameters\n",
    "        str llm_model: evaluation model\n",
    "\n",
    "        Returns:\n",
    "        dict response_json: the evaluated metric in json format\n",
    "        \"\"\"\n",
    "            \n",
    "        # set evaluation metric schema\n",
    "        metric_response_schema = {\n",
    "            \"type\": \"OBJECT\",\n",
    "            \"properties\": {\n",
    "                \"score\": {\"type\": \"NUMBER\"},\n",
    "                \"explanation\": {\"type\": \"STRING\"},\n",
    "            },\n",
    "            \"required\": [\"score\", \"explanation\"],\n",
    "        }     \n",
    "        #define a generative model as an autorator\n",
    "        autorater = GenerativeModel(\n",
    "            llm_model,\n",
    "            generation_config=GenerationConfig(\n",
    "                response_mime_type=\"application/json\",\n",
    "                response_schema=metric_response_schema,\n",
    "            ),\n",
    "            safety_settings={\n",
    "                HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        metric_prompt= f\"\"\"\n",
    "                        # Instruction \n",
    "                        You are an expert evaluator. Your task is to evaluate the amount of the relevancy between a given question and a given article. You should first read the question carefully for analyzing the task, then read the article. Then evaluate the how relevant the given question is to the given article based on the Criteria provided in the Evaluation section below. You will assign the response a rating following the Rating Rubric and Evaluation Steps. Only choose ratings from the Rating Rubric. \n",
    "                        # Evaluation\n",
    "                        ## Metric Definition \n",
    "                        You will be assessing Relevancy, which measures the ability to find a clear and thorough answer to the given question within given artcile.\n",
    "                        ## Criteria \n",
    "                        Relevancy: Measures the ability to find a clear and thorough answer to the given question within given artcile\n",
    "                        - Category - Detailed Description Of Events And Conversations - Brands, Company Names, and Logos -\n",
    "                        Key Locations And Scenes - Key Themes - People Appearing And Mentioned Thi\n",
    "                        s AI-generated responses will be used for data retrieval. So, it has to be able to capture all the details of a scene. \n",
    "                        ## Rating Rubric \n",
    "                         0: No relevancy. The document has no connection to the question. It lacks relevant keywords, topics, or context. \n",
    "                         1: Low Relevance. The document contains some keywords but does not provide meaningful information related to the question. The context is weak or unrelated. \\n\n",
    "                         2: Moderate Relevance. The document partially addresses the question but lacks completeness, clarity, or depth. It may require inference to extract an answer.\\n\n",
    "                         3\tHigh Relevance. The document directly and clearly answers the question with specific, well-aligned information. Strong contextual alignment.\\n\n",
    "                        \n",
    "                        ## Evaluation Steps \n",
    "                        STEP 1: Assess question: Carefully read the question to underestand what it is asking. \n",
    "                        STEP 2: Readt the artcile including title and content\n",
    "                        STEP 3: Evaluate relevancy: Evaluate how much the article could be relevant to the question and if the answer can be find in this article. \n",
    "                        STEP 4: Determine relevancy score: Based on the previous steps, assign a relevancy score using the\n",
    "                        0-3 rubric.\n",
    "\n",
    "                        Here is the question and article:\n",
    "                        ## Question:\\n\n",
    "                        {query}\\n                      \n",
    "                        ## Article:\\n                    \n",
    "                        \"title\": \n",
    "                                {title}\\n\n",
    "                        \"content\":\n",
    "                                 {text}\"\"\"\n",
    "    \n",
    "        #generate the rating metrics as per requested measures and metric in the prompt\n",
    "        response = autorater.generate_content([metric_prompt])\n",
    "\n",
    "        response_json = {}\n",
    "\n",
    "        if response.candidates and len(response.candidates) > 0:\n",
    "            candidate = response.candidates[0]\n",
    "            if (\n",
    "                candidate.content\n",
    "                and candidate.content.parts\n",
    "                and len(candidate.content.parts) > 0\n",
    "            ):\n",
    "                part = candidate.content.parts[0]\n",
    "                if part.text:\n",
    "                    response_json = json.loads(part.text)\n",
    "\n",
    "        return response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7ed000-cd88-44f9-be97-66cffe40569b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['doc0', 'q0', 'What does Intelia do?', 'Intelia is a data consultancy that helps their customer achieve success with pricision, innovation and care.'], ['doc0', 'q1', \"What are Intelia's core values?\", 'Intelia values customer success, passionate employees, and teamwork.']]\n",
      "[['doc0', 'q0', 'What does Intelia do?', 'Intelia is a data consultancy that helps their customer achieve success with pricision, innovation and care.'], ['doc0', 'q1', \"What are Intelia's core values?\", 'Intelia values customer success, passionate employees, and teamwork.'], ['doc1', 'q2', \"What are Intelia's areas of expertise?\", 'Intelia specializes in data-related services, particularly data migration, assisting organizations in transitioning their data to cloud platforms.'], ['doc1', 'q3', 'How can Intelia support organizations with cloud data migration?', 'Intelia provides expert guidance and support throughout the entire data migration process, from initial assessment and planning to implementation and post-migration optimization.']]\n",
      "[['doc0', 'q0', 'What does Intelia do?', 'Intelia is a data consultancy that helps their customer achieve success with pricision, innovation and care.'], ['doc0', 'q1', \"What are Intelia's core values?\", 'Intelia values customer success, passionate employees, and teamwork.'], ['doc1', 'q2', \"What are Intelia's areas of expertise?\", 'Intelia specializes in data-related services, particularly data migration, assisting organizations in transitioning their data to cloud platforms.'], ['doc1', 'q3', 'How can Intelia support organizations with cloud data migration?', 'Intelia provides expert guidance and support throughout the entire data migration process, from initial assessment and planning to implementation and post-migration optimization.'], ['doc2', 'q4', 'What specific services does Intelia offer to help businesses become data-driven?', \"The article mentions Intelia helps customers 'accelerate the opportunities, commercial benefits and competitive advantage' in a data-driven world. To get a clearer picture, you'd likely want to ask about their specific services, like data strategy consulting, data analytics, or implementation of data platforms.\"], ['doc2', 'q5', \"Could you elaborate on what 'a truly unique approach to helping customers' entails for Intelia?\", \"The article highlights Intelia's 'truly unique approach.' Asking for concrete examples of how this approach differs from competitors would be key to understanding their value proposition.\"]]\n",
      "[['doc0', 'q0', 'What does Intelia do?', 'Intelia is a data consultancy that helps their customer achieve success with pricision, innovation and care.'], ['doc0', 'q1', \"What are Intelia's core values?\", 'Intelia values customer success, passionate employees, and teamwork.'], ['doc1', 'q2', \"What are Intelia's areas of expertise?\", 'Intelia specializes in data-related services, particularly data migration, assisting organizations in transitioning their data to cloud platforms.'], ['doc1', 'q3', 'How can Intelia support organizations with cloud data migration?', 'Intelia provides expert guidance and support throughout the entire data migration process, from initial assessment and planning to implementation and post-migration optimization.'], ['doc2', 'q4', 'What specific services does Intelia offer to help businesses become data-driven?', \"The article mentions Intelia helps customers 'accelerate the opportunities, commercial benefits and competitive advantage' in a data-driven world. To get a clearer picture, you'd likely want to ask about their specific services, like data strategy consulting, data analytics, or implementation of data platforms.\"], ['doc2', 'q5', \"Could you elaborate on what 'a truly unique approach to helping customers' entails for Intelia?\", \"The article highlights Intelia's 'truly unique approach.' Asking for concrete examples of how this approach differs from competitors would be key to understanding their value proposition.\"], ['doc3', 'q6', \"What are Intelia's key technology partnerships and specializations?\", 'Intelia is a Google Cloud Premier Partner specializing in machine learning and data analytics. They are also a Snowflake partner.'], ['doc3', 'q7', 'How does Intelia help businesses leverage cloud technology like GCP and Snowflake?', 'Intelia provides technology strategists, architects, engineers, and delivery professionals to help businesses leverage Google Cloud Platform (GCP) and Snowflake for data warehousing, analytics, and cloud transformation.']]\n",
      "[['doc0', 'q0', 'What does Intelia do?', 'Intelia is a data consultancy that helps their customer achieve success with pricision, innovation and care.'], ['doc0', 'q1', \"What are Intelia's core values?\", 'Intelia values customer success, passionate employees, and teamwork.'], ['doc1', 'q2', \"What are Intelia's areas of expertise?\", 'Intelia specializes in data-related services, particularly data migration, assisting organizations in transitioning their data to cloud platforms.'], ['doc1', 'q3', 'How can Intelia support organizations with cloud data migration?', 'Intelia provides expert guidance and support throughout the entire data migration process, from initial assessment and planning to implementation and post-migration optimization.'], ['doc2', 'q4', 'What specific services does Intelia offer to help businesses become data-driven?', \"The article mentions Intelia helps customers 'accelerate the opportunities, commercial benefits and competitive advantage' in a data-driven world. To get a clearer picture, you'd likely want to ask about their specific services, like data strategy consulting, data analytics, or implementation of data platforms.\"], ['doc2', 'q5', \"Could you elaborate on what 'a truly unique approach to helping customers' entails for Intelia?\", \"The article highlights Intelia's 'truly unique approach.' Asking for concrete examples of how this approach differs from competitors would be key to understanding their value proposition.\"], ['doc3', 'q6', \"What are Intelia's key technology partnerships and specializations?\", 'Intelia is a Google Cloud Premier Partner specializing in machine learning and data analytics. They are also a Snowflake partner.'], ['doc3', 'q7', 'How does Intelia help businesses leverage cloud technology like GCP and Snowflake?', 'Intelia provides technology strategists, architects, engineers, and delivery professionals to help businesses leverage Google Cloud Platform (GCP) and Snowflake for data warehousing, analytics, and cloud transformation.'], ['doc4', 'q8', 'What kind of services does Intelia provide to its customers?', 'Based on the article, Intelia is a data consultancy that leverages AI and data to deliver value to its clients. More information is needed to specify the exact services.'], ['doc4', 'q9', \"What is the significance of Intelia's 'One Tribe' value?\", \"The article highlights 'One Tribe' as a core value and an award category, suggesting its importance to Intelia's culture and teamwork.\"]]\n"
     ]
    }
   ],
   "source": [
    "generated_queries=[]\n",
    "request_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=True) \n",
    "rf= open(request_file.name, \"a\") \n",
    "all_queries=[]\n",
    "qid=0\n",
    "for idx,row in data.iterrows():\n",
    "    queries=generate_queries(title= row['title'],text= row['content']) \n",
    "    tmp=queries.get(\"question_expression\", \"\")\n",
    "    for exp in tmp:          \n",
    "          all_queries.append(['doc'+str(idx),'q'+str(qid),exp['query_expression'],exp['answer']])\n",
    "          qid=qid+1\n",
    "    \n",
    "    print(all_queries)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d6d48451-9a31-42df-a973-bd212d19eb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_expression': \"What are Intelia's core values?\"}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "94f09953-d12a-47c9-9be8-af152128d1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with column names\n",
    "df = pd.DataFrame(all_queries, columns=[ 'corpus-id' , 'query-id' ,'query','answer'])\n",
    "df.to_csv('all_queries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ee0301a2-d0f6-47c9-96ba-6dd8a655fb62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_expression': 'How does Intelia view its commitment to clients?',\n",
       " 'answer': 'Intelia sees client commitment as central to their own success, emphasizing precision, innovation, and care in delivery.'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1b69b7da-870a-46d5-b1fd-5ed244397cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=True) \n",
    "rf= open(request_file.name, \"a\") \n",
    "q1=[\"What is Intelia's core philosophy and how does it impact their approach to customer success?\",  'How does Intelia balance its focus on customer delight with the well-being of its employees?',  'What specific actions does Intelia take to foster a passionate and enjoyable work environment?',  'How does Intelia leverage diversity and collaboration to achieve its goals?',  'What sets Intelia apart from other data consultancies in the market?']\n",
    "\n",
    "q2=['## Questions about Intelia:',  '1. **What specific types of data migrations does Intelia specialize in?**',  '2. **Does Intelia offer end-to-end data migration services, including planning, execution, and post-migration support?**',  '3. **What cloud platforms is Intelia most experienced with and certified in?**',  '4. **Can Intelia provide case studies or examples of successful data migration projects they have completed?**',  \"5. **What is Intelia's pricing model for data migration services?**\"]\n",
    "\n",
    "q3=['## Intelia: Key Questions',  '1. **What specific data-driven opportunities does Intelia help its clients unlock?** ', '2. **Beyond data analysis, what other services does Intelia provide to its clients?**', \"3. **Can you elaborate on Intelia's unique approach to data consultancy?**\", '4. **How does Intelia tailor its services to address the specific challenges of each client?**', '5. **What are some examples of successful projects Intelia has completed for its clients?** ']\n",
    "\n",
    "q4=['What types of businesses does Intelia typically work with?', 'What makes Intelia different from other cloud data platform providers?', \"How does Snowflake's cloud-first architecture benefit businesses?\", 'How can Intelia assist with planning a cloud or multi-cloud strategy? ', 'How does Intelia help clients focus on business value rather than data warehousing complexity']\n",
    "\n",
    "q5=['## Questions about Intelia:',  '1. What specific data consultancy services does Intelia offer?', '2. What kind of impact does Intelia make for its customers?', '3. How does Intelia foster a culture of innovation and excellence within its team?', \"4. What are Intelia's plans for the future, especially in the context of the evolving AI and data landscape?\", \"5. What are some examples of projects or achievements that demonstrate Intelia's expertise and success? \"]\n",
    "\n",
    "q6=['1. What specific data governance services does Intelia offer to help businesses succeed with their machine learning solutions? ', '2. How does Intelia ensure compliance and facilitate collaboration when implementing data governance strategies?', '3. Can Intelia provide examples of how they have helped businesses improve their data management and avoid the need for significant changes down the line?', '4. What are the key benefits of partnering with Intelia for data governance, particularly in the context of Generative AI adoption?', '5. Does Intelia offer tailored solutions for different industries or specific data-driven challenges? ', '']\n",
    "\n",
    "q7=['- What services does Intelia provide?', \"- What are some of Intelia's major accomplishments in 2024?\", \"- What are some of Intelia's core values?\", \"- What are Intelia's goals for 2025?\", '- What is the meaning of the hashtag \"#onetribe\"?']\n",
    "\n",
    "queries=q1+q2+q3+q4+q5+q6+q7\n",
    "\n",
    "qid=0\n",
    "for query in queries:\n",
    "        if query!=\"\":\n",
    "            generated_queries=[ json.dumps( {  \"_id\": qid,  \n",
    "                                               \"text\":query                                      \n",
    "                                         }\n",
    "                                       )  +\"\\n\"\n",
    "                        ]\n",
    "        \n",
    "            rf.writelines(generated_queries)\n",
    "            rf.flush()\n",
    "            qid +=1\n",
    "\n",
    "upload_file(rf,dest_bucket_name='vlt_search_and_contet_output',request_file_folder='finetunning',request_file_prefix='fine_tuning_query_sample', version=0, request_file_post_fix ='0')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ec8fb2d8-4c72-4e9f-a1bc-0dd9ad1a639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qid=0\n",
    "relevancy=[]\n",
    "\n",
    "import time\n",
    "\n",
    "try:\n",
    "    for query in queries:\n",
    "        for idx,row in data.iterrows():\n",
    "            r=get_autorater_response(title=row['title'], text=row['content'], query=query) \n",
    "            relevancy.append([qid,idx,r.get(\"score\", \"\")])\n",
    "            time.sleep(2)\n",
    "        qid=qid+1\n",
    "except:\n",
    "    print(qid)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9c51e53f-f481-4c07-bf21-ed0c9d70335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with column names\n",
    "df = pd.DataFrame(relevancy, columns=['query-id' , 'corpus-id' ,  'score'])\n",
    "\n",
    "df.to_csv('labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c36b9d06-bbc8-4f09-9bd6-d313e8fd4928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query-id  corpus-id  score\n",
       "0           0          0    1.0\n",
       "1           0          1    0.0\n",
       "2           0          2    1.0\n",
       "3           0          3    0.0\n",
       "4           0          4    1.0\n",
       "..        ...        ...    ...\n",
       "268        38          2    0.0\n",
       "269        38          3    0.0\n",
       "270        38          4    1.0\n",
       "271        38          5    1.0\n",
       "272        38          6    3.0\n",
       "\n",
       "[273 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "499f3f74-897a-42f4-8655-60d797d2a67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bceab1b4-6ce1-4c9d-9f12-e9e5b38d7324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e75c6132-7044-44c8-a044-87f3cc2475f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query-id  corpus-id  score\n",
       "0           0          0    1.0\n",
       "2           0          2    1.0\n",
       "4           0          4    1.0\n",
       "5           0          5    1.0\n",
       "7           1          0    1.0\n",
       "..        ...        ...    ...\n",
       "264        37          5    1.0\n",
       "266        38          0    3.0\n",
       "270        38          4    1.0\n",
       "271        38          5    1.0\n",
       "272        38          6    3.0\n",
       "\n",
       "[147 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[df['score']>0]\n",
    "df[['query-id' , 'corpus-id' ,  'score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "192f8eb2-7dec-418d-abde-8903a49453fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  query-id  corpus-id  score\n",
       "64          64         9          1    1.0\n",
       "68          68         9          5    1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['query-id']==9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac0f219b-6a0c-4ee8-a04a-c6b64c018ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train=df.iloc[0:100].reset_index(drop=True)[['query-id' , 'corpus-id' ,  'score']]\n",
    "test=df.iloc[100:].reset_index(drop=True)[['query-id' , 'corpus-id' ,  'score']]\n",
    "\n",
    "test['score']=[1]*len(test)\n",
    "train['score']=[1]*len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3a3aac82-1147-483f-8e7c-75816132abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to TSV file\n",
    "train.to_csv('train.tsv', sep='\\t', index=False)\n",
    "test.to_csv('test.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "01e5d429-d6f1-4a57-b6d4-314b16441515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from google.cloud.aiplatform import initializer as aiplatform_init\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "\n",
    "\n",
    "def tune_embedding_model(\n",
    "    api_endpoint: str,\n",
    "    base_model_name: str =  'textembedding-gecko@003',\n",
    "    corpus_path: str = \"gs://vlt_search_and_contet_output/finetunning/fine_tuning_intelia_sample_0_0.json\",\n",
    "    queries_path: str = \"gs://vlt_search_and_contet_output/finetunning/fine_tuning_query_sample_0_0.json\",\n",
    "    train_label_path: str = \"gs://vlt_search_and_contet_output/finetunning/train.tsv\",\n",
    "    test_label_path: str = \"gs://vlt_search_and_contet_output/finetunning/test.tsv\",\n",
    "):  # noqa: ANN201\n",
    "    \"\"\"Tune an embedding model using the specified parameters.\n",
    "    Args:\n",
    "        api_endpoint (str): The API endpoint for the Vertex AI service.\n",
    "        base_model_name (str): The name of the base model to use for tuning.\n",
    "        corpus_path (str): GCS URI of the JSONL file containing the corpus data.\n",
    "        queries_path (str): GCS URI of the JSONL file containing the queries data.\n",
    "        train_label_path (str): GCS URI of the TSV file containing the training labels.\n",
    "        test_label_path (str): GCS URI of the TSV file containing the test labels.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"^(\\w+-\\w+)\", api_endpoint)\n",
    "    location = match.group(1) if match else \"us-central1\"\n",
    "    base_model = TextEmbeddingModel.from_pretrained(base_model_name)\n",
    "    tuning_job = base_model.tune_model(\n",
    "        task_type=\"DEFAULT\",\n",
    "        corpus_data=corpus_path,\n",
    "        queries_data=queries_path,\n",
    "        training_data=train_label_path,\n",
    "        test_data=test_label_path,\n",
    "        batch_size=128,  # The batch size to use for training.\n",
    "        train_steps=1000,  # The number of training steps.\n",
    "        tuned_model_location=location,\n",
    "        #output_dimensionality=768,  # The dimensionality of the output embeddings.\n",
    "        learning_rate_multiplier=1.0,  # The multiplier for the learning rate.\n",
    "    )\n",
    "    return tuning_job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "09e40c8e-4a94-4d7b-9b41-4db35f445370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/494586852359/locations/us-central1/pipelineJobs/tune-text-embedding-model-20250202023252\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/494586852359/locations/us-central1/pipelineJobs/tune-text-embedding-model-20250202023252')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/tune-text-embedding-model-20250202023252?project=494586852359\n"
     ]
    }
   ],
   "source": [
    "tuningjob=tune_embedding_model('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64262f68-a191-4ca1-b944-f2f4d2542530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_base_model',\n",
       " '_cancel',\n",
       " '_get_tuned_model_name',\n",
       " '_job',\n",
       " '_model',\n",
       " '_status',\n",
       " '_tuned_model_name',\n",
       " 'deploy_tuned_model',\n",
       " 'get_tuned_model',\n",
       " 'pipeline_job_name']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tuningjob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3eddfca3-a88e-4ff5-86f7-1143bc66f6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PipelineState.PIPELINE_STATE_FAILED: 5>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuningjob._status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d69a6fc-f023-41d7-8948-41c248839612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>queries/0</td>\n",
       "      <td>Based on the information provided in the docum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>queries/1</td>\n",
       "      <td>## Exam Question: **Based on the document prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>queries/2</td>\n",
       "      <td>## Exam Question: **Based on the provided docu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>queries/3</td>\n",
       "      <td>**Based on the provided document, analyze the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queries/4</td>\n",
       "      <td>## Exam Question: **Based on the provided docu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         _id                                               text\n",
       "0  queries/0  Based on the information provided in the docum...\n",
       "1  queries/1  ## Exam Question: **Based on the document prov...\n",
       "2  queries/2  ## Exam Question: **Based on the provided docu...\n",
       "3  queries/3  **Based on the provided document, analyze the ...\n",
       "4  queries/4  ## Exam Question: **Based on the provided docu..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import gcsfs\n",
    "\n",
    "# GCS file path\n",
    "gcs_uri = \"gs://cloud-samples-data/ai-platform/embedding/goog-10k-2024/r11/queries.jsonl\"\n",
    "\n",
    "# Initialize GCS file system\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "\n",
    "# Read JSONL file into DataFrame\n",
    "with fs.open(gcs_uri, 'r') as f:\n",
    "    df = pd.read_json(f, lines=True)\n",
    "\n",
    "# Display DataFram\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c91d1fe9-babf-4cb3-8dd8-f2ceba062c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>query-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>corpus/113</td>\n",
       "      <td>queries/113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corpus/98</td>\n",
       "      <td>queries/97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corpus/157</td>\n",
       "      <td>queries/155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corpus/199</td>\n",
       "      <td>queries/203</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corpus/186</td>\n",
       "      <td>queries/188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    corpus-id     query-id  score\n",
       "0  corpus/113  queries/113      1\n",
       "1   corpus/98   queries/97      1\n",
       "2  corpus/157  queries/155      1\n",
       "3  corpus/199  queries/203      1\n",
       "4  corpus/186  queries/188      1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gcsfs\n",
    "\n",
    "# GCS file path\n",
    "gcs_uri = \"gs://cloud-samples-data/ai-platform/embedding/goog-10k-2024/r11/train.tsv\"\n",
    "\n",
    "# Initialize GCS file system\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "\n",
    "# Read JSONL file into DataFrame\n",
    "with fs.open(gcs_uri, 'r') as f:\n",
    "    df = pd.read_csv(f, sep='\\t')\n",
    "\n",
    "# Display DataFram\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9803f4f1-558a-412e-9fd6-1174a3c15a01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
