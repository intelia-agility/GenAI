{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab31c62-609f-4913-ad5c-9a79f902dfbc",
   "metadata": {},
   "source": [
    "### reference\n",
    "https://partner.cloudskillsboost.google/course_templates/948/video/485086"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b0aa0-abf0-4336-9e78-c20546c04c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade --user google-cloud-aiplatform umap-learn tqdm pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db04d67-94f0-4953-ac89-bb5778263971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "text_embedding_model = TextEmbeddingModel.from_pretrained(\"text-embedding-004\")\n",
    "model = GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ce33910-1baa-440f-873a-79ff2346f3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intelia ethos</td>\n",
       "      <td>\\t\\n#delightthecustomer\\n\\nOur customers' succ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Migrating Data from Legacy Enterprise Data War...</td>\n",
       "      <td>Migrating data from a legacy on-prem data ware...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data is at our core. It's what we're passionat...</td>\n",
       "      <td>intelia was founded in 2018, with a desire to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intelia has a unique technology partner ecosys...</td>\n",
       "      <td>In an increasingly fast-paced and competitive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>? Celebrating Excellence at intelia! ?</td>\n",
       "      <td>ast night, we came together as hashtag#onetrib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Direnc Uysal's linked-in post</td>\n",
       "      <td>Amidst the excitement surrounding Generative A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>intelia's post on 22rd december</td>\n",
       "      <td>As 2024 comes to a close, the intelia hashtag#...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                      intelia ethos   \n",
       "1  Migrating Data from Legacy Enterprise Data War...   \n",
       "2  Data is at our core. It's what we're passionat...   \n",
       "3  intelia has a unique technology partner ecosys...   \n",
       "4             ? Celebrating Excellence at intelia! ?   \n",
       "5                      Direnc Uysal's linked-in post   \n",
       "6                    intelia's post on 22rd december   \n",
       "\n",
       "                                             content  \n",
       "0  \\t\\n#delightthecustomer\\n\\nOur customers' succ...  \n",
       "1  Migrating data from a legacy on-prem data ware...  \n",
       "2  intelia was founded in 2018, with a desire to ...  \n",
       "3  In an increasingly fast-paced and competitive ...  \n",
       "4  ast night, we came together as hashtag#onetrib...  \n",
       "5  Amidst the excitement surrounding Generative A...  \n",
       "6  As 2024 comes to a close, the intelia hashtag#...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('testdata.csv',encoding='latin1')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4310a25-66e8-45b5-b6eb-5f0b9eca48e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import tempfile, shutil\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "from google.cloud import bigquery \n",
    "import os \n",
    "import gcsfs\n",
    "import pandas as pd\n",
    "\n",
    "def upload_file(request_file : tempfile,dest_bucket_name:str =None,request_file_folder: str =None,request_file_prefix: str =None, version: int=0, request_file_post_fix : str=\"\"):\n",
    "\n",
    "    \"\"\"upload file into gcs\n",
    "   \n",
    "        Args:\n",
    "            tempfile request_file: request file\n",
    "            str dest_bucket_name:  name of destination bucket\n",
    "            str request_file_folder: name of the destination folder name to write files to\n",
    "            list request_file_prefix: prefix of request file name\n",
    "          \n",
    "    \"\"\"\n",
    "\n",
    "    temp=request_file\n",
    "    client = storage.Client()\n",
    "    # Extract name to the temp file\n",
    "    temp_file = \"\".join([str(temp.name)])\n",
    "    # Uploading the temp image file to the bucket\n",
    "    dest_filename = f\"{request_file_folder}/\"+request_file_prefix+'_'+request_file_post_fix+'_'+str(version)+\".json\" \n",
    "    dest_bucket = client.get_bucket(dest_bucket_name)\n",
    "    dest_blob = dest_bucket.blob(dest_filename)\n",
    "    dest_blob.upload_from_filename(temp_file)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c9ea7f8-589b-4bc0-8d44-f3ab4383c15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intelia ethos</td>\n",
       "      <td>\\t\\n#delightthecustomer\\n\\nOur customers' succ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Migrating Data from Legacy Enterprise Data War...</td>\n",
       "      <td>Migrating data from a legacy on-prem data ware...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data is at our core. It's what we're passionat...</td>\n",
       "      <td>intelia was founded in 2018, with a desire to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intelia has a unique technology partner ecosys...</td>\n",
       "      <td>In an increasingly fast-paced and competitive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>? Celebrating Excellence at intelia! ?</td>\n",
       "      <td>ast night, we came together as hashtag#onetrib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Direnc Uysal's linked-in post</td>\n",
       "      <td>Amidst the excitement surrounding Generative A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>intelia's post on 22rd december</td>\n",
       "      <td>As 2024 comes to a close, the intelia hashtag#...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                      intelia ethos   \n",
       "1  Migrating Data from Legacy Enterprise Data War...   \n",
       "2  Data is at our core. It's what we're passionat...   \n",
       "3  intelia has a unique technology partner ecosys...   \n",
       "4             ? Celebrating Excellence at intelia! ?   \n",
       "5                      Direnc Uysal's linked-in post   \n",
       "6                    intelia's post on 22rd december   \n",
       "\n",
       "                                             content  \n",
       "0  \\t\\n#delightthecustomer\\n\\nOur customers' succ...  \n",
       "1  Migrating data from a legacy on-prem data ware...  \n",
       "2  intelia was founded in 2018, with a desire to ...  \n",
       "3  In an increasingly fast-paced and competitive ...  \n",
       "4  ast night, we came together as hashtag#onetrib...  \n",
       "5  Amidst the excitement surrounding Generative A...  \n",
       "6  As 2024 comes to a close, the intelia hashtag#...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "522a7ade-f64d-48fb-8cdf-8e76a74c0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=True) \n",
    "rf= open(request_file.name, \"a\") \n",
    "\n",
    "for idx,row in data.iterrows():\n",
    "    data_items=[ json.dumps( {  \"_id\": idx,\n",
    "                                \"title\":row['title'],\n",
    "                                 \"text\":row['content']                                          \n",
    "                               }\n",
    "                               )  +\"\\n\"\n",
    "                ]\n",
    "\n",
    "    rf.writelines(data_items)\n",
    "    rf.flush()\n",
    "upload_file(rf,dest_bucket_name='vlt_search_and_contet_output',request_file_folder='finetunning',request_file_prefix='fine_tuning_intelia_sample', version=0, request_file_post_fix ='0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349d2d00-c38f-4f41-a0c0-6864670396b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries(model, title, text):\n",
    "\n",
    "    prompt = (f'You are a human being who is tasked with extracting some questions from a given text.\\n'\n",
    "    f'Think throughly when reading this text and see what sort of questions may people ask from the content from a data consultancy called Intelia.\\n'\n",
    "    f'Suggest 1 to 5 short questions that are important to ask when people read this text or want to know more about Intelia.\\n'    \n",
    "    f'Output each question on a separate line divided by a newline.\\n'\n",
    "    f'Here is the text:\\n'\n",
    "    f'\"title\": {title}\\n'\n",
    "    f'\"content\":{text}')\n",
    "    \n",
    "    responses = model.generate_content(prompt, stream=False)\n",
    "    return responses.text.split('\\n')\n",
    "\n",
    "generated_queries = generate_queries(model)\n",
    "for query in generated_queries:\n",
    "    print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7ed000-cd88-44f9-be97-66cffe40569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_queries=[]\n",
    "request_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=True) \n",
    "rf= open(request_file.name, \"a\") \n",
    "\n",
    "for idx,row in data.iterrows():\n",
    "    queries=generate_queries(model, row['title'], row['content'])\n",
    "    generated_queries.append()\n",
    "\n",
    "\n",
    "for idx,row in data.iterrows():\n",
    "    data_items=[ json.dumps( {  \"_id\": idx,\n",
    "                                \"title\":row['title'],\n",
    "                                 \"text\":row['content']                                          \n",
    "                               }\n",
    "                               )  +\"\\n\"\n",
    "                ]\n",
    "\n",
    "    rf.writelines(data_items)\n",
    "    rf.flush()\n",
    "upload_file(rf,dest_bucket_name='vlt_search_and_contet_output',request_file_folder='finetunning',request_file_prefix='fine_tuning_intelia_sample', version=0, request_file_post_fix ='0')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b69b7da-870a-46d5-b1fd-5ed244397cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_results(query, statement, model):\n",
    "\n",
    "    prompt = (f'You are a helpful expert financial research assistant.\\n'\n",
    "    f'You help users analyze financial statements to better understand companies.\\n'\n",
    "    f'For the given query, evaluate whether the following satement is relevant.\\n'\n",
    "    f'Output only \\'yes\\' or \\'no\\'.\\n'\n",
    "    f'Question: {query}, Statement: {statement}.')\n",
    "    \n",
    "    responses = model.generate_content(prompt, stream=False)\n",
    "    if responses.text == 'yes':\n",
    "        return 1\n",
    "    return -1\n",
    "\n",
    "retrieved_embeddings = results['embeddings']\n",
    "query_embeddings = embedding_function(generated_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8fb2d8-4c72-4e9f-a1bc-0dd9ad1a639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_query_embeddings = []\n",
    "adapter_doc_embeddings = []\n",
    "adapter_labels = []\n",
    "\n",
    "for q, query in enumerate(tqdm(generated_queries)):\n",
    "    for d, document in enumerate(retrieved_documents[q]):\n",
    "        adapter_query_embeddings.append(query_embeddings[q])\n",
    "        adapter_doc_embeddings.append(retrieved_embeddings[q][d])\n",
    "        adapter_labels.append(evaluate_results(query, document, model))\n",
    "\n",
    "len(adapter_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5abeb-5e4b-4902-b6c4-157b624cd601",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a7df16-3611-4acc-b31b-23635a4503b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_query_embeddings = torch.Tensor(np.array(adapter_query_embeddings))\n",
    "adapter_doc_embeddings = torch.Tensor(np.array(adapter_doc_embeddings))\n",
    "adapter_labels = torch.Tensor(np.expand_dims(np.array(adapter_labels),1))\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(adapter_query_embeddings, adapter_doc_embeddings, adapter_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e88eb5-4d9d-484f-bab1-b246b71d2ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(query_embedding, document_embedding, adaptor_matrix):\n",
    "    updated_query_embedding = torch.matmul(adaptor_matrix, query_embedding)\n",
    "    return torch.cosine_similarity(updated_query_embedding, document_embedding, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99599aa-385b-49c9-9f88-0b4ba4d0b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(query_embedding, document_embedding, adaptor_matrix, label):\n",
    "    return torch.nn.MSELoss()(model(query_embedding, document_embedding, adaptor_matrix), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c4edbc-5a30-4552-9ff5-788a55827f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_size = len(adapter_query_embeddings[0])\n",
    "adapter_matrix = torch.randn(mat_size, mat_size, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332104e3-1aea-4b48-992a-df47f936c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = float('inf')\n",
    "best_matrix = None\n",
    "\n",
    "for epoch in tqdm(range(100)):\n",
    "    for query_embedding, document_embedding, label in dataset:\n",
    "        loss = mse_loss(query_embedding, document_embedding, adapter_matrix, label)\n",
    "\n",
    "        if loss < min_loss:\n",
    "            min_loss = loss\n",
    "            best_matrix = adapter_matrix.clone().detach().numpy()\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            adapter_matrix -= 0.01 * adapter_matrix.grad\n",
    "            adapter_matrix.grad.zero_()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd04549d-2660-4a44-9c4c-53be1d245915",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best loss: {min_loss.detach().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778e589a-1bef-46a8-8c5a-a9bb67c354cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vector = torch.ones((mat_size,1))\n",
    "scaled_vector = np.matmul(best_matrix, test_vector).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cece1c65-7b5a-4a9a-95b0-e06576aa892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(len(scaled_vector)), scaled_vector.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658d25c6-3c8c-4b1d-8bc7-7e37b8275cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embeddings = embedding_function(generated_queries)\n",
    "adapted_query_embeddings = np.matmul(best_matrix, np.array(query_embeddings).T).T\n",
    "\n",
    "projected_query_embeddings = project_embeddings(query_embeddings, umap_transform)\n",
    "projected_adapted_query_embeddings = project_embeddings(adapted_query_embeddings, umap_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d91bc5-b024-4a7a-9e3d-88aefd9d7492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the projected query and retrieved documents in the embedding space\n",
    "plt.figure()\n",
    "plt.scatter(projected_dataset_embeddings[:, 0], projected_dataset_embeddings[:, 1], s=10, color='gray')\n",
    "plt.scatter(projected_query_embeddings[:, 0], projected_query_embeddings[:, 1], s=150, marker='X', color='r', label=\"original\")\n",
    "plt.scatter(projected_adapted_query_embeddings[:, 0], projected_adapted_query_embeddings[:, 1], s=150, marker='X', color='green', label=\"adapted\")\n",
    "\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title(\"Adapted Queries\")\n",
    "plt.axis('off')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cacc883-65bc-4e4b-b571-929788515df2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
