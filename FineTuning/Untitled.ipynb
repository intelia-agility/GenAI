{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab31c62-609f-4913-ad5c-9a79f902dfbc",
   "metadata": {},
   "source": [
    "### reference\n",
    "https://partner.cloudskillsboost.google/course_templates/948/video/485086"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b0aa0-abf0-4336-9e78-c20546c04c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade --user google-cloud-aiplatform umap-learn tqdm pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db04d67-94f0-4953-ac89-bb5778263971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part as GenerativeModelPart,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce33910-1baa-440f-873a-79ff2346f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('testdata.csv',encoding='latin1')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4310a25-66e8-45b5-b6eb-5f0b9eca48e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import tempfile, shutil\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "from google.cloud import bigquery \n",
    "import os \n",
    "import gcsfs\n",
    "import pandas as pd\n",
    "\n",
    "def upload_file(request_file : tempfile,dest_bucket_name:str =None,request_file_folder: str =None,request_file_prefix: str =None, version: int=0, request_file_post_fix : str=\"\"):\n",
    "\n",
    "    \"\"\"upload file into gcs\n",
    "   \n",
    "        Args:\n",
    "            tempfile request_file: request file\n",
    "            str dest_bucket_name:  name of destination bucket\n",
    "            str request_file_folder: name of the destination folder name to write files to\n",
    "            list request_file_prefix: prefix of request file name\n",
    "          \n",
    "    \"\"\"\n",
    "\n",
    "    temp=request_file\n",
    "    client = storage.Client()\n",
    "    # Extract name to the temp file\n",
    "    temp_file = \"\".join([str(temp.name)])\n",
    "    # Uploading the temp image file to the bucket\n",
    "    dest_filename = f\"{request_file_folder}/\"+request_file_prefix+'_'+request_file_post_fix+'_'+str(version)+\".json\" \n",
    "    dest_bucket = client.get_bucket(dest_bucket_name)\n",
    "    dest_blob = dest_bucket.blob(dest_filename)\n",
    "    dest_blob.upload_from_filename(temp_file)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a7ade-f64d-48fb-8cdf-8e76a74c0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=True) \n",
    "rf= open(request_file.name, \"a\") \n",
    "\n",
    "for idx,row in data.iterrows():\n",
    "    data_items=[ json.dumps( {  \"_id\": idx,\n",
    "                                \"title\":row['title'],\n",
    "                                 \"text\":row['content']                                          \n",
    "                               }\n",
    "                               )  +\"\\n\"\n",
    "                ]\n",
    "\n",
    "    rf.writelines(data_items)\n",
    "    rf.flush()\n",
    "upload_file(rf,dest_bucket_name='vlt_search_and_contet_output',request_file_folder='finetunning',request_file_prefix='fine_tuning_intelia_sample', version=0, request_file_post_fix ='0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349d2d00-c38f-4f41-a0c0-6864670396b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries(model=\"gemini-1.5-pro\", title=\"\", text=\"\"):\n",
    "\n",
    "        metric_prompt = (f'You are an expert who is tasked with extracting some questions from a given article.\\n'\n",
    "        f'Think throughly when reading this article including both title and content. Think of questions may people may ask to know more about a data consultancy called Intelia.\\n'\n",
    "        f'Suggest 1 to 2 short questions that are important to ask when people want to explore who Intelia is and what it does.\\n'\n",
    "        f' Also suggest 1-2 labels or short expressions that are related to this articleor highlight them.\\n'\n",
    "        f' These expressions or questions should be optimized for fine tuning a text embedding model.\\n'    \n",
    "        f'Output each response on a separate line divided by a newline.\\n'\n",
    "        f'Here is the article:\\n'\n",
    "        f'\"title\": {title}\\n'\n",
    "        f'\"content\":{text}')\n",
    "\n",
    "        # set evaluation metric schema\n",
    "        metric_response_schema = {\n",
    "            \"type\": \"OBJECT\",\n",
    "            \"properties\": {\n",
    "                \"question_expression\": {\n",
    "                    \"type\": \"ARRAY\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"OBJECT\",\n",
    "                        \"properties\": {\n",
    "                            \"query_expression\": {\"type\": \"STRING\"},\n",
    "                            \"answer\": {\"type\": \"STRING\"}\n",
    "                        },\n",
    "                        \"required\": [\"query_expression\",\"answer\"]\n",
    "                    }\n",
    "                } \n",
    "            },\n",
    "            \"required\": [\"question_expression\"],\n",
    "        }\n",
    "    \n",
    "      \n",
    "        #define a generative model as an autorator\n",
    "  \n",
    "  \n",
    "        autorater = GenerativeModel(\n",
    "            model,\n",
    "            generation_config=GenerationConfig(\n",
    "                response_mime_type=\"application/json\",\n",
    "                response_schema=metric_response_schema,\n",
    "            ),\n",
    "            safety_settings={\n",
    "                HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            },\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "    \n",
    "        #generate the rating metrics as per requested measures and metric in the prompt\n",
    "        response = autorater.generate_content([metric_prompt])\n",
    "\n",
    "        response_json = {}\n",
    "\n",
    "        if response.candidates and len(response.candidates) > 0:\n",
    "            candidate = response.candidates[0]\n",
    "            if (\n",
    "                candidate.content\n",
    "                and candidate.content.parts\n",
    "                and len(candidate.content.parts) > 0\n",
    "            ):\n",
    "                part = candidate.content.parts[0]\n",
    "                if part.text:\n",
    "                    response_json = json.loads(part.text)\n",
    "\n",
    "        return response_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c30cc03-17e7-4ab8-951d-6290e430436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autorater_response(llm_model: str=\"gemini-1.5-pro\", title=\"\", text=\"\", query=\"\") -> dict:\n",
    "        \n",
    "        \"\"\"Extract evaluation metric on a AI-generated content using a AI-as-judge approach\n",
    "        \n",
    "        Args:\n",
    "        list metric_prompt: the input metric prompt parameters\n",
    "        str llm_model: evaluation model\n",
    "\n",
    "        Returns:\n",
    "        dict response_json: the evaluated metric in json format\n",
    "        \"\"\"\n",
    "            \n",
    "        # set evaluation metric schema\n",
    "        metric_response_schema = {\n",
    "            \"type\": \"OBJECT\",\n",
    "            \"properties\": {\n",
    "                \"score\": {\"type\": \"NUMBER\"},\n",
    "                \"explanation\": {\"type\": \"STRING\"},\n",
    "            },\n",
    "            \"required\": [\"score\", \"explanation\"],\n",
    "        }     \n",
    "        #define a generative model as an autorator\n",
    "        autorater = GenerativeModel(\n",
    "            llm_model,\n",
    "            generation_config=GenerationConfig(\n",
    "                response_mime_type=\"application/json\",\n",
    "                response_schema=metric_response_schema,\n",
    "            ),\n",
    "            safety_settings={\n",
    "                HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        metric_prompt= f\"\"\"\n",
    "                        # Instruction \n",
    "                        You are an expert evaluator. Your task is to evaluate the amount of the relevancy between a given question and a given article. You should first read the question carefully for analyzing the task, then read the article. Then evaluate the how relevant the given question is to the given article based on the Criteria provided in the Evaluation section below. You will assign the response a rating following the Rating Rubric and Evaluation Steps. Only choose ratings from the Rating Rubric. \n",
    "                        # Evaluation\n",
    "                        ## Metric Definition \n",
    "                        You will be assessing Relevancy, which measures the ability to find a clear and thorough answer to the given question within given artcile.\n",
    "                        ## Criteria \n",
    "                        Relevancy: Measures the ability to find a clear and thorough answer to the given question within given artcile\n",
    "                        - Category - Detailed Description Of Events And Conversations - Brands, Company Names, and Logos -\n",
    "                        Key Locations And Scenes - Key Themes - People Appearing And Mentioned Thi\n",
    "                        s AI-generated responses will be used for data retrieval. So, it has to be able to capture all the details of a scene. \n",
    "                        ## Rating Rubric \n",
    "                         0: No relevancy. The document has no connection to the question. It lacks relevant keywords, topics, or context. \n",
    "                         1: Low Relevance. The document contains some keywords but does not provide meaningful information related to the question. The context is weak or unrelated. \\n\n",
    "                         2: Moderate Relevance. The document partially addresses the question but lacks completeness, clarity, or depth. It may require inference to extract an answer.\\n\n",
    "                         3\tHigh Relevance. The document directly and clearly answers the question with specific, well-aligned information. Strong contextual alignment.\\n\n",
    "                        \n",
    "                        ## Evaluation Steps \n",
    "                        STEP 1: Assess question: Carefully read the question to underestand what it is asking. \n",
    "                        STEP 2: Readt the artcile including title and content\n",
    "                        STEP 3: Evaluate relevancy: Evaluate how much the article could be relevant to the question and if the answer can be find in this article. \n",
    "                        STEP 4: Determine relevancy score: Based on the previous steps, assign a relevancy score using the\n",
    "                        0-3 rubric.\n",
    "\n",
    "                        Here is the question and article:\n",
    "                        ## Question:\\n\n",
    "                        {query}\\n                      \n",
    "                        ## Article:\\n                    \n",
    "                        \"title\": \n",
    "                                {title}\\n\n",
    "                        \"content\":\n",
    "                                 {text}\"\"\"\n",
    "\n",
    "   \n",
    "        #generate the rating metrics as per requested measures and metric in the prompt\n",
    "        response = autorater.generate_content([metric_prompt])\n",
    "\n",
    "        response_json = {}\n",
    "\n",
    "        if response.candidates and len(response.candidates) > 0:\n",
    "            candidate = response.candidates[0]\n",
    "            if (\n",
    "                candidate.content\n",
    "                and candidate.content.parts\n",
    "                and len(candidate.content.parts) > 0\n",
    "            ):\n",
    "                part = candidate.content.parts[0]\n",
    "                if part.text:\n",
    "                    response_json = json.loads(part.text)\n",
    "\n",
    "        return response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7ed000-cd88-44f9-be97-66cffe40569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_queries=[]\n",
    "request_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=True) \n",
    "rf= open(request_file.name, \"a\") \n",
    "all_queries=[]\n",
    "qid=0\n",
    "for idx,row in data.iterrows():\n",
    "    queries=generate_queries(title= row['title'],text= row['content']) \n",
    "    tmp=queries.get(\"question_expression\", \"\")\n",
    "    for exp in tmp:          \n",
    "          all_queries.append(['doc'+str(idx),'q'+str(qid),exp['query_expression'],exp['answer']])\n",
    "          qid=qid+1\n",
    "    \n",
    "    print(all_queries)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f09953-d12a-47c9-9be8-af152128d1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with column names\n",
    "df = pd.DataFrame(all_queries, columns=[ 'corpus-id' , 'query-id' ,'query','answer'])\n",
    "df.to_csv('all_queries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05f126c-2b3b-401e-93e9-ba04e4e09827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc1c0f-4bdf-4860-a79a-54275d7e418e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb27322-c689-41b8-a618-abae369e8535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92678420-225c-4353-b7df-0629acb1df44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b59985-611b-4c8a-80d9-f82b20038058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b69b7da-870a-46d5-b1fd-5ed244397cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=True) \n",
    "rf= open(request_file.name, \"a\") \n",
    "q1=[\"What is Intelia's core philosophy and how does it impact their approach to customer success?\",  'How does Intelia balance its focus on customer delight with the well-being of its employees?',  'What specific actions does Intelia take to foster a passionate and enjoyable work environment?',  'How does Intelia leverage diversity and collaboration to achieve its goals?',  'What sets Intelia apart from other data consultancies in the market?']\n",
    "\n",
    "q2=['1. **What specific types of data migrations does Intelia specialize in?**',  '2. **Does Intelia offer end-to-end data migration services, including planning, execution, and post-migration support?**',  '3. **What cloud platforms is Intelia most experienced with and certified in?**',  '4. **Can Intelia provide case studies or examples of successful data migration projects they have completed?**',  \"5. **What is Intelia's pricing model for data migration services?**\"]\n",
    "\n",
    "q3=[ '1. **What specific data-driven opportunities does Intelia help its clients unlock?** ', '2. **Beyond data analysis, what other services does Intelia provide to its clients?**', \"3. **Can you elaborate on Intelia's unique approach to data consultancy?**\", '4. **How does Intelia tailor its services to address the specific challenges of each client?**', '5. **What are some examples of successful projects Intelia has completed for its clients?** ']\n",
    "\n",
    "q4=['What types of businesses does Intelia typically work with?', 'What makes Intelia different from other cloud data platform providers?', \"How does Snowflake's cloud-first architecture benefit businesses?\", 'How can Intelia assist with planning a cloud or multi-cloud strategy? ', 'How does Intelia help clients focus on business value rather than data warehousing complexity']\n",
    "\n",
    "q5=[  '1. What specific data consultancy services does Intelia offer?', '2. What kind of impact does Intelia make for its customers?', '3. How does Intelia foster a culture of innovation and excellence within its team?', \"4. What are Intelia's plans for the future, especially in the context of the evolving AI and data landscape?\", \"5. What are some examples of projects or achievements that demonstrate Intelia's expertise and success? \"]\n",
    "\n",
    "q6=['1. What specific data governance services does Intelia offer to help businesses succeed with their machine learning solutions? ', '2. How does Intelia ensure compliance and facilitate collaboration when implementing data governance strategies?', '3. Can Intelia provide examples of how they have helped businesses improve their data management and avoid the need for significant changes down the line?', '4. What are the key benefits of partnering with Intelia for data governance, particularly in the context of Generative AI adoption?', '5. Does Intelia offer tailored solutions for different industries or specific data-driven challenges? ']\n",
    "\n",
    "q7=['- What services does Intelia provide?', \"- What are some of Intelia's major accomplishments in 2024?\", \"- What are some of Intelia's core values?\", \"- What are Intelia's goals for 2025?\", '- What is the meaning of the hashtag \"#onetribe\"?']\n",
    "\n",
    "queries=q1+q2+q3+q4+q5+q6+q7\n",
    "\n",
    "qid=0\n",
    "for query in queries:\n",
    "        if query!=\"\":\n",
    "            generated_queries=[ json.dumps( {  \"_id\": qid,  \n",
    "                                               \"text\":query                                      \n",
    "                                         }\n",
    "                                       )  +\"\\n\"\n",
    "                        ]\n",
    "        \n",
    "            rf.writelines(generated_queries)\n",
    "            rf.flush()\n",
    "            qid +=1\n",
    "\n",
    "upload_file(rf,dest_bucket_name='vlt_search_and_contet_output',request_file_folder='finetunning',request_file_prefix='fine_tuning_query_sample', version=0, request_file_post_fix ='0')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87522dca-2d38-4e25-af99-85bdddfcc091",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e820aee-f7f7-4e3e-b8b4-721a75bd1eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries=[{\"_id\": 0, \"text\": \"What is Intelia's core philosophy and how does it impact their approach to customer success?\"},\n",
    "{\"_id\": 1, \"text\": \"How does Intelia balance its focus on customer delight with the well-being of its employees?\"},\n",
    "{\"_id\": 2, \"text\": \"What specific actions does Intelia take to foster a passionate and enjoyable work environment?\"},\n",
    "{\"_id\": 3, \"text\": \"How does Intelia leverage diversity and collaboration to achieve its goals?\"},\n",
    "{\"_id\": 4, \"text\": \"What sets Intelia apart from other data consultancies in the market?\"},\n",
    "{\"_id\": 5, \"text\": \"1. **What specific types of data migrations does Intelia specialize in?**\"},\n",
    "{\"_id\": 6, \"text\": \"2. **Does Intelia offer end-to-end data migration services, including planning, execution, and post-migration support?**\"},\n",
    "{\"_id\": 7, \"text\": \"3. **What cloud platforms is Intelia most experienced with and certified in?**\"},\n",
    "{\"_id\": 8, \"text\": \"4. **Can Intelia provide case studies or examples of successful data migration projects they have completed?**\"},\n",
    "{\"_id\": 9, \"text\": \"5. **What is Intelia's pricing model for data migration services?**\"},\n",
    "{\"_id\": 10, \"text\": \"1. **What specific data-driven opportunities does Intelia help its clients unlock?** \"},\n",
    "{\"_id\": 11, \"text\": \"2. **Beyond data analysis, what other services does Intelia provide to its clients?**\"},\n",
    "{\"_id\": 12, \"text\": \"3. **Can you elaborate on Intelia's unique approach to data consultancy?**\"},\n",
    "{\"_id\": 13, \"text\": \"4. **How does Intelia tailor its services to address the specific challenges of each client?**\"},\n",
    "{\"_id\": 14, \"text\": \"5. **What are some examples of successful projects Intelia has completed for its clients?** \"},\n",
    "{\"_id\": 15, \"text\": \"What types of businesses does Intelia typically work with?\"},\n",
    "{\"_id\": 16, \"text\": \"What makes Intelia different from other cloud data platform providers?\"},\n",
    "{\"_id\": 17, \"text\": \"How does Snowflake's cloud-first architecture benefit businesses?\"},\n",
    "{\"_id\": 18, \"text\": \"How can Intelia assist with planning a cloud or multi-cloud strategy? \"},\n",
    "{\"_id\": 19, \"text\": \"How does Intelia help clients focus on business value rather than data warehousing complexity\"},\n",
    "{\"_id\": 20, \"text\": \"1. What specific data consultancy services does Intelia offer?\"},\n",
    "{\"_id\": 21, \"text\": \"2. What kind of impact does Intelia make for its customers?\"},\n",
    "{\"_id\": 22, \"text\": \"3. How does Intelia foster a culture of innovation and excellence within its team?\"},\n",
    "{\"_id\": 23, \"text\": \"4. What are Intelia's plans for the future, especially in the context of the evolving AI and data landscape?\"},\n",
    "{\"_id\": 24, \"text\": \"5. What are some examples of projects or achievements that demonstrate Intelia's expertise and success? \"},\n",
    "{\"_id\": 25, \"text\": \"1. What specific data governance services does Intelia offer to help businesses succeed with their machine learning solutions? \"},\n",
    "{\"_id\": 26, \"text\": \"2. How does Intelia ensure compliance and facilitate collaboration when implementing data governance strategies?\"},\n",
    "{\"_id\": 27, \"text\": \"3. Can Intelia provide examples of how they have helped businesses improve their data management and avoid the need for significant changes down the line?\"},\n",
    "{\"_id\": 28, \"text\": \"4. What are the key benefits of partnering with Intelia for data governance, particularly in the context of Generative AI adoption?\"},\n",
    "{\"_id\": 29, \"text\": \"5. Does Intelia offer tailored solutions for different industries or specific data-driven challenges? \"},\n",
    "{\"_id\": 30, \"text\": \"- What services does Intelia provide?\"},\n",
    "{\"_id\": 31, \"text\": \"- What are some of Intelia's major accomplishments in 2024?\"},\n",
    "{\"_id\": 32, \"text\": \"- What are some of Intelia's core values?\"},\n",
    "{\"_id\": 33, \"text\": \"- What are Intelia's goals for 2025?\"},\n",
    "{\"_id\": 34, \"text\": \"- What is the meaning of the hashtag \\\"#onetribe\\\"?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbfefb5-544f-40d9-bf42-dfe8ac858dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8fb2d8-4c72-4e9f-a1bc-0dd9ad1a639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qid=0\n",
    "relevancy=[]\n",
    "\n",
    "import time\n",
    "\n",
    "try:\n",
    "    for query in queries:\n",
    "        for idx,row in data.iterrows():\n",
    "            r=get_autorater_response(title=row['title'], text=row['content'], query=query['text']) \n",
    "            relevancy.append([query['_id'],idx,r.get(\"score\", \"\")])\n",
    "            print(relevancy)\n",
    "            time.sleep(2)\n",
    "            \n",
    "     \n",
    "except:\n",
    "    print(qid)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c51e53f-f481-4c07-bf21-ed0c9d70335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with column names\n",
    "df = pd.DataFrame(relevancy, columns=['query-id' , 'corpus-id' ,  'score'])\n",
    "\n",
    "df.to_csv('relevancies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c36b9d06-bbc8-4f09-9bd6-d313e8fd4928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query-id  corpus-id  score\n",
       "0           0          0    1.0\n",
       "1           0          1    0.0\n",
       "2           0          2    1.0\n",
       "3           0          3    0.0\n",
       "4           0          4    0.0\n",
       "..        ...        ...    ...\n",
       "240        34          2    0.0\n",
       "241        34          3    0.0\n",
       "242        34          4    2.0\n",
       "243        34          5    0.0\n",
       "244        34          6    2.0\n",
       "\n",
       "[245 rows x 3 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f3f74-897a-42f4-8655-60d797d2a67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bceab1b4-6ce1-4c9d-9f12-e9e5b38d7324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('relevancies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e75c6132-7044-44c8-a044-87f3cc2475f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query-id  corpus-id  score\n",
       "0           0          0    1.0\n",
       "2           0          2    1.0\n",
       "5           0          5    1.0\n",
       "7           1          0    1.0\n",
       "11          1          4    1.0\n",
       "..        ...        ...    ...\n",
       "229        32          5    1.0\n",
       "230        32          6    1.0\n",
       "238        34          0    3.0\n",
       "242        34          4    2.0\n",
       "244        34          6    2.0\n",
       "\n",
       "[95 rows x 3 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[df['score']>0]\n",
    "df[['query-id' , 'corpus-id' ,  'score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192f8eb2-7dec-418d-abde-8903a49453fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['query-id']==9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ac0f219b-6a0c-4ee8-a04a-c6b64c018ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train=df.reset_index(drop=True)[['query-id' , 'corpus-id' ,  'score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3a3aac82-1147-483f-8e7c-75816132abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to TSV file\n",
    "train.to_csv('train.tsv', sep='\\t', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "01e5d429-d6f1-4a57-b6d4-314b16441515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from google.cloud.aiplatform import initializer as aiplatform_init\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "\n",
    "\n",
    "def tune_embedding_model(\n",
    "    api_endpoint: str,\n",
    "    base_model_name: str =  'textembedding-gecko@003',\n",
    "    corpus_path: str = \"gs://vlt_search_and_contet_output/finetunning/fine_tuning_intelia_sample_0_0.json\",\n",
    "    queries_path: str = \"gs://vlt_search_and_contet_output/finetunning/fine_tuning_query_sample_0_0.json\",\n",
    "    train_label_path: str = \"gs://vlt_search_and_contet_output/finetunning/train.tsv\",\n",
    "    #test_label_path: str = \"gs://vlt_search_and_contet_output/finetunning/test.tsv\",\n",
    "):  # noqa: ANN201\n",
    "    \"\"\"Tune an embedding model using the specified parameters.\n",
    "    Args:\n",
    "        api_endpoint (str): The API endpoint for the Vertex AI service.\n",
    "        base_model_name (str): The name of the base model to use for tuning.\n",
    "        corpus_path (str): GCS URI of the JSONL file containing the corpus data.\n",
    "        queries_path (str): GCS URI of the JSONL file containing the queries data.\n",
    "        train_label_path (str): GCS URI of the TSV file containing the training labels.\n",
    "        test_label_path (str): GCS URI of the TSV file containing the test labels.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"^(\\w+-\\w+)\", api_endpoint)\n",
    "    location = match.group(1) if match else \"us-central1\"\n",
    "    base_model = TextEmbeddingModel.from_pretrained(base_model_name)\n",
    "    tuning_job = base_model.tune_model(\n",
    "        task_type=\"DEFAULT\",\n",
    "        corpus_data=corpus_path,\n",
    "        queries_data=queries_path,\n",
    "        training_data=train_label_path,\n",
    "        #test_data=test_label_path,\n",
    "        batch_size=128,  # The batch size to use for training.\n",
    "        train_steps=1000,  # The number of training steps.\n",
    "        tuned_model_location=location,\n",
    "        #output_dimensionality=768,  # The dimensionality of the output embeddings.\n",
    "        learning_rate_multiplier=1.0,  # The multiplier for the learning rate.\n",
    "    )\n",
    "    return tuning_job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "09e40c8e-4a94-4d7b-9b41-4db35f445370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/494586852359/locations/us-central1/pipelineJobs/tune-text-embedding-model-20250202050250\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/494586852359/locations/us-central1/pipelineJobs/tune-text-embedding-model-20250202050250')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/tune-text-embedding-model-20250202050250?project=494586852359\n"
     ]
    }
   ],
   "source": [
    "tuningjob=tune_embedding_model('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64262f68-a191-4ca1-b944-f2f4d2542530",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(tuningjob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3eddfca3-a88e-4ff5-86f7-1143bc66f6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PipelineState.PIPELINE_STATE_RUNNING: 3>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuningjob._status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3d69a6fc-f023-41d7-8948-41c248839612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>corpus/0</td>\n",
       "      <td>### Note About Forward-Looking Statements</td>\n",
       "      <td>This Annual Report on Form 10-K contains forwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corpus/1</td>\n",
       "      <td>### Note About Forward-Looking Statements</td>\n",
       "      <td>that our traffic acquisition costs (TAC) and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corpus/2</td>\n",
       "      <td>### Note About Forward-Looking Statements</td>\n",
       "      <td>come online; •our expectation that our foreign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corpus/3</td>\n",
       "      <td>### Note About Forward-Looking Statements</td>\n",
       "      <td>long-term initiatives, in particular in suppor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corpus/4</td>\n",
       "      <td>### Note About Forward-Looking Statements</td>\n",
       "      <td>our other income (expense), net (OI&amp;E), will f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>corpus/318</td>\n",
       "      <td>### CERTIFICATION OF CHIEF EXECUTIVE OFFICER</td>\n",
       "      <td>I, Sundar Pichai, certify that: 1.I have revie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>corpus/319</td>\n",
       "      <td>### CERTIFICATION OF CHIEF EXECUTIVE OFFICER</td>\n",
       "      <td>other certifying officer and I are responsible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>corpus/320</td>\n",
       "      <td>### CERTIFICATION OF CHIEF EXECUTIVE OFFICER</td>\n",
       "      <td>control over financial reporting, or caused su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>corpus/321</td>\n",
       "      <td>### CERTIFICATION OF CHIEF EXECUTIVE OFFICER</td>\n",
       "      <td>over financial reporting that occurred during ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>corpus/322</td>\n",
       "      <td>### CERTIFICATIONS OF CHIEF FINANCIAL OFFICER</td>\n",
       "      <td>I, Ruth Porat, certify pursuant to 18 U.S.C. S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            _id                                          title  \\\n",
       "0      corpus/0      ### Note About Forward-Looking Statements   \n",
       "1      corpus/1      ### Note About Forward-Looking Statements   \n",
       "2      corpus/2      ### Note About Forward-Looking Statements   \n",
       "3      corpus/3      ### Note About Forward-Looking Statements   \n",
       "4      corpus/4      ### Note About Forward-Looking Statements   \n",
       "..          ...                                            ...   \n",
       "318  corpus/318   ### CERTIFICATION OF CHIEF EXECUTIVE OFFICER   \n",
       "319  corpus/319   ### CERTIFICATION OF CHIEF EXECUTIVE OFFICER   \n",
       "320  corpus/320   ### CERTIFICATION OF CHIEF EXECUTIVE OFFICER   \n",
       "321  corpus/321   ### CERTIFICATION OF CHIEF EXECUTIVE OFFICER   \n",
       "322  corpus/322  ### CERTIFICATIONS OF CHIEF FINANCIAL OFFICER   \n",
       "\n",
       "                                                  text  \n",
       "0    This Annual Report on Form 10-K contains forwa...  \n",
       "1    that our traffic acquisition costs (TAC) and t...  \n",
       "2    come online; •our expectation that our foreign...  \n",
       "3    long-term initiatives, in particular in suppor...  \n",
       "4    our other income (expense), net (OI&E), will f...  \n",
       "..                                                 ...  \n",
       "318  I, Sundar Pichai, certify that: 1.I have revie...  \n",
       "319  other certifying officer and I are responsible...  \n",
       "320  control over financial reporting, or caused su...  \n",
       "321  over financial reporting that occurred during ...  \n",
       "322  I, Ruth Porat, certify pursuant to 18 U.S.C. S...  \n",
       "\n",
       "[323 rows x 3 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import gcsfs\n",
    "\n",
    "# GCS file path\n",
    "gcs_uri = \"gs://cloud-samples-data/ai-platform/embedding/goog-10k-2024/r11/corpus.jsonl\"\n",
    "\n",
    "# Initialize GCS file system\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "\n",
    "# Read JSONL file into DataFrame\n",
    "with fs.open(gcs_uri, 'r') as f:\n",
    "    df = pd.read_json(f, lines=True)\n",
    "\n",
    "# Display DataFram\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c91d1fe9-babf-4cb3-8dd8-f2ceba062c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>query-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>corpus/195</td>\n",
       "      <td>queries/251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corpus/225</td>\n",
       "      <td>queries/221</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corpus/177</td>\n",
       "      <td>queries/177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corpus/183</td>\n",
       "      <td>queries/185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corpus/306</td>\n",
       "      <td>queries/307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>corpus/85</td>\n",
       "      <td>queries/86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>corpus/232</td>\n",
       "      <td>queries/221</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>corpus/272</td>\n",
       "      <td>queries/273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>corpus/203</td>\n",
       "      <td>queries/201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>corpus/201</td>\n",
       "      <td>queries/200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      corpus-id     query-id  score\n",
       "0    corpus/195  queries/251      1\n",
       "1    corpus/225  queries/221      1\n",
       "2    corpus/177  queries/177      1\n",
       "3    corpus/183  queries/185      1\n",
       "4    corpus/306  queries/307      1\n",
       "..          ...          ...    ...\n",
       "150   corpus/85   queries/86      1\n",
       "151  corpus/232  queries/221      1\n",
       "152  corpus/272  queries/273      1\n",
       "153  corpus/203  queries/201      1\n",
       "154  corpus/201  queries/200      1\n",
       "\n",
       "[155 rows x 3 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gcsfs\n",
    "\n",
    "# GCS file path\n",
    "gcs_uri = \"gs://cloud-samples-data/ai-platform/embedding/goog-10k-2024/r11/test.tsv\"\n",
    "\n",
    "# Initialize GCS file system\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "\n",
    "# Read JSONL file into DataFrame\n",
    "with fs.open(gcs_uri, 'r') as f:\n",
    "    df = pd.read_csv(f, sep='\\t')\n",
    "\n",
    "# Display DataFram\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9803f4f1-558a-412e-9fd6-1174a3c15a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from google.cloud.aiplatform import initializer as aiplatform_init\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "\n",
    "\n",
    "def tune_embedding_model(\n",
    "    api_endpoint: str,\n",
    "    base_model_name: str = \"text-embedding-005\",\n",
    "    corpus_path: str = \"gs://cloud-samples-data/ai-platform/embedding/goog-10k-2024/r11/corpus.jsonl\",\n",
    "    queries_path: str = \"gs://cloud-samples-data/ai-platform/embedding/goog-10k-2024/r11/queries.jsonl\",\n",
    "    train_label_path: str = \"gs://cloud-samples-data/ai-platform/embedding/goog-10k-2024/r11/train.tsv\",\n",
    "    test_label_path: str = \"gs://cloud-samples-data/ai-platform/embedding/goog-10k-2024/r11/test.tsv\",\n",
    "):  # noqa: ANN201\n",
    "    \"\"\"Tune an embedding model using the specified parameters.\n",
    "    Args:\n",
    "        api_endpoint (str): The API endpoint for the Vertex AI service.\n",
    "        base_model_name (str): The name of the base model to use for tuning.\n",
    "        corpus_path (str): GCS URI of the JSONL file containing the corpus data.\n",
    "        queries_path (str): GCS URI of the JSONL file containing the queries data.\n",
    "        train_label_path (str): GCS URI of the TSV file containing the training labels.\n",
    "        test_label_path (str): GCS URI of the TSV file containing the test labels.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"^(\\w+-\\w+)\", api_endpoint)\n",
    "    location = match.group(1) if match else \"us-central1\"\n",
    "    base_model = TextEmbeddingModel.from_pretrained(base_model_name)\n",
    "    tuning_job = base_model.tune_model(\n",
    "        task_type=\"DEFAULT\",\n",
    "        corpus_data=corpus_path,\n",
    "        queries_data=queries_path,\n",
    "        training_data=train_label_path,\n",
    "        test_data=test_label_path,\n",
    "        batch_size=128,  # The batch size to use for training.\n",
    "        train_steps=1000,  # The number of training steps.\n",
    "        tuned_model_location=location,\n",
    "        output_dimensionality=768,  # The dimensionality of the output embeddings.\n",
    "        learning_rate_multiplier=1.0,  # The multiplier for the learning rate.\n",
    "    )\n",
    "    return tuning_job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fba7cb9c-e2a6-437b-9418-16e1fec4df2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/494586852359/locations/us-central1/pipelineJobs/tune-text-embedding-model-20250202052109\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/494586852359/locations/us-central1/pipelineJobs/tune-text-embedding-model-20250202052109')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/tune-text-embedding-model-20250202052109?project=494586852359\n"
     ]
    }
   ],
   "source": [
    "job=tune_embedding_model('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5ef875-8f63-4906-a65a-1552da42f026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
