{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab31c62-609f-4913-ad5c-9a79f902dfbc",
   "metadata": {},
   "source": [
    "### reference\n",
    "https://partner.cloudskillsboost.google/course_templates/948/video/485086"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b0aa0-abf0-4336-9e78-c20546c04c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade --user google-cloud-aiplatform umap-learn tqdm pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9db04d67-94f0-4953-ac89-bb5778263971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "text_embedding_model = TextEmbeddingModel.from_pretrained(\"text-embedding-004\")\n",
    "model = GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ce33910-1baa-440f-873a-79ff2346f3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intelia ethos</td>\n",
       "      <td>\\t\\n#delightthecustomer\\n\\nOur customers' succ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Migrating Data from Legacy Enterprise Data War...</td>\n",
       "      <td>Migrating data from a legacy on-prem data ware...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data is at our core. It's what we're passionat...</td>\n",
       "      <td>intelia was founded in 2018, with a desire to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intelia has a unique technology partner ecosys...</td>\n",
       "      <td>In an increasingly fast-paced and competitive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>? Celebrating Excellence at intelia! ?</td>\n",
       "      <td>ast night, we came together as hashtag#onetrib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Direnc Uysal's linked-in post</td>\n",
       "      <td>Amidst the excitement surrounding Generative A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>intelia's post on 22rd december</td>\n",
       "      <td>As 2024 comes to a close, the intelia hashtag#...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                      intelia ethos   \n",
       "1  Migrating Data from Legacy Enterprise Data War...   \n",
       "2  Data is at our core. It's what we're passionat...   \n",
       "3  intelia has a unique technology partner ecosys...   \n",
       "4             ? Celebrating Excellence at intelia! ?   \n",
       "5                      Direnc Uysal's linked-in post   \n",
       "6                    intelia's post on 22rd december   \n",
       "\n",
       "                                             content  \n",
       "0  \\t\\n#delightthecustomer\\n\\nOur customers' succ...  \n",
       "1  Migrating data from a legacy on-prem data ware...  \n",
       "2  intelia was founded in 2018, with a desire to ...  \n",
       "3  In an increasingly fast-paced and competitive ...  \n",
       "4  ast night, we came together as hashtag#onetrib...  \n",
       "5  Amidst the excitement surrounding Generative A...  \n",
       "6  As 2024 comes to a close, the intelia hashtag#...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('testdata.csv',encoding='latin1')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4310a25-66e8-45b5-b6eb-5f0b9eca48e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import tempfile, shutil\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "from google.cloud import bigquery \n",
    "import os \n",
    "import gcsfs\n",
    "import pandas as pd\n",
    "\n",
    "def upload_file(request_file : tempfile,dest_bucket_name:str =None,request_file_folder: str =None,request_file_prefix: str =None, version: int=0, request_file_post_fix : str=\"\"):\n",
    "\n",
    "    \"\"\"upload file into gcs\n",
    "   \n",
    "        Args:\n",
    "            tempfile request_file: request file\n",
    "            str dest_bucket_name:  name of destination bucket\n",
    "            str request_file_folder: name of the destination folder name to write files to\n",
    "            list request_file_prefix: prefix of request file name\n",
    "          \n",
    "    \"\"\"\n",
    "\n",
    "    temp=request_file\n",
    "    client = storage.Client()\n",
    "    # Extract name to the temp file\n",
    "    temp_file = \"\".join([str(temp.name)])\n",
    "    # Uploading the temp image file to the bucket\n",
    "    dest_filename = f\"{request_file_folder}/\"+request_file_prefix+'_'+request_file_post_fix+'_'+str(version)+\".json\" \n",
    "    dest_bucket = client.get_bucket(dest_bucket_name)\n",
    "    dest_blob = dest_bucket.blob(dest_filename)\n",
    "    dest_blob.upload_from_filename(temp_file)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c9ea7f8-589b-4bc0-8d44-f3ab4383c15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intelia ethos</td>\n",
       "      <td>\\t\\n#delightthecustomer\\n\\nOur customers' succ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Migrating Data from Legacy Enterprise Data War...</td>\n",
       "      <td>Migrating data from a legacy on-prem data ware...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data is at our core. It's what we're passionat...</td>\n",
       "      <td>intelia was founded in 2018, with a desire to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intelia has a unique technology partner ecosys...</td>\n",
       "      <td>In an increasingly fast-paced and competitive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>? Celebrating Excellence at intelia! ?</td>\n",
       "      <td>ast night, we came together as hashtag#onetrib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Direnc Uysal's linked-in post</td>\n",
       "      <td>Amidst the excitement surrounding Generative A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>intelia's post on 22rd december</td>\n",
       "      <td>As 2024 comes to a close, the intelia hashtag#...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                      intelia ethos   \n",
       "1  Migrating Data from Legacy Enterprise Data War...   \n",
       "2  Data is at our core. It's what we're passionat...   \n",
       "3  intelia has a unique technology partner ecosys...   \n",
       "4             ? Celebrating Excellence at intelia! ?   \n",
       "5                      Direnc Uysal's linked-in post   \n",
       "6                    intelia's post on 22rd december   \n",
       "\n",
       "                                             content  \n",
       "0  \\t\\n#delightthecustomer\\n\\nOur customers' succ...  \n",
       "1  Migrating data from a legacy on-prem data ware...  \n",
       "2  intelia was founded in 2018, with a desire to ...  \n",
       "3  In an increasingly fast-paced and competitive ...  \n",
       "4  ast night, we came together as hashtag#onetrib...  \n",
       "5  Amidst the excitement surrounding Generative A...  \n",
       "6  As 2024 comes to a close, the intelia hashtag#...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "522a7ade-f64d-48fb-8cdf-8e76a74c0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=True) \n",
    "rf= open(request_file.name, \"a\") \n",
    "\n",
    "for idx,row in data.iterrows():\n",
    "    data_items=[ json.dumps( {  \"_id\": idx,\n",
    "                                \"title\":row['title'],\n",
    "                                 \"text\":row['content']                                          \n",
    "                               }\n",
    "                               )  +\"\\n\"\n",
    "                ]\n",
    "\n",
    "    rf.writelines(data_items)\n",
    "    rf.flush()\n",
    "upload_file(rf,dest_bucket_name='vlt_search_and_contet_output',request_file_folder='finetunning',request_file_prefix='fine_tuning_intelia_sample', version=0, request_file_post_fix ='0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "349d2d00-c38f-4f41-a0c0-6864670396b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries(model, title, text):\n",
    "\n",
    "    prompt = (f'You are a human being who is tasked with extracting some questions from a given text.\\n'\n",
    "    f'Think throughly when reading this text including both title and content. Think of questions may people ask to know more about a data consultancy called Intelia.\\n'\n",
    "    f'Suggest 1 to 5 short questions and 2-3 labels or short expressions that are important to ask when people want to explore who Intelia is and what it does. These expressions or questions should be optimized for fine tuning a text embedding model.\\n'    \n",
    "    f'Output each response on a separate line divided by a newline.\\n'\n",
    "    f'Here is the text:\\n'\n",
    "    f'\"title\": {title}\\n'\n",
    "    f'\"content\":{text}')\n",
    "    \n",
    "    responses = model.generate_content(prompt, stream=False)\n",
    "    return responses.text.split('\\n')\n",
    "\n",
    "\n",
    "def get_autorater_response(llm_model: str=\"gemini-1.5-pro\", title=\"\", text=\"\", query=\"\") -> dict:\n",
    "        \n",
    "        \"\"\"Extract evaluation metric on a AI-generated content using a AI-as-judge approach\n",
    "        \n",
    "        Args:\n",
    "        list metric_prompt: the input metric prompt parameters\n",
    "        str llm_model: evaluation model\n",
    "\n",
    "        Returns:\n",
    "        dict response_json: the evaluated metric in json format\n",
    "        \"\"\"\n",
    "            \n",
    "        # set evaluation metric schema\n",
    "        metric_response_schema = {\n",
    "            \"type\": \"OBJECT\",\n",
    "            \"properties\": {\n",
    "                \"score\": {\"type\": \"NUMBER\"},\n",
    "                \"explanation\": {\"type\": \"STRING\"},\n",
    "            },\n",
    "            \"required\": [\"score\", \"explanation\"],\n",
    "        }\n",
    "\n",
    "        #define a generative model as an autorator\n",
    "        autorater = GenerativeModel(\n",
    "            llm_model,\n",
    "            generation_config=GenerationConfig(\n",
    "                response_mime_type=\"application/json\",\n",
    "                response_schema=metric_response_schema,\n",
    "            ),\n",
    "            safety_settings={\n",
    "                HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        metric_prompt=  (f'You are a human being who is tasked with finding the answer of a given question within an aricle.\\n'\n",
    "                        f'Read the given question and analyse the given artcile to see if you can find the answer to the question within this aricle.\\n'\n",
    "                        f'Use this rating rubric to give a relevancy score for your analysis:\\n'\n",
    "                        f'\"Rating Rubric:\\n'\n",
    "                        f'0: No relevancy. The document has no connection to the question. It lacks relevant keywords, topics, or context. \\n'\n",
    "                        f'1: Low Relevance. The document contains some keywords but does not provide meaningful information related to the question. The context is weak or unrelated. \\n'\n",
    "                        f'2: Moderate Relevance. The document partially addresses the question but lacks completeness, clarity, or depth. It may require inference to extract an answer.\\n'\n",
    "                        f'3\tHigh Relevance. The document directly and clearly answers the question with specific, well-aligned information. Strong contextual alignment.\\n'\n",
    "\n",
    "                        f'Question:\\n'\n",
    "                        f'{query}\\n'                      \n",
    "                        f'Article:\\n'                    \n",
    "                        f'\"title\": {title}\\n'\n",
    "                        f'\"content\":{text}')\n",
    "    \n",
    "        #generate the rating metrics as per requested measures and metric in the prompt\n",
    "        response = autorater.generate_content(metric_prompt)\n",
    "\n",
    "        response_json = {}\n",
    "\n",
    "        if response.candidates and len(response.candidates) > 0:\n",
    "            candidate = response.candidates[0]\n",
    "            if (\n",
    "                candidate.content\n",
    "                and candidate.content.parts\n",
    "                and len(candidate.content.parts) > 0\n",
    "            ):\n",
    "                part = candidate.content.parts[0]\n",
    "                if part.text:\n",
    "                    response_json = json.loads(part.text)\n",
    "\n",
    "        return response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa7ed000-cd88-44f9-be97-66cffe40569b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"What is Intelia's core philosophy and how does it impact their approach to customer success?\", '', 'How does Intelia balance its focus on customer delight with the well-being of its employees?', '', 'What specific actions does Intelia take to foster a passionate and enjoyable work environment?', '', 'How does Intelia leverage diversity and collaboration to achieve its goals?', '', 'What sets Intelia apart from other data consultancies in the market?']\n",
      "\n",
      "['## Questions about Intelia:', '', '1. **What specific types of data migrations does Intelia specialize in?**', '', '2. **Does Intelia offer end-to-end data migration services, including planning, execution, and post-migration support?**', '', '3. **What cloud platforms is Intelia most experienced with and certified in?**', '', '4. **Can Intelia provide case studies or examples of successful data migration projects they have completed?**', '', \"5. **What is Intelia's pricing model for data migration services?**\"]\n",
      "\n",
      "['## Intelia: Key Questions', '', '1. **What specific data-driven opportunities does Intelia help its clients unlock?** ', '2. **Beyond data analysis, what other services does Intelia provide to its clients?**', \"3. **Can you elaborate on Intelia's unique approach to data consultancy?**\", '4. **How does Intelia tailor its services to address the specific challenges of each client?**', '5. **What are some examples of successful projects Intelia has completed for its clients?** ', '']\n",
      "\n",
      "['What types of businesses does Intelia typically work with?', 'What makes Intelia different from other cloud data platform providers?', \"How does Snowflake's cloud-first architecture benefit businesses?\", 'How can Intelia assist with planning a cloud or multi-cloud strategy? ', 'How does Intelia help clients focus on business value rather than data warehousing complexity']\n",
      "\n",
      "['## Questions about Intelia:', '', '1. What specific data consultancy services does Intelia offer?', '2. What kind of impact does Intelia make for its customers?', '3. How does Intelia foster a culture of innovation and excellence within its team?', \"4. What are Intelia's plans for the future, especially in the context of the evolving AI and data landscape?\", \"5. What are some examples of projects or achievements that demonstrate Intelia's expertise and success? \", '']\n",
      "\n",
      "['1. What specific data governance services does Intelia offer to help businesses succeed with their machine learning solutions? ', '2. How does Intelia ensure compliance and facilitate collaboration when implementing data governance strategies?', '3. Can Intelia provide examples of how they have helped businesses improve their data management and avoid the need for significant changes down the line?', '4. What are the key benefits of partnering with Intelia for data governance, particularly in the context of Generative AI adoption?', '5. Does Intelia offer tailored solutions for different industries or specific data-driven challenges? ', '']\n",
      "\n",
      "['- What services does Intelia provide?', \"- What are some of Intelia's major accomplishments in 2024?\", \"- What are some of Intelia's core values?\", \"- What are Intelia's goals for 2025?\", '- What is the meaning of the hashtag \"#onetribe\"?']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generated_queries=[]\n",
    "request_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=True) \n",
    "rf= open(request_file.name, \"a\") \n",
    "\n",
    "for idx,row in data.iterrows():\n",
    "    queries=generate_queries(model, row['title'], row['content']) \n",
    "    print(queries)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1b69b7da-870a-46d5-b1fd-5ed244397cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1=[\"What is Intelia's core philosophy and how does it impact their approach to customer success?\",  'How does Intelia balance its focus on customer delight with the well-being of its employees?',  'What specific actions does Intelia take to foster a passionate and enjoyable work environment?',  'How does Intelia leverage diversity and collaboration to achieve its goals?',  'What sets Intelia apart from other data consultancies in the market?']\n",
    "\n",
    "q2=['## Questions about Intelia:',  '1. **What specific types of data migrations does Intelia specialize in?**',  '2. **Does Intelia offer end-to-end data migration services, including planning, execution, and post-migration support?**',  '3. **What cloud platforms is Intelia most experienced with and certified in?**',  '4. **Can Intelia provide case studies or examples of successful data migration projects they have completed?**',  \"5. **What is Intelia's pricing model for data migration services?**\"]\n",
    "\n",
    "q3=['## Intelia: Key Questions',  '1. **What specific data-driven opportunities does Intelia help its clients unlock?** ', '2. **Beyond data analysis, what other services does Intelia provide to its clients?**', \"3. **Can you elaborate on Intelia's unique approach to data consultancy?**\", '4. **How does Intelia tailor its services to address the specific challenges of each client?**', '5. **What are some examples of successful projects Intelia has completed for its clients?** ']\n",
    "\n",
    "q4=['What types of businesses does Intelia typically work with?', 'What makes Intelia different from other cloud data platform providers?', \"How does Snowflake's cloud-first architecture benefit businesses?\", 'How can Intelia assist with planning a cloud or multi-cloud strategy? ', 'How does Intelia help clients focus on business value rather than data warehousing complexity']\n",
    "\n",
    "q5=['## Questions about Intelia:',  '1. What specific data consultancy services does Intelia offer?', '2. What kind of impact does Intelia make for its customers?', '3. How does Intelia foster a culture of innovation and excellence within its team?', \"4. What are Intelia's plans for the future, especially in the context of the evolving AI and data landscape?\", \"5. What are some examples of projects or achievements that demonstrate Intelia's expertise and success? \"]\n",
    "\n",
    "q6=['1. What specific data governance services does Intelia offer to help businesses succeed with their machine learning solutions? ', '2. How does Intelia ensure compliance and facilitate collaboration when implementing data governance strategies?', '3. Can Intelia provide examples of how they have helped businesses improve their data management and avoid the need for significant changes down the line?', '4. What are the key benefits of partnering with Intelia for data governance, particularly in the context of Generative AI adoption?', '5. Does Intelia offer tailored solutions for different industries or specific data-driven challenges? ', '']\n",
    "\n",
    "q7=['- What services does Intelia provide?', \"- What are some of Intelia's major accomplishments in 2024?\", \"- What are some of Intelia's core values?\", \"- What are Intelia's goals for 2025?\", '- What is the meaning of the hashtag \"#onetribe\"?']\n",
    "\n",
    "queries=q1+q2+q3+q4+q5+q6+q7\n",
    "\n",
    "qid=0\n",
    "for query in queries:\n",
    "        if query!=\"\":\n",
    "            generated_queries=[ json.dumps( {  \"_id\": qid,  \n",
    "                                               \"text\":query                                      \n",
    "                                         }\n",
    "                                       )  +\"\\n\"\n",
    "                        ]\n",
    "        \n",
    "            rf.writelines(generated_queries)\n",
    "            rf.flush()\n",
    "            qid +=1\n",
    "\n",
    "upload_file(rf,dest_bucket_name='vlt_search_and_contet_output',request_file_folder='finetunning',request_file_prefix='fine_tuning_query_sample', version=0, request_file_post_fix ='0')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8fb2d8-4c72-4e9f-a1bc-0dd9ad1a639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in queries:\n",
    "    for idx,row in data.iterrows():\n",
    "        get_autorater_response(data[''itle=\"\", text=\"\", query=\"\") -> dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5abeb-5e4b-4902-b6c4-157b624cd601",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a7df16-3611-4acc-b31b-23635a4503b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_query_embeddings = torch.Tensor(np.array(adapter_query_embeddings))\n",
    "adapter_doc_embeddings = torch.Tensor(np.array(adapter_doc_embeddings))\n",
    "adapter_labels = torch.Tensor(np.expand_dims(np.array(adapter_labels),1))\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(adapter_query_embeddings, adapter_doc_embeddings, adapter_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e88eb5-4d9d-484f-bab1-b246b71d2ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(query_embedding, document_embedding, adaptor_matrix):\n",
    "    updated_query_embedding = torch.matmul(adaptor_matrix, query_embedding)\n",
    "    return torch.cosine_similarity(updated_query_embedding, document_embedding, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99599aa-385b-49c9-9f88-0b4ba4d0b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(query_embedding, document_embedding, adaptor_matrix, label):\n",
    "    return torch.nn.MSELoss()(model(query_embedding, document_embedding, adaptor_matrix), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c4edbc-5a30-4552-9ff5-788a55827f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_size = len(adapter_query_embeddings[0])\n",
    "adapter_matrix = torch.randn(mat_size, mat_size, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332104e3-1aea-4b48-992a-df47f936c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = float('inf')\n",
    "best_matrix = None\n",
    "\n",
    "for epoch in tqdm(range(100)):\n",
    "    for query_embedding, document_embedding, label in dataset:\n",
    "        loss = mse_loss(query_embedding, document_embedding, adapter_matrix, label)\n",
    "\n",
    "        if loss < min_loss:\n",
    "            min_loss = loss\n",
    "            best_matrix = adapter_matrix.clone().detach().numpy()\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            adapter_matrix -= 0.01 * adapter_matrix.grad\n",
    "            adapter_matrix.grad.zero_()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd04549d-2660-4a44-9c4c-53be1d245915",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best loss: {min_loss.detach().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778e589a-1bef-46a8-8c5a-a9bb67c354cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vector = torch.ones((mat_size,1))\n",
    "scaled_vector = np.matmul(best_matrix, test_vector).numpy()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
