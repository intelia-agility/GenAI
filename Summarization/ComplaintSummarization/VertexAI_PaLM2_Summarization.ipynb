{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf6f0251-1ba6-40cd-b860-80e1d22373dd",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# POC for complaint summarization\n",
    "\n",
    "source code for a quick POC for exploring the PaLM2 Vertex AI LLM for summarizing complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2568734d-a759-4da1-b958-05875d03c505",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface-hub\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (2024.7.4)\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface-hub\n",
      "Successfully installed huggingface-hub-0.26.2\n",
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.3.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.3.15)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.129)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.24.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain) (3.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.0)\n",
      "Collecting SentencePiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: SentencePiece\n",
      "Successfully installed SentencePiece-0.2.0\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.46.1-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n",
      "Downloading transformers-4.46.1-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, tokenizers, transformers\n",
      "Successfully installed safetensors-0.4.5 tokenizers-0.20.1 transformers-4.46.1\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface-hub\n",
    "!pip install langchain\n",
    "!pip install SentencePiece\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e071e32b-f459-4b90-b681-115c5602e0a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########### IMPORT HFACE PIPELINE FROM LANGCHAIN AND SUMMARIZE CHAIN ################\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import VertexAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pandas as pd\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a93935f-676c-4315-9465-d48412e91a14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.vertexai.VertexAI` was deprecated in langchain-community 0.0.12 and will be removed in 0.2.0. An updated version of the class exists in the langchain-google-vertexai package and should be used instead. To use it run `pip install -U langchain-google-vertexai` and import as `from langchain_google_vertexai import VertexAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "#define Palm2 vertex AI\n",
    "llm = VertexAI(model_name='text-bison@001',batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d69f594-3106-408f-9b97-db521664fd58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set prompt template\n",
    "prompt_template =\"\"\"\n",
    "summarize the given text by high lighting most important information\n",
    "\n",
    "{text}\n",
    "\n",
    "Summary:\n",
    "    \"\"\"\n",
    "\n",
    "#define prompt template\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "#define chain with a map_reduce type\n",
    "chain = load_summarize_chain(llm, map_prompt=prompt, combine_prompt=prompt, verbose=True,chain_type=\"map_reduce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "832f3168-8497-4972-9eff-034a6b446327",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read data\n",
    "#I am reading data from my local repo\n",
    "df_complaints=pd.read_csv('../data/complaints.csv',low_memory=False)\n",
    "desc_col='Consumer complaint narrative'\n",
    "df_complaints=df_complaints[~df_complaints[desc_col].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5879bb1d-efec-44d5-a5a5-308c0e90471b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# define text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 1000,#set this for chunking texts\n",
    "    chunk_overlap  = 40,\n",
    "    length_function = len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccc188bd-b43a-40c7-ba9c-f230ce626d96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    " def split_doc(text_splitter,doc):\n",
    "    \"\"\"\n",
    "    function to split an input document using Langchain\n",
    "    Args:\n",
    "        text_splitter: a langchain text splitter\n",
    "        doc: string text\n",
    "    Output:\n",
    "        texts: a dictionary of splitted text\n",
    "    \"\"\"\n",
    "    texts = text_splitter.create_documents([doc])\n",
    "\n",
    "    return texts\n",
    "\n",
    "def summarize_docs(llm_chain,docs):\n",
    "    \"\"\"\n",
    "    function to summarize chunked documents\n",
    "    Args:\n",
    "        llm_chain: a langchain summarize chain\n",
    "        docs: chunked documents\n",
    "    Output:\n",
    "        summaries: list of summarized documents\n",
    "    \"\"\"\n",
    "    #summarize all chunks in one go\n",
    "    summary = llm_chain.batch(docs)\n",
    "\n",
    "    summaries=[]\n",
    "    #extract summaries\n",
    "    for summarized_doc in summary:\n",
    "        summaries.append(summarized_doc['output_text'])\n",
    "\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2cc1b0e3-9346-4bc0-842a-71498070921b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "summarize the given text by high lighting most important information\n",
      "\n",
      "Zions Debt Holdings has posted a collection action on my credit report with respect to an alleged debt owed in connection with an account I previously had with years ago ( Account Number ) That account was cancelled in ( in accordance with the terms of the agreement with ) and at the time of cancellation no amounts were owed. I supplied all of this information ( and more ) to Zions, including a copy of both the agreement I had with showing my right to cancel ) and a copy of the cancellation letter I sent to I have also disputed this account with times already. However, in each case Zions continued to allege that the subject collection action was valid without suppling any supporting information whatsoever ; either to me or to I\n",
      "\n",
      "Summary:\n",
      "    \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "summarize the given text by high lighting most important information\n",
      "\n",
      "Zions Debt Holdings has posted a collection action on my credit report.\n",
      "     The debt is for an account I had with years ago.\n",
      "     The account was cancelled in accordance with the terms of the agreement.\n",
      "     I supplied all of this information to Zions.\n",
      "     I have disputed the account with times already.\n",
      "     Zions continued to allege that the subject collection action was valid.\n",
      "\n",
      "Summary:\n",
      "    \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "[{'input_documents': [Document(page_content='Zions Debt Holdings has posted a collection action on my credit report with respect to an alleged debt owed in connection with an account I previously had with years ago ( Account Number ) That account was cancelled in ( in accordance with the terms of the agreement with ) and at the time of cancellation no amounts were owed. I supplied all of this information ( and more ) to Zions, including a copy of both the agreement I had with showing my right to cancel ) and a copy of the cancellation letter I sent to I have also disputed this account with times already. However, in each case Zions continued to allege that the subject collection action was valid without suppling any supporting information whatsoever ; either to me or to I')], 'output_text': 'Zions Debt Holdings has posted a collection action on my credit report.\\n     The debt is for an account I had with years ago.\\n     The account was cancelled in accordance with the terms of the agreement.\\n     I have disputed the account with times already.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_3559/3063748425.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_complaints['complaint_summary']= summarize_docs(chain,list(splitted_texts))\n"
     ]
    }
   ],
   "source": [
    "#split all complaints\n",
    "splitted_texts=df_complaints[desc_col].apply(lambda doc: split_doc(text_splitter,doc) )\n",
    "\n",
    "#summarize splited complaints\n",
    "df_complaints['complaint_summary']= summarize_docs(chain,list(splitted_texts))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
