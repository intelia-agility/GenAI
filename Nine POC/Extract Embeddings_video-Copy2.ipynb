{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a354f9-0984-4c94-9042-efb28db5f4be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.58.0)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.59.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (2.14.0)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.17.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.31.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.19.6)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (24.1)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.25.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.12.3)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.4)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.10.17)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.7.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.32.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.1)\n",
      "INFO: pip is looking at multiple versions of google-api-core[grpc] to determine which version is compatible with other requirements. This could take a while.\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.7)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.7.4)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
      "Downloading google_cloud_aiplatform-1.59.0-py2.py3-none-any.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-2.17.0-py2.py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: google-api-core, google-cloud-storage, google-cloud-aiplatform\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 1.34.1\n",
      "    Uninstalling google-api-core-1.34.1:\n",
      "      Successfully uninstalled google-api-core-1.34.1\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.14.0\n",
      "    Uninstalling google-cloud-storage-2.14.0:\n",
      "      Successfully uninstalled google-cloud-storage-2.14.0\n",
      "  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 1.58.0\n",
      "    Uninstalling google-cloud-aiplatform-1.58.0:\n",
      "      Successfully uninstalled google-cloud-aiplatform-1.58.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.19.1 which is incompatible.\n",
      "google-cloud-pubsub 2.21.4 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.48.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-api-core-2.11.1 google-cloud-aiplatform-1.59.0 google-cloud-storage-2.17.0\n",
      "Requirement already satisfied: google-cloud-vision in /opt/conda/lib/python3.10/site-packages (3.7.2)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2.11.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-vision) (2.31.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-vision) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-vision) (3.19.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.63.1)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.48.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (4.9)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "# Install the packages\n",
    "! pip3 install --upgrade google-cloud-aiplatform \\\n",
    "                         google-cloud-storage\n",
    "\n",
    "# Install the packages\n",
    "! pip install google-cloud-vision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895e40a3-1749-4b68-ac38-7e001f32a101",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-videointelligence in /opt/conda/lib/python3.10/site-packages (1.16.3)\n",
      "Collecting google-cloud-videointelligence\n",
      "  Downloading google_cloud_videointelligence-2.13.4-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2.11.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-videointelligence) (2.31.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-videointelligence) (1.24.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 (from google-cloud-videointelligence)\n",
      "  Downloading protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.63.1)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.48.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (4.9)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2024.7.4)\n",
      "Downloading google_cloud_videointelligence-2.13.4-py2.py3-none-any.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.0/245.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf, google-cloud-videointelligence\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: google-cloud-videointelligence\n",
      "    Found existing installation: google-cloud-videointelligence 1.16.3\n",
      "    Uninstalling google-cloud-videointelligence-1.16.3:\n",
      "      Successfully uninstalled google-cloud-videointelligence-1.16.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "apache-beam 2.46.0 requires grpcio!=1.48.0,<2,>=1.33.1, but you have grpcio 1.48.0 which is incompatible.\n",
      "apache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.11.1 which is incompatible.\n",
      "google-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-datastore 1.15.5 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-language 1.3.2 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-pubsub 2.21.4 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.48.0 which is incompatible.\n",
      "google-cloud-storage 2.17.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 2.11.1 which is incompatible.\n",
      "kfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.3 which is incompatible.\n",
      "kfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorboardx 2.6 requires protobuf<4,>=3.8.0, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-serving-api 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-cloud-videointelligence-2.13.4 protobuf-3.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-videointelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70639287-6593-462f-a952-cfa0605b29dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8162339b-0555-46c0-8271-a26fe9fe99a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set project info\n",
    "PROJECT = !gcloud config get-value project\n",
    "PROJECT_ID = PROJECT[0]\n",
    "REGION = \"us-central1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fb72555-1765-496b-ad6a-d8c7d3aff330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "video_directory = \"SampleVideo\"\n",
    "\n",
    "video_names=[]\n",
    "for file_name in os.listdir(video_directory):\n",
    "    if  not file_name.startswith('.'):\n",
    "        video_names.append(file_name)\n",
    "\n",
    "video_paths = [os.path.join(video_directory, video_name) for video_name in video_names]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6125a26-9f33-4c17-bd52-657233921201",
   "metadata": {},
   "source": [
    "### Define function to detect explicit images\n",
    "\n",
    "enable clound vision api before running this bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b070ae5-1f9e-430f-9fda-9e01bcee82b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.cloud.videointelligence.v1beta import SafeSearchAnnotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43fd0fed-43ad-4679-a484-5ee18231b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this has not been testes\n",
    "from google.cloud import videointelligence\n",
    "\n",
    "def analyze_video_safe_search(gcs_uri):\n",
    "    client = videointelligence.VideoIntelligenceServiceClient()\n",
    "    \n",
    "    # Configure the request\n",
    "    config = videointelligence.SafeSearchDetectionConfig()\n",
    "    context = videointelligence.VideoContext(\n",
    "        safe_search_detection_config=config\n",
    "    )\n",
    "    operation = client.annotate_video(\n",
    "        request={\"input_uri\": gcs_uri, \"features\": [videointelligence.Feature.SAFE_SEARCH_DETECTION], \"video_context\": context}\n",
    "    )\n",
    "    \n",
    "    # Wait for the operation to complete\n",
    "    result = operation.result(timeout=180)\n",
    "    \n",
    "    # Process the result\n",
    "    annotation_results = result.annotation_results[0]\n",
    "    for frame in annotation_results.safe_search_annotations:\n",
    "        print(f\"Time offset: {frame.time_offset.seconds}.{frame.time_offset.nanos // 1000000}s\")\n",
    "        print(f\"Adult: {videointelligence.Likelihood(frame.adult)}\")\n",
    "        print(f\"Violence: {videointelligence.Likelihood(frame.violence)}\")\n",
    "        print(f\"Racy: {videointelligence.Likelihood(frame.racy)}\")\n",
    "        print(f\"Medical: {videointelligence.Likelihood(frame.medical)}\")\n",
    "        print(f\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4839766e-611a-4f1b-b7eb-9f4ab6c03f41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for now the api is not active just to save costs. I set everything to true\n",
    "is_safe_values_cloud_vision=[True for i in range (len(video_paths))]\n",
    "is_safe_values_cloud_vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f555e1b5-65f5-4afb-a36b-d00a43d174f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter images by safety\n",
    "video_names = [\n",
    "    video_name\n",
    "    for video_name, is_safe in zip(video_names, is_safe_values_cloud_vision)\n",
    "    if is_safe\n",
    "]\n",
    "video_paths = [\n",
    "    video_path\n",
    "    for video_path, is_safe in zip(video_paths, is_safe_values_cloud_vision)\n",
    "    if is_safe\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a501aa-a4d2-4971-b0db-56de6cee03f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"contents\": {\n",
    "    \"role\": \"USER\",\n",
    "    \"parts\": [\n",
    "      {\n",
    "        \"fileData\": {\n",
    "          \"fileUri\": \"FILE_URI1\",\n",
    "          \"mimeType\": \"MIME_TYPE\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"TEXT1\"\n",
    "      },\n",
    "      {\n",
    "        \"fileData\": {\n",
    "          \"fileUri\": \"FILE_URI2\",\n",
    "          \"mimeType\": \"MIME_TYPE\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"TEXT2\"\n",
    "      },\n",
    "      {\n",
    "        \"fileData\": {\n",
    "          \"fileUri\": \"FILE_URI3\",\n",
    "          \"mimeType\": \"MIME_TYPE\"\n",
    "        }\n",
    "      },\n",
    "        \n",
    "        \"videoMetadata\": {\n",
    "            \"startOffset\": {\n",
    "              \"seconds\": integer,\n",
    "              \"nanos\": integer\n",
    "            },\n",
    "            \"endOffset\": {\n",
    "              \"seconds\": integer,\n",
    "              \"nanos\": integer\n",
    "            }\n",
    "        }\n",
    "            \n",
    "            \n",
    "    ]\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0ab397c-3dd3-4012-b502-f331fdc6d998",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'You are an assistant tasked with summarizing videos for retrieval.         These summaries will be embedded and used to retrieve the raw video.         Give a concise summary of the video that is well optimized for retrieval.',\n",
       " 'fileData': {'fileUri': 'gs://github-repo/embeddings/getting_started_embeddings/UCF-101-subset/BrushingTeeth/v_BrushingTeeth_g01_c02.mp4',\n",
       "  'mimeType': 'video/MP4'},\n",
       " 'videoMetadata': {'startOffset': {'seconds': 0, 'nanos': 0},\n",
       "  'endOffset': {'seconds': 4, 'nanos': 0}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e69ccea-7f02-46d8-999e-b745a70720f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " safety_settings = {\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1aa8899-e810-4958-98f9-86535108e40c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<HarmCategory.HARM_CATEGORY_HATE_SPEECH: 1>: <HarmBlockThreshold.BLOCK_ONLY_HIGH: 3>,\n",
       " <HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 2>: <HarmBlockThreshold.BLOCK_ONLY_HIGH: 3>,\n",
       " <HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 4>: <HarmBlockThreshold.BLOCK_ONLY_HIGH: 3>,\n",
       " <HarmCategory.HARM_CATEGORY_HARASSMENT: 3>: <HarmBlockThreshold.BLOCK_ONLY_HIGH: 3>}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "safety_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43093e8e-bd03-42f6-86c9-0cddf6022d93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7844fbf9-4ca1-40a1-ba14-8536cabd4bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "text= \"\"\"You are an assistant tasked with summarizing videos for retrieval. \\\n",
    "        These summaries will be embedded and used to retrieve the raw video. \\\n",
    "        Give a concise summary of the video for the given videometadata that is well optimized for retrieval.\"\"\"\n",
    "video_file=\"gs://cloud-samples-data/vertex-ai-vision/highway_vehicles.mp4\"\n",
    "if 1==1:\n",
    " \n",
    "        # Load video file\n",
    "        video_bytes = None\n",
    " \n",
    "\n",
    "        instance ={}\n",
    "        items={}\n",
    "       \n",
    "        items[\"role\"]= \"USER\"\n",
    "        if text:\n",
    "            items[\"text\"]= text\n",
    "\n",
    "        if video_file:             \n",
    "            items[\"fileData\"]= {\n",
    "                          \"fileUri\": video_file,\n",
    "                          \"mimeType\": \"video/MP4\"\n",
    "                        }\n",
    "            items[\"videoMetadata\"]= {\n",
    "\n",
    "                                \"startOffset\": {\n",
    "                                  \"seconds\": 0,\n",
    "                                  \"nanos\": 0\n",
    "                                },\n",
    "                                \"endOffset\": {\n",
    "                                  \"seconds\": 4,\n",
    "                                  \"nanos\": 0\n",
    "                                }\n",
    "            }\n",
    "            #as the files are incomplete, for now set it fix\n",
    "            video_duration=120\n",
    "            instance={}\n",
    "            instance[\"contents\"]={\"role\":\"USER\",\n",
    "\n",
    "                                  \"Parts\":[items],\n",
    "\n",
    "\n",
    "              \"generationConfig\": {\n",
    "                \"temperature\": 1,\n",
    "                \"topP\": 0.95, \n",
    "                \"maxOutputTokens\": 8192 \n",
    "              }\n",
    "            }\n",
    "\n",
    "          \n",
    "\n",
    "        endpoint = (\n",
    "           f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "           \"/publishers/google/models/gemini-1.5-flash@001\"\n",
    "        )\n",
    "\n",
    "        #response =self.client.predict(endpoint=endpoint, instances=instances)\n",
    "#client.predict(endpoint=endpoint, instances=instances)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44858b9b-3377-4cc9-a162-b121ff8252d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/nine-quality-test/locations/us-central1/publishers/google/models/gemini-1.5-flash@001'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "021d559a-836a-4886-a5ce-64a38de888b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = aiplatform.gapic.PredictionServiceClient  (\n",
    "            client_options=client_options\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ad32535-21b1-4c74-a631-3119cc973a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PredictionServiceClient.stream_generate_content() got an unexpected keyword argument 'endpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 13\u001b[0m\n\u001b[1;32m      6\u001b[0m client_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_endpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: api_regional_endpoint}\n\u001b[1;32m      8\u001b[0m client \u001b[38;5;241m=\u001b[39m aiplatform\u001b[38;5;241m.\u001b[39mgapic\u001b[38;5;241m.\u001b[39mPredictionServiceClient  (\n\u001b[1;32m      9\u001b[0m             client_options\u001b[38;5;241m=\u001b[39mclient_options\n\u001b[1;32m     10\u001b[0m         )\n\u001b[0;32m---> 13\u001b[0m response \u001b[38;5;241m=\u001b[39m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_generate_content\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: PredictionServiceClient.stream_generate_content() got an unexpected keyword argument 'endpoint'"
     ]
    }
   ],
   "source": [
    "endpoint = (\n",
    "           f\"projects/{PROJECT_ID}/locations/us-central1/publishers/google/models/gemini-1.5-flash-001\"\n",
    "        )\n",
    "    \n",
    "api_regional_endpoint= \"us-central1-aiplatform.googleapis.com\" \n",
    "client_options = {\"api_endpoint\": api_regional_endpoint}\n",
    "        \n",
    "client = aiplatform.gapic.PredictionServiceClient  (\n",
    "            client_options=client_options\n",
    "        )\n",
    "    \n",
    "\n",
    "response =client.stream_generate_content (endpoint=endpoint, parts=[instance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "615fe893-1ba7-4846-ae50-63f6eda82fea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'A list of comic book recommendations',\n",
       " 'startOffset': 'decimal',\n",
       " 'endOffset': 'decimal',\n",
       " 'chapterSummary': 'string'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2c1214d6-0d71-4086-814f-491bf2a20437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "schema = '''\n",
    "{\n",
    "  \"description\": \"A list of chapters\",\n",
    "  \"type\": \"array\",\n",
    "  \"items\": {\n",
    "\t\"type\":\"object\",\n",
    "\t\"properties\": {\n",
    "\t\t\"startOffset\": {\n",
    "\t\t\t\"type\":\"integer\"\n",
    "\t\t},\n",
    "\t\t\"endOffset\": {\n",
    "\t\t\t\"type\":\"integer\"\n",
    "\t\t},\n",
    "\t\t\"chapterSummary\": {\n",
    "\t\t\t\"type\":\"string\"\n",
    "\t\t}\n",
    "\t},\n",
    "\t\"required\": [\"startOffset\",\"endOffset\",\"chapterSummary\" ]\n",
    "  }\n",
    "}\n",
    "'''\n",
    " \n",
    "\n",
    "g=GenerationConfig(temperature=1, top_k=40,top_p=0.95,max_output_tokens=8192, response_mime_type='application/json',\n",
    "\tresponse_schema=json.loads(schema)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c415c293-ab1c-442b-912c-213c6b7ec4c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 120, 'end': 120}\n",
      "{'start': 120, 'end': 240}\n",
      "{'start': 240, 'end': 360}\n",
      "{'start': 360, 'end': 480}\n",
      "{'start': 480, 'end': 600}\n"
     ]
    }
   ],
   "source": [
    "segments_to_process=120\n",
    "intervals=16\n",
    "video_duration=10*60\n",
    "val=0\n",
    "\n",
    "for val in range (segments_to_process,video_duration+segments_to_process,segments_to_process):\n",
    "                offset={'start':prev, 'end':val}\n",
    "                prev=val    \n",
    "                print(offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2612b078-2278-47cf-a970-a8293ac7d96b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 0, 'end': 120}\n",
      "getting summaries..\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n},\\n{\\n  \\\"startOffset\\\": 0,\\n  \\\"endOffset\\\": 16,\\n  \\\"chapterSummary\\\": \\\"A woman in a sparkling dress walks down a marble stairway.\\\"\\n},\\n{\\n  \\\"startOffset\\\": 16,\\n  \\\"endOffset\\\": 32,\\n  \\\"chapterSummary\\\": \\\"A woman in a green shirt talks about being abused by a man and about her role in bringing him to justice.\\\"\\n},\\n{\\n  \\\"startOffset\\\": 32,\\n  \\\"endOffset\\\": 48,\\n  \\\"chapterSummary\\\": \\\"A man with tattoos and beard talks about his work and how Madeline West, an Australian actress, got her abuser put behind bars.\\\"\\n},\\n{\\n  \\\"startOffset\\\": 48,\\n  \\\"endOffset\\\": 64,\\n  \\\"chapterSummary\\\": \\\"Donald Trump, a politician, walks among supporters, raising a clenched fist.  He is famous for being president of the United States.\\\"\\n},\\n{\\n  \\\"startOffset\\\": 64,\\n  \\\"endOffset\\\": 80,\\n  \\\"chapterSummary\\\": \\\"A man with grey hair and a beard talks about how Peter White, a plumber,  was a predator in a sleepy town.\\\"\\n},\\n{\\n  \\\"startOffset\\\": 80,\\n  \\\"endOffset\\\": 96,\\n  \\\"chapterSummary\\\": \\\"Madeline West and an interviewer walk down a street and discuss how she was abused by a man when she was a child.\\\"\\n},\\n{\\n  \\\"startOffset\\\": 96,\\n  \\\"endOffset\\\": 112,\\n  \\\"chapterSummary\\\": \\\"Madeline West talks about the abuse she suffered as a child and how she didn\\'t tell anyone until she was a teenager.\\\"\\n},\\n{\\n  \\\"startOffset\\\": 112,\\n  \\\"endOffset\\\": 120,\\n  \\\"chapterSummary\\\": \\\"A man with tattoos and a beard talks about his work and how Madeleine West and her friend Amanda Lee went to police. Amanda Lee also suffered abuse by the same man.\\\"\\n}\\n]\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.178239584\n",
      "    severity: HARM_SEVERITY_LOW\n",
      "    severity_score: 0.231614232\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.189971507\n",
      "    severity: HARM_SEVERITY_LOW\n",
      "    severity_score: 0.240061253\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: LOW\n",
      "    probability_score: 0.553776801\n",
      "    severity: HARM_SEVERITY_MEDIUM\n",
      "    severity_score: 0.418162197\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: LOW\n",
      "    probability_score: 0.369883925\n",
      "    severity: HARM_SEVERITY_MEDIUM\n",
      "    severity_score: 0.424829543\n",
      "  }\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 851372\n",
      "  candidates_token_count: 580\n",
      "  total_token_count: 851952\n",
      "}\n",
      "\n",
      "**********\n",
      "['{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n  \"startOffset\": 0,\\n  \"endOffset\": 16,\\n  \"chapterSummary\": \"A woman in a sparkling dress walks down a marble stairway.\"\\n}', '{\\n  \"startOffset\": 16,\\n  \"endOffset\": 32,\\n  \"chapterSummary\": \"A woman in a green shirt talks about being abused by a man and about her role in bringing him to justice.\"\\n}', '{\\n  \"startOffset\": 32,\\n  \"endOffset\": 48,\\n  \"chapterSummary\": \"A man with tattoos and beard talks about his work and how Madeline West, an Australian actress, got her abuser put behind bars.\"\\n}', '{\\n  \"startOffset\": 48,\\n  \"endOffset\": 64,\\n  \"chapterSummary\": \"Donald Trump, a politician, walks among supporters, raising a clenched fist.  He is famous for being president of the United States.\"\\n}', '{\\n  \"startOffset\": 64,\\n  \"endOffset\": 80,\\n  \"chapterSummary\": \"A man with grey hair and a beard talks about how Peter White, a plumber,  was a predator in a sleepy town.\"\\n}', '{\\n  \"startOffset\": 80,\\n  \"endOffset\": 96,\\n  \"chapterSummary\": \"Madeline West and an interviewer walk down a street and discuss how she was abused by a man when she was a child.\"\\n}', '{\\n  \"startOffset\": 96,\\n  \"endOffset\": 112,\\n  \"chapterSummary\": \"Madeline West talks about the abuse she suffered as a child and how she didn\\'t tell anyone until she was a teenager.\"\\n}', '{\\n  \"startOffset\": 112,\\n  \"endOffset\": 120,\\n  \"chapterSummary\": \"A man with tattoos and a beard talks about his work and how Madeleine West and her friend Amanda Lee went to police. Amanda Lee also suffered abuse by the same man.\"\\n}']\n",
      "\n",
      "\n",
      "hereh are you chapters:\n",
      "\n",
      "[{'startOffset': '0', 'endOffset': '16', 'chapterSummary': 'A woman in a sparkling dress walks down a marble stairway.'}, {'startOffset': '16', 'endOffset': '32', 'chapterSummary': 'A woman in a green shirt talks about being abused by a man and about her role in bringing him to justice.'}, {'startOffset': '32', 'endOffset': '48', 'chapterSummary': 'A man with tattoos and beard talks about his work and how Madeline West, an Australian actress, got her abuser put behind bars.'}, {'startOffset': '48', 'endOffset': '64', 'chapterSummary': 'Donald Trump, a politician, walks among supporters, raising a clenched fist.  He is famous for being president of the United States.'}, {'startOffset': '64', 'endOffset': '80', 'chapterSummary': 'A man with grey hair and a beard talks about how Peter White, a plumber,  was a predator in a sleepy town.'}, {'startOffset': '80', 'endOffset': '96', 'chapterSummary': 'Madeline West and an interviewer walk down a street and discuss how she was abused by a man when she was a child.'}, {'startOffset': '96', 'endOffset': '112', 'chapterSummary': \"Madeline West talks about the abuse she suffered as a child and how she didn't tell anyone until she was a teenager.\"}, {'startOffset': '112', 'endOffset': '120', 'chapterSummary': 'A man with tattoos and a beard talks about his work and how Madeleine West and her friend Amanda Lee went to police. Amanda Lee also suffered abuse by the same man.'}]\n",
      "{'start': 120, 'end': 240}\n",
      "getting summaries..\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n},\\n{\\n  \\\"startOffset\\\": 120,\\n  \\\"endOffset\\\": 136,\\n  \\\"chapterSummary\\\": \\\"A woman talks about her experience with a pedophile who was her neighbor. She says the abuse started when she was 4.5 years old and continued until she was 10. \\\"\\n},\\n{\\n  \\\"startOffset\\\": 136,\\n  \\\"endOffset\\\": 152,\\n  \\\"chapterSummary\\\": \\\"The woman talks about the pedophile who was her neighbor. She says he was well-loved by everyone in town. She says her parents were young and didn\\'t know what to do.\\\"\\n},\\n{\\n  \\\"startOffset\\\": 152,\\n  \\\"endOffset\\\": 168,\\n  \\\"chapterSummary\\\": \\\"A detective who worked tirelessly on the pedophile case talks about why he took the risk of having the woman wear a hidden recording device.\\\"\\n},\\n{\\n  \\\"startOffset\\\": 168,\\n  \\\"endOffset\\\": 184,\\n  \\\"chapterSummary\\\": \\\"The woman who was abused by the pedophile talks about the recordings they made of him, which were used in the case against him.\\\"\\n},\\n{\\n  \\\"startOffset\\\": 184,\\n  \\\"endOffset\\\": 200,\\n  \\\"chapterSummary\\\": \\\"\\\"\\n},\\n{\\n  \\\"startOffset\\\": 200,\\n  \\\"endOffset\\\": 216,\\n  \\\"chapterSummary\\\": \\\"A woman talks about the recording device they made of the pedophile who was her neighbor. She says the pedophile would say, \\\\\\\"Please, please forgive me, for the stuff I don\\'t remember that I did. I\\'m very very sorry, if I did.\\\\\\\" \\\"\\n},\\n{\\n  \\\"startOffset\\\": 216,\\n  \\\"endOffset\\\": 232,\\n  \\\"chapterSummary\\\": \\\"The woman talks about her neighbor who was a pedophile and the impact that the abuse had on her. She says that she almost died from starving herself because of the abuse and shame. \\\"\\n},\\n{\\n  \\\"startOffset\\\": 232,\\n  \\\"endOffset\\\": 240,\\n  \\\"chapterSummary\\\": \\\"A woman talks about her experience with the pedophile who was her neighbor. She says she and her friend both went to the police independently.\\\"\\n}\\n]\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.169543326\n",
      "    severity: HARM_SEVERITY_LOW\n",
      "    severity_score: 0.23022674\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.198529914\n",
      "    severity: HARM_SEVERITY_LOW\n",
      "    severity_score: 0.23353152\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: LOW\n",
      "    probability_score: 0.553837061\n",
      "    severity: HARM_SEVERITY_MEDIUM\n",
      "    severity_score: 0.415195197\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: LOW\n",
      "    probability_score: 0.377196461\n",
      "    severity: HARM_SEVERITY_MEDIUM\n",
      "    severity_score: 0.424769819\n",
      "  }\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 851374\n",
      "  candidates_token_count: 650\n",
      "  total_token_count: 852024\n",
      "}\n",
      "\n",
      "**********\n",
      "['{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n  \"startOffset\": 120,\\n  \"endOffset\": 136,\\n  \"chapterSummary\": \"A woman talks about her experience with a pedophile who was her neighbor. She says the abuse started when she was 4.5 years old and continued until she was 10. \"\\n}', '{\\n  \"startOffset\": 136,\\n  \"endOffset\": 152,\\n  \"chapterSummary\": \"The woman talks about the pedophile who was her neighbor. She says he was well-loved by everyone in town. She says her parents were young and didn\\'t know what to do.\"\\n}', '{\\n  \"startOffset\": 152,\\n  \"endOffset\": 168,\\n  \"chapterSummary\": \"A detective who worked tirelessly on the pedophile case talks about why he took the risk of having the woman wear a hidden recording device.\"\\n}', '{\\n  \"startOffset\": 168,\\n  \"endOffset\": 184,\\n  \"chapterSummary\": \"The woman who was abused by the pedophile talks about the recordings they made of him, which were used in the case against him.\"\\n}', '{\\n  \"startOffset\": 184,\\n  \"endOffset\": 200,\\n  \"chapterSummary\": \"\"\\n}', '{\\n  \"startOffset\": 200,\\n  \"endOffset\": 216,\\n  \"chapterSummary\": \"A woman talks about the recording device they made of the pedophile who was her neighbor. She says the pedophile would say, \\\\\"Please, please forgive me, for the stuff I don\\'t remember that I did. I\\'m very very sorry, if I did.\\\\\" \"\\n}', '{\\n  \"startOffset\": 216,\\n  \"endOffset\": 232,\\n  \"chapterSummary\": \"The woman talks about her neighbor who was a pedophile and the impact that the abuse had on her. She says that she almost died from starving herself because of the abuse and shame. \"\\n}', '{\\n  \"startOffset\": 232,\\n  \"endOffset\": 240,\\n  \"chapterSummary\": \"A woman talks about her experience with the pedophile who was her neighbor. She says she and her friend both went to the police independently.\"\\n}']\n",
      "\n",
      "\n",
      "hereh are you chapters:\n",
      "\n",
      "[{'startOffset': '120', 'endOffset': '136', 'chapterSummary': 'A woman talks about her experience with a pedophile who was her neighbor. She says the abuse started when she was 4.5 years old and continued until she was 10.'}, {'startOffset': '136', 'endOffset': '152', 'chapterSummary': \"The woman talks about the pedophile who was her neighbor. She says he was well-loved by everyone in town. She says her parents were young and didn't know what to do.\"}, {'startOffset': '152', 'endOffset': '168', 'chapterSummary': 'A detective who worked tirelessly on the pedophile case talks about why he took the risk of having the woman wear a hidden recording device.'}, {'startOffset': '168', 'endOffset': '184', 'chapterSummary': 'The woman who was abused by the pedophile talks about the recordings they made of him, which were used in the case against him.'}, {'startOffset': '184', 'endOffset': '200', 'chapterSummary': ''}, {'startOffset': '200', 'endOffset': '216', 'chapterSummary': 'A woman talks about the recording device they made of the pedophile who was her neighbor. She says the pedophile would say, \\\\\"Please, please forgive me, for the stuff I don\\'t remember that I did. I\\'m very very sorry, if I did.\\\\\"'}, {'startOffset': '216', 'endOffset': '232', 'chapterSummary': 'The woman talks about her neighbor who was a pedophile and the impact that the abuse had on her. She says that she almost died from starving herself because of the abuse and shame.'}, {'startOffset': '232', 'endOffset': '240', 'chapterSummary': 'A woman talks about her experience with the pedophile who was her neighbor. She says she and her friend both went to the police independently.'}]\n",
      "{'start': 240, 'end': 360}\n",
      "getting summaries..\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n\\t\\\"type\\\":\\\"object\\\",\\n\\t\\\"properties\\\": {\\n\\t\\t\\\"startOffset\\\": {\\n\\t\\t\\t\\\"type\\\":\\\"integer\\\"\\n\\t\\t},\\n\\t\\t\\\"endOffset\\\": {\\n\\t\\t\\t\\\"type\\\":\\\"integer\\\"\\n\\t\\t},\\n\\t\\t\\\"chapterSummary\\\": {\\n\\t\\t\\t\\\"type\\\":\\\"string\\\"\\n\\t\\t}\\n\\t},\\n\\t\\\"required\\\": [\\\"startOffset\\\",\\\"endOffset\\\",\\\"chapterSummary\\\" ]\\n  }\\n},\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n      \\\"startOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"endOffset\\\": {\\n        \\\"type\\\": \\\"integer\\\"\\n      },\\n      \\\"chapterSummary\\\": {\\n        \\\"type\\\": \\\"string\\\"\\n      }\\n    },\\n    \\\"required\\\": [\\n      \\\"startOffset\\\",\\n      \\\"endOffset\\\",\\n      \\\"chapterSummary\\\"\\n    ]\\n  }\\n}\\n{\\n  \\\"description\\\": \\\"A list of chapters\\\",\\n  \\\"type\\\": \\\"array\\\",\\n  \\\"items\\\": {\\n    \\\"type\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: MAX_TOKENS\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.180539683\n",
      "    severity: HARM_SEVERITY_LOW\n",
      "    severity_score: 0.200557694\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.173428148\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.188174739\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: LOW\n",
      "    probability_score: 0.486781359\n",
      "    severity: HARM_SEVERITY_LOW\n",
      "    severity_score: 0.353093535\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: LOW\n",
      "    probability_score: 0.346651882\n",
      "    severity: HARM_SEVERITY_LOW\n",
      "    severity_score: 0.317849576\n",
      "  }\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 851374\n",
      "  candidates_token_count: 8192\n",
      "  total_token_count: 859566\n",
      "}\n",
      "\n",
      "**********\n",
      "['{\\n\\t\\t\\t\"type\":\"integer\"\\n\\t\\t}', '{\\n\\t\\t\\t\"type\":\"integer\"\\n\\t\\t}', '{\\n\\t\\t\\t\"type\":\"string\"\\n\\t\\t}', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }']\n",
      "\n",
      "\n",
      "hereh are you chapters:\n",
      "\n",
      "[]\n",
      "{'start': 360, 'end': 480}\n",
      "getting summaries..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(offset)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgetting summaries..\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m chapters\u001b[38;5;241m=\u001b[39m\u001b[43mget_video_summarycontent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvideo_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstartOffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstart\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mendOffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mintervals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintervals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chapter \u001b[38;5;129;01min\u001b[39;00m chapters:\n\u001b[1;32m     30\u001b[0m     video_chapters\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     31\u001b[0m         VideoChapter(\n\u001b[1;32m     32\u001b[0m             embedding\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m         )\n\u001b[1;32m     38\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[125], line 81\u001b[0m, in \u001b[0;36mget_video_summarycontent\u001b[0;34m(text, video_file, startOffset, endOffset, intervals)\u001b[0m\n\u001b[1;32m     75\u001b[0m          \u001b[38;5;66;03m# Load the saved video as a Gemini Part Object\u001b[39;00m\n\u001b[1;32m     77\u001b[0m          contents\u001b[38;5;241m=\u001b[39m[GenerativeModelPart\u001b[38;5;241m.\u001b[39mfrom_uri(video_file,mime_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo/mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     78\u001b[0m                    video_description_prompt,]\n\u001b[0;32m---> 81\u001b[0m          model_response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerative_multimodal_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m            \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m#          response_list = []\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m#          for chunk in response:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m#          response = ''.join(response_list)\u001b[39;00m\n\u001b[1;32m    102\u001b[0m          response\u001b[38;5;241m=\u001b[39mmodel_response\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py:524\u001b[0m, in \u001b[0;36m_GenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, stream)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content_streaming(\n\u001b[1;32m    517\u001b[0m         contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    518\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    521\u001b[0m         tool_config\u001b[38;5;241m=\u001b[39mtool_config,\n\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 524\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py:613\u001b[0m, in \u001b[0;36m_GenerativeModel._generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates content.\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \n\u001b[1;32m    590\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;124;03m    A single GenerationResponse object\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    606\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m    607\u001b[0m     contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    608\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    611\u001b[0m     tool_config\u001b[38;5;241m=\u001b[39mtool_config,\n\u001b[1;32m    612\u001b[0m )\n\u001b[0;32m--> 613\u001b[0m gapic_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_response(gapic_response)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform_v1beta1/services/prediction_service/client.py:2287\u001b[0m, in \u001b[0;36mPredictionServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2284\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   2286\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2287\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2292\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2294\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_channel.py:1178\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1168\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1174\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1175\u001b[0m     (\n\u001b[1;32m   1176\u001b[0m         state,\n\u001b[1;32m   1177\u001b[0m         call,\n\u001b[0;32m-> 1178\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[1;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[1;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[0;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:400\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "video_chapters=[]\n",
    "segments_to_process=120\n",
    "intervals=16\n",
    "video_duration=45*60\n",
    "prev=0\n",
    "import time\n",
    "\n",
    "        \n",
    "        \n",
    "video_file = \"gs://github-repo/embeddings/getting_started_embeddings/UCF-101-subset/BrushingTeeth/v_BrushingTeeth_g01_c02.mp4\"\n",
    "video_file=\"gs://raw_nine_files/60MI23_33_A_HBB.mp4\"\n",
    "video_file=\"gs://raw_nine_files/60MI24_1_A_HBB.mp4\"\n",
    "\n",
    "#video_file=\"gs://github-repo/embeddings/getting_started_embeddings/UCF-101-subset/BrushingTeeth/v_BrushingTeeth_g01_c02.mp4\"\n",
    "startOffset=0\n",
    "endOffset=120\n",
    "intervals=16\n",
    "\n",
    "\n",
    "for val in range (segments_to_process,video_duration+segments_to_process,segments_to_process):\n",
    "                offset={'start':prev, 'end':val}\n",
    "                prev=val    \n",
    "                print(offset)\n",
    "                 \n",
    "                print('getting summaries..')\n",
    "                \n",
    "                chapters=get_video_summarycontent(video_file=video_file,startOffset=offset['start'],endOffset=offset['end'],intervals=intervals)\n",
    "               \n",
    "                for chapter in chapters:\n",
    "                    video_chapters.append(\n",
    "                        VideoChapter(\n",
    "                            embedding=[1,2,3],\n",
    "                            #self.get_summarycontent_embedding_from_text_embedding_model(text=chapter[\"chapterSummary\"]).text_embedding,                           \n",
    "                            start_offset_sec=chapter[\"startOffset\"],\n",
    "                            end_offset_sec=chapter[\"endOffset\"],\n",
    "                            summary=chapter[\"chapterSummary\"]\n",
    "                        )\n",
    "                    )\n",
    "                print(\"hereh are you chapters:\")\n",
    "                print()\n",
    "                print(chapters)\n",
    "                time.sleep(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1f28b301-9e6a-4e23-b77f-4ed52d88164c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\\n    \"startOffset\": 240,\\n    \"endOffset\": 256,\\n    \"chapterSummary\": \"Madeleine West, an Australian actress, talks about her past abuse. She says she was abused for years. \"\\n  }', '{\\n    \"startOffset\": 256,\\n    \"endOffset\": 272,\\n    \"chapterSummary\": \"A detective named Scott Tudman says he thought Madeleine\\'s case was worth taking on. He also says that confronting the horrors of Madeleine\\'s childhood was crippling.\"\\n  }', '{\\n    \"startOffset\": 272,\\n    \"endOffset\": 288,\\n    \"chapterSummary\": \"Madeleine says she considered the ordeal to be like jumping off a waterfall, but knew she had to confront her abuser.\"\\n  }', '{\\n    \"startOffset\": 288,\\n    \"endOffset\": 304,\\n    \"chapterSummary\": \"The detective suggests she just act like she is seeking justice. Madeleine says she felt like she was going to be swallowed by the trauma.\"\\n  }', '{\\n    \"startOffset\": 304,\\n    \"endOffset\": 320,\\n    \"chapterSummary\": \"Madeleine West discusses her childhood. She says that she was first abused when she was 4 1/2 and it continued until she was 10.\"\\n  }', '{\\n    \"startOffset\": 320,\\n    \"endOffset\": 336,\\n    \"chapterSummary\": \"Peter White, a 73-year-old plumber from Woodend, was Madeleine\\'s abuser. He is a serial pedophile. \"\\n  }', '{\\n    \"startOffset\": 336,\\n    \"endOffset\": 352,\\n    \"chapterSummary\": \"The detective says he has dealt with many offenders in his career, but Peter White\\'s depravity shocked him.  The detective says he thinks Peter White\\'s home was like a magnet for children. \"\\n  }', '{\\n    \"startOffset\": 352,\\n    \"endOffset\": 360,\\n    \"chapterSummary\": \"The detective says he had a gut feeling about Peter White that he was not an ordinary offender.  \"\\n  }']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "startOffset=240\n",
    "endOffset=360\n",
    "intervals=16\n",
    "\n",
    "if 1==1:\n",
    "         '''\n",
    "         Gimini Features for Video as per:https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/video-understanding\n",
    "         gemini-1.5-flash, Gemini 1.5 Pro: \n",
    "         With audio: ~50 minutes\n",
    "         Without audio: 60 minutes\n",
    "         Maximum videos per prompt: 10\n",
    "         \n",
    "         Gemini 1.0 Pro Vision:\n",
    "         Maximum video length: 2 minutes\n",
    "         The maximum videos per prompt: 1\n",
    "         Audio in the video is ignored.\n",
    "         \n",
    "         Gimini feature for Part as per:https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#sample-requests\n",
    "        '''\n",
    "        \n",
    "\n",
    " \n",
    "         generative_multimodal_model= GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "         # Please only capture key events and highlights.\n",
    "        \n",
    "         video_description_prompt=f\"\"\"You are an assistant tasked with summarizing videos for retrieval.\\\n",
    "         These summaries will be embedded and used to retrieve the raw video.\\\n",
    "        Chapterize the video content by grouping the video content into chapters \\\n",
    "        with intervals of {intervals} seconds and providing a concise detail for each chapter that is well optimized for retrieval.\\\n",
    "        If there is a famous person like politician, celebrity or athlete, indicate their name and describe what they are famous for.\\\n",
    "        Describe important scenes in the video concisely.\\\n",
    "        If you are not sure about any info, please do not make it up. \\\n",
    "        Only consider video from {startOffset} seconds to {endOffset} seconds. Ignore analyzing the rest of video.\\\n",
    "        If it is the last chapter, set the endOffset to {endOffset} instead.\\ \n",
    "        If a chapter includes prohibited content, set chapterSummary to \"\".\\\n",
    "        For result, follow JSON schema.<JSONSchema>{json.dumps(schema)}</JSONSchema>\"\n",
    "        \"\"\"\n",
    "                   \n",
    "         #generation_config= GenerationConfig(temperature=1, top_k=40,top_p=0.95,max_output_tokens=8192) \n",
    "         generation_config=GenerationConfig(temperature=1, top_k=40,top_p=0.95,max_output_tokens=8192)#, response_mime_type='application/json',\n",
    "\t         # response_schema=json.loads(schema))  \n",
    "         #for video, BLOCK_NONE gives error. So, have to set it to BLOCK_ONLY_HIGH\n",
    "         safety_settings=  {\n",
    "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    }\n",
    "         stream=False\n",
    "        \n",
    "        \n",
    "         # Load the saved video as a Gemini Part Object\n",
    "          \n",
    "         contents=[GenerativeModelPart.from_uri(video_file,mime_type=\"video/mp4\"),\n",
    "                   video_description_prompt,]\n",
    "        \n",
    "        \n",
    "         model_response = generative_multimodal_model.generate_content(\n",
    "            contents,\n",
    "            generation_config=generation_config,\n",
    "            stream=stream,\n",
    "            safety_settings=safety_settings, )\n",
    "        \n",
    "        \n",
    "         response_list = []\n",
    "\n",
    "#          for chunk in model_response:\n",
    "#             try:\n",
    "#                 print(chunk)\n",
    "#                 print('******')\n",
    "#                 response_list.append(chunk.text)\n",
    "#             except Exception as e:\n",
    "#                 print(\n",
    "#                     \"Exception occurred while calling gemini. Something is wrong. Lower the safety thresholds [safety_settings: BLOCK_NONE ] if not already done. -----\",\n",
    "#                     e,\n",
    "#                 )\n",
    "#                 response_list.append(\"****Exception occurred***:\"+str(e))\n",
    "#                 continue\n",
    "\n",
    "#          response = ''.join(response_list)\n",
    "         # print(model_response)\n",
    "         # print('**********')\n",
    "    \n",
    "         if str(model_response.prompt_feedback).strip()!='block_reason: PROHIBITED_CONTENT':\n",
    "             response=model_response.text\n",
    "           \n",
    "\n",
    "             #response=response.replace('''{\\n  \"description\": \"A list of chapters\",\\n  \"type\": \"array\",\\n  \"items\": {\\n\\t\"type\":\"object\",\\n\\t\"properties\": {\\n\\t\\t\"startOffset\": {\\n\\t\\t\\t\"type\":\"integer\"\\n\\t\\t},\\n\\t\\t\"endOffset\": {\\n\\t\\t\\t\"type\":\"integer\"\\n\\t\\t},\\n\\t\\t\"chapterSummary\": {\\n\\t\\t\\t\"type\":\"string\"\\n\\t\\t}\\n\\t},\\n\\t\"required\": [\"startOffset\",\"endOffset\" ]\\n  }\\n},\\n  ''','')\n",
    "             #response=response[response.index('\"items\"'):len(response)-1]\n",
    "\n",
    "             chapters=[]\n",
    "             chapters_text=re.findall(r'\\{[^{}]*\\}',response )\n",
    "             print(chapters_text)\n",
    "             print('\\n')\n",
    "             for chapter in chapters_text:\n",
    "                         if 'startOffset' in chapter:\n",
    "                             chapter=chapter.replace('{','').replace('}','').strip()\n",
    "                             chapters.append(\n",
    "                                 {\n",
    "                                    \"startOffset\":chapter.split(',')[0].replace('\"startOffset\":','').replace(\"{\",'').strip(),\n",
    "                                    \"endOffset\":chapter.split(',')[1].replace('\"endOffset\":','').strip(),\n",
    "                                     \"chapterSummary\": ('[ST]'+chapter[chapter.index('\"chapterSummary\":'): len(chapter)-1].replace('\"chapterSummary\":','').replace(\"}\",'').strip()).replace('[ST]\"','')\n",
    "\n",
    "                                 }\n",
    "                             )\n",
    "         else:\n",
    "               chapters.append(\n",
    "                                 {\n",
    "                                    \"startOffset\":str(startOffset),\n",
    "                                    \"endOffset\":str(endOffset),\n",
    "                                     \"chapterSummary\": '***PROHIBITED_CONTENT***'\n",
    "\n",
    "                                 }\n",
    "               )\n",
    "             \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ec7e098a-7c0c-4af8-85e5-f2f9624af60b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'startOffset': '240',\n",
       "  'endOffset': '256',\n",
       "  'chapterSummary': 'Madeleine West, an Australian actress, talks about her past abuse. She says she was abused for years.'},\n",
       " {'startOffset': '256',\n",
       "  'endOffset': '272',\n",
       "  'chapterSummary': \"A detective named Scott Tudman says he thought Madeleine's case was worth taking on. He also says that confronting the horrors of Madeleine's childhood was crippling.\"},\n",
       " {'startOffset': '272',\n",
       "  'endOffset': '288',\n",
       "  'chapterSummary': 'Madeleine says she considered the ordeal to be like jumping off a waterfall, but knew she had to confront her abuser.'},\n",
       " {'startOffset': '288',\n",
       "  'endOffset': '304',\n",
       "  'chapterSummary': 'The detective suggests she just act like she is seeking justice. Madeleine says she felt like she was going to be swallowed by the trauma.'},\n",
       " {'startOffset': '304',\n",
       "  'endOffset': '320',\n",
       "  'chapterSummary': 'Madeleine West discusses her childhood. She says that she was first abused when she was 4 1/2 and it continued until she was 10.'},\n",
       " {'startOffset': '320',\n",
       "  'endOffset': '336',\n",
       "  'chapterSummary': \"Peter White, a 73-year-old plumber from Woodend, was Madeleine's abuser. He is a serial pedophile.\"},\n",
       " {'startOffset': '336',\n",
       "  'endOffset': '352',\n",
       "  'chapterSummary': \"The detective says he has dealt with many offenders in his career, but Peter White's depravity shocked him.  The detective says he thinks Peter White's home was like a magnet for children.\"},\n",
       " {'startOffset': '352',\n",
       "  'endOffset': '360',\n",
       "  'chapterSummary': 'The detective says he had a gut feeling about Peter White that he was not an ordinary offender.'}]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9bd4d469-34dc-4869-9eaa-337adbad2ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "\n",
    "class VideoChapter:\n",
    "    \"\"\"Chapters generated from video with offset times.\"\"\"\n",
    "\n",
    "    start_offset_sec: int\n",
    "    end_offset_sec: int\n",
    "    embedding: List[float]\n",
    "    summary: str\n",
    "\n",
    "    def __init__(\n",
    "        self, start_offset_sec: int, end_offset_sec: int, embedding: List[float], summary: str\n",
    "    ):\n",
    "        \"\"\"Creates a `VideoEmbedding` object.\n",
    "\n",
    "        Args:\n",
    "            start_offset_sec: Start time offset (in seconds) of generated embeddings.\n",
    "            end_offset_sec: End time offset (in seconds) of generated embeddings.\n",
    "            embedding: Generated embedding for interval.\n",
    "        \"\"\"\n",
    "        self.start_offset_sec = start_offset_sec\n",
    "        self.end_offset_sec = end_offset_sec\n",
    "        self.embedding = embedding\n",
    "        self.summary=summary\n",
    "        \n",
    "\n",
    "def get_video_summarycontent( text: str = None, video_file: str = None,startOffset: int=0, endOffset: int=120, intervals: int=16):\n",
    "        \n",
    "         '''\n",
    "         Gimini Features for Video as per:https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/video-understanding\n",
    "         gemini-1.5-flash, Gemini 1.5 Pro: \n",
    "         With audio: ~50 minutes\n",
    "         Without audio: 60 minutes\n",
    "         Maximum videos per prompt: 10\n",
    "         \n",
    "         Gemini 1.0 Pro Vision:\n",
    "         Maximum video length: 2 minutes\n",
    "         The maximum videos per prompt: 1\n",
    "         Audio in the video is ignored.\n",
    "         \n",
    "         Gimini feature for Part as per:https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#sample-requests\n",
    "        '''\n",
    "        \n",
    "\n",
    " \n",
    "         generative_multimodal_model= GenerativeModel(\"gemini-1.5-pro-latest\")\n",
    "         # Please only capture key events and highlights.\n",
    "        \n",
    "         video_description_prompt=f\"\"\"You are an assistant tasked with summarizing videos for retrieval.\\\n",
    "         These summaries will be embedded and used to retrieve the raw video.\\\n",
    "        Chapterize the video content by grouping the video content into chapters \\\n",
    "        with intervals of {intervals} seconds and providing a concise detail for each chapter that is well optimized for retrieval.\\\n",
    "        If there is a famous person like politician, celebrity or athlete, indicate their name and describe what they are famous for.\\\n",
    "        Describe important scenes in the video concisely.\\\n",
    "        If you are not sure about any info, please do not make it up. \\\n",
    "        Only consider video from {startOffset} seconds to {endOffset} seconds. Ignore analyzing the rest of video.\\\n",
    "        If it is the last chapter, set the endOffset to {endOffset} instead.\\ \n",
    "        If a chapter includes prohibited content, set chapterSummary to \"\".\\\n",
    "        For result, follow JSON schema.<JSONSchema>{json.dumps(schema)}</JSONSchema>\"\n",
    "        \"\"\"\n",
    "                   \n",
    "         #generation_config= GenerationConfig(temperature=1, top_k=40,top_p=0.95,max_output_tokens=8192) \n",
    "         generation_config=GenerationConfig(temperature=1, top_k=40,top_p=0.95,max_output_tokens=8192, response_mime_type='application/json',\n",
    "\t          response_schema=json.loads(schema))  \n",
    "         #for video, BLOCK_NONE gives error. So, have to set it to BLOCK_ONLY_HIGH\n",
    "         safety_settings=  {\n",
    "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    }\n",
    "         stream=False\n",
    "        \n",
    "        \n",
    "         # Load the saved video as a Gemini Part Object\n",
    "          \n",
    "         contents=[GenerativeModelPart.from_uri(video_file,mime_type=\"video/mp4\"),\n",
    "                   video_description_prompt,]\n",
    "        \n",
    "        \n",
    "         model_response = generative_multimodal_model.generate_content(\n",
    "            contents,\n",
    "            generation_config=generation_config,\n",
    "            stream=stream,\n",
    "            safety_settings=safety_settings, )\n",
    "        \n",
    "        \n",
    "#          response_list = []\n",
    "\n",
    "#          for chunk in response:\n",
    "#             try:\n",
    "#                 response_list.append(chunk.text)\n",
    "#             except Exception as e:\n",
    "#                 print(\n",
    "#                     \"Exception occurred while calling gemini. Something is wrong. Lower the safety thresholds [safety_settings: BLOCK_NONE ] if not already done. -----\",\n",
    "#                     e,\n",
    "#                 )\n",
    "#                 response_list.append(\"****Exception occurred***:\"+e)\n",
    "#                 continue\n",
    "\n",
    "#          response = ''.join(response_list)\n",
    "         if str(model_response.prompt_feedback).strip()!='block_reason: PROHIBITED_CONTENT':\n",
    "             response=model_response.text\n",
    "             print(model_response)\n",
    "             print('**********')\n",
    "\n",
    "             response=response.replace('''{\\n  \"description\": \"A list of chapters\",\\n  \"type\": \"array\",\\n  \"items\": {\\n\\t\"type\":\"object\",\\n\\t\"properties\": {\\n\\t\\t\"startOffset\": {\\n\\t\\t\\t\"type\":\"integer\"\\n\\t\\t},\\n\\t\\t\"endOffset\": {\\n\\t\\t\\t\"type\":\"integer\"\\n\\t\\t},\\n\\t\\t\"chapterSummary\": {\\n\\t\\t\\t\"type\":\"string\"\\n\\t\\t}\\n\\t},\\n\\t\"required\": [\"startOffset\",\"endOffset\" ]\\n  }\\n},\\n  ''','')\n",
    "             response=response[response.index('\"items\"'):len(response)-1]\n",
    "\n",
    "             chapters=[]\n",
    "             chapters_text=re.findall(r'\\{[^{}]*\\}',response )\n",
    "             print(chapters_text)\n",
    "             print('\\n')\n",
    "             for chapter in chapters_text:\n",
    "                         if 'startOffset' in chapter:\n",
    "                             chapter=chapter.replace('{','').replace('}','').strip()\n",
    "                             chapters.append(\n",
    "                                 {\n",
    "                                    \"startOffset\":chapter.split(',')[0].replace('\"startOffset\":','').replace(\"{\",'').strip(),\n",
    "                                    \"endOffset\":chapter.split(',')[1].replace('\"endOffset\":','').strip(),\n",
    "                                     \"chapterSummary\": ('[ST]'+chapter[chapter.index('\"chapterSummary\":'): len(chapter)-1].replace('\"chapterSummary\":','').replace(\"}\",'').strip()).replace('[ST]\"','')\n",
    "\n",
    "                                 }\n",
    "                             )\n",
    "         else:\n",
    "               chapters.append(\n",
    "                                 {\n",
    "                                    \"startOffset\":str(startOffset),\n",
    "                                    \"endOffset\":str(endOffset),\n",
    "                                     \"chapterSummary\": '***PROHIBITED_CONTENT***'\n",
    "\n",
    "                                 }\n",
    "               )\n",
    "             \n",
    " \n",
    "         return chapters\n",
    "\n",
    "#def get_video_summarycontent( text: str = None, video_file: str = None):\n",
    "# def get_video_summarycontent1( text: str = None, video_file: str = None,startOffset: int=0, endOffset: int=120, intervals: int=16):\n",
    "#          '''\n",
    "#          Gimini Features for Video as per:https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/video-understanding\n",
    "#          gemini-1.5-flash, Gemini 1.5 Pro: \n",
    "#          With audio: ~50 minutes\n",
    "#          Without audio: 60 minutes\n",
    "#          Maximum videos per prompt: 10\n",
    "         \n",
    "#          Gemini 1.0 Pro Vision:\n",
    "#          Maximum video length: 2 minutes\n",
    "#          The maximum videos per prompt: 1\n",
    "#          Audio in the video is ignored.\n",
    "         \n",
    "#          Gimini feature for Part as per:https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#sample-requests\n",
    "#         '''\n",
    "        \n",
    "\n",
    " \n",
    "#          generative_multimodal_model= GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "#          # Please only capture key events and highlights.\n",
    "        \n",
    "#          video_description_prompt=f\"\"\"You are an assistant tasked with summarizing videos for retrieval.\\\n",
    "#          These summaries will be embedded and used to retrieve the raw video.\\\n",
    "#         Chapterize the video content by grouping the video content into chapters \\\n",
    "#         with intervals of {intervals} seconds and providing a concise detail for each chapter that is well optimized for retrieval.\\\n",
    "#         If there is a famous person like politician, celebrity or athlete, indicate their name and describe what they are famous for.\\\n",
    "#         Describe important scenes in the video concisely.\\\n",
    "#         If you are not sure about any info, please do not make it up. \\\n",
    "#         Only consider video from {startOffset} seconds to {endOffset} seconds. Ignore analyzing the rest of video.\\\n",
    "#         Return the result as per given schema:\\\n",
    "#         {schema}.\\\n",
    "#         If it is the last chapter, set the endOffset to {endOffset} instead.\\  \n",
    "#         \"\"\"\n",
    "                   \n",
    "#          generation_config= GenerationConfig(temperature=1, top_k=40,top_p=0.95,max_output_tokens=8192) \n",
    "         \n",
    "#         #for video, BLOCK_NONE gives error. So, have to set it to BLOCK_ONLY_HIGH\n",
    "#          safety_settings=  {\n",
    "#                     HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "#                     HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "#                     HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "#                     HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "#                     }\n",
    "#          stream=True\n",
    "        \n",
    "#          # Load the saved video as a Gemini Part Object\n",
    "          \n",
    "#          contents=[GenerativeModelPart.from_uri(video_file,mime_type=\"video/mp4\"),\n",
    "#                    video_description_prompt,]\n",
    "        \n",
    "        \n",
    "#          res = generative_multimodal_model.generate_content(\n",
    "#             contents,\n",
    "#             generation_config=generation_config,\n",
    "#             stream=stream,\n",
    "#             safety_settings=safety_settings, )\n",
    "        \n",
    "        \n",
    "#          response_list = []\n",
    "\n",
    "#          for chunk in res:\n",
    "#             try:\n",
    "#                 response_list.append(chunk.text)\n",
    "#             except Exception as e:\n",
    "#                 print(\n",
    "#                     \"Exception occurred while calling gemini. Something is wrong. Lower the safety thresholds [safety_settings: BLOCK_NONE ] if not already done. -----\",\n",
    "#                     e,\n",
    "#                 )\n",
    "#                 response_list.append(\"****Exception occurred***:\"+e)\n",
    "#                 continue\n",
    "                \n",
    "#          response = ''.join(response_list)\n",
    "#          response=response.replace('''{\\n  \"description\": \"A list of chapters\",\\n  \"type\": \"array\",\\n  \"items\": {\\n\\t\"type\":\"object\",\\n\\t\"properties\": {\\n\\t\\t\"startOffset\": {\\n\\t\\t\\t\"type\":\"integer\"\\n\\t\\t},\\n\\t\\t\"endOffset\": {\\n\\t\\t\\t\"type\":\"integer\"\\n\\t\\t},\\n\\t\\t\"chapterSummary\": {\\n\\t\\t\\t\"type\":\"string\"\\n\\t\\t}\\n\\t},\\n\\t\"required\": [\"startOffset\",\"endOffset\" ]\\n  }\\n},\\n  ''','')\n",
    "#          response=response[response.index('\"items\"'):len(response)-1]\n",
    "\n",
    "#          chapters=[]\n",
    "#          chapters_text=re.findall(r'\\{[^{}]*\\}',response )\n",
    "#          print(chapters_text)\n",
    "#          print('\\n')\n",
    "#          for chapter in chapters_text:\n",
    "#                      chapter=chapter.replace('{','').replace('}','').strip()\n",
    "#                      chapters.append(\n",
    "#                          {\n",
    "#                             \"startOffset\":chapter.split(',')[0].replace('\"startOffset\":','').replace(\"{\",'').strip(),\n",
    "#                             \"endOffset\":chapter.split(',')[1].replace('\"endOffset\":','').strip(),\n",
    "#                              \"chapterSummary\": ('[ST]'+chapter[chapter.index('\"chapterSummary\":'): len(chapter)-1].replace('\"chapterSummary\":','').replace(\"}\",'').strip()).replace('[ST]\"','')\n",
    "                        \n",
    "#                          }\n",
    "#                      )\n",
    "#          return chapters\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f7216a5a-6aa9-4121-984c-2830ffdc2e86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"items\": [\\n    {\\n      \"startOffset\": 0,\\n      \"endOffset\": 16,\\n      \"chapterSummary\": \"A woman with long blonde hair, looking directly at the camera. She is wearing a black, scoop-neck shirt.\"\\n    },\\n    {\\n      \"startOffset\": 16,\\n      \"endOffset\": 32,\\n      \"chapterSummary\": \"A woman with blonde hair is talking about her sister\\'s disappearance. She is wearing a black blazer over a white top and looks emotional.\"\\n    },\\n    {\\n      \"startOffset\": 32,\\n      \"endOffset\": 48,\\n      \"chapterSummary\": \"A woman with blonde hair is talking about her sister\\'s possessions being found. She is wearing a black blazer over a white top. She is looking emotional.\"\\n    },\\n    {\\n      \"startOffset\": 48,\\n      \"endOffset\": 64,\\n      \"chapterSummary\": \"The news of a woman\\'s disappearance is being discussed. The woman was 22 years old. There is discussion about her possessions being found and her connection to the sex industry. She worked as an escort.\"\\n    },\\n    {\\n      \"startOffset\": 64,\\n      \"endOffset\": 80,\\n      \"chapterSummary\": \"The woman\\'s sister is talking about the discovery of her sister\\'s possessions. She is wearing a striped shirt. Her hair is blonde.\"\\n    },\\n    {\\n      \"startOffset\": 80,\\n      \"endOffset\": 96,\\n      \"chapterSummary\": \"The woman\\'s sister is talking about her sister\\'s disappearance and the timeline surrounding it. She is wearing a striped shirt. Her hair is blonde.\"\\n    },\\n    {\\n      \"startOffset\": 96,\\n      \"endOffset\": 112,\\n      \"chapterSummary\": \"A man with grey hair and glasses is talking about his wife\\'s work as an escort. He is wearing a white shirt and a blue, checkered shirt, which is visible underneath.\"\\n    },\\n    {\\n      \"startOffset\": 112,\\n      \"endOffset\": 120,\\n      \"chapterSummary\": \"A woman is talking about her sister\\'s disappearance, where her sister was headed the night she went missing, and the people involved.  She is wearing a white shirt over a black top.\"\\n    }\\n  ]\\n}\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.replace('''{\\n  \"description\": \"A list of chapters\",\\n  \"type\": \"array\",\\n  \"items\": {\\n\\t\"type\":\"object\",\\n\\t\"properties\": {\\n\\t\\t\"startOffset\": {\\n\\t\\t\\t\"type\":\"integer\"\\n\\t\\t},\\n\\t\\t\"endOffset\": {\\n\\t\\t\\t\"type\":\"integer\"\\n\\t\\t},\\n\\t\\t\"chapterSummary\": {\\n\\t\\t\\t\"type\":\"string\"\\n\\t\\t}\\n\\t},\\n\\t\"required\": [\"startOffset\",\"endOffset\" ]\\n  }\\n},\\n  ''','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c6625dcf-3bcd-4479-9f29-10599f5bc94d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "0\n",
      "16\n",
      "A woman with long blonde hair, looking directly at the camera. She is wearing a black, scoop-neck shirt.\n",
      "\n",
      "16\n",
      "32\n",
      "A woman with blonde hair is talking about her sister's disappearance. She is wearing a black blazer over a white top and looks emotional.\n",
      "\n",
      "32\n",
      "48\n",
      "A woman with blonde hair is talking about her sister's possessions being found. She is wearing a black blazer over a white top. She is looking emotional.\n",
      "\n",
      "48\n",
      "64\n",
      "The news of a woman's disappearance is being discussed. The woman was 22 years old. There is discussion about her possessions being found and her connection to the sex industry. She worked as an escort.\n",
      "\n",
      "64\n",
      "80\n",
      "The woman's sister is talking about the discovery of her sister's possessions. She is wearing a striped shirt. Her hair is blonde.\n",
      "\n",
      "80\n",
      "96\n",
      "The woman's sister is talking about her sister's disappearance and the timeline surrounding it. She is wearing a striped shirt. Her hair is blonde.\n",
      "\n",
      "96\n",
      "112\n",
      "A man with grey hair and glasses is talking about his wife's work as an escort. He is wearing a white shirt and a blue, checkered shirt, which is visible underneath.\n",
      "\n",
      "112\n",
      "120\n",
      "A woman is talking about her sister's disappearance, where her sister was headed the night she went missing, and the people involved.  She is wearing a white shirt over a black top.\n"
     ]
    }
   ],
   "source": [
    "response=response.replace('''{\\n  \"description\": \"A list of chapters\",\\n  \"type\": \"array\",\\n  \"items\": {\\n\\t\"type\":\"object\",\\n\\t\"properties\": {\\n\\t\\t\"startOffset\": {\\n\\t\\t\\t\"type\":\"integer\"\\n\\t\\t},\\n\\t\\t\"endOffset\": {\\n\\t\\t\\t\"type\":\"integer\"\\n\\t\\t},\\n\\t\\t\"chapterSummary\": {\\n\\t\\t\\t\"type\":\"string\"\\n\\t\\t}\\n\\t},\\n\\t\"required\": [\"startOffset\",\"endOffset\" ]\\n  }\\n},\\n  ''','')\n",
    "response=response[response.index('\"items\"'):len(response)-1]\n",
    "\n",
    "chapters=[]\n",
    "chapters_text=re.findall(r'\\{[^{}]*\\}', x )\n",
    "#print(chapters_text)\n",
    "print('\\n')\n",
    "for chapter in chapters_text:\n",
    "             chapter=chapter.replace('{','').replace('}','').strip()\n",
    "             #print(chapter)\n",
    "             print()\n",
    "             print(chapter.split(',')[0].replace('\"startOffset\":','').replace(\"{\",'').strip())\n",
    "             print(chapter.split(',')[1].replace('\"endOffset\":','').strip())\n",
    "             print( ('[ST]'+chapter[chapter.index('\"chapterSummary\":'): len(chapter)-1].replace('\"chapterSummary\":','').strip()).replace('[ST]\"',''))\n",
    "            \n",
    "             chapters.append(\n",
    "                 {\n",
    "                    \"startOffset\":chapter.split(',')[0].replace('\"startOffset\":','').replace(\"{\",'').strip(),\n",
    "                    \"endOffset\":chapter.split(',')[1].replace('\"endOffset\":','').strip(),\n",
    "                    \"chapterSummary\": ('[ST]'+chapter[chapter.index('\"chapterSummary\":'): len(chapter)-1].replace('\"chapterSummary\":','').replace(\"}\",'').strip()).replace('[ST]\"','')\n",
    "                             \n",
    "                 }\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1408f27d-5298-431a-8193-2d1e68d37eca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'startOffset': '360',\n",
       "  'endOffset': '376',\n",
       "  'chapterSummary': '\"The reporter, Tara Brown, is asking a witness, Adam Owen, about his experience working at the restaurant where Ravell Belmaine was last seen.'},\n",
       " {'startOffset': '376',\n",
       "  'endOffset': '392',\n",
       "  'chapterSummary': '\"Adam Owen talks about the police investigation into Ravell Belmaine\\'s murder and about how the police were trying to establish a timeline quickly.'},\n",
       " {'startOffset': '392',\n",
       "  'endOffset': '408',\n",
       "  'chapterSummary': '\"The reporter asks Adam Owen about the phone call the woman made to the restaurant and whether he remembers the words she used.'},\n",
       " {'startOffset': '408',\n",
       "  'endOffset': '424',\n",
       "  'chapterSummary': '\"Adam Owen  is asked whether he believes the woman was in the restaurant on that night. The reporter and the witness discuss the police investigation and whether Owen could be a suspect in the case.'},\n",
       " {'startOffset': '424',\n",
       "  'endOffset': '440',\n",
       "  'chapterSummary': '\"The reporter asks Zoran,  the ex-husband of Jane King, about his whereabouts when Ravell Belmaine went missing.'},\n",
       " {'startOffset': '440',\n",
       "  'endOffset': '456',\n",
       "  'chapterSummary': '\"The reporter asks about Zoran\\'s whereabouts on the night Ravell went missing and how he changed his story to police. The reporter is looking for answers.'},\n",
       " {'startOffset': '456',\n",
       "  'endOffset': '472',\n",
       "  'chapterSummary': '\"The reporter asks  Zoran  about whether his story matches the phone records. Zoran denies it and the reporter says she thinks he is not being honest.'},\n",
       " {'startOffset': '472',\n",
       "  'endOffset': '480',\n",
       "  'chapterSummary': '\"The reporter asks Zoran if he thinks he did something to do with Ravell\\'s disappearance. Zoran does not want to answer, but the reporter thinks he does have something to do with it.'}]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "08b1d784-ca57-4424-9841-5e6eb10c4d19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'startOffset': '0', 'endOffset': '16', 'chapterSummary': '\"A woman with long blonde hair, looking directly at the camera. She is wearing a black, scoop-neck shirt.'}\n",
      "\n",
      "{'startOffset': '16', 'endOffset': '32', 'chapterSummary': '\"A woman with blonde hair is talking about her sister\\'s disappearance. She is wearing a black blazer over a white top and looks emotional.'}\n",
      "\n",
      "{'startOffset': '32', 'endOffset': '48', 'chapterSummary': '\"A woman with blonde hair is talking about her sister\\'s possessions being found. She is wearing a black blazer over a white top. She is looking emotional.'}\n",
      "\n",
      "{'startOffset': '48', 'endOffset': '64', 'chapterSummary': '\"The news of a woman\\'s disappearance is being discussed. The woman was 22 years old. There is discussion about her possessions being found and her connection to the sex industry. She worked as an escort.'}\n",
      "\n",
      "{'startOffset': '64', 'endOffset': '80', 'chapterSummary': '\"The woman\\'s sister is talking about the discovery of her sister\\'s possessions. She is wearing a striped shirt. Her hair is blonde.'}\n",
      "\n",
      "{'startOffset': '80', 'endOffset': '96', 'chapterSummary': '\"The woman\\'s sister is talking about her sister\\'s disappearance and the timeline surrounding it. She is wearing a striped shirt. Her hair is blonde.'}\n",
      "\n",
      "{'startOffset': '96', 'endOffset': '112', 'chapterSummary': '\"A man with grey hair and glasses is talking about his wife\\'s work as an escort. He is wearing a white shirt and a blue, checkered shirt, which is visible underneath.'}\n",
      "\n",
      "{'startOffset': '112', 'endOffset': '120', 'chapterSummary': '\"A woman is talking about her sister\\'s disappearance, where her sister was headed the night she went missing, and the people involved.  She is wearing a white shirt over a black top.'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for l in chapters:\n",
    "    print(l)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7023158d-b1eb-43e7-91b2-6f6d30ed7566",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "res='''\n",
    "\n",
    "{\n",
    "  \"description\": \"A list of chapters\",\n",
    "  \"type\": \"array\",\n",
    "  \"items\": {\n",
    "\t\"type\":\"object\",\n",
    "\t\"properties\": {\n",
    "\t\t\"startOffset\": {\n",
    "\t\t\t\"type\":\"integer\"\n",
    "\t\t},\n",
    "\t\t\"endOffset\": {\n",
    "\t\t\t\"type\":\"integer\"\n",
    "\t\t},\n",
    "\t\t\"chapterSummary\": {\n",
    "\t\t\t\"type\":\"string\"\n",
    "\t\t}\n",
    "\t},\n",
    "\t\"required\": [\"startOffset\",\"endOffset\" ]\n",
    "  }\n",
    "},\n",
    "  \"items\": [\n",
    "    {\n",
    "      \"startOffset\": 424,\n",
    "      \"endOffset\": 440,\n",
    "      \"chapterSummary\": \"A new investigation is underway into the disappearance of Rebel Belmain. Police are focusing on Jane King's now ex-husband, Zoron, and his changing story.\"\n",
    "    },\n",
    "    {\n",
    "      \"startOffset\": 440,\n",
    "      \"endOffset\": 456,\n",
    "      \"chapterSummary\": \"Zoron has never been arrested or charged in relation to Rebel's disappearance.  However, police believe he deserves further investigation.\"\n",
    "    },\n",
    "    {\n",
    "      \"startOffset\": 456,\n",
    "      \"endOffset\": 472,\n",
    "      \"chapterSummary\": \"Rebel's sister, Suellen Simpson, has lived with grief and uncertainty for almost 30 years.  She feels like the police didn't care about escorts or working girls.\"\n",
    "    },\n",
    "    {\n",
    "      \"startOffset\": 472,\n",
    "      \"endOffset\": 488,\n",
    "      \"chapterSummary\": \"Zoron said he was home the night Rebel disappeared with a heavily pregnant Jane.\"\n",
    "    },\n",
    "    {\n",
    "      \"startOffset\": 488,\n",
    "      \"endOffset\": 504,\n",
    "      \"chapterSummary\": \"Jane says Zoron was not home that night.  The discovery of Rebel's belongings shortly after her disappearance raised concerns about Zoron.\"\n",
    "    },\n",
    "    {\n",
    "      \"startOffset\": 504,\n",
    "      \"endOffset\": 520,\n",
    "      \"chapterSummary\": \"A new inquest into Rebel's death has been launched with the hope that it may offer answers for Rebel's family and friends.\"\n",
    "    },\n",
    "    {\n",
    "      \"startOffset\": 520,\n",
    "      \"endOffset\": 536,\n",
    "      \"chapterSummary\": \"The new investigation focuses on Zoron and his changing story.  It is thought that the initial investigation may have brushed over the details.\"\n",
    "    },\n",
    "    {\n",
    "      \"startOffset\": 536,\n",
    "      \"endOffset\": 544,\n",
    "      \"chapterSummary\": \"The family questions why the police didn't investigate more thoroughly, given that they were aware of the case's significance.\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "'''\n",
    "res=res.replace('''{\n",
    "  \"description\": \"A list of chapters\",\n",
    "  \"type\": \"array\",\n",
    "  \"items\": {\n",
    "\t\"type\":\"object\",\n",
    "\t\"properties\": {\n",
    "\t\t\"startOffset\": {\n",
    "\t\t\t\"type\":\"integer\"\n",
    "\t\t},\n",
    "\t\t\"endOffset\": {\n",
    "\t\t\t\"type\":\"integer\"\n",
    "\t\t},\n",
    "\t\t\"chapterSummary\": {\n",
    "\t\t\t\"type\":\"string\"\n",
    "\t\t}\n",
    "\t},\n",
    "\t\"required\": [\"startOffset\",\"endOffset\" ]\n",
    "  }\n",
    "},''','')\n",
    "\n",
    "chapters_text=re.findall(r\"\\[.*?\\]\", res )\n",
    "chapters_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b190505-b937-4aff-8672-a7e1f88cf68d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "      \"startOffset\": 424,\n",
      "      \"endOffset\": 440,\n",
      "      \"chapterSummary\": \"A new investigation is underway into the disappearance of Rebel Belmain. Police are focusing on Jane King's now ex-husband, Zoron, and his changing story.\"\n",
      "    }\n",
      "{\n",
      "      \"startOffset\": 440,\n",
      "      \"endOffset\": 456,\n",
      "      \"chapterSummary\": \"Zoron has never been arrested or charged in relation to Rebel's disappearance.  However, police believe he deserves further investigation.\"\n",
      "    }\n",
      "{\n",
      "      \"startOffset\": 456,\n",
      "      \"endOffset\": 472,\n",
      "      \"chapterSummary\": \"Rebel's sister, Suellen Simpson, has lived with grief and uncertainty for almost 30 years.  She feels like the police didn't care about escorts or working girls.\"\n",
      "    }\n",
      "{\n",
      "      \"startOffset\": 472,\n",
      "      \"endOffset\": 488,\n",
      "      \"chapterSummary\": \"Zoron said he was home the night Rebel disappeared with a heavily pregnant Jane.\"\n",
      "    }\n",
      "{\n",
      "      \"startOffset\": 488,\n",
      "      \"endOffset\": 504,\n",
      "      \"chapterSummary\": \"Jane says Zoron was not home that night.  The discovery of Rebel's belongings shortly after her disappearance raised concerns about Zoron.\"\n",
      "    }\n",
      "{\n",
      "      \"startOffset\": 504,\n",
      "      \"endOffset\": 520,\n",
      "      \"chapterSummary\": \"A new inquest into Rebel's death has been launched with the hope that it may offer answers for Rebel's family and friends.\"\n",
      "    }\n",
      "{\n",
      "      \"startOffset\": 520,\n",
      "      \"endOffset\": 536,\n",
      "      \"chapterSummary\": \"The new investigation focuses on Zoron and his changing story.  It is thought that the initial investigation may have brushed over the details.\"\n",
      "    }\n",
      "{\n",
      "      \"startOffset\": 536,\n",
      "      \"endOffset\": 544,\n",
      "      \"chapterSummary\": \"The family questions why the police didn't investigate more thoroughly, given that they were aware of the case's significance.\"\n",
      "    }\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chapters=[]\n",
    "for chapter in ((re.findall(r'\\{[^{}]*\\}', res ))):\n",
    "    print(chapter)\n",
    "    chapters.append(\n",
    "                 {\n",
    "                    \"startOffset\":chapter.split(',')[0].replace('\"startOffset\":','').replace(\"{\",'').strip(),\n",
    "                    \"endOffset\":chapter.split(',')[1].replace('\"endOffset\":','').strip(),\n",
    "                    \"chapterSummary\":chapter[chapter.index('\"chapterSummary\":'): len(chapter)-1].replace('\"chapterSummary\":','').replace(\"}\",'').strip()\n",
    "                             \n",
    "                 }\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "00673256-5cec-4750-8673-b0d3139129c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'startOffset': '424', 'endOffset': '440', 'chapterSummary': '\"A new investigation is underway into the disappearance of Rebel Belmain. Police are focusing on Jane King\\'s now ex-husband, Zoron, and his changing story.\"'}\n",
      "---\n",
      "{'startOffset': '440', 'endOffset': '456', 'chapterSummary': '\"Zoron has never been arrested or charged in relation to Rebel\\'s disappearance.  However, police believe he deserves further investigation.\"'}\n",
      "---\n",
      "{'startOffset': '456', 'endOffset': '472', 'chapterSummary': '\"Rebel\\'s sister, Suellen Simpson, has lived with grief and uncertainty for almost 30 years.  She feels like the police didn\\'t care about escorts or working girls.\"'}\n",
      "---\n",
      "{'startOffset': '472', 'endOffset': '488', 'chapterSummary': '\"Zoron said he was home the night Rebel disappeared with a heavily pregnant Jane.\"'}\n",
      "---\n",
      "{'startOffset': '488', 'endOffset': '504', 'chapterSummary': '\"Jane says Zoron was not home that night.  The discovery of Rebel\\'s belongings shortly after her disappearance raised concerns about Zoron.\"'}\n",
      "---\n",
      "{'startOffset': '504', 'endOffset': '520', 'chapterSummary': '\"A new inquest into Rebel\\'s death has been launched with the hope that it may offer answers for Rebel\\'s family and friends.\"'}\n",
      "---\n",
      "{'startOffset': '520', 'endOffset': '536', 'chapterSummary': '\"The new investigation focuses on Zoron and his changing story.  It is thought that the initial investigation may have brushed over the details.\"'}\n",
      "---\n",
      "{'startOffset': '536', 'endOffset': '544', 'chapterSummary': '\"The family questions why the police didn\\'t investigate more thoroughly, given that they were aware of the case\\'s significance.\"'}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for c in chapters:\n",
    "    print(c)\n",
    "    print('---')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92afb6b4-d2b5-4e7a-9421-a797989bbc40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{ \"startOffset\": 360, \"endOffset\": 376, \"chapterSummary\": \"Suellen Simpson, the sister of the victim, talks about the pain she has been going through for almost 30 years and still hopes for answers.\" }',\n",
       " '{ \"startOffset\": 376, \"endOffset\": 392, \"chapterSummary\": \"The police have reopened the investigation into the disappearance of Revel Belmain because of new evidence and are appealing for witnesses to come forward with information.\" }',\n",
       " '{ \"startOffset\": 392, \"endOffset\": 408, \"chapterSummary\": \"A witness, Adam Owen, says he remembered Jane King, the victim’s former boss, and her story does not match up with the evidence.\" }',\n",
       " '{ \"startOffset\": 408, \"endOffset\": 424, \"chapterSummary\": \"The police are looking for witnesses to identify the man in the photo. This man is a person of interest and they are not sure whether he is in Australia or overseas.\" }',\n",
       " '{ \"startOffset\": 424, \"endOffset\": 440, \"chapterSummary\": \"Zoran Stanojevic, the victim’s former husband, is a person of interest and they are going to hold an inquest because of the inconsistencies in his story.\" }',\n",
       " '{ \"startOffset\": 440, \"endOffset\": 456, \"chapterSummary\": \"Suellen Simpson has been through a lot for the past 30 years, but she is not giving up on finding answers.\" }',\n",
       " '{ \"startOffset\": 456, \"endOffset\": 472, \"chapterSummary\": \"The police are looking for witnesses to provide information about the man in the photo. He is someone who Zoran may have gone to for help after Revel went missing.\" }',\n",
       " '{ \"startOffset\": 472, \"endOffset\": 480, \"chapterSummary\": \"The police are asking for witnesses to come forward so that they can understand what happened. They value any information.\" }']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapters_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d7cdb332-15f9-4bd6-bc26-3dd4a43553a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 120\n",
      "120 240\n"
     ]
    }
   ],
   "source": [
    "prev=0\n",
    "for val in range (video_segments,video_duration+video_segments,video_segments):\n",
    "                startOffset=prev\n",
    "                endOffset=val\n",
    "                prev=val  \n",
    "                print(startOffset,endOffset )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "f20cd584-4b7c-4fbe-93e1-de623d05d73c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "250f62ee-fd0e-48a7-8ab8-4038079bea3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\n",
      "    \"startOffset\": 0,\n",
      "    \"endOffset\": 16,\n",
      "    \"chapterSummary\": \"A black and white photo of a young blonde woman with a black top is shown. She appears to be in her 20s and is looking directly at the camera.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 16,\n",
      "    \"endOffset\": 32,\n",
      "    \"chapterSummary\": \"A woman is talking about how she felt when her sister went missing. She says she was hysterical and worried about her.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 32,\n",
      "    \"endOffset\": 48,\n",
      "    \"chapterSummary\": \"A woman is talking about the evidence they found that scared her. She says it was her sister's possessions that were found so quickly after she went missing.  \"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 48,\n",
      "    \"endOffset\": 64,\n",
      "    \"chapterSummary\": \"A man is being interviewed about the disappearance of the woman in the photo.  He is asked why the police were wondering who was responsible for her disappearance after all these years. The man is evasive, and says that he doesn’t know how they could still be wondering that. \"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 64,\n",
      "    \"endOffset\": 80,\n",
      "    \"chapterSummary\": \"The woman who is talking about her sister’s disappearance says that the man in the interview is lying.  She says that it is the fact that her sister’s possessions were found so quickly after she went missing that made it clear that something was terribly wrong. \"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 80,\n",
      "    \"endOffset\": 96,\n",
      "    \"chapterSummary\": \"The man who is being interviewed about the disappearance of the woman in the photo continues to be evasive, but he does admit that a new investigation is being done into the case. \"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 96,\n",
      "    \"endOffset\": 112,\n",
      "    \"chapterSummary\": \"The woman who is talking about her sister’s disappearance says she was beside herself when she was told about her sister’s disappearance, and that she felt like she was going to break into a million pieces.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 112,\n",
      "    \"endOffset\": 120,\n",
      "    \"chapterSummary\": \"The woman who is talking about her sister’s disappearance says it was the fact that her sister’s possessions were found so quickly after she went missing that made it clear that something was terribly wrong.\"\n",
      "  }\n",
      " {\n",
      "    \"startOffset\": 120,\n",
      "    \"endOffset\": 136,\n",
      "    \"chapterSummary\": \"A woman named Jane King ran an escort agency with her husband Zoran. King speaks to the camera and describes the day her escort worker Revel went missing.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 136,\n",
      "    \"endOffset\": 152,\n",
      "    \"chapterSummary\": \"King describes the discovery of Revel's possessions that made her worried.  She also recalls the moment she learned that her sister was missing.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 152,\n",
      "    \"endOffset\": 168,\n",
      "    \"chapterSummary\": \"King describes the escort agency and her husband and  that Zoran was the prime suspect, but never charged. He changed his story about being home with a pregnant Jane on the night she went missing.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 168,\n",
      "    \"endOffset\": 184,\n",
      "    \"chapterSummary\": \"King continues to talk about Zoran's alibi that does not match phone records. King says she did not believe his story.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 184,\n",
      "    \"endOffset\": 200,\n",
      "    \"chapterSummary\": \"King says she and her husband were at the restaurant early that night, before the escort agency worker went missing.  A man named Boyan is mentioned in connection to the case. The case remains unsolved.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 200,\n",
      "    \"endOffset\": 216,\n",
      "    \"chapterSummary\": \"King speaks to a reporter about the case.  They are at a site where a billboard was located that had photos of the escort worker.  She was on a magazine cover just days before going missing.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 216,\n",
      "    \"endOffset\": 240,\n",
      "    \"chapterSummary\": \"King describes why she thinks the original investigation did not go far enough. She states she never thought Zoran had anything to do with Revel's disappearance.\"\n",
      "  }\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "chapters=[]\n",
    "for response in responses:\n",
    "    response=response.replace('```json\\n[\\n ','').replace('\\n]\\n```','') \n",
    "    chapter=''\n",
    "    for char in response:\n",
    "        chapter=chapter+char\n",
    "        if \"}\" in char:\n",
    "            #item.replace(\"{\",'')\n",
    "            chapter =chapter.replace(',\\n  {','\\n  {')\n",
    "            chapters.append(yaml.safe_load(chapter))\n",
    "            print(chapter)\n",
    "            chapter=''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f53c0ad8-89c2-4d2a-a996-bbe955ab7cc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "video_file=\"gs://raw_nine_files/60MI23_33_A_HBB.mp4\"\n",
    "def get_video_summarycontent( video_file: str = None,startOffset: int=0, endOffset: int=120, intervals: int=16):\n",
    "        \n",
    "         '''\n",
    "         Gimini Features for Video as per:https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/video-understanding\n",
    "         gemini-1.5-flash, Gemini 1.5 Pro: \n",
    "         With audio: ~50 minutes\n",
    "         Without audio: 60 minutes\n",
    "         Maximum videos per prompt: 10\n",
    "         \n",
    "         Gemini 1.0 Pro Vision:\n",
    "         Maximum video length: 2 minutes\n",
    "         The maximum videos per prompt: 1\n",
    "         Audio in the video is ignored.\n",
    "         \n",
    "         Gimini feature for Part as per:https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#sample-requests\n",
    "        '''\n",
    "        \n",
    "\n",
    " \n",
    "         generative_multimodal_model= GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "         # Please only capture key events and highlights.\n",
    "        \n",
    "         video_description_prompt=f\"\"\"You are an assistant tasked with summarizing videos for retrieval.\\\n",
    "         These summaries will be embedded and used to retrieve the raw video.\\\n",
    "        Chapterize the video content by grouping the video content into chapters \\\n",
    "        with intervals of {intervals} seconds and providing a concise summary for each chapter that is well optimized for retrieval.\\\n",
    "        If there is a famous person like politician, celebrity or athlete, indicate their name and describe what they are famous for.\\\n",
    "        If you are not sure about any info, please do not make it up. \\\n",
    "        Only consider video from {startOffset} seconds to {endOffset} seconds. Ignore analyzing the rest of video.\\\n",
    "        Return the result in the JSON format with keys as follows : \"startOffset\",\"endOffset\", \"chapterSummary\".\\\n",
    "        If it is the last chapter, set the endOffset to {endOffset} instead.\\\n",
    "       \"\"\"\n",
    "\n",
    "        \n",
    "         generation_config= GenerationConfig(temperature=1, top_k=40,top_p=0.95,max_output_tokens=8192) \n",
    "         \n",
    "        #for video, BLOCK_NONE gives error. So, have to set it to BLOCK_ONLY_HIGH\n",
    "         safety_settings=  {\n",
    "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    }\n",
    "         stream=True\n",
    "        \n",
    "         # Load the saved video as a Gemini Part Object\n",
    "          \n",
    "         contents=[GenerativeModelPart.from_uri(video_file,mime_type=\"video/mp4\"),\n",
    "                   video_description_prompt,]\n",
    "        \n",
    "        \n",
    "         response = generative_multimodal_model.generate_content(\n",
    "            contents,\n",
    "            generation_config=generation_config,\n",
    "            stream=stream,\n",
    "            safety_settings=safety_settings, )\n",
    "        \n",
    "        \n",
    "         response_list = []\n",
    "\n",
    "         for chunk in response:\n",
    "            try:\n",
    "                response_list.append(chunk.text)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    \"Exception occurred while calling gemini. Something is wrong. Lower the safety thresholds [safety_settings: BLOCK_NONE ] if not already done. -----\",\n",
    "                    e,\n",
    "                )\n",
    "                response_list.append(\"Exception occurred\")\n",
    "                continue\n",
    "         response = \"\".join(response_list)\n",
    "        \n",
    "         chapters_text=re.findall(r\"\\{.*?\\}\", response.replace('\\n',''))\n",
    "         chapters=[]\n",
    "         for chapter in chapters_text:\n",
    "            chapters.append(yaml.safe_load(chapter))\n",
    " \n",
    "         return response,chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feed633f-4307-48de-b8d8-79b638be35c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "ss=re.findall(r\"\\{.*?\\}\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3fca16-464a-4355-ae03-7323b733d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml.safe_load(chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7d4c421-188e-4834-a292-7cde738f26f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res,chapters=get_video_summarycontent(video_file=video_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1abf8546-76cb-4f7d-8528-5c86db105cea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'startOffset': 0,\n",
       "  'endOffset': 16,\n",
       "  'chapterSummary': 'A black and white photo of a young woman with long hair staring at the camera is displayed.'},\n",
       " {'startOffset': 16,\n",
       "  'endOffset': 32,\n",
       "  'chapterSummary': 'A woman with blond hair speaks about the disappearance of her sister, Revel, and how it was a terrifying experience because she was everywhere and nowhere at the same time.'},\n",
       " {'startOffset': 32,\n",
       "  'endOffset': 48,\n",
       "  'chapterSummary': \"The video explores the discovery of Revel's possessions, which included a bag, shoes, and a diary, and how this evidence was critical to the investigation.\"},\n",
       " {'startOffset': 48,\n",
       "  'endOffset': 64,\n",
       "  'chapterSummary': \"The video continues to delve into the investigation and reveals shocking new details about the night Revel went missing. It also introduces the key figure, Jane King, who was Revel's boss and ran an escort agency with her husband, Zoran.\"},\n",
       " {'startOffset': 64,\n",
       "  'endOffset': 80,\n",
       "  'chapterSummary': \"The video highlights the inconsistencies in Zoran's story, particularly regarding his whereabouts on the night Revel disappeared.\"},\n",
       " {'startOffset': 80,\n",
       "  'endOffset': 96,\n",
       "  'chapterSummary': 'The video focuses on the new evidence that has emerged in the case and how it is changing the entire focus of the investigation. It also introduces the name of the person of interest, Gavin Sama.'},\n",
       " {'startOffset': 96,\n",
       "  'endOffset': 112,\n",
       "  'chapterSummary': \"The video describes the ongoing investigation and the hope that the new evidence will help solve the case.  It also mentions that Zoran has changed his story several times and hasn't been able to verify his whereabouts.\"},\n",
       " {'startOffset': 112,\n",
       "  'endOffset': 120,\n",
       "  'chapterSummary': \"The video concludes by emphasizing the importance of finding answers for Revel's family and the ongoing need for anyone with information to come forward and contact the police.\"}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5e1d236-9148-4ba4-a526-03adf91b55c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res1='{ \"startOffset\": 0, \"endOffset\": 16, \"chapterSummary\": \"A black and white photo of a woman looking into the camera with long blonde hair and heavy makeup is shown. The 60 Minutes logo is shown in the bottom left corner of the screen. \"},{ \"startOffset\": 16, \"endOffset\": 32, \"chapterSummary\": \"A woman with blonde hair and a black blazer is talking about a missing person, Revele Belmaine. She says Revele was a model and dancer. She says she was hysterical with worry. \"}'\n",
    "chapters_text=re.findall(r\"\\{.*?\\}\", res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0fb7ea8c-3333-4f32-9357-e7bc6fd2e312",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chapters_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76a267ff-bf5f-4f53-b88f-e2f206a992ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"startOffset\": 0, \"endOffset\": 16, \"chapterSummary\": \"A black and white photo of a woman looking into the camera with long blonde hair and heavy makeup is shown. The 60 Minutes logo is shown in the bottom left corner of the screen. \"}\n",
      "-------------------\n",
      "{ \"startOffset\": 16, \"endOffset\": 32, \"chapterSummary\": \"A woman with blonde hair and a black blazer is talking about a missing person, Revele Belmaine. She says Revele was a model and dancer. She says she was hysterical with worry. \"}\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "chapters=[]\n",
    "\n",
    "for chapter in chapters_text:\n",
    "               \n",
    "                print(chapter)\n",
    "                print('-------------------')\n",
    "                chapters.append(yaml.safe_load(chapter))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce147c78-3e80-46a9-b3ca-77c328c458b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapters[0]['endOffset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "783e7640-ac2c-48a6-83eb-bd72a2e100d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\n",
      "    \"startOffset\": 120,\n",
      "    \"endOffset\": 136,\n",
      "    \"chapterSummary\": \"The program focuses on the case of Rebel Belmaine, a model and dancer who disappeared in 1994. Her last client, Gavin Sejmer, is under renewed scrutiny. Sejmer claimed he wasn't working the night of Rebel's disappearance and told police that he dropped her at a nearby pub.  However, the discovery of the young woman's bag, shoes, and diary discarded near his home prompted an investigation.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 136,\n",
      "    \"endOffset\": 152,\n",
      "    \"chapterSummary\": \"New evidence has been discovered that raises new questions about the disappearance of Rebel Belmaine. Her former boss, Jane King, who ran the escort agency with her then-husband Zoran Stanojevic, said that her husband lied about his whereabouts and was not home the night Rebel disappeared.  King also says that police never verified Stanojevic's alibi.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 152,\n",
      "    \"endOffset\": 168,\n",
      "    \"chapterSummary\": \"Jane King and her family have lived with grief and uncertainty for years because they didn't know what happened to Rebel. She said she was beside herself when she was told that her sister was missing. It wasn't until her husband's possessions were found near his home that King's family felt like something was terribly wrong and a new investigation was warranted.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 168,\n",
      "    \"endOffset\": 184,\n",
      "    \"chapterSummary\": \"King said that her husband's alibi didn't match phone records from the night of Rebel's disappearance. She said she would have thought someone would have come forward with answers after her sister's belongings were found near her husband's home, but they never did.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 184,\n",
      "    \"endOffset\": 200,\n",
      "    \"chapterSummary\": \"The new evidence, not found during the initial investigation, has given police new leads.  Jane King said that the police never verified her husband's alibi, and that is why police are conducting a new inquiry.  The police have also received information that suggests that Gavin Sejmer may be involved in Rebel's disappearance.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 200,\n",
      "    \"endOffset\": 216,\n",
      "    \"chapterSummary\": \"King said that the police should have conducted a more thorough investigation into the missing person case, and that there was no way she would ever believe that her husband had something to do with the disappearance of her sister.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 216,\n",
      "    \"endOffset\": 232,\n",
      "    \"chapterSummary\": \"The program continues to follow the case of the missing model, Rebel Belmaine, who disappeared in 1994.  Police have uncovered new evidence that suggests a new direction in the investigation.  Police are looking at Zoran Stanojevic, the former husband of Rebel's former boss, Jane King.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 232,\n",
      "    \"endOffset\": 240,\n",
      "    \"chapterSummary\": \"The program continues to discuss the mystery surrounding Rebel Belmaine's disappearance, and how new evidence has been found.  One of the possible new suspects in the investigation is Gavin Sejmer, the person who Rebel was last known to have been with.\"\n",
      "  }\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "x=response.text.replace('```json\\n[\\n ','').replace('\\n]\\n```','') \n",
    "\n",
    "item=''\n",
    "items=[]\n",
    "for c in x:\n",
    "    item=item+c\n",
    "    if \"}\" in c:\n",
    "        #item.replace(\"{\",'')\n",
    "        item =item.replace(',\\n  {','\\n  {')\n",
    "        items.append(yaml.safe_load(item))\n",
    "        print(item)\n",
    "        item=''\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "919540b4-7d33-4123-9197-16465052871a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{ \"a\": 1, \"b\": 2,\"c\":\"asknasnlsnd\"}', '{ kashkha}']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=', { \"a\": 1, \\\n",
    "\"b\": 2,\\\n",
    "\"c\":\"asknasnlsnd\"\\\n",
    "}\\\n",
    ",\\\n",
    "{ kashkha}'\n",
    "import re\n",
    "ss=re.findall(r\"\\{.*?\\}\", s)\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "cc40b8fc-aeba-45df-9377-1cfbceed5e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x='{ce are finally close to solving the case.\"\\n},\\n'\n",
    "oo=[]\n",
    "if x.count(\"}\\n]\\n```\")==0:\n",
    " \n",
    "    for s in reversed(x):\n",
    "        if s !='{' and s!='}':\n",
    "            oo.append(s)\n",
    "        else:\n",
    "            oo.append(s)\n",
    "            oo.append(\"\\n,\")\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190401dc-00a4-4d0e-927d-b41ed0a54c05",
   "metadata": {},
   "source": [
    "### Defining encoding functions\n",
    "Create an EmbeddingPredictionClient which encapsulates the logic to call the embedding API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2909bb5d-edfb-4921-ba30-450df70aa1b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'google.cloud.aiplatform_v1beta1.types.content' from '/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform_v1beta1/types/content.py'>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part ,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory \n",
    ")\n",
    "\n",
    "from google.cloud.aiplatform_v1beta1.types import (\n",
    "    content as gapic_content_types,\n",
    ")\n",
    "gapic_content_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "90dc1b9d-a545-41d4-9a4a-912228ecfc77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HarmBlockMethod',\n",
       " 'HarmBlockThreshold',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__base__',\n",
       " '__bases__',\n",
       " '__basicsize__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dictoffset__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__flags__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__instancecheck__',\n",
       " '__itemsize__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__mro__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__prepare__',\n",
       " '__qualname__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__ror__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasscheck__',\n",
       " '__subclasses__',\n",
       " '__subclasshook__',\n",
       " '__text_signature__',\n",
       " '__weakrefoffset__',\n",
       " 'copy_from',\n",
       " 'deserialize',\n",
       " 'from_json',\n",
       " 'meta',\n",
       " 'mro',\n",
       " 'pb',\n",
       " 'serialize',\n",
       " 'to_dict',\n",
       " 'to_json',\n",
       " 'wrap']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(gapic_content_types.SafetySetting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a2ad50c-4171-4375-ad84-977710db7a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import time\n",
    "import typing\n",
    "import math\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.protobuf import struct_pb2\n",
    "\n",
    "#libraries to generate image summaries\n",
    "from vertexai.vision_models import Video\n",
    "from vertexai.vision_models import VideoSegmentConfig\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.vision_models import Image as vision_model_Image\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part as GenerativeModelPart,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    "    model_response.prompt_feedback.block_reason.value\n",
    ")\n",
    "from typing import Any, Dict, List, Literal, Optional, Union\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "text_embedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@latest\")\n",
    "#multimodal_embedding_model = MultiModalEmbeddingModel.from_pretrained(\n",
    " #   \"multimodalembedding@001\"\n",
    "#)\n",
    "intervals=120\n",
    "max_duration=120#math.ceil(2719.04)#\n",
    "\n",
    "\n",
    "class VideoEmbedding:\n",
    "    \"\"\"Embeddings generated from video with offset times.\"\"\"\n",
    "\n",
    "    __module__ = \"vertexai.vision_models\"\n",
    "\n",
    "    start_offset_sec: int\n",
    "    end_offset_sec: int\n",
    "    embedding: List[float]\n",
    "\n",
    "    def __init__(\n",
    "        self, start_offset_sec: int, end_offset_sec: int, embedding: List[float]\n",
    "    ):\n",
    "        \"\"\"Creates a `VideoEmbedding` object.\n",
    "\n",
    "        Args:\n",
    "            start_offset_sec: Start time offset (in seconds) of generated embeddings.\n",
    "            end_offset_sec: End time offset (in seconds) of generated embeddings.\n",
    "            embedding: Generated embedding for interval.\n",
    "        \"\"\"\n",
    "        self.start_offset_sec = start_offset_sec\n",
    "        self.end_offset_sec = end_offset_sec\n",
    "        self.embedding = embedding\n",
    "        \n",
    "class EmbeddingResponse(typing.NamedTuple):\n",
    "    text_embedding: typing.Sequence[float]\n",
    "    video_embedding: typing.Sequence[VideoEmbedding]\n",
    "       \n",
    "        \n",
    "def load_video_bytes(video_uri: str) -> bytes:\n",
    "    \"\"\"Load image bytes from a remote or local URI.\"\"\"\n",
    "    video_bytes = None\n",
    "    if video_uri.startswith(\"http://\") or video_uri.startswith(\"https://\") or video_uri.startswith(\"gs://\"):\n",
    "        video_uri=video_uri.replace(\"gs://\", \"https://storage.googleapis.com/\").replace(\n",
    "        \" \", \"%20\")\n",
    "            \n",
    "        response = requests.get(video_uri, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            video_bytes = response.content\n",
    "    else:\n",
    "        video_bytes = open(video_uri, \"rb\").read()\n",
    "        \n",
    "\n",
    "    return video_bytes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_video_duration(video_uri):\n",
    "  try:\n",
    "    \n",
    "    if video_uri.startswith(\"http://\") or video_uri.startswith(\"https://\") or video_uri.startswith(\"gs://\"):\n",
    "        video_uri=video_uri.replace(\"gs://\", \"https://storage.googleapis.com/\").replace(\n",
    "        \" \", \"%20\")\n",
    "        \n",
    "    clip = VideoFileClip(video_uri)\n",
    "    duration = clip.duration\n",
    "    clip.close()  # Release resources\n",
    "    return duration\n",
    "  except OSError as e:\n",
    "    if \"moov atom not found\" in str(e):\n",
    "      print(\"Error: The video file seems to be corrupted or incomplete.\")\n",
    "      #To Do: fix this\n",
    "      #fix the issue using \n",
    "      ##!MP4Box -inter 0  'drive/MyDrive/Colab Notebooks/60MI23_33_A_HBB.mp4'\n",
    "      #for now\n",
    "      return max_duration\n",
    "    else:\n",
    "      print(f\"Error reading video file: {e}\")\n",
    "    return None\n",
    "\n",
    "    \n",
    "class EmbeddingPredictionClient:\n",
    "    \"\"\"Wrapper around Prediction Service Client.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        project: str,\n",
    "        location: str = \"us-central1\",\n",
    "        api_regional_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "    ):\n",
    "        client_options = {\"api_endpoint\": api_regional_endpoint}\n",
    "        # Initialize client that will be used to create and send requests.\n",
    "        # This client only needs to be created once, and can be reused for multiple requests.\n",
    "        self.client = aiplatform.gapic.PredictionServiceClient(\n",
    "            client_options=client_options\n",
    "        )\n",
    "        self.location = location\n",
    "        self.project = project\n",
    "\n",
    "    \n",
    "    def get_embedding(self, text: str = None, video_file: str = None  ):\n",
    "        if not text and not video_file:\n",
    "            raise ValueError(\"At least one of text or video_file must be specified.\")\n",
    "\n",
    " \n",
    "        # Load video file\n",
    "        video_bytes = None\n",
    "        if video_file:           \n",
    "            video_bytes = load_video_bytes(video_file)\n",
    "\n",
    "        instance ={}\n",
    "        if text:\n",
    "            instance[\"text\"] = text\n",
    "\n",
    "        if video_bytes:             \n",
    "                     \n",
    "            encoded_content = base64.b64encode(video_bytes).decode(\"utf-8\")\n",
    "            instance[\"video\"] = {\n",
    "                    \"bytesBase64Encoded\": encoded_content # pylint: disable=protected-access\n",
    "                }  # pylint: disable=protected-access\n",
    "            #get video duration\n",
    "            #as the files are incomplete, for now set it fix\n",
    "            video_duration=math.ceil(get_video_duration(video_file))\n",
    "\n",
    "\n",
    "        endpoint = (\n",
    "           f\"projects/{self.project}/locations/{self.location}\"\n",
    "           \"/publishers/google/models/multimodalembedding@001\"\n",
    "        )\n",
    "\n",
    "        #response =self.client.predict(endpoint=endpoint, instances=instances)\n",
    "\n",
    "        text_embedding = None\n",
    "        if text:\n",
    "            instances = [instance]\n",
    "            response =self.client.predict(endpoint=endpoint, instances=instances)\n",
    "            text_emb_value = response.predictions[0][\"textEmbedding\"]\n",
    "            text_embedding = [v for v in text_emb_value]\n",
    "\n",
    "         \n",
    "        video_embedding = None\n",
    "        if video_bytes:\n",
    "            video_embeddings = []  \n",
    "            prev=0\n",
    "            #iterate over the file and get embeddings of the whole file\n",
    "            for val in range (intervals,video_duration+intervals,intervals):\n",
    "                offset={'start':prev, 'end':val}\n",
    "                prev=val    \n",
    "                print(offset)\n",
    "                video_segments=VideoSegmentConfig(start_offset_sec=offset['start'],end_offset_sec=offset['end'])\n",
    "\n",
    "                if video_segments:\n",
    "                    instance[\"video\"][\"videoSegmentConfig\"] = {\n",
    "                            \"startOffsetSec\": video_segments.start_offset_sec,\n",
    "                            \"endOffsetSec\": video_segments.end_offset_sec,\n",
    "                            \"intervalSec\": video_segments.interval_sec,\n",
    "                        }\n",
    "                \n",
    "                instances = [instance]\n",
    "                response =self.client.predict(endpoint=endpoint, instances=instances)\n",
    "                for video_embedding in response.predictions[0].get(\"videoEmbeddings\", []):\n",
    "                    video_embeddings.append(\n",
    "                        VideoEmbedding(\n",
    "                            embedding=video_embedding[\"embedding\"],\n",
    "                            start_offset_sec=video_embedding[\"startOffsetSec\"],\n",
    "                            end_offset_sec=video_embedding[\"endOffsetSec\"],\n",
    "                        )\n",
    "                    )\n",
    "                # video_embeddings.append(\n",
    "                #         VideoEmbedding(\n",
    "                #             embedding=[1,2,3],\n",
    "                #             start_offset_sec=video_segments.start_offset_sec,\n",
    "                #             end_offset_sec=video_segments.end_offset_sec,\n",
    "                #         )\n",
    "                #     )\n",
    "\n",
    "                \n",
    "        return EmbeddingResponse (text_embedding=text_embedding, video_embedding=video_embeddings)\n",
    " \n",
    "   \n",
    "   \n",
    "    def get_video_summarycontent(self, text: str = None, video_file: str = None):\n",
    "        \n",
    "         '''\n",
    "         Gimini Features for Video as per:https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/video-understanding\n",
    "         gemini-1.5-flash, Gemini 1.5 Pro: \n",
    "         With audio: ~50 minutes\n",
    "         Without audio: 60 minutes\n",
    "         Maximum videos per prompt: 10\n",
    "         \n",
    "         Gemini 1.0 Pro Vision:\n",
    "         Maximum video length: 2 minutes\n",
    "         The maximum videos per prompt: 1\n",
    "         Audio in the video is ignored.\n",
    "         \n",
    "         Gimini feature for Part as per:https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#sample-requests\n",
    "        '''\n",
    "        \n",
    "\n",
    " \n",
    "         generative_multimodal_model= GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "         # Please only capture key events and highlights.\n",
    "         video_description_prompt=\"\"\"You are an assistant tasked with summarizing videos for retrieval.\\\n",
    "         These summaries will be embedded and used to retrieve the raw video.\\\n",
    "        Chapterize the video content by grouping the video content into chapters \\\n",
    "        and providing a concise summary for each chapter that is well optimized for retrieval.\\\n",
    "        If there is a famous person like politician, celebrity or athlete, indicate their name and describe what they are famous for.\\\n",
    "        If you are not sure about any info, please do not make it up. \\\n",
    "        Return the result in the JSON format with keys as follows : \"timecode\", \"chapterSummary\"\n",
    "        \"\"\"\n",
    "\n",
    "         generation_config= GenerationConfig(temperature=1, max_output_tokens=8192,TopK=40,TopP=0.95) \n",
    "        \n",
    "         safety_settings=  {\n",
    "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    }\n",
    "         stream=True\n",
    "        \n",
    "         # Load the saved video as a Gemini Part Object\n",
    "        \n",
    "         video_for_gemini=GenerativeModelPart.from_uri(video_file,mimeType='video/mp4')\n",
    "   \n",
    "         model_input=[video_description_prompt, video_for_gemini]\n",
    "        \n",
    "       \n",
    "        \n",
    "         response = generative_multimodal_model.generate_content(\n",
    "            model_input,\n",
    "            generation_config=generation_config,\n",
    "            stream=stream,\n",
    "            safety_settings=safety_settings, )\n",
    "        \n",
    "        \n",
    "         response_list = []\n",
    "\n",
    "         for chunk in response:\n",
    "            try:\n",
    "                response_list.append(chunk.text)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    \"Exception occurred while calling gemini. Something is wrong. Lower the safety thresholds [safety_settings: BLOCK_NONE ] if not already done. -----\",\n",
    "                    e,\n",
    "                )\n",
    "                response_list.append(\"Exception occurred\")\n",
    "                continue\n",
    "         response = \"\".join(response_list)\n",
    " \n",
    "         return response\n",
    "\n",
    "    \n",
    "    def get_summarycontent_embedding_from_text_embedding_model(self, text: str, return_array: Optional[bool] = False,) -> list:\n",
    "        \"\"\"\n",
    "        Generates a numerical text embedding from a provided text input using a text embedding model.\n",
    "\n",
    "        Args:\n",
    "            text: The input text string to be embedded.\n",
    "            return_array: If True, returns the embedding as a NumPy array.\n",
    "                          If False, returns the embedding as a list. (Default: False)\n",
    "\n",
    "        Returns:\n",
    "            list or numpy.ndarray: A 768-dimensional vector representation of the input text.\n",
    "                                   The format (list or NumPy array) depends on the\n",
    "                                   value of the 'return_array' parameter.\n",
    "        \"\"\"\n",
    "\n",
    "        #the given text is maximum 2048 token. If more, it has to be chunked.\n",
    "        embeddings = text_embedding_model.get_embeddings([text])\n",
    "        text_embedding = [embedding.values for embedding in embeddings][0]\n",
    "\n",
    "        if return_array:\n",
    "            text_embedding = np.fromiter(text_embedding, dtype=float)\n",
    "\n",
    "        # returns 768 dimensional array\n",
    "        return EmbeddingResponse(\n",
    "            text_embedding=text_embedding, image_embedding=None\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728cf6b-baeb-476a-a061-68c748a8dc6e",
   "metadata": {},
   "source": [
    "### Create helper functions to process data in batches\n",
    "Datasets can be large, so it's recommended to load a batch of data at a time into memory using a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e6f9ef7-0279-48f4-a576-3868ec14a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Callable, Generator, List,Tuple\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#Number of API calls per second\n",
    "API_IMAGES_PER_SECOND = 2\n",
    "\n",
    "def generate_batches(\n",
    "    inputs: List[str], batch_size: int\n",
    ") -> Generator[List[str], None, None]:\n",
    "    \"\"\"\n",
    "    Generator function that takes a list of strings and a batch size, and yields batches of the specified size.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(inputs), batch_size):\n",
    "        yield inputs [i : i + batch_size] \n",
    "\n",
    "\n",
    "\n",
    "def encode_to_embeddings_chunked(\n",
    "    process_function: Callable[[List[str]], List[Optional[List[float]]]],\n",
    "    items: str,\n",
    "    batch_size: int = 1,\n",
    ") -> List[Optional[List[float]]]:\n",
    "    \"\"\"\n",
    "    Function that encodes a list of strings into embeddings using a process function.\n",
    "    It takes a list of strings and returns a list of optional lists of floats.\n",
    "    The data is processed in chunks to prevent out-of-memory errors.\n",
    "    \"\"\"\n",
    "    \n",
    "    embeddings_list: List[Optional[List[float]]] = []\n",
    "\n",
    "    # Prepare the batches using a generator\n",
    "    batches = generate_batches(items, batch_size)\n",
    "    \n",
    "   \n",
    "    seconds_per_job = batch_size / API_IMAGES_PER_SECOND\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for batch in tqdm(batches, total=len(items) // batch_size, position=0):\n",
    "            futures.append(executor.submit(process_function, batch))\n",
    "            time.sleep(seconds_per_job)\n",
    "\n",
    "        for future in futures:\n",
    "            embeddings_list.extend(future.result())\n",
    "    return embeddings_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70084d60-e64f-4acf-b41d-07295141df90",
   "metadata": {},
   "source": [
    "### Create functions that wrap embedding functions in try-except and retry logic\n",
    "This particular embedding model can only process 1 image at a time, so inputs are validated to be equal to a length of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc24f964-09eb-4641-a0ed-2a9fc05247aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from tenacity import retry, stop_after_attempt\n",
    "\n",
    "client = EmbeddingPredictionClient(project=PROJECT_ID)\n",
    "\n",
    "\n",
    "# Use a retry handler in case of failure\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_texts_to_embeddings_with_retry(text: List[str]) -> List[List[float]]:\n",
    "    assert len(text) == 1\n",
    "\n",
    "    try:\n",
    "        return [client.get_embedding(text=text[0], image_file=None).text_embedding]\n",
    "    except Exception:\n",
    "        raise RuntimeError(\"Error getting embedding.\")\n",
    "\n",
    "\n",
    "def encode_texts_to_embeddings(text: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_texts_to_embeddings_with_retry(text=text)\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(text))]\n",
    "\n",
    "\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_videos_to_embeddings_with_retry(video_uris: List[str] ) -> List[List[float]]:\n",
    "    assert len(video_uris) == 1\n",
    "\n",
    "    try:\n",
    "        return [\n",
    "            client.get_embedding(text=None, video_file=video_uris[0] ).video_embedding\n",
    "        ]\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        raise RuntimeError(\"Error getting embedding for video.\")\n",
    "\n",
    "\n",
    "def encode_videos_to_embeddings(video_uris: List[str] ) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        \n",
    "        return encode_videos_to_embeddings_with_retry(video_uris=video_uris )\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return [None for _ in range(len(video_uris))]\n",
    "    \n",
    "\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_videos_to_summarycontent_with_retry(video_uris: List[str]) -> List[List[float]]:\n",
    "    assert len(image_uris) == 1\n",
    "\n",
    "    try:\n",
    "        return [\n",
    "            client.get_video_summarycontent(text=None, video_file=video_uris[0])\n",
    "        ]\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        raise RuntimeError(\"Error getting summaries.\")\n",
    "\n",
    "\n",
    "def encode_videos_to_summarycontent(video_uris: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_videos_to_summarycontent_with_retry(video_uris=video_uris)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return [None for _ in range(len(video_uris))]\n",
    "    \n",
    "    \n",
    "# Use a retry handler in case of failure\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_summarycontent_to_embeddings_with_retry(text: List[str]) -> List[List[float]]:\n",
    "    assert len(text) == 1\n",
    "\n",
    "    try:\n",
    "        return [client.get_summarycontent_embedding_from_text_embedding_model(text=text[0]).text_embedding]\n",
    "    except Exception:\n",
    "        raise RuntimeError(\"Error getting embedding for summary content.\")\n",
    "\n",
    "\n",
    "def encode_summarycontent_to_embeddings(text: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_summarycontent_to_embeddings_with_retry(text=text)\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(text))]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e9287-4332-4ac5-8d6a-4b6f2a24f0ff",
   "metadata": {},
   "source": [
    "### Create and save the embeddings in JSONL format\n",
    "The data must be formatted in JSONL format, which means each embedding dictionary is written as an individual JSON object on its own line.\n",
    "\n",
    "See more information in the docs at Input data format and structure.\n",
    "\n",
    "Run the following code in the next available cells, to create a temporary file to store embeddings in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aeb8b57-7ab4-490d-8a98-01f71f45d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile, shutil\n",
    "\n",
    "# Create temporary file to write embeddings to\n",
    "videoembeddings_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=False)\n",
    "\n",
    "# Create temporary file to write summaries to\n",
    "videosummaries_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25a08f1-1e9a-4c97-a0eb-624ce9d75165",
   "metadata": {},
   "source": [
    "### embedding file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a898f97e-a4c3-49b5-afae-9bfa7e1a05d8",
   "metadata": {},
   "source": [
    "### Video Embeddings in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a0e2eed2-d8ff-4d1f-b802-fdf099777d33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SampleVideo/highway_vehicles.mp4']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_paths_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de986c74-1704-4dbb-bc76-6e4493b61755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad0c2e7537840658420d01422db2244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c89c746dc5949d89f6dc035aaa61637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 0, 'end': 120}\n",
      "[[<vertexai.vision_models.VideoEmbedding object at 0x7ff06eff4df0>]]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "BATCH_SIZE = 1# this can be changed\n",
    " \n",
    "           \n",
    "with open(videoembeddings_file.name, \"a\") as ef:     \n",
    "         for i in tqdm(range(0, len(video_paths), BATCH_SIZE)):#len(image_names)\n",
    "            video_names_chunk = video_names[i : i + BATCH_SIZE]\n",
    "            video_paths_chunk = video_paths[i : i + BATCH_SIZE]\n",
    "            \n",
    "            \n",
    "            embeddings=[]\n",
    "            video_summaries=[]\n",
    "            #comment to prevent extra costs\n",
    "            #********************************\n",
    "            embeddings = encode_to_embeddings_chunked(\n",
    "                    process_function=encode_videos_to_embeddings, items=video_paths_chunk)                 \n",
    "            #********************************\n",
    "\n",
    "            #comment to prevent extra costs\n",
    "            #********************************\n",
    "            #summaries = encode_to_embeddings_chunked(\n",
    "                #process_function=encode_videos_to_summarycontent, items=video_paths_chunk\n",
    "               #)\n",
    "\n",
    "            #********************************\n",
    "            #summaries=[' The image shows three people: Joe Biden, a young girl, and Hunter Biden. Joe Biden is smiling and wearing a dark suit. The young girl is smiling and wearing a white dress. Hunter Biden is smiling and wearing a dark suit. The background is a photo of the White House.','this is test']\n",
    "\n",
    "            #comment to prevent extra costs\n",
    "            #********************************\n",
    "            #summaries_embeddings = encode_to_embeddings_chunked(\n",
    "                 #process_function=encode_summarycontent_to_embeddings, items=summaries\n",
    "            #)\n",
    "            #summaries_embeddings=[[1,2],[1,2,3]]\n",
    "\n",
    "            #********************************\n",
    "\n",
    "            print(embeddings)\n",
    "\n",
    "            # Append to file\n",
    "            embeddings_formatted=[]\n",
    "            for id,path,embedding in zip(video_names_chunk,video_paths_chunk,embeddings):\n",
    "                for value in embedding:\n",
    "                    if value.embedding is not None:\n",
    "                        embeddings_formatted.append(  \n",
    "                            json.dumps(\n",
    "                                {\n",
    "                                    \"id\": str(id), \n",
    "                                    \"video path\":str(path),\n",
    "                                    \"embedding\": [str(value) for value in value.embedding],\n",
    "                                    \"start_offset_sec\": value.start_offset_sec,\n",
    "                                    \"end_offset_sec\": value.end_offset_sec \n",
    "                                }\n",
    "                            )\n",
    "                            + \"\\n\"\n",
    "\n",
    "                        )\n",
    "            ef.writelines(embeddings_formatted)\n",
    "        \n",
    " \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb182a-2199-4b47-b844-65df08836758",
   "metadata": {},
   "source": [
    "### Create bucket and push embeddings into the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e5e18b-8a1c-4d1a-8013-d5ebd1a173cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#set bucket info to create a bucket\n",
    "BUCKET_URI = f\"gs://artifacts-{PROJECT_ID}-unique\"  # @param {type:\"string\"}\n",
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2354d-42f3-4b45-a387-c9f225f9b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIQUE_FOLDER_NAME = \"embeddings_results_NinePOC\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58369a05-16b4-4f93-b792-03b389544a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings\n",
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/{UNIQUE_FOLDER_NAME}/\"\n",
    "! gsutil cp {embeddings_file.name} {EMBEDDINGS_INITIAL_URI}\n",
    "\n",
    "#summaries\n",
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/{UNIQUE_FOLDER_NAME}/\"\n",
    "! gsutil cp {summaries_file.name} {EMBEDDINGS_INITIAL_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4fae7267-4f5f-43e7-a0fe-c39b4e0b9d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'summaries_file.json'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the temp files in persistent disk\n",
    "import tempfile, shutil\n",
    " \n",
    "file_name = embeddings_file.name\n",
    "embeddings_file.close()\n",
    "shutil.copy(file_name, 'embeddings_file.json')\n",
    "\n",
    "file_name = summaries_file.name\n",
    "summaries_file.close()\n",
    "shutil.copy(file_name, 'summaries_file.json')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe4468d-d92f-45cb-a3d0-9de84d8344be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
