{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a354f9-0984-4c94-9042-efb28db5f4be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.58.0)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.59.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (2.14.0)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.17.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.31.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.19.6)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (24.1)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.25.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.12.3)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.4)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.10.17)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.7.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.32.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.1)\n",
      "INFO: pip is looking at multiple versions of google-api-core[grpc] to determine which version is compatible with other requirements. This could take a while.\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.7)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.7.4)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
      "Downloading google_cloud_aiplatform-1.59.0-py2.py3-none-any.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-2.17.0-py2.py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: google-api-core, google-cloud-storage, google-cloud-aiplatform\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 1.34.1\n",
      "    Uninstalling google-api-core-1.34.1:\n",
      "      Successfully uninstalled google-api-core-1.34.1\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.14.0\n",
      "    Uninstalling google-cloud-storage-2.14.0:\n",
      "      Successfully uninstalled google-cloud-storage-2.14.0\n",
      "  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 1.58.0\n",
      "    Uninstalling google-cloud-aiplatform-1.58.0:\n",
      "      Successfully uninstalled google-cloud-aiplatform-1.58.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.19.1 which is incompatible.\n",
      "google-cloud-pubsub 2.21.4 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.48.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-api-core-2.11.1 google-cloud-aiplatform-1.59.0 google-cloud-storage-2.17.0\n",
      "Requirement already satisfied: google-cloud-vision in /opt/conda/lib/python3.10/site-packages (3.7.2)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2.11.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-vision) (2.31.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-vision) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-vision) (3.19.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.63.1)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.48.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (4.9)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "# Install the packages\n",
    "! pip3 install --upgrade google-cloud-aiplatform \\\n",
    "                         google-cloud-storage\n",
    "\n",
    "# Install the packages\n",
    "! pip install google-cloud-vision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895e40a3-1749-4b68-ac38-7e001f32a101",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-videointelligence in /opt/conda/lib/python3.10/site-packages (1.16.3)\n",
      "Collecting google-cloud-videointelligence\n",
      "  Downloading google_cloud_videointelligence-2.13.4-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2.11.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-videointelligence) (2.31.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-videointelligence) (1.24.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 (from google-cloud-videointelligence)\n",
      "  Downloading protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.63.1)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.48.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (4.9)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2024.7.4)\n",
      "Downloading google_cloud_videointelligence-2.13.4-py2.py3-none-any.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.0/245.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf, google-cloud-videointelligence\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: google-cloud-videointelligence\n",
      "    Found existing installation: google-cloud-videointelligence 1.16.3\n",
      "    Uninstalling google-cloud-videointelligence-1.16.3:\n",
      "      Successfully uninstalled google-cloud-videointelligence-1.16.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "apache-beam 2.46.0 requires grpcio!=1.48.0,<2,>=1.33.1, but you have grpcio 1.48.0 which is incompatible.\n",
      "apache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.11.1 which is incompatible.\n",
      "google-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-datastore 1.15.5 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-language 1.3.2 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-pubsub 2.21.4 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.48.0 which is incompatible.\n",
      "google-cloud-storage 2.17.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 2.11.1 which is incompatible.\n",
      "kfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.3 which is incompatible.\n",
      "kfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorboardx 2.6 requires protobuf<4,>=3.8.0, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-serving-api 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-cloud-videointelligence-2.13.4 protobuf-3.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-videointelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70639287-6593-462f-a952-cfa0605b29dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8162339b-0555-46c0-8271-a26fe9fe99a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set project info\n",
    "PROJECT = !gcloud config get-value project\n",
    "PROJECT_ID = PROJECT[0]\n",
    "REGION = \"us-central1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fb72555-1765-496b-ad6a-d8c7d3aff330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "video_directory = \"SampleVideo\"\n",
    "\n",
    "video_names=[]\n",
    "for file_name in os.listdir(video_directory):\n",
    "    if  not file_name.startswith('.'):\n",
    "        video_names.append(file_name)\n",
    "\n",
    "video_paths = [os.path.join(video_directory, video_name) for video_name in video_names]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6125a26-9f33-4c17-bd52-657233921201",
   "metadata": {},
   "source": [
    "### Define function to detect explicit images\n",
    "\n",
    "enable clound vision api before running this bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b070ae5-1f9e-430f-9fda-9e01bcee82b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.cloud.videointelligence.v1beta import SafeSearchAnnotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43fd0fed-43ad-4679-a484-5ee18231b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this has not been testes\n",
    "from google.cloud import videointelligence\n",
    "\n",
    "def analyze_video_safe_search(gcs_uri):\n",
    "    client = videointelligence.VideoIntelligenceServiceClient()\n",
    "    \n",
    "    # Configure the request\n",
    "    config = videointelligence.SafeSearchDetectionConfig()\n",
    "    context = videointelligence.VideoContext(\n",
    "        safe_search_detection_config=config\n",
    "    )\n",
    "    operation = client.annotate_video(\n",
    "        request={\"input_uri\": gcs_uri, \"features\": [videointelligence.Feature.SAFE_SEARCH_DETECTION], \"video_context\": context}\n",
    "    )\n",
    "    \n",
    "    # Wait for the operation to complete\n",
    "    result = operation.result(timeout=180)\n",
    "    \n",
    "    # Process the result\n",
    "    annotation_results = result.annotation_results[0]\n",
    "    for frame in annotation_results.safe_search_annotations:\n",
    "        print(f\"Time offset: {frame.time_offset.seconds}.{frame.time_offset.nanos // 1000000}s\")\n",
    "        print(f\"Adult: {videointelligence.Likelihood(frame.adult)}\")\n",
    "        print(f\"Violence: {videointelligence.Likelihood(frame.violence)}\")\n",
    "        print(f\"Racy: {videointelligence.Likelihood(frame.racy)}\")\n",
    "        print(f\"Medical: {videointelligence.Likelihood(frame.medical)}\")\n",
    "        print(f\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4839766e-611a-4f1b-b7eb-9f4ab6c03f41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for now the api is not active just to save costs. I set everything to true\n",
    "is_safe_values_cloud_vision=[True for i in range (len(video_paths))]\n",
    "is_safe_values_cloud_vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f555e1b5-65f5-4afb-a36b-d00a43d174f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter images by safety\n",
    "video_names = [\n",
    "    video_name\n",
    "    for video_name, is_safe in zip(video_names, is_safe_values_cloud_vision)\n",
    "    if is_safe\n",
    "]\n",
    "video_paths = [\n",
    "    video_path\n",
    "    for video_path, is_safe in zip(video_paths, is_safe_values_cloud_vision)\n",
    "    if is_safe\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a501aa-a4d2-4971-b0db-56de6cee03f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"contents\": {\n",
    "    \"role\": \"USER\",\n",
    "    \"parts\": [\n",
    "      {\n",
    "        \"fileData\": {\n",
    "          \"fileUri\": \"FILE_URI1\",\n",
    "          \"mimeType\": \"MIME_TYPE\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"TEXT1\"\n",
    "      },\n",
    "      {\n",
    "        \"fileData\": {\n",
    "          \"fileUri\": \"FILE_URI2\",\n",
    "          \"mimeType\": \"MIME_TYPE\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"TEXT2\"\n",
    "      },\n",
    "      {\n",
    "        \"fileData\": {\n",
    "          \"fileUri\": \"FILE_URI3\",\n",
    "          \"mimeType\": \"MIME_TYPE\"\n",
    "        }\n",
    "      },\n",
    "        \n",
    "        \"videoMetadata\": {\n",
    "            \"startOffset\": {\n",
    "              \"seconds\": integer,\n",
    "              \"nanos\": integer\n",
    "            },\n",
    "            \"endOffset\": {\n",
    "              \"seconds\": integer,\n",
    "              \"nanos\": integer\n",
    "            }\n",
    "        }\n",
    "            \n",
    "            \n",
    "    ]\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0ab397c-3dd3-4012-b502-f331fdc6d998",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'You are an assistant tasked with summarizing videos for retrieval.         These summaries will be embedded and used to retrieve the raw video.         Give a concise summary of the video that is well optimized for retrieval.',\n",
       " 'fileData': {'fileUri': 'gs://github-repo/embeddings/getting_started_embeddings/UCF-101-subset/BrushingTeeth/v_BrushingTeeth_g01_c02.mp4',\n",
       "  'mimeType': 'video/MP4'},\n",
       " 'videoMetadata': {'startOffset': {'seconds': 0, 'nanos': 0},\n",
       "  'endOffset': {'seconds': 4, 'nanos': 0}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e69ccea-7f02-46d8-999e-b745a70720f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " safety_settings = {\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1aa8899-e810-4958-98f9-86535108e40c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<HarmCategory.HARM_CATEGORY_HATE_SPEECH: 1>: <HarmBlockThreshold.BLOCK_ONLY_HIGH: 3>,\n",
       " <HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 2>: <HarmBlockThreshold.BLOCK_ONLY_HIGH: 3>,\n",
       " <HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 4>: <HarmBlockThreshold.BLOCK_ONLY_HIGH: 3>,\n",
       " <HarmCategory.HARM_CATEGORY_HARASSMENT: 3>: <HarmBlockThreshold.BLOCK_ONLY_HIGH: 3>}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "safety_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43093e8e-bd03-42f6-86c9-0cddf6022d93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7844fbf9-4ca1-40a1-ba14-8536cabd4bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "text= \"\"\"You are an assistant tasked with summarizing videos for retrieval. \\\n",
    "        These summaries will be embedded and used to retrieve the raw video. \\\n",
    "        Give a concise summary of the video for the given videometadata that is well optimized for retrieval.\"\"\"\n",
    "video_file=\"gs://cloud-samples-data/vertex-ai-vision/highway_vehicles.mp4\"\n",
    "if 1==1:\n",
    " \n",
    "        # Load video file\n",
    "        video_bytes = None\n",
    " \n",
    "\n",
    "        instance ={}\n",
    "        items={}\n",
    "       \n",
    "        items[\"role\"]= \"USER\"\n",
    "        if text:\n",
    "            items[\"text\"]= text\n",
    "\n",
    "        if video_file:             \n",
    "            items[\"fileData\"]= {\n",
    "                          \"fileUri\": video_file,\n",
    "                          \"mimeType\": \"video/MP4\"\n",
    "                        }\n",
    "            items[\"videoMetadata\"]= {\n",
    "\n",
    "                                \"startOffset\": {\n",
    "                                  \"seconds\": 0,\n",
    "                                  \"nanos\": 0\n",
    "                                },\n",
    "                                \"endOffset\": {\n",
    "                                  \"seconds\": 4,\n",
    "                                  \"nanos\": 0\n",
    "                                }\n",
    "            }\n",
    "            #as the files are incomplete, for now set it fix\n",
    "            video_duration=120\n",
    "            instance={}\n",
    "            instance[\"contents\"]={\"role\":\"USER\",\n",
    "\n",
    "                                  \"Parts\":[items],\n",
    "\n",
    "\n",
    "              \"generationConfig\": {\n",
    "                \"temperature\": 1,\n",
    "                \"topP\": 0.95, \n",
    "                \"maxOutputTokens\": 8192 \n",
    "              }\n",
    "            }\n",
    "\n",
    "          \n",
    "\n",
    "        endpoint = (\n",
    "           f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "           \"/publishers/google/models/gemini-1.5-flash@001\"\n",
    "        )\n",
    "\n",
    "        #response =self.client.predict(endpoint=endpoint, instances=instances)\n",
    "#client.predict(endpoint=endpoint, instances=instances)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44858b9b-3377-4cc9-a162-b121ff8252d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/nine-quality-test/locations/us-central1/publishers/google/models/gemini-1.5-flash@001'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "021d559a-836a-4886-a5ce-64a38de888b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = aiplatform.gapic.PredictionServiceClient  (\n",
    "            client_options=client_options\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ad32535-21b1-4c74-a631-3119cc973a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PredictionServiceClient.stream_generate_content() got an unexpected keyword argument 'endpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 13\u001b[0m\n\u001b[1;32m      6\u001b[0m client_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_endpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: api_regional_endpoint}\n\u001b[1;32m      8\u001b[0m client \u001b[38;5;241m=\u001b[39m aiplatform\u001b[38;5;241m.\u001b[39mgapic\u001b[38;5;241m.\u001b[39mPredictionServiceClient  (\n\u001b[1;32m      9\u001b[0m             client_options\u001b[38;5;241m=\u001b[39mclient_options\n\u001b[1;32m     10\u001b[0m         )\n\u001b[0;32m---> 13\u001b[0m response \u001b[38;5;241m=\u001b[39m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_generate_content\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: PredictionServiceClient.stream_generate_content() got an unexpected keyword argument 'endpoint'"
     ]
    }
   ],
   "source": [
    "endpoint = (\n",
    "           f\"projects/{PROJECT_ID}/locations/us-central1/publishers/google/models/gemini-1.5-flash-001\"\n",
    "        )\n",
    "    \n",
    "api_regional_endpoint= \"us-central1-aiplatform.googleapis.com\" \n",
    "client_options = {\"api_endpoint\": api_regional_endpoint}\n",
    "        \n",
    "client = aiplatform.gapic.PredictionServiceClient  (\n",
    "            client_options=client_options\n",
    "        )\n",
    "    \n",
    "\n",
    "response =client.stream_generate_content (endpoint=endpoint, parts=[instance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1214d6-0d71-4086-814f-491bf2a20437",
   "metadata": {},
   "outputs": [],
   "source": [
    " for val in range (240,video_duration+intervals,intervals):"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99773a1a-c930-4892-8fc6-57a05d3b53df",
   "metadata": {
    "tags": []
   },
   "source": [
    "import yaml\n",
    "    \n",
    "video_file = \"gs://github-repo/embeddings/getting_started_embeddings/UCF-101-subset/BrushingTeeth/v_BrushingTeeth_g01_c02.mp4\"\n",
    "video_file=\"gs://raw_nine_files/60MI23_33_A_HBB.mp4\"\n",
    "#video_file=\"gs://github-repo/embeddings/getting_started_embeddings/UCF-101-subset/BrushingTeeth/v_BrushingTeeth_g01_c02.mp4\"\n",
    " \n",
    "#def get_video_summarycontent( text: str = None, video_file: str = None):\n",
    "if 1==1:\n",
    "         '''\n",
    "         Gimini Features for Video as per:https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/video-understanding\n",
    "         gemini-1.5-flash, Gemini 1.5 Pro: \n",
    "         With audio: ~50 minutes\n",
    "         Without audio: 60 minutes\n",
    "         Maximum videos per prompt: 10\n",
    "         \n",
    "         Gemini 1.0 Pro Vision:\n",
    "         Maximum video length: 2 minutes\n",
    "         The maximum videos per prompt: 1\n",
    "         Audio in the video is ignored.\n",
    "         \n",
    "         Gimini feature for Part as per:https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#sample-requests\n",
    "        '''\n",
    "        \n",
    "\n",
    " \n",
    "         generative_multimodal_model= GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "         # Please only capture key events and highlights.\n",
    " \n",
    "         intervals=16\n",
    "         video_segments=120\n",
    "         prev=0\n",
    "         video_duration=240\n",
    "         #iterate over the file and get embeddings of the whole file\n",
    "         responses=[]\n",
    "         for val in range (video_segments,video_duration+video_segments,video_segments):\n",
    "                startOffset=prev\n",
    "                endOffset=val\n",
    "                prev=val  \n",
    "                print(startOffset,endOffset )\n",
    "               \n",
    "                video_description_prompt=f\"\"\"You are an assistant tasked with summarizing videos for retrieval.\\\n",
    "                 These summaries will be embedded and used to retrieve the raw video.\\\n",
    "                Chapterize the video content by grouping the video content into chapters \\\n",
    "                with intervals of {intervals} seconds and providing a concise summary for each chapter that is well optimized for retrieval.\\\n",
    "                If there is a famous person like politician, celebrity or athlete, indicate their name and describe what they are famous for.\\\n",
    "                If you are not sure about any info, please do not make it up. \\\n",
    "                Only consider video from {startOffset} seconds to {endOffset} seconds. Ignore analyzing the rest of video.\\\n",
    "                Return the result in the JSON format with keys as follows : \"startOffset\",\"endOffset\", \"chapterSummary\".\\\n",
    "                If it is the last chapter, set the endOffset to {endOffset} instead.\\  \n",
    "                \"\"\"\n",
    "\n",
    "                video_description_prompt1=f\"\"\"You are an assistant tasked with summarizing videos for retrieval.\\\n",
    "                 These summaries will be embedded and used to retrieve the raw video.\\\n",
    "                Chapterize the video content by grouping the video content into chapters \\\n",
    "                with intervals of {intervals} seconds and providing a concise summary for each chapter that is well optimized for retrieval.\\\n",
    "                If there is a famous person like politician, celebrity or athlete, indicate their name and describe what they are famous for.\\\n",
    "                If you are not sure about any info, please do not make it up. \\\n",
    "                If the length of the generated analysis is close to exceeding 8192 token, do not generate unfinished chapter.\\ \n",
    "                Return the result in the JSON format with keys as follows : \"startOffset\",\"endOffset\", \"chapterSummary\".\\\n",
    "                Also return the endOffset for the last generated chapter as \"lastProcessedOffset\".\\\n",
    "                Also return video length in seconds as \"videoDuration\".\n",
    "               \"\"\"\n",
    "\n",
    "                generation_config= GenerationConfig(temperature=1, top_k=40,top_p=0.95,max_output_tokens=8192) \n",
    "\n",
    "                safety_settings=  {\n",
    "                            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                            }\n",
    "                stream=True\n",
    "\n",
    "                 # Load the saved video as a Gemini Part Object\n",
    "\n",
    "\n",
    "\n",
    "                contents=[GenerativeModelPart.from_uri(video_file,mime_type=\"video/mp4\"),\n",
    "                           video_description_prompt,]\n",
    "\n",
    " \n",
    "                response = generative_multimodal_model.generate_content(\n",
    "                    contents,\n",
    "                    generation_config=generation_config,  \n",
    "                    stream=stream,\n",
    "                    safety_settings=safety_settings )\n",
    "                \n",
    "                response_list = []\n",
    "\n",
    "                for chunk in response:\n",
    "                            try:\n",
    "                                response_list.append(chunk.text)\n",
    "                            except Exception as e:\n",
    "                                print(\n",
    "                                    \"Exception occurred while calling gemini. Something is wrong. Lower the safety thresholds [safety_settings: BLOCK_NONE ] if not already done. -----\",\n",
    "                                    e,\n",
    "                                )\n",
    "                                response_list.append(\"Exception occurred\")\n",
    "                                continue\n",
    "                res= \"\".join(response_list)\n",
    "                print(res)\n",
    "                responses.append(res)\n",
    "\n",
    "        chapters=[]\n",
    "        for response in responses:\n",
    "            response=response.replace('```json\\n[\\n ','').replace('\\n]\\n```','') \n",
    "            chapter=''\n",
    "            for char in response:\n",
    "                chapter=chapter+char\n",
    "                if \"}\" in char:\n",
    "                    #item.replace(\"{\",'')\n",
    "                    chapter =chapter.replace(',\\n  {','\\n  {')\n",
    "                    chapters.append(yaml.safe_load(chapter))\n",
    "                    print(chapter)\n",
    "                    chapter=''\n",
    "        \n",
    "       \n",
    "chapters        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "7023158d-b1eb-43e7-91b2-6f6d30ed7566",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "216+16+16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "00673256-5cec-4750-8673-b0d3139129c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "232+16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d7cdb332-15f9-4bd6-bc26-3dd4a43553a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 120\n",
      "120 240\n"
     ]
    }
   ],
   "source": [
    "prev=0\n",
    "for val in range (video_segments,video_duration+video_segments,video_segments):\n",
    "                startOffset=prev\n",
    "                endOffset=val\n",
    "                prev=val  \n",
    "                print(startOffset,endOffset )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "f20cd584-4b7c-4fbe-93e1-de623d05d73c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "250f62ee-fd0e-48a7-8ab8-4038079bea3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\n",
      "    \"startOffset\": 0,\n",
      "    \"endOffset\": 16,\n",
      "    \"chapterSummary\": \"A black and white photo of a young blonde woman with a black top is shown. She appears to be in her 20s and is looking directly at the camera.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 16,\n",
      "    \"endOffset\": 32,\n",
      "    \"chapterSummary\": \"A woman is talking about how she felt when her sister went missing. She says she was hysterical and worried about her.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 32,\n",
      "    \"endOffset\": 48,\n",
      "    \"chapterSummary\": \"A woman is talking about the evidence they found that scared her. She says it was her sister's possessions that were found so quickly after she went missing.  \"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 48,\n",
      "    \"endOffset\": 64,\n",
      "    \"chapterSummary\": \"A man is being interviewed about the disappearance of the woman in the photo.  He is asked why the police were wondering who was responsible for her disappearance after all these years. The man is evasive, and says that he doesn’t know how they could still be wondering that. \"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 64,\n",
      "    \"endOffset\": 80,\n",
      "    \"chapterSummary\": \"The woman who is talking about her sister’s disappearance says that the man in the interview is lying.  She says that it is the fact that her sister’s possessions were found so quickly after she went missing that made it clear that something was terribly wrong. \"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 80,\n",
      "    \"endOffset\": 96,\n",
      "    \"chapterSummary\": \"The man who is being interviewed about the disappearance of the woman in the photo continues to be evasive, but he does admit that a new investigation is being done into the case. \"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 96,\n",
      "    \"endOffset\": 112,\n",
      "    \"chapterSummary\": \"The woman who is talking about her sister’s disappearance says she was beside herself when she was told about her sister’s disappearance, and that she felt like she was going to break into a million pieces.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 112,\n",
      "    \"endOffset\": 120,\n",
      "    \"chapterSummary\": \"The woman who is talking about her sister’s disappearance says it was the fact that her sister’s possessions were found so quickly after she went missing that made it clear that something was terribly wrong.\"\n",
      "  }\n",
      " {\n",
      "    \"startOffset\": 120,\n",
      "    \"endOffset\": 136,\n",
      "    \"chapterSummary\": \"A woman named Jane King ran an escort agency with her husband Zoran. King speaks to the camera and describes the day her escort worker Revel went missing.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 136,\n",
      "    \"endOffset\": 152,\n",
      "    \"chapterSummary\": \"King describes the discovery of Revel's possessions that made her worried.  She also recalls the moment she learned that her sister was missing.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 152,\n",
      "    \"endOffset\": 168,\n",
      "    \"chapterSummary\": \"King describes the escort agency and her husband and  that Zoran was the prime suspect, but never charged. He changed his story about being home with a pregnant Jane on the night she went missing.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 168,\n",
      "    \"endOffset\": 184,\n",
      "    \"chapterSummary\": \"King continues to talk about Zoran's alibi that does not match phone records. King says she did not believe his story.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 184,\n",
      "    \"endOffset\": 200,\n",
      "    \"chapterSummary\": \"King says she and her husband were at the restaurant early that night, before the escort agency worker went missing.  A man named Boyan is mentioned in connection to the case. The case remains unsolved.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 200,\n",
      "    \"endOffset\": 216,\n",
      "    \"chapterSummary\": \"King speaks to a reporter about the case.  They are at a site where a billboard was located that had photos of the escort worker.  She was on a magazine cover just days before going missing.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 216,\n",
      "    \"endOffset\": 240,\n",
      "    \"chapterSummary\": \"King describes why she thinks the original investigation did not go far enough. She states she never thought Zoran had anything to do with Revel's disappearance.\"\n",
      "  }\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "chapters=[]\n",
    "for response in responses:\n",
    "    response=response.replace('```json\\n[\\n ','').replace('\\n]\\n```','') \n",
    "    chapter=''\n",
    "    for char in response:\n",
    "        chapter=chapter+char\n",
    "        if \"}\" in char:\n",
    "            #item.replace(\"{\",'')\n",
    "            chapter =chapter.replace(',\\n  {','\\n  {')\n",
    "            chapters.append(yaml.safe_load(chapter))\n",
    "            print(chapter)\n",
    "            chapter=''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "f53c0ad8-89c2-4d2a-a996-bbe955ab7cc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'startOffset': 0,\n",
       "  'endOffset': 16,\n",
       "  'chapterSummary': 'A black and white photo of a young blonde woman with a black top is shown. She appears to be in her 20s and is looking directly at the camera.'},\n",
       " {'startOffset': 16,\n",
       "  'endOffset': 32,\n",
       "  'chapterSummary': 'A woman is talking about how she felt when her sister went missing. She says she was hysterical and worried about her.'},\n",
       " {'startOffset': 32,\n",
       "  'endOffset': 48,\n",
       "  'chapterSummary': \"A woman is talking about the evidence they found that scared her. She says it was her sister's possessions that were found so quickly after she went missing.  \"},\n",
       " {'startOffset': 48,\n",
       "  'endOffset': 64,\n",
       "  'chapterSummary': 'A man is being interviewed about the disappearance of the woman in the photo.  He is asked why the police were wondering who was responsible for her disappearance after all these years. The man is evasive, and says that he doesn’t know how they could still be wondering that. '},\n",
       " {'startOffset': 64,\n",
       "  'endOffset': 80,\n",
       "  'chapterSummary': 'The woman who is talking about her sister’s disappearance says that the man in the interview is lying.  She says that it is the fact that her sister’s possessions were found so quickly after she went missing that made it clear that something was terribly wrong. '},\n",
       " {'startOffset': 80,\n",
       "  'endOffset': 96,\n",
       "  'chapterSummary': 'The man who is being interviewed about the disappearance of the woman in the photo continues to be evasive, but he does admit that a new investigation is being done into the case. '},\n",
       " {'startOffset': 96,\n",
       "  'endOffset': 112,\n",
       "  'chapterSummary': 'The woman who is talking about her sister’s disappearance says she was beside herself when she was told about her sister’s disappearance, and that she felt like she was going to break into a million pieces.'},\n",
       " {'startOffset': 112,\n",
       "  'endOffset': 120,\n",
       "  'chapterSummary': 'The woman who is talking about her sister’s disappearance says it was the fact that her sister’s possessions were found so quickly after she went missing that made it clear that something was terribly wrong.'},\n",
       " {'startOffset': 120,\n",
       "  'endOffset': 136,\n",
       "  'chapterSummary': 'A woman named Jane King ran an escort agency with her husband Zoran. King speaks to the camera and describes the day her escort worker Revel went missing.'},\n",
       " {'startOffset': 136,\n",
       "  'endOffset': 152,\n",
       "  'chapterSummary': \"King describes the discovery of Revel's possessions that made her worried.  She also recalls the moment she learned that her sister was missing.\"},\n",
       " {'startOffset': 152,\n",
       "  'endOffset': 168,\n",
       "  'chapterSummary': 'King describes the escort agency and her husband and  that Zoran was the prime suspect, but never charged. He changed his story about being home with a pregnant Jane on the night she went missing.'},\n",
       " {'startOffset': 168,\n",
       "  'endOffset': 184,\n",
       "  'chapterSummary': \"King continues to talk about Zoran's alibi that does not match phone records. King says she did not believe his story.\"},\n",
       " {'startOffset': 184,\n",
       "  'endOffset': 200,\n",
       "  'chapterSummary': 'King says she and her husband were at the restaurant early that night, before the escort agency worker went missing.  A man named Boyan is mentioned in connection to the case. The case remains unsolved.'},\n",
       " {'startOffset': 200,\n",
       "  'endOffset': 216,\n",
       "  'chapterSummary': 'King speaks to a reporter about the case.  They are at a site where a billboard was located that had photos of the escort worker.  She was on a magazine cover just days before going missing.'},\n",
       " {'startOffset': 216,\n",
       "  'endOffset': 240,\n",
       "  'chapterSummary': \"King describes why she thinks the original investigation did not go far enough. She states she never thought Zoran had anything to do with Revel's disappearance.\"}]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "783e7640-ac2c-48a6-83eb-bd72a2e100d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\n",
      "    \"startOffset\": 120,\n",
      "    \"endOffset\": 136,\n",
      "    \"chapterSummary\": \"The program focuses on the case of Rebel Belmaine, a model and dancer who disappeared in 1994. Her last client, Gavin Sejmer, is under renewed scrutiny. Sejmer claimed he wasn't working the night of Rebel's disappearance and told police that he dropped her at a nearby pub.  However, the discovery of the young woman's bag, shoes, and diary discarded near his home prompted an investigation.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 136,\n",
      "    \"endOffset\": 152,\n",
      "    \"chapterSummary\": \"New evidence has been discovered that raises new questions about the disappearance of Rebel Belmaine. Her former boss, Jane King, who ran the escort agency with her then-husband Zoran Stanojevic, said that her husband lied about his whereabouts and was not home the night Rebel disappeared.  King also says that police never verified Stanojevic's alibi.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 152,\n",
      "    \"endOffset\": 168,\n",
      "    \"chapterSummary\": \"Jane King and her family have lived with grief and uncertainty for years because they didn't know what happened to Rebel. She said she was beside herself when she was told that her sister was missing. It wasn't until her husband's possessions were found near his home that King's family felt like something was terribly wrong and a new investigation was warranted.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 168,\n",
      "    \"endOffset\": 184,\n",
      "    \"chapterSummary\": \"King said that her husband's alibi didn't match phone records from the night of Rebel's disappearance. She said she would have thought someone would have come forward with answers after her sister's belongings were found near her husband's home, but they never did.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 184,\n",
      "    \"endOffset\": 200,\n",
      "    \"chapterSummary\": \"The new evidence, not found during the initial investigation, has given police new leads.  Jane King said that the police never verified her husband's alibi, and that is why police are conducting a new inquiry.  The police have also received information that suggests that Gavin Sejmer may be involved in Rebel's disappearance.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 200,\n",
      "    \"endOffset\": 216,\n",
      "    \"chapterSummary\": \"King said that the police should have conducted a more thorough investigation into the missing person case, and that there was no way she would ever believe that her husband had something to do with the disappearance of her sister.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 216,\n",
      "    \"endOffset\": 232,\n",
      "    \"chapterSummary\": \"The program continues to follow the case of the missing model, Rebel Belmaine, who disappeared in 1994.  Police have uncovered new evidence that suggests a new direction in the investigation.  Police are looking at Zoran Stanojevic, the former husband of Rebel's former boss, Jane King.\"\n",
      "  }\n",
      "\n",
      "  {\n",
      "    \"startOffset\": 232,\n",
      "    \"endOffset\": 240,\n",
      "    \"chapterSummary\": \"The program continues to discuss the mystery surrounding Rebel Belmaine's disappearance, and how new evidence has been found.  One of the possible new suspects in the investigation is Gavin Sejmer, the person who Rebel was last known to have been with.\"\n",
      "  }\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "x=response.text.replace('```json\\n[\\n ','').replace('\\n]\\n```','') \n",
    "\n",
    "item=''\n",
    "items=[]\n",
    "for c in x:\n",
    "    item=item+c\n",
    "    if \"}\" in c:\n",
    "        #item.replace(\"{\",'')\n",
    "        item =item.replace(',\\n  {','\\n  {')\n",
    "        items.append(yaml.safe_load(item))\n",
    "        print(item)\n",
    "        item=''\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "cc40b8fc-aeba-45df-9377-1cfbceed5e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x='{ce are finally close to solving the case.\"\\n},\\n'\n",
    "oo=[]\n",
    "if x.count(\"}\\n]\\n```\")==0:\n",
    " \n",
    "    for s in reversed(x):\n",
    "        if s !='{' and s!='}':\n",
    "            oo.append(s)\n",
    "        else:\n",
    "            oo.append(s)\n",
    "            oo.append(\"\\n,\")\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190401dc-00a4-4d0e-927d-b41ed0a54c05",
   "metadata": {},
   "source": [
    "### Defining encoding functions\n",
    "Create an EmbeddingPredictionClient which encapsulates the logic to call the embedding API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2ad50c-4171-4375-ad84-977710db7a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import time\n",
    "import typing\n",
    "import math\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.protobuf import struct_pb2\n",
    "\n",
    "#libraries to generate image summaries\n",
    "from vertexai.vision_models import Video\n",
    "from vertexai.vision_models import VideoSegmentConfig\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.vision_models import Image as vision_model_Image\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part as GenerativeModelPart,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n",
    "from typing import Any, Dict, List, Literal, Optional, Union\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "text_embedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@latest\")\n",
    "#multimodal_embedding_model = MultiModalEmbeddingModel.from_pretrained(\n",
    " #   \"multimodalembedding@001\"\n",
    "#)\n",
    "intervals=120\n",
    "max_duration=120#math.ceil(2719.04)#\n",
    "\n",
    "\n",
    "class VideoEmbedding:\n",
    "    \"\"\"Embeddings generated from video with offset times.\"\"\"\n",
    "\n",
    "    __module__ = \"vertexai.vision_models\"\n",
    "\n",
    "    start_offset_sec: int\n",
    "    end_offset_sec: int\n",
    "    embedding: List[float]\n",
    "\n",
    "    def __init__(\n",
    "        self, start_offset_sec: int, end_offset_sec: int, embedding: List[float]\n",
    "    ):\n",
    "        \"\"\"Creates a `VideoEmbedding` object.\n",
    "\n",
    "        Args:\n",
    "            start_offset_sec: Start time offset (in seconds) of generated embeddings.\n",
    "            end_offset_sec: End time offset (in seconds) of generated embeddings.\n",
    "            embedding: Generated embedding for interval.\n",
    "        \"\"\"\n",
    "        self.start_offset_sec = start_offset_sec\n",
    "        self.end_offset_sec = end_offset_sec\n",
    "        self.embedding = embedding\n",
    "        \n",
    "class EmbeddingResponse(typing.NamedTuple):\n",
    "    text_embedding: typing.Sequence[float]\n",
    "    video_embedding: typing.Sequence[VideoEmbedding]\n",
    "       \n",
    "        \n",
    "def load_video_bytes(video_uri: str) -> bytes:\n",
    "    \"\"\"Load image bytes from a remote or local URI.\"\"\"\n",
    "    video_bytes = None\n",
    "    if video_uri.startswith(\"http://\") or video_uri.startswith(\"https://\") or video_uri.startswith(\"gs://\"):\n",
    "        video_uri=video_uri.replace(\"gs://\", \"https://storage.googleapis.com/\").replace(\n",
    "        \" \", \"%20\")\n",
    "            \n",
    "        response = requests.get(video_uri, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            video_bytes = response.content\n",
    "    else:\n",
    "        video_bytes = open(video_uri, \"rb\").read()\n",
    "        \n",
    "\n",
    "    return video_bytes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_video_duration(video_uri):\n",
    "  try:\n",
    "    \n",
    "    if video_uri.startswith(\"http://\") or video_uri.startswith(\"https://\") or video_uri.startswith(\"gs://\"):\n",
    "        video_uri=video_uri.replace(\"gs://\", \"https://storage.googleapis.com/\").replace(\n",
    "        \" \", \"%20\")\n",
    "        \n",
    "    clip = VideoFileClip(video_uri)\n",
    "    duration = clip.duration\n",
    "    clip.close()  # Release resources\n",
    "    return duration\n",
    "  except OSError as e:\n",
    "    if \"moov atom not found\" in str(e):\n",
    "      print(\"Error: The video file seems to be corrupted or incomplete.\")\n",
    "      #To Do: fix this\n",
    "      #fix the issue using \n",
    "      ##!MP4Box -inter 0  'drive/MyDrive/Colab Notebooks/60MI23_33_A_HBB.mp4'\n",
    "      #for now\n",
    "      return max_duration\n",
    "    else:\n",
    "      print(f\"Error reading video file: {e}\")\n",
    "    return None\n",
    "\n",
    "    \n",
    "class EmbeddingPredictionClient:\n",
    "    \"\"\"Wrapper around Prediction Service Client.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        project: str,\n",
    "        location: str = \"us-central1\",\n",
    "        api_regional_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "    ):\n",
    "        client_options = {\"api_endpoint\": api_regional_endpoint}\n",
    "        # Initialize client that will be used to create and send requests.\n",
    "        # This client only needs to be created once, and can be reused for multiple requests.\n",
    "        self.client = aiplatform.gapic.PredictionServiceClient(\n",
    "            client_options=client_options\n",
    "        )\n",
    "        self.location = location\n",
    "        self.project = project\n",
    "\n",
    "    \n",
    "    def get_embedding(self, text: str = None, video_file: str = None  ):\n",
    "        if not text and not video_file:\n",
    "            raise ValueError(\"At least one of text or video_file must be specified.\")\n",
    "\n",
    " \n",
    "        # Load video file\n",
    "        video_bytes = None\n",
    "        if video_file:           \n",
    "            video_bytes = load_video_bytes(video_file)\n",
    "\n",
    "        instance ={}\n",
    "        if text:\n",
    "            instance[\"text\"] = text\n",
    "\n",
    "        if video_bytes:             \n",
    "                     \n",
    "            encoded_content = base64.b64encode(video_bytes).decode(\"utf-8\")\n",
    "            instance[\"video\"] = {\n",
    "                    \"bytesBase64Encoded\": encoded_content # pylint: disable=protected-access\n",
    "                }  # pylint: disable=protected-access\n",
    "            #get video duration\n",
    "            #as the files are incomplete, for now set it fix\n",
    "            video_duration=math.ceil(get_video_duration(video_file))\n",
    "\n",
    "\n",
    "        endpoint = (\n",
    "           f\"projects/{self.project}/locations/{self.location}\"\n",
    "           \"/publishers/google/models/multimodalembedding@001\"\n",
    "        )\n",
    "\n",
    "        #response =self.client.predict(endpoint=endpoint, instances=instances)\n",
    "\n",
    "        text_embedding = None\n",
    "        if text:\n",
    "            instances = [instance]\n",
    "            response =self.client.predict(endpoint=endpoint, instances=instances)\n",
    "            text_emb_value = response.predictions[0][\"textEmbedding\"]\n",
    "            text_embedding = [v for v in text_emb_value]\n",
    "\n",
    "         \n",
    "        video_embedding = None\n",
    "        if video_bytes:\n",
    "            video_embeddings = []  \n",
    "            prev=0\n",
    "            #iterate over the file and get embeddings of the whole file\n",
    "            for val in range (intervals,video_duration+intervals,intervals):\n",
    "                offset={'start':prev, 'end':val}\n",
    "                prev=val    \n",
    "                print(offset)\n",
    "                video_segments=VideoSegmentConfig(start_offset_sec=offset['start'],end_offset_sec=offset['end'])\n",
    "\n",
    "                if video_segments:\n",
    "                    instance[\"video\"][\"videoSegmentConfig\"] = {\n",
    "                            \"startOffsetSec\": video_segments.start_offset_sec,\n",
    "                            \"endOffsetSec\": video_segments.end_offset_sec,\n",
    "                            \"intervalSec\": video_segments.interval_sec,\n",
    "                        }\n",
    "                \n",
    "                instances = [instance]\n",
    "                response =self.client.predict(endpoint=endpoint, instances=instances)\n",
    "                for video_embedding in response.predictions[0].get(\"videoEmbeddings\", []):\n",
    "                    video_embeddings.append(\n",
    "                        VideoEmbedding(\n",
    "                            embedding=video_embedding[\"embedding\"],\n",
    "                            start_offset_sec=video_embedding[\"startOffsetSec\"],\n",
    "                            end_offset_sec=video_embedding[\"endOffsetSec\"],\n",
    "                        )\n",
    "                    )\n",
    "                # video_embeddings.append(\n",
    "                #         VideoEmbedding(\n",
    "                #             embedding=[1,2,3],\n",
    "                #             start_offset_sec=video_segments.start_offset_sec,\n",
    "                #             end_offset_sec=video_segments.end_offset_sec,\n",
    "                #         )\n",
    "                #     )\n",
    "\n",
    "                \n",
    "        return EmbeddingResponse (text_embedding=text_embedding, video_embedding=video_embeddings)\n",
    " \n",
    "   \n",
    "   \n",
    "    def get_video_summarycontent(self, text: str = None, video_file: str = None):\n",
    "        \n",
    "         '''\n",
    "         Gimini Features for Video as per:https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/video-understanding\n",
    "         gemini-1.5-flash, Gemini 1.5 Pro: \n",
    "         With audio: ~50 minutes\n",
    "         Without audio: 60 minutes\n",
    "         Maximum videos per prompt: 10\n",
    "         \n",
    "         Gemini 1.0 Pro Vision:\n",
    "         Maximum video length: 2 minutes\n",
    "         The maximum videos per prompt: 1\n",
    "         Audio in the video is ignored.\n",
    "         \n",
    "         Gimini feature for Part as per:https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#sample-requests\n",
    "        '''\n",
    "        \n",
    "\n",
    " \n",
    "         generative_multimodal_model= GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "         # Please only capture key events and highlights.\n",
    "         video_description_prompt=\"\"\"You are an assistant tasked with summarizing videos for retrieval.\\\n",
    "         These summaries will be embedded and used to retrieve the raw video.\\\n",
    "        Chapterize the video content by grouping the video content into chapters \\\n",
    "        and providing a concise summary for each chapter that is well optimized for retrieval.\\\n",
    "        If there is a famous person like politician, celebrity or athlete, indicate their name and describe what they are famous for.\\\n",
    "        If you are not sure about any info, please do not make it up. \\\n",
    "        Return the result in the JSON format with keys as follows : \"timecode\", \"chapterSummary\"\n",
    "        \"\"\"\n",
    "\n",
    "         generation_config= GenerationConfig(temperature=1, max_output_tokens=8192,TopK=40,TopP=0.95) \n",
    "        \n",
    "         safety_settings=  {\n",
    "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    }\n",
    "         stream=True\n",
    "        \n",
    "         # Load the saved video as a Gemini Part Object\n",
    "        \n",
    "         video_for_gemini=GenerativeModelPart.from_uri(video_file,mimeType='video/mp4')\n",
    "   \n",
    "         model_input=[video_description_prompt, video_for_gemini]\n",
    "        \n",
    "       \n",
    "        \n",
    "         response = generative_multimodal_model.generate_content(\n",
    "            model_input,\n",
    "            generation_config=generation_config,\n",
    "            stream=stream,\n",
    "            safety_settings=safety_settings, )\n",
    "        \n",
    "        \n",
    "         response_list = []\n",
    "\n",
    "         for chunk in response:\n",
    "            try:\n",
    "                response_list.append(chunk.text)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    \"Exception occurred while calling gemini. Something is wrong. Lower the safety thresholds [safety_settings: BLOCK_NONE ] if not already done. -----\",\n",
    "                    e,\n",
    "                )\n",
    "                response_list.append(\"Exception occurred\")\n",
    "                continue\n",
    "         response = \"\".join(response_list)\n",
    " \n",
    "         return response\n",
    "\n",
    "    \n",
    "    def get_summarycontent_embedding_from_text_embedding_model(self, text: str, return_array: Optional[bool] = False,) -> list:\n",
    "        \"\"\"\n",
    "        Generates a numerical text embedding from a provided text input using a text embedding model.\n",
    "\n",
    "        Args:\n",
    "            text: The input text string to be embedded.\n",
    "            return_array: If True, returns the embedding as a NumPy array.\n",
    "                          If False, returns the embedding as a list. (Default: False)\n",
    "\n",
    "        Returns:\n",
    "            list or numpy.ndarray: A 768-dimensional vector representation of the input text.\n",
    "                                   The format (list or NumPy array) depends on the\n",
    "                                   value of the 'return_array' parameter.\n",
    "        \"\"\"\n",
    "\n",
    "        #the given text is maximum 2048 token. If more, it has to be chunked.\n",
    "        embeddings = text_embedding_model.get_embeddings([text])\n",
    "        text_embedding = [embedding.values for embedding in embeddings][0]\n",
    "\n",
    "        if return_array:\n",
    "            text_embedding = np.fromiter(text_embedding, dtype=float)\n",
    "\n",
    "        # returns 768 dimensional array\n",
    "        return EmbeddingResponse(\n",
    "            text_embedding=text_embedding, image_embedding=None\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728cf6b-baeb-476a-a061-68c748a8dc6e",
   "metadata": {},
   "source": [
    "### Create helper functions to process data in batches\n",
    "Datasets can be large, so it's recommended to load a batch of data at a time into memory using a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e6f9ef7-0279-48f4-a576-3868ec14a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Callable, Generator, List,Tuple\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#Number of API calls per second\n",
    "API_IMAGES_PER_SECOND = 2\n",
    "\n",
    "def generate_batches(\n",
    "    inputs: List[str], batch_size: int\n",
    ") -> Generator[List[str], None, None]:\n",
    "    \"\"\"\n",
    "    Generator function that takes a list of strings and a batch size, and yields batches of the specified size.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(inputs), batch_size):\n",
    "        yield inputs [i : i + batch_size] \n",
    "\n",
    "\n",
    "\n",
    "def encode_to_embeddings_chunked(\n",
    "    process_function: Callable[[List[str]], List[Optional[List[float]]]],\n",
    "    items: str,\n",
    "    batch_size: int = 1,\n",
    ") -> List[Optional[List[float]]]:\n",
    "    \"\"\"\n",
    "    Function that encodes a list of strings into embeddings using a process function.\n",
    "    It takes a list of strings and returns a list of optional lists of floats.\n",
    "    The data is processed in chunks to prevent out-of-memory errors.\n",
    "    \"\"\"\n",
    "    \n",
    "    embeddings_list: List[Optional[List[float]]] = []\n",
    "\n",
    "    # Prepare the batches using a generator\n",
    "    batches = generate_batches(items, batch_size)\n",
    "    \n",
    "   \n",
    "    seconds_per_job = batch_size / API_IMAGES_PER_SECOND\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for batch in tqdm(batches, total=len(items) // batch_size, position=0):\n",
    "            futures.append(executor.submit(process_function, batch))\n",
    "            time.sleep(seconds_per_job)\n",
    "\n",
    "        for future in futures:\n",
    "            embeddings_list.extend(future.result())\n",
    "    return embeddings_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70084d60-e64f-4acf-b41d-07295141df90",
   "metadata": {},
   "source": [
    "### Create functions that wrap embedding functions in try-except and retry logic\n",
    "This particular embedding model can only process 1 image at a time, so inputs are validated to be equal to a length of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc24f964-09eb-4641-a0ed-2a9fc05247aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from tenacity import retry, stop_after_attempt\n",
    "\n",
    "client = EmbeddingPredictionClient(project=PROJECT_ID)\n",
    "\n",
    "\n",
    "# Use a retry handler in case of failure\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_texts_to_embeddings_with_retry(text: List[str]) -> List[List[float]]:\n",
    "    assert len(text) == 1\n",
    "\n",
    "    try:\n",
    "        return [client.get_embedding(text=text[0], image_file=None).text_embedding]\n",
    "    except Exception:\n",
    "        raise RuntimeError(\"Error getting embedding.\")\n",
    "\n",
    "\n",
    "def encode_texts_to_embeddings(text: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_texts_to_embeddings_with_retry(text=text)\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(text))]\n",
    "\n",
    "\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_videos_to_embeddings_with_retry(video_uris: List[str] ) -> List[List[float]]:\n",
    "    assert len(video_uris) == 1\n",
    "\n",
    "    try:\n",
    "        return [\n",
    "            client.get_embedding(text=None, video_file=video_uris[0] ).video_embedding\n",
    "        ]\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        raise RuntimeError(\"Error getting embedding for video.\")\n",
    "\n",
    "\n",
    "def encode_videos_to_embeddings(video_uris: List[str] ) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        \n",
    "        return encode_videos_to_embeddings_with_retry(video_uris=video_uris )\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return [None for _ in range(len(video_uris))]\n",
    "    \n",
    "\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_videos_to_summarycontent_with_retry(video_uris: List[str]) -> List[List[float]]:\n",
    "    assert len(image_uris) == 1\n",
    "\n",
    "    try:\n",
    "        return [\n",
    "            client.get_video_summarycontent(text=None, video_file=video_uris[0])\n",
    "        ]\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        raise RuntimeError(\"Error getting summaries.\")\n",
    "\n",
    "\n",
    "def encode_videos_to_summarycontent(video_uris: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_videos_to_summarycontent_with_retry(video_uris=video_uris)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return [None for _ in range(len(video_uris))]\n",
    "    \n",
    "    \n",
    "# Use a retry handler in case of failure\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_summarycontent_to_embeddings_with_retry(text: List[str]) -> List[List[float]]:\n",
    "    assert len(text) == 1\n",
    "\n",
    "    try:\n",
    "        return [client.get_summarycontent_embedding_from_text_embedding_model(text=text[0]).text_embedding]\n",
    "    except Exception:\n",
    "        raise RuntimeError(\"Error getting embedding for summary content.\")\n",
    "\n",
    "\n",
    "def encode_summarycontent_to_embeddings(text: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_summarycontent_to_embeddings_with_retry(text=text)\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(text))]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e9287-4332-4ac5-8d6a-4b6f2a24f0ff",
   "metadata": {},
   "source": [
    "### Create and save the embeddings in JSONL format\n",
    "The data must be formatted in JSONL format, which means each embedding dictionary is written as an individual JSON object on its own line.\n",
    "\n",
    "See more information in the docs at Input data format and structure.\n",
    "\n",
    "Run the following code in the next available cells, to create a temporary file to store embeddings in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aeb8b57-7ab4-490d-8a98-01f71f45d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile, shutil\n",
    "\n",
    "# Create temporary file to write embeddings to\n",
    "videoembeddings_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=False)\n",
    "\n",
    "# Create temporary file to write summaries to\n",
    "videosummaries_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25a08f1-1e9a-4c97-a0eb-624ce9d75165",
   "metadata": {},
   "source": [
    "### embedding file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a898f97e-a4c3-49b5-afae-9bfa7e1a05d8",
   "metadata": {},
   "source": [
    "### Video Embeddings in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a0e2eed2-d8ff-4d1f-b802-fdf099777d33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SampleVideo/highway_vehicles.mp4']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_paths_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de986c74-1704-4dbb-bc76-6e4493b61755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad0c2e7537840658420d01422db2244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c89c746dc5949d89f6dc035aaa61637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 0, 'end': 120}\n",
      "[[<vertexai.vision_models.VideoEmbedding object at 0x7ff06eff4df0>]]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "BATCH_SIZE = 1# this can be changed\n",
    " \n",
    "           \n",
    "with open(videoembeddings_file.name, \"a\") as ef:     \n",
    "         for i in tqdm(range(0, len(video_paths), BATCH_SIZE)):#len(image_names)\n",
    "            video_names_chunk = video_names[i : i + BATCH_SIZE]\n",
    "            video_paths_chunk = video_paths[i : i + BATCH_SIZE]\n",
    "            \n",
    "            \n",
    "            embeddings=[]\n",
    "            video_summaries=[]\n",
    "            #comment to prevent extra costs\n",
    "            #********************************\n",
    "            embeddings = encode_to_embeddings_chunked(\n",
    "                    process_function=encode_videos_to_embeddings, items=video_paths_chunk)                 \n",
    "            #********************************\n",
    "\n",
    "            #comment to prevent extra costs\n",
    "            #********************************\n",
    "            #summaries = encode_to_embeddings_chunked(\n",
    "                #process_function=encode_videos_to_summarycontent, items=video_paths_chunk\n",
    "               #)\n",
    "\n",
    "            #********************************\n",
    "            #summaries=[' The image shows three people: Joe Biden, a young girl, and Hunter Biden. Joe Biden is smiling and wearing a dark suit. The young girl is smiling and wearing a white dress. Hunter Biden is smiling and wearing a dark suit. The background is a photo of the White House.','this is test']\n",
    "\n",
    "            #comment to prevent extra costs\n",
    "            #********************************\n",
    "            #summaries_embeddings = encode_to_embeddings_chunked(\n",
    "                 #process_function=encode_summarycontent_to_embeddings, items=summaries\n",
    "            #)\n",
    "            #summaries_embeddings=[[1,2],[1,2,3]]\n",
    "\n",
    "            #********************************\n",
    "\n",
    "            print(embeddings)\n",
    "\n",
    "            # Append to file\n",
    "            embeddings_formatted=[]\n",
    "            for id,path,embedding in zip(video_names_chunk,video_paths_chunk,embeddings):\n",
    "                for value in embedding:\n",
    "                    if value.embedding is not None:\n",
    "                        embeddings_formatted.append(  \n",
    "                            json.dumps(\n",
    "                                {\n",
    "                                    \"id\": str(id), \n",
    "                                    \"video path\":str(path),\n",
    "                                    \"embedding\": [str(value) for value in value.embedding],\n",
    "                                    \"start_offset_sec\": value.start_offset_sec,\n",
    "                                    \"end_offset_sec\": value.end_offset_sec \n",
    "                                }\n",
    "                            )\n",
    "                            + \"\\n\"\n",
    "\n",
    "                        )\n",
    "            ef.writelines(embeddings_formatted)\n",
    "        \n",
    " \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb182a-2199-4b47-b844-65df08836758",
   "metadata": {},
   "source": [
    "### Create bucket and push embeddings into the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e5e18b-8a1c-4d1a-8013-d5ebd1a173cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#set bucket info to create a bucket\n",
    "BUCKET_URI = f\"gs://artifacts-{PROJECT_ID}-unique\"  # @param {type:\"string\"}\n",
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2354d-42f3-4b45-a387-c9f225f9b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIQUE_FOLDER_NAME = \"embeddings_results_NinePOC\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58369a05-16b4-4f93-b792-03b389544a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings\n",
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/{UNIQUE_FOLDER_NAME}/\"\n",
    "! gsutil cp {embeddings_file.name} {EMBEDDINGS_INITIAL_URI}\n",
    "\n",
    "#summaries\n",
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/{UNIQUE_FOLDER_NAME}/\"\n",
    "! gsutil cp {summaries_file.name} {EMBEDDINGS_INITIAL_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4fae7267-4f5f-43e7-a0fe-c39b4e0b9d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'summaries_file.json'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the temp files in persistent disk\n",
    "import tempfile, shutil\n",
    " \n",
    "file_name = embeddings_file.name\n",
    "embeddings_file.close()\n",
    "shutil.copy(file_name, 'embeddings_file.json')\n",
    "\n",
    "file_name = summaries_file.name\n",
    "summaries_file.close()\n",
    "shutil.copy(file_name, 'summaries_file.json')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe4468d-d92f-45cb-a3d0-9de84d8344be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
