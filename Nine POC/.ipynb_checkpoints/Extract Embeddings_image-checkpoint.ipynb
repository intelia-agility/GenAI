{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a354f9-0984-4c94-9042-efb28db5f4be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.58.0)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.59.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (2.14.0)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.17.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.31.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.19.6)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (24.1)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.25.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.12.3)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.4)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.10.17)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.7.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.32.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.1)\n",
      "INFO: pip is looking at multiple versions of google-api-core[grpc] to determine which version is compatible with other requirements. This could take a while.\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.7)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.7.4)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
      "Downloading google_cloud_aiplatform-1.59.0-py2.py3-none-any.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-2.17.0-py2.py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: google-api-core, google-cloud-storage, google-cloud-aiplatform\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 1.34.1\n",
      "    Uninstalling google-api-core-1.34.1:\n",
      "      Successfully uninstalled google-api-core-1.34.1\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.14.0\n",
      "    Uninstalling google-cloud-storage-2.14.0:\n",
      "      Successfully uninstalled google-cloud-storage-2.14.0\n",
      "  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 1.58.0\n",
      "    Uninstalling google-cloud-aiplatform-1.58.0:\n",
      "      Successfully uninstalled google-cloud-aiplatform-1.58.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.19.1 which is incompatible.\n",
      "google-cloud-pubsub 2.21.4 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.48.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-api-core-2.11.1 google-cloud-aiplatform-1.59.0 google-cloud-storage-2.17.0\n",
      "Requirement already satisfied: google-cloud-vision in /opt/conda/lib/python3.10/site-packages (3.7.2)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2.11.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-vision) (2.31.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-vision) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-vision) (3.19.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.63.1)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.48.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (4.9)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "# Install the packages\n",
    "! pip3 install --upgrade google-cloud-aiplatform \\\n",
    "                         google-cloud-storage\n",
    "\n",
    "# Install the packages\n",
    "! pip install google-cloud-vision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70639287-6593-462f-a952-cfa0605b29dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8162339b-0555-46c0-8271-a26fe9fe99a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set project info\n",
    "PROJECT = !gcloud config get-value project\n",
    "PROJECT_ID = PROJECT[0]\n",
    "REGION = \"us-central1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fb72555-1765-496b-ad6a-d8c7d3aff330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "image_directory = \"SampleImage\"\n",
    "\n",
    "image_names=[]\n",
    "for file_name in os.listdir(image_directory):\n",
    "    image_names.append(file_name)\n",
    "\n",
    "image_paths = [os.path.join(image_directory, image_name) for image_name in image_names]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6125a26-9f33-4c17-bd52-657233921201",
   "metadata": {},
   "source": [
    "### Define function to detect explicit images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2741363-7aef-42a4-95c5-7e56cc368501",
   "metadata": {},
   "outputs": [],
   "source": [
    "commented as we do not need this for now \n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision_v1.types.image_annotator import SafeSearchAnnotation\n",
    "from google.cloud.videointelligence.v1beta1 import SafeSearchDetection\n",
    "\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "\n",
    "def detect_safe_search(path: str) -> Optional[SafeSearchAnnotation]:\n",
    "    \"\"\"Detects unsafe features in the file.\"\"\"\n",
    "\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.safe_search_detection(image=image)\n",
    "\n",
    "    if response.error.message:\n",
    "        print(response.error.message)\n",
    "        return None\n",
    "\n",
    "    return response.safe_search_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d545a5e-4635-4942-8cc9-6d1b96561cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.vision_v1.types.image_annotator import Likelihood\n",
    "\n",
    "\n",
    "# Returns true if some annotations have a potential safety issues\n",
    "def convert_annotation_to_safety(safe_search_annotation: SafeSearchAnnotation) -> bool:\n",
    "    return all(\n",
    "        [\n",
    "            (safe_level == Likelihood.VERY_UNLIKELY)\n",
    "            or (safe_level == Likelihood.UNLIKELY)\n",
    "            for safe_level in [\n",
    "                safe_search_annotation.adult,\n",
    "                safe_search_annotation.medical,\n",
    "                safe_search_annotation.violence,\n",
    "                safe_search_annotation.racy,\n",
    "            ]\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89871e0e-5821-4617-a564-3311b5388048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create a rate limiter with a limit of 1800 requests per minute\n",
    "seconds_per_job = 1 / (1800 / 60)\n",
    "\n",
    "\n",
    "def process_image(image_path: str) -> Optional[bool]:\n",
    "    try:\n",
    "        annotation = detect_safe_search(image_path)\n",
    "\n",
    "        if annotation:\n",
    "            return convert_annotation_to_safety(safe_search_annotation=annotation)\n",
    "        else:\n",
    "            return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Process images using ThreadPool\n",
    "is_safe_values_cloud_vision = []\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for img_url in tqdm(image_paths, total=len(image_paths), position=0):\n",
    "        futures.append(executor.submit(process_image, img_url))\n",
    "        time.sleep(seconds_per_job)\n",
    "\n",
    "    for future in futures:\n",
    "        is_safe_values_cloud_vision.append(future.result())\n",
    "\n",
    "# Set Nones to False\n",
    "is_safe_values_cloud_vision = [\n",
    "    is_safe or False for is_safe in is_safe_values_cloud_vision\n",
    "]\n",
    "\n",
    "# Print number of safe images found\n",
    "print(\n",
    "    f\"Safe images = {np.array(is_safe_values_cloud_vision).sum()} out of {len(is_safe_values_cloud_vision)} images\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f555e1b5-65f5-4afb-a36b-d00a43d174f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter images by safety\n",
    "image_names = [\n",
    "    image_name\n",
    "    for image_name, is_safe in zip(image_names, is_safe_values_cloud_vision)\n",
    "    if is_safe\n",
    "]\n",
    "image_paths = [\n",
    "    image_path\n",
    "    for image_path, is_safe in zip(image_paths, is_safe_values_cloud_vision)\n",
    "    if is_safe\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190401dc-00a4-4d0e-927d-b41ed0a54c05",
   "metadata": {},
   "source": [
    "### Defining encoding functions\n",
    "Create an EmbeddingPredictionClient which encapsulates the logic to call the embedding API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a2ad50c-4171-4375-ad84-977710db7a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import time\n",
    "import typing\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.protobuf import struct_pb2\n",
    "\n",
    "\n",
    "class EmbeddingResponse(typing.NamedTuple):\n",
    "    text_embedding: typing.Sequence[float]\n",
    "    image_embedding: typing.Sequence[float]\n",
    "\n",
    "\n",
    "def load_image_bytes(image_uri: str) -> bytes:\n",
    "    \"\"\"Load image bytes from a remote or local URI.\"\"\"\n",
    "    image_bytes = None\n",
    "    if image_uri.startswith(\"http://\") or image_uri.startswith(\"https://\"):\n",
    "        response = requests.get(image_uri, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            image_bytes = response.content\n",
    "    else:\n",
    "        image_bytes = open(image_uri, \"rb\").read()\n",
    "    return image_bytes\n",
    "\n",
    "\n",
    "class EmbeddingPredictionClient:\n",
    "    \"\"\"Wrapper around Prediction Service Client.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        project: str,\n",
    "        location: str = \"us-central1\",\n",
    "        api_regional_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "    ):\n",
    "        client_options = {\"api_endpoint\": api_regional_endpoint}\n",
    "        # Initialize client that will be used to create and send requests.\n",
    "        # This client only needs to be created once, and can be reused for multiple requests.\n",
    "        self.client = aiplatform.gapic.PredictionServiceClient(\n",
    "            client_options=client_options\n",
    "        )\n",
    "        self.location = location\n",
    "        self.project = project\n",
    "\n",
    "    def get_embedding(self, text: str = None, image_file: str = None):\n",
    "        if not text and not image_file:\n",
    "            raise ValueError(\"At least one of text or image_file must be specified.\")\n",
    "\n",
    "        # Load image file\n",
    "        image_bytes = None\n",
    "        if image_file:\n",
    "            image_bytes = load_image_bytes(image_file)\n",
    "\n",
    "        instance = struct_pb2.Struct()\n",
    "        if text:\n",
    "            instance.fields[\"text\"].string_value = text\n",
    "\n",
    "        if image_bytes:\n",
    "            encoded_content = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "            image_struct = instance.fields[\"image\"].struct_value\n",
    "            image_struct.fields[\"bytesBase64Encoded\"].string_value = encoded_content\n",
    "\n",
    "        instances = [instance]\n",
    "        endpoint = (\n",
    "            f\"projects/{self.project}/locations/{self.location}\"\n",
    "            \"/publishers/google/models/multimodalembedding@001\"\n",
    "        )\n",
    "        response = self.client.predict(endpoint=endpoint, instances=instances)\n",
    "\n",
    "        text_embedding = None\n",
    "        if text:\n",
    "            text_emb_value = response.predictions[0][\"textEmbedding\"]\n",
    "            text_embedding = [v for v in text_emb_value]\n",
    "\n",
    "        image_embedding = None\n",
    "        if image_bytes:\n",
    "            image_emb_value = response.predictions[0][\"imageEmbedding\"]\n",
    "            image_embedding = [v for v in image_emb_value]\n",
    "\n",
    "        return EmbeddingResponse(\n",
    "            text_embedding=text_embedding, image_embedding=image_embedding\n",
    "        )\n",
    "    \n",
    "    def get_image_summarycontent(self, text: str = None, image_file: str = None):\n",
    "        \n",
    "        generative_multimodal_model,\n",
    "        image_description_prompt=\"\"\"You are an assistant tasked with summarizing images for retrieval. \\\n",
    "        These summaries will be embedded and used to retrieve the raw image. \\\n",
    "        Give a concise summary of the image that is well optimized for retrieval.\"\"\"\n",
    "                    generation_config=generation_config,\n",
    "                    safety_settings=safety_settings,\n",
    "                    stream=True,\n",
    "                    \n",
    "                    \n",
    "        if not text and not image_file:\n",
    "            raise ValueError(\"At least one of text or image_file must be specified.\")\n",
    "\n",
    "         \n",
    "        return EmbeddingResponse(\n",
    "            text_embedding=text_embedding, image_embedding=image_embedding\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def image_summarize(self, img_base64, prompt):\n",
    "    \"\"\"\n",
    "    Make image summary\n",
    "\n",
    "    :param img_base64: Base64 encoded string for image\n",
    "    :param prompt: Text prompt for summarizatiomn\n",
    "    :return: Image summarization prompt\n",
    "\n",
    "    \"\"\"\n",
    "    chat = ChatOpenAI(model=\"gpt-4-vision-preview\", max_tokens=1024)\n",
    "\n",
    "    msg = chat.invoke(\n",
    "        [\n",
    "            HumanMessage(\n",
    "                content=[\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img_base64}\"},\n",
    "                    },\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    return msg.content\n",
    "\n",
    "\n",
    "    def generate_img_summaries(img_base64_list):\n",
    "        \"\"\"\n",
    "        Generate summaries for images\n",
    "\n",
    "        :param img_base64_list: Base64 encoded images\n",
    "        :return: List of image summaries and processed images\n",
    "        \"\"\"\n",
    "\n",
    "        # Store image summaries\n",
    "        image_summaries = []\n",
    "        processed_images = []\n",
    "\n",
    "        # Prompt\n",
    "        prompt = \n",
    "\n",
    "        # Apply summarization to images\n",
    "        for i, base64_image in enumerate(img_base64_list):\n",
    "            try:\n",
    "                image_summaries.append(image_summarize(base64_image, prompt))\n",
    "                processed_images.append(base64_image)\n",
    "            except:\n",
    "                print(f\"BadRequestError with image {i+1}\")\n",
    "\n",
    "        return image_summaries, processed_images\n",
    "\n",
    "\n",
    "# Image summaries\n",
    "image_summaries, images_base_64_processed = generate_img_summaries(images_base_64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728cf6b-baeb-476a-a061-68c748a8dc6e",
   "metadata": {},
   "source": [
    "### Create helper functions to process data in batches\n",
    "Datasets can be large, so it's recommended to load a batch of data at a time into memory using a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f9ef7-0279-48f4-a576-3868ec14a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Callable, Generator, List\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "API_IMAGES_PER_SECOND = 2\n",
    "\n",
    "def generate_batches(\n",
    "    inputs: List[str], batch_size: int\n",
    ") -> Generator[List[str], None, None]:\n",
    "    \"\"\"\n",
    "    Generator function that takes a list of strings and a batch size, and yields batches of the specified size.\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(0, len(inputs), batch_size):\n",
    "        yield inputs[i : i + batch_size]\n",
    "\n",
    "\n",
    "\n",
    "def encode_to_embeddings_chunked(\n",
    "    process_function: Callable[[List[str]], List[Optional[List[float]]]],\n",
    "    items: List[str],\n",
    "    batch_size: int = 1,\n",
    ") -> List[Optional[List[float]]]:\n",
    "    \"\"\"\n",
    "    Function that encodes a list of strings into embeddings using a process function.\n",
    "    It takes a list of strings and returns a list of optional lists of floats.\n",
    "    The data is processed in chunks to prevent out-of-memory errors.\n",
    "    \"\"\"\n",
    "\n",
    "    embeddings_list: List[Optional[List[float]]] = []\n",
    "\n",
    "    # Prepare the batches using a generator\n",
    "    batches = generate_batches(items, batch_size)\n",
    "\n",
    "    seconds_per_job = batch_size / API_IMAGES_PER_SECOND\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for batch in tqdm(batches, total=len(items) // batch_size, position=0):\n",
    "            futures.append(executor.submit(process_function, batch))\n",
    "            time.sleep(seconds_per_job)\n",
    "\n",
    "        for future in futures:\n",
    "            embeddings_list.extend(future.result())\n",
    "    return embeddings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f82e7-f459-4b09-87c1-7258d8b5e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from tenacity import retry, stop_after_attempt\n",
    "\n",
    "client = EmbeddingPredictionClient(project=PROJECT_ID)\n",
    "\n",
    "\n",
    "# Use a retry handler in case of failure\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_texts_to_embeddings_with_retry(text: List[str]) -> List[List[float]]:\n",
    "    assert len(text) == 1\n",
    "\n",
    "    try:\n",
    "        return [client.get_embedding(text=text[0], image_file=None).text_embedding]\n",
    "    except Exception:\n",
    "        raise RuntimeError(\"Error getting embedding.\")\n",
    "\n",
    "\n",
    "def encode_texts_to_embeddings(text: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_texts_to_embeddings_with_retry(text=text)\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(text))]\n",
    "\n",
    "\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_images_to_embeddings_with_retry(image_uris: List[str]) -> List[List[float]]:\n",
    "    assert len(image_uris) == 1\n",
    "\n",
    "    try:\n",
    "        return [\n",
    "            client.get_embedding(text=None, image_file=image_uris[0]).image_embedding\n",
    "        ]\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        raise RuntimeError(\"Error getting embedding.\")\n",
    "\n",
    "\n",
    "def encode_images_to_embeddings(image_uris: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_images_to_embeddings_with_retry(image_uris=image_uris)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return [None for _ in range(len(image_uris))]\n",
    "    \n",
    "\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_images_to_summarycontent_with_retry(image_uris: List[str]) -> List[List[float]]:\n",
    "    assert len(image_uris) == 1\n",
    "\n",
    "    try:\n",
    "        return [\n",
    "            client.get_image_summarycontent(text=None, image_file=image_uris[0]).image_embedding\n",
    "        ]\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        raise RuntimeError(\"Error getting embedding.\")\n",
    "\n",
    "\n",
    "def encode_images_to_summarycontent(image_uris: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_images_to_summarycontent_with_retry(image_uris=image_uris)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return [None for _ in range(len(image_uris))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70084d60-e64f-4acf-b41d-07295141df90",
   "metadata": {},
   "source": [
    "### Create functions that wrap embedding functions in try-except and retry logic\n",
    "This particular embedding model can only process 1 image at a time, so inputs are validated to be equal to a length of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc24f964-09eb-4641-a0ed-2a9fc05247aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from tenacity import retry, stop_after_attempt\n",
    "\n",
    "client = EmbeddingPredictionClient(project=PROJECT_ID)\n",
    "\n",
    "\n",
    "# Use a retry handler in case of failure\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_texts_to_embeddings_with_retry(text: List[str]) -> List[List[float]]:\n",
    "    assert len(text) == 1\n",
    "\n",
    "    try:\n",
    "        return [client.get_embedding(text=text[0], image_file=None).text_embedding]\n",
    "    except Exception:\n",
    "        raise RuntimeError(\"Error getting embedding.\")\n",
    "\n",
    "\n",
    "def encode_texts_to_embeddings(text: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_texts_to_embeddings_with_retry(text=text)\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(text))]\n",
    "\n",
    "\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_images_to_embeddings_with_retry(image_uris: List[str]) -> List[List[float]]:\n",
    "    assert len(image_uris) == 1\n",
    "\n",
    "    try:\n",
    "        return [\n",
    "            client.get_embedding(text=None, image_file=image_uris[0]).image_embedding\n",
    "        ]\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        raise RuntimeError(\"Error getting embedding.\")\n",
    "\n",
    "\n",
    "def encode_images_to_embeddings(image_uris: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_images_to_embeddings_with_retry(image_uris=image_uris)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return [None for _ in range(len(image_uris))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e9287-4332-4ac5-8d6a-4b6f2a24f0ff",
   "metadata": {},
   "source": [
    "### Create and save the embeddings in JSONL format\n",
    "The data must be formatted in JSONL format, which means each embedding dictionary is written as an individual JSON object on its own line.\n",
    "\n",
    "See more information in the docs at Input data format and structure.\n",
    "\n",
    "Run the following code in the next available cells, to create a temporary file to store embeddings in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeb8b57-7ab4-490d-8a98-01f71f45d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile, shutil\n",
    "\n",
    "# Create temporary file to write embeddings to\n",
    "embeddings_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=False)\n",
    "\n",
    "embeddings_file.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de986c74-1704-4dbb-bc76-6e4493b61755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "BATCH_SIZE = 10# this can be changed\n",
    "\n",
    "with open(embeddings_file.name, \"a\") as f:\n",
    "    for i in tqdm(range(0, len(image_names), BATCH_SIZE)):\n",
    "        image_names_chunk = image_names[i : i + BATCH_SIZE]\n",
    "        image_paths_chunk = image_paths[i : i + BATCH_SIZE]\n",
    "\n",
    "        embeddings = encode_to_embeddings_chunked(\n",
    "            process_function=encode_images_to_embeddings, items=image_paths_chunk\n",
    "        )\n",
    "\n",
    "        # Append to file\n",
    "        embeddings_formatted = [\n",
    "            json.dumps(\n",
    "                {\n",
    "                    \"id\": str(id),\n",
    "                    \"embedding\": [str(value) for value in embedding],\n",
    "                }\n",
    "            )\n",
    "            + \"\\n\"\n",
    "            for id, embedding in zip(image_names_chunk, embeddings)\n",
    "            if embedding is not None\n",
    "        ]\n",
    "        f.writelines(embeddings_formatted)\n",
    "        \n",
    "        #create a local file\n",
    "        new_file = open(os.path.join('embeddings', 'ImageEmbeddings'+str(i)+'.json') , 'rw')\n",
    "        shutil.copyfileobj(f, new_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb182a-2199-4b47-b844-65df08836758",
   "metadata": {},
   "source": [
    "### Create bucket and push embeddings into the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e5e18b-8a1c-4d1a-8013-d5ebd1a173cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#set bucket info to create a bucket\n",
    "BUCKET_URI = f\"gs://artifacts-{PROJECT_ID}-unique\"  # @param {type:\"string\"}\n",
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2354d-42f3-4b45-a387-c9f225f9b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIQUE_FOLDER_NAME = \"embeddings_results_NinePOC\"\n",
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/{UNIQUE_FOLDER_NAME}/\"\n",
    "! gsutil cp {embeddings_file.name} {EMBEDDINGS_INITIAL_URI}\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
