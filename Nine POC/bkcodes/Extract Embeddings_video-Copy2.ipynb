{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a354f9-0984-4c94-9042-efb28db5f4be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.58.0)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.59.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (2.14.0)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.17.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.31.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.19.6)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (24.1)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.25.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.12.3)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.4)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.10.17)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.7.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.32.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.1)\n",
      "INFO: pip is looking at multiple versions of google-api-core[grpc] to determine which version is compatible with other requirements. This could take a while.\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.7)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.7.4)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
      "Downloading google_cloud_aiplatform-1.59.0-py2.py3-none-any.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-2.17.0-py2.py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: google-api-core, google-cloud-storage, google-cloud-aiplatform\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 1.34.1\n",
      "    Uninstalling google-api-core-1.34.1:\n",
      "      Successfully uninstalled google-api-core-1.34.1\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.14.0\n",
      "    Uninstalling google-cloud-storage-2.14.0:\n",
      "      Successfully uninstalled google-cloud-storage-2.14.0\n",
      "  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 1.58.0\n",
      "    Uninstalling google-cloud-aiplatform-1.58.0:\n",
      "      Successfully uninstalled google-cloud-aiplatform-1.58.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.19.1 which is incompatible.\n",
      "google-cloud-pubsub 2.21.4 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.48.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-api-core-2.11.1 google-cloud-aiplatform-1.59.0 google-cloud-storage-2.17.0\n",
      "Requirement already satisfied: google-cloud-vision in /opt/conda/lib/python3.10/site-packages (3.7.2)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2.11.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-vision) (2.31.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-vision) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-vision) (3.19.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.63.1)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.48.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (4.9)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "# Install the packages\n",
    "! pip3 install --upgrade google-cloud-aiplatform \\\n",
    "                         google-cloud-storage\n",
    "\n",
    "# Install the packages\n",
    "! pip install google-cloud-vision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895e40a3-1749-4b68-ac38-7e001f32a101",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-videointelligence in /opt/conda/lib/python3.10/site-packages (1.16.3)\n",
      "Collecting google-cloud-videointelligence\n",
      "  Downloading google_cloud_videointelligence-2.13.4-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2.11.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-videointelligence) (2.31.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-videointelligence) (1.24.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 (from google-cloud-videointelligence)\n",
      "  Downloading protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.63.1)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.48.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (4.9)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2024.7.4)\n",
      "Downloading google_cloud_videointelligence-2.13.4-py2.py3-none-any.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.0/245.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf, google-cloud-videointelligence\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: google-cloud-videointelligence\n",
      "    Found existing installation: google-cloud-videointelligence 1.16.3\n",
      "    Uninstalling google-cloud-videointelligence-1.16.3:\n",
      "      Successfully uninstalled google-cloud-videointelligence-1.16.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "apache-beam 2.46.0 requires grpcio!=1.48.0,<2,>=1.33.1, but you have grpcio 1.48.0 which is incompatible.\n",
      "apache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.11.1 which is incompatible.\n",
      "google-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-datastore 1.15.5 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-language 1.3.2 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-pubsub 2.21.4 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.48.0 which is incompatible.\n",
      "google-cloud-storage 2.17.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 2.11.1 which is incompatible.\n",
      "kfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.3 which is incompatible.\n",
      "kfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorboardx 2.6 requires protobuf<4,>=3.8.0, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-serving-api 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-cloud-videointelligence-2.13.4 protobuf-3.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-videointelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70639287-6593-462f-a952-cfa0605b29dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8162339b-0555-46c0-8271-a26fe9fe99a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set project info\n",
    "PROJECT = !gcloud config get-value project\n",
    "PROJECT_ID = PROJECT[0]\n",
    "REGION = \"us-central1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fb72555-1765-496b-ad6a-d8c7d3aff330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "video_directory = \"SampleVideo\"\n",
    "\n",
    "video_names=[]\n",
    "for file_name in os.listdir(video_directory):\n",
    "    if  not file_name.startswith('.'):\n",
    "        video_names.append(file_name)\n",
    "\n",
    "video_paths = [os.path.join(video_directory, video_name) for video_name in video_names]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6125a26-9f33-4c17-bd52-657233921201",
   "metadata": {},
   "source": [
    "### Define function to detect explicit images\n",
    "\n",
    "enable clound vision api before running this bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b070ae5-1f9e-430f-9fda-9e01bcee82b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.cloud.videointelligence.v1beta import SafeSearchAnnotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43fd0fed-43ad-4679-a484-5ee18231b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this has not been testes\n",
    "from google.cloud import videointelligence\n",
    "\n",
    "def analyze_video_safe_search(gcs_uri):\n",
    "    client = videointelligence.VideoIntelligenceServiceClient()\n",
    "    \n",
    "    # Configure the request\n",
    "    config = videointelligence.SafeSearchDetectionConfig()\n",
    "    context = videointelligence.VideoContext(\n",
    "        safe_search_detection_config=config\n",
    "    )\n",
    "    operation = client.annotate_video(\n",
    "        request={\"input_uri\": gcs_uri, \"features\": [videointelligence.Feature.SAFE_SEARCH_DETECTION], \"video_context\": context}\n",
    "    )\n",
    "    \n",
    "    # Wait for the operation to complete\n",
    "    result = operation.result(timeout=180)\n",
    "    \n",
    "    # Process the result\n",
    "    annotation_results = result.annotation_results[0]\n",
    "    for frame in annotation_results.safe_search_annotations:\n",
    "        print(f\"Time offset: {frame.time_offset.seconds}.{frame.time_offset.nanos // 1000000}s\")\n",
    "        print(f\"Adult: {videointelligence.Likelihood(frame.adult)}\")\n",
    "        print(f\"Violence: {videointelligence.Likelihood(frame.violence)}\")\n",
    "        print(f\"Racy: {videointelligence.Likelihood(frame.racy)}\")\n",
    "        print(f\"Medical: {videointelligence.Likelihood(frame.medical)}\")\n",
    "        print(f\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4839766e-611a-4f1b-b7eb-9f4ab6c03f41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for now the api is not active just to save costs. I set everything to true\n",
    "is_safe_values_cloud_vision=[True for i in range (len(video_paths))]\n",
    "is_safe_values_cloud_vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f555e1b5-65f5-4afb-a36b-d00a43d174f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter images by safety\n",
    "video_names = [\n",
    "    video_name\n",
    "    for video_name, is_safe in zip(video_names, is_safe_values_cloud_vision)\n",
    "    if is_safe\n",
    "]\n",
    "video_paths = [\n",
    "    video_path\n",
    "    for video_path, is_safe in zip(video_paths, is_safe_values_cloud_vision)\n",
    "    if is_safe\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a501aa-a4d2-4971-b0db-56de6cee03f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"contents\": {\n",
    "    \"role\": \"USER\",\n",
    "    \"parts\": [\n",
    "      {\n",
    "        \"fileData\": {\n",
    "          \"fileUri\": \"FILE_URI1\",\n",
    "          \"mimeType\": \"MIME_TYPE\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"TEXT1\"\n",
    "      },\n",
    "      {\n",
    "        \"fileData\": {\n",
    "          \"fileUri\": \"FILE_URI2\",\n",
    "          \"mimeType\": \"MIME_TYPE\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"TEXT2\"\n",
    "      },\n",
    "      {\n",
    "        \"fileData\": {\n",
    "          \"fileUri\": \"FILE_URI3\",\n",
    "          \"mimeType\": \"MIME_TYPE\"\n",
    "        }\n",
    "      },\n",
    "        \n",
    "        \"videoMetadata\": {\n",
    "            \"startOffset\": {\n",
    "              \"seconds\": integer,\n",
    "              \"nanos\": integer\n",
    "            },\n",
    "            \"endOffset\": {\n",
    "              \"seconds\": integer,\n",
    "              \"nanos\": integer\n",
    "            }\n",
    "        }\n",
    "            \n",
    "            \n",
    "    ]\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0ab397c-3dd3-4012-b502-f331fdc6d998",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'You are an assistant tasked with summarizing videos for retrieval.         These summaries will be embedded and used to retrieve the raw video.         Give a concise summary of the video that is well optimized for retrieval.',\n",
       " 'fileData': {'fileUri': 'gs://github-repo/embeddings/getting_started_embeddings/UCF-101-subset/BrushingTeeth/v_BrushingTeeth_g01_c02.mp4',\n",
       "  'mimeType': 'video/MP4'},\n",
       " 'videoMetadata': {'startOffset': {'seconds': 0, 'nanos': 0},\n",
       "  'endOffset': {'seconds': 4, 'nanos': 0}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e69ccea-7f02-46d8-999e-b745a70720f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " safety_settings = {\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1aa8899-e810-4958-98f9-86535108e40c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<HarmCategory.HARM_CATEGORY_HATE_SPEECH: 1>: <HarmBlockThreshold.BLOCK_ONLY_HIGH: 3>,\n",
       " <HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 2>: <HarmBlockThreshold.BLOCK_ONLY_HIGH: 3>,\n",
       " <HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 4>: <HarmBlockThreshold.BLOCK_ONLY_HIGH: 3>,\n",
       " <HarmCategory.HARM_CATEGORY_HARASSMENT: 3>: <HarmBlockThreshold.BLOCK_ONLY_HIGH: 3>}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "safety_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43093e8e-bd03-42f6-86c9-0cddf6022d93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7844fbf9-4ca1-40a1-ba14-8536cabd4bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "text= \"\"\"You are an assistant tasked with summarizing videos for retrieval. \\\n",
    "        These summaries will be embedded and used to retrieve the raw video. \\\n",
    "        Give a concise summary of the video for the given videometadata that is well optimized for retrieval.\"\"\"\n",
    "video_file=\"gs://cloud-samples-data/vertex-ai-vision/highway_vehicles.mp4\"\n",
    "if 1==1:\n",
    " \n",
    "        # Load video file\n",
    "        video_bytes = None\n",
    " \n",
    "\n",
    "        instance ={}\n",
    "        items={}\n",
    "       \n",
    "        items[\"role\"]= \"USER\"\n",
    "        if text:\n",
    "            items[\"text\"]= text\n",
    "\n",
    "        if video_file:             \n",
    "            items[\"fileData\"]= {\n",
    "                          \"fileUri\": video_file,\n",
    "                          \"mimeType\": \"video/MP4\"\n",
    "                        }\n",
    "            items[\"videoMetadata\"]= {\n",
    "\n",
    "                                \"startOffset\": {\n",
    "                                  \"seconds\": 0,\n",
    "                                  \"nanos\": 0\n",
    "                                },\n",
    "                                \"endOffset\": {\n",
    "                                  \"seconds\": 4,\n",
    "                                  \"nanos\": 0\n",
    "                                }\n",
    "            }\n",
    "            #as the files are incomplete, for now set it fix\n",
    "            video_duration=120\n",
    "            instance={}\n",
    "            instance[\"contents\"]={\"role\":\"USER\",\n",
    "\n",
    "                                  \"Parts\":[items],\n",
    "\n",
    "\n",
    "              \"generationConfig\": {\n",
    "                \"temperature\": 1,\n",
    "                \"topP\": 0.95, \n",
    "                \"maxOutputTokens\": 8192 \n",
    "              }\n",
    "            }\n",
    "\n",
    "          \n",
    "\n",
    "        endpoint = (\n",
    "           f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "           \"/publishers/google/models/gemini-1.5-flash@001\"\n",
    "        )\n",
    "\n",
    "        #response =self.client.predict(endpoint=endpoint, instances=instances)\n",
    "#client.predict(endpoint=endpoint, instances=instances)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44858b9b-3377-4cc9-a162-b121ff8252d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/nine-quality-test/locations/us-central1/publishers/google/models/gemini-1.5-flash@001'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "021d559a-836a-4886-a5ce-64a38de888b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = aiplatform.gapic.PredictionServiceClient  (\n",
    "            client_options=client_options\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ad32535-21b1-4c74-a631-3119cc973a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PredictionServiceClient.stream_generate_content() got an unexpected keyword argument 'endpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 13\u001b[0m\n\u001b[1;32m      6\u001b[0m client_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_endpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: api_regional_endpoint}\n\u001b[1;32m      8\u001b[0m client \u001b[38;5;241m=\u001b[39m aiplatform\u001b[38;5;241m.\u001b[39mgapic\u001b[38;5;241m.\u001b[39mPredictionServiceClient  (\n\u001b[1;32m      9\u001b[0m             client_options\u001b[38;5;241m=\u001b[39mclient_options\n\u001b[1;32m     10\u001b[0m         )\n\u001b[0;32m---> 13\u001b[0m response \u001b[38;5;241m=\u001b[39m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_generate_content\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: PredictionServiceClient.stream_generate_content() got an unexpected keyword argument 'endpoint'"
     ]
    }
   ],
   "source": [
    "endpoint = (\n",
    "           f\"projects/{PROJECT_ID}/locations/us-central1/publishers/google/models/gemini-1.5-flash-001\"\n",
    "        )\n",
    "    \n",
    "api_regional_endpoint= \"us-central1-aiplatform.googleapis.com\" \n",
    "client_options = {\"api_endpoint\": api_regional_endpoint}\n",
    "        \n",
    "client = aiplatform.gapic.PredictionServiceClient  (\n",
    "            client_options=client_options\n",
    "        )\n",
    "    \n",
    "\n",
    "response =client.stream_generate_content (endpoint=endpoint, parts=[instance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "615fe893-1ba7-4846-ae50-63f6eda82fea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'A list of comic book recommendations',\n",
       " 'startOffset': 'decimal',\n",
       " 'endOffset': 'decimal',\n",
       " 'chapterSummary': 'string'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2c1214d6-0d71-4086-814f-491bf2a20437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "schema = '''\n",
    "{\n",
    "  \"description\": \"A list of chapters\",\n",
    "  \"type\": \"array\",\n",
    "  \"items\": {\n",
    "\t\"type\":\"object\",\n",
    "\t\"properties\": {\n",
    "\t\t\"startOffset\": {\n",
    "\t\t\t\"type\":\"integer\"\n",
    "\t\t},\n",
    "\t\t\"endOffset\": {\n",
    "\t\t\t\"type\":\"integer\"\n",
    "\t\t},\n",
    "\t\t\"chapterSummary\": {\n",
    "\t\t\t\"type\":\"string\"\n",
    "\t\t}\n",
    "\t},\n",
    "\t\"required\": [\"startOffset\",\"endOffset\",\"chapterSummary\" ]\n",
    "  }\n",
    "}\n",
    "'''\n",
    " \n",
    "\n",
    "g=GenerationConfig(temperature=1, top_k=40,top_p=0.95,max_output_tokens=8192, response_mime_type='application/json',\n",
    "\tresponse_schema=json.loads(schema)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c415c293-ab1c-442b-912c-213c6b7ec4c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 120, 'end': 120}\n",
      "{'start': 120, 'end': 240}\n",
      "{'start': 240, 'end': 360}\n",
      "{'start': 360, 'end': 480}\n",
      "{'start': 480, 'end': 600}\n"
     ]
    }
   ],
   "source": [
    "segments_to_process=120\n",
    "intervals=16\n",
    "video_duration=10*60\n",
    "val=0\n",
    "\n",
    "for val in range (segments_to_process,video_duration+segments_to_process,segments_to_process):\n",
    "                offset={'start':prev, 'end':val}\n",
    "                prev=val    \n",
    "                print(offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2612b078-2278-47cf-a970-a8293ac7d96b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 0, 'end': 120}\n",
      "getting summaries..\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"```json\\n[\\n  {\\n    \\\"startOffset\\\": 0,\\n    \\\"endOffset\\\": 16,\\n    \\\"chapterSummary\\\": \\\"A woman walks down a hallway wearing a sequined dress.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 16,\\n    \\\"endOffset\\\": 32,\\n    \\\"chapterSummary\\\": \\\"A woman in a green top speaks about how her childhood was difficult and that she had an opportunity to stand up for herself later in life.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 32,\\n    \\\"endOffset\\\": 48,\\n    \\\"chapterSummary\\\": \\\"The woman speaks about a man that she would babysit for, who was a serial pedophile. She describes how the police investigated her case.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 48,\\n    \\\"endOffset\\\": 64,\\n    \\\"chapterSummary\\\": \\\"A man named Scott Tudnem was a detective who worked on the woman\\'s case and investigated other sex offenders. He felt she was deserving of his attention and help to put the man away.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 64,\\n    \\\"endOffset\\\": 80,\\n    \\\"chapterSummary\\\": \\\"The woman speaks about the man who was a pedophile. She says the man would play games with them. She describes the games and says that they were sickening.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 80,\\n    \\\"endOffset\\\": 96,\\n    \\\"chapterSummary\\\": \\\"The woman describes the house she was brought to as a child. She says that she would babysit for the man and his wife. She also speaks about the emotional impact of the abuse.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 96,\\n    \\\"endOffset\\\": 112,\\n    \\\"chapterSummary\\\": \\\"The woman speaks about when she told her parents about the abuse. She says that they were young and that they did not know what to do.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 112,\\n    \\\"endOffset\\\": 120,\\n    \\\"chapterSummary\\\": \\\"\\\"\\n  }\\n]\\n```\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.168583021\n",
      "    severity: HARM_SEVERITY_LOW\n",
      "    severity_score: 0.226270318\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.19421494\n",
      "    severity: HARM_SEVERITY_LOW\n",
      "    severity_score: 0.23616375\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: LOW\n",
      "    probability_score: 0.540075\n",
      "    severity: HARM_SEVERITY_MEDIUM\n",
      "    severity_score: 0.40809983\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: LOW\n",
      "    probability_score: 0.372276962\n",
      "    severity: HARM_SEVERITY_MEDIUM\n",
      "    severity_score: 0.415728837\n",
      "  }\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 851417\n",
      "  candidates_token_count: 482\n",
      "  total_token_count: 851899\n",
      "}\n",
      "\n",
      "['{\\n    \"startOffset\": 0,\\n    \"endOffset\": 16,\\n    \"chapterSummary\": \"A woman walks down a hallway wearing a sequined dress.\"\\n  }', '{\\n    \"startOffset\": 16,\\n    \"endOffset\": 32,\\n    \"chapterSummary\": \"A woman in a green top speaks about how her childhood was difficult and that she had an opportunity to stand up for herself later in life.\"\\n  }', '{\\n    \"startOffset\": 32,\\n    \"endOffset\": 48,\\n    \"chapterSummary\": \"The woman speaks about a man that she would babysit for, who was a serial pedophile. She describes how the police investigated her case.\"\\n  }', '{\\n    \"startOffset\": 48,\\n    \"endOffset\": 64,\\n    \"chapterSummary\": \"A man named Scott Tudnem was a detective who worked on the woman\\'s case and investigated other sex offenders. He felt she was deserving of his attention and help to put the man away.\"\\n  }', '{\\n    \"startOffset\": 64,\\n    \"endOffset\": 80,\\n    \"chapterSummary\": \"The woman speaks about the man who was a pedophile. She says the man would play games with them. She describes the games and says that they were sickening.\"\\n  }', '{\\n    \"startOffset\": 80,\\n    \"endOffset\": 96,\\n    \"chapterSummary\": \"The woman describes the house she was brought to as a child. She says that she would babysit for the man and his wife. She also speaks about the emotional impact of the abuse.\"\\n  }', '{\\n    \"startOffset\": 96,\\n    \"endOffset\": 112,\\n    \"chapterSummary\": \"The woman speaks about when she told her parents about the abuse. She says that they were young and that they did not know what to do.\"\\n  }', '{\\n    \"startOffset\": 112,\\n    \"endOffset\": 120,\\n    \"chapterSummary\": \"\"\\n  }']\n",
      "\n",
      "\n",
      "hereh are you chapters:\n",
      "\n",
      "[{'startOffset': '0', 'endOffset': '16', 'chapterSummary': 'A woman walks down a hallway wearing a sequined dress.'}, {'startOffset': '16', 'endOffset': '32', 'chapterSummary': 'A woman in a green top speaks about how her childhood was difficult and that she had an opportunity to stand up for herself later in life.'}, {'startOffset': '32', 'endOffset': '48', 'chapterSummary': 'The woman speaks about a man that she would babysit for, who was a serial pedophile. She describes how the police investigated her case.'}, {'startOffset': '48', 'endOffset': '64', 'chapterSummary': \"A man named Scott Tudnem was a detective who worked on the woman's case and investigated other sex offenders. He felt she was deserving of his attention and help to put the man away.\"}, {'startOffset': '64', 'endOffset': '80', 'chapterSummary': 'The woman speaks about the man who was a pedophile. She says the man would play games with them. She describes the games and says that they were sickening.'}, {'startOffset': '80', 'endOffset': '96', 'chapterSummary': 'The woman describes the house she was brought to as a child. She says that she would babysit for the man and his wife. She also speaks about the emotional impact of the abuse.'}, {'startOffset': '96', 'endOffset': '112', 'chapterSummary': 'The woman speaks about when she told her parents about the abuse. She says that they were young and that they did not know what to do.'}, {'startOffset': '112', 'endOffset': '120', 'chapterSummary': ''}]\n",
      "{'start': 120, 'end': 240}\n",
      "getting summaries..\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"```json\\n[\\n  {\\n    \\\"startOffset\\\": 120,\\n    \\\"endOffset\\\": 136,\\n    \\\"chapterSummary\\\": \\\"A man who is facing 91 criminal charges. A woman thinks it\\'s baloney.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 136,\\n    \\\"endOffset\\\": 152,\\n    \\\"chapterSummary\\\": \\\"Madeline West, one of the most recognizable actors, about to play the most nerve-wracking and important role of her life.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 152,\\n    \\\"endOffset\\\": 168,\\n    \\\"chapterSummary\\\": \\\"Madeline West has been convinced to wear a hidden recording device by detective Scott Tudnem.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 168,\\n    \\\"endOffset\\\": 184,\\n    \\\"chapterSummary\\\": \\\"Madeline says that she can\\'t do this. A man tells her just to act like she\\'s a woman seeking justice.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 184,\\n    \\\"endOffset\\\": 200,\\n    \\\"chapterSummary\\\": \\\"Madeline compares the situation to jumping off a waterfall.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 200,\\n    \\\"endOffset\\\": 216,\\n    \\\"chapterSummary\\\": \\\"Madeline West is about to confront the monster who had preyed on her and a neighborhood of young children for more than a decade.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 216,\\n    \\\"endOffset\\\": 232,\\n    \\\"chapterSummary\\\": \\\"Peter Vincent White, Madeline\\'s abuser and former next-door neighbor, has no idea what\\'s about to hit him.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 232,\\n    \\\"endOffset\\\": 240,\\n    \\\"chapterSummary\\\": \\\"Madeline\\'s audio recording captures the most significant steps of her life.\\\"\\n  }\\n]\\n```\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.166539818\n",
      "    severity: HARM_SEVERITY_LOW\n",
      "    severity_score: 0.229707971\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.197135136\n",
      "    severity: HARM_SEVERITY_LOW\n",
      "    severity_score: 0.247441471\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: LOW\n",
      "    probability_score: 0.539316893\n",
      "    severity: HARM_SEVERITY_MEDIUM\n",
      "    severity_score: 0.416737288\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: LOW\n",
      "    probability_score: 0.352982\n",
      "    severity: HARM_SEVERITY_MEDIUM\n",
      "    severity_score: 0.408394754\n",
      "  }\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 851419\n",
      "  candidates_token_count: 459\n",
      "  total_token_count: 851878\n",
      "}\n",
      "\n",
      "['{\\n    \"startOffset\": 120,\\n    \"endOffset\": 136,\\n    \"chapterSummary\": \"A man who is facing 91 criminal charges. A woman thinks it\\'s baloney.\"\\n  }', '{\\n    \"startOffset\": 136,\\n    \"endOffset\": 152,\\n    \"chapterSummary\": \"Madeline West, one of the most recognizable actors, about to play the most nerve-wracking and important role of her life.\"\\n  }', '{\\n    \"startOffset\": 152,\\n    \"endOffset\": 168,\\n    \"chapterSummary\": \"Madeline West has been convinced to wear a hidden recording device by detective Scott Tudnem.\"\\n  }', '{\\n    \"startOffset\": 168,\\n    \"endOffset\": 184,\\n    \"chapterSummary\": \"Madeline says that she can\\'t do this. A man tells her just to act like she\\'s a woman seeking justice.\"\\n  }', '{\\n    \"startOffset\": 184,\\n    \"endOffset\": 200,\\n    \"chapterSummary\": \"Madeline compares the situation to jumping off a waterfall.\"\\n  }', '{\\n    \"startOffset\": 200,\\n    \"endOffset\": 216,\\n    \"chapterSummary\": \"Madeline West is about to confront the monster who had preyed on her and a neighborhood of young children for more than a decade.\"\\n  }', '{\\n    \"startOffset\": 216,\\n    \"endOffset\": 232,\\n    \"chapterSummary\": \"Peter Vincent White, Madeline\\'s abuser and former next-door neighbor, has no idea what\\'s about to hit him.\"\\n  }', '{\\n    \"startOffset\": 232,\\n    \"endOffset\": 240,\\n    \"chapterSummary\": \"Madeline\\'s audio recording captures the most significant steps of her life.\"\\n  }']\n",
      "\n",
      "\n",
      "hereh are you chapters:\n",
      "\n",
      "[{'startOffset': '120', 'endOffset': '136', 'chapterSummary': \"A man who is facing 91 criminal charges. A woman thinks it's baloney.\"}, {'startOffset': '136', 'endOffset': '152', 'chapterSummary': 'Madeline West, one of the most recognizable actors, about to play the most nerve-wracking and important role of her life.'}, {'startOffset': '152', 'endOffset': '168', 'chapterSummary': 'Madeline West has been convinced to wear a hidden recording device by detective Scott Tudnem.'}, {'startOffset': '168', 'endOffset': '184', 'chapterSummary': \"Madeline says that she can't do this. A man tells her just to act like she's a woman seeking justice.\"}, {'startOffset': '184', 'endOffset': '200', 'chapterSummary': 'Madeline compares the situation to jumping off a waterfall.'}, {'startOffset': '200', 'endOffset': '216', 'chapterSummary': 'Madeline West is about to confront the monster who had preyed on her and a neighborhood of young children for more than a decade.'}, {'startOffset': '216', 'endOffset': '232', 'chapterSummary': \"Peter Vincent White, Madeline's abuser and former next-door neighbor, has no idea what's about to hit him.\"}, {'startOffset': '232', 'endOffset': '240', 'chapterSummary': \"Madeline's audio recording captures the most significant steps of her life.\"}]\n",
      "{'start': 240, 'end': 360}\n",
      "getting summaries..\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"```json\\n[\\n  {\\n    \\\"startOffset\\\": 240,\\n    \\\"endOffset\\\": 256,\\n    \\\"chapterSummary\\\": \\\"A man named Peter White, a plumber in a small town Woodend, was a pedophile who used his respectable facade to abuse children. \\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 256,\\n    \\\"endOffset\\\": 272,\\n    \\\"chapterSummary\\\": \\\"Madeleine West, an Australian actor who became famous for being in the TV show Neighbors,  has now come forward to help police put Peter White behind bars. \\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 272,\\n    \\\"endOffset\\\": 288,\\n    \\\"chapterSummary\\\": \\\"The detective in charge of the case, Scott Tuddenham, is not your average detective, he is a former professional fighter. He is a specialist in catching sex offenders. \\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 288,\\n    \\\"endOffset\\\": 304,\\n    \\\"chapterSummary\\\": \\\"Madeleine West says she has had to relive the horrible experience of her childhood abuse from her neighbour, Peter White, a long time ago. \\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 304,\\n    \\\"endOffset\\\": 320,\\n    \\\"chapterSummary\\\": \\\"Peter White was known to invite kids over to watch VHS movies. \\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 320,\\n    \\\"endOffset\\\": 336,\\n    \\\"chapterSummary\\\": \\\"Madeleine West says she told her parents about the abuse. She says, her parents were very young and she remembers the toilet being full of blood after the abuse. \\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 336,\\n    \\\"endOffset\\\": 352,\\n    \\\"chapterSummary\\\": \\\"Madeleine West\\'s childhood friend, Amanda Lee, who grew up in Woodend, says that she also suffered abuse from Peter White. \\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 352,\\n    \\\"endOffset\\\": 360,\\n    \\\"chapterSummary\\\": \\\"Amanda Lee says the abuse happened every weekend for years.  \\\"\\n  }\\n]\\n```\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.169543326\n",
      "    severity: HARM_SEVERITY_LOW\n",
      "    severity_score: 0.230919778\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.193299592\n",
      "    severity: HARM_SEVERITY_LOW\n",
      "    severity_score: 0.23265864\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: LOW\n",
      "    probability_score: 0.551302\n",
      "    severity: HARM_SEVERITY_MEDIUM\n",
      "    severity_score: 0.412175208\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: LOW\n",
      "    probability_score: 0.369770139\n",
      "    severity: HARM_SEVERITY_MEDIUM\n",
      "    severity_score: 0.417271525\n",
      "  }\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 851419\n",
      "  candidates_token_count: 501\n",
      "  total_token_count: 851920\n",
      "}\n",
      "\n",
      "['{\\n    \"startOffset\": 240,\\n    \"endOffset\": 256,\\n    \"chapterSummary\": \"A man named Peter White, a plumber in a small town Woodend, was a pedophile who used his respectable facade to abuse children. \"\\n  }', '{\\n    \"startOffset\": 256,\\n    \"endOffset\": 272,\\n    \"chapterSummary\": \"Madeleine West, an Australian actor who became famous for being in the TV show Neighbors,  has now come forward to help police put Peter White behind bars. \"\\n  }', '{\\n    \"startOffset\": 272,\\n    \"endOffset\": 288,\\n    \"chapterSummary\": \"The detective in charge of the case, Scott Tuddenham, is not your average detective, he is a former professional fighter. He is a specialist in catching sex offenders. \"\\n  }', '{\\n    \"startOffset\": 288,\\n    \"endOffset\": 304,\\n    \"chapterSummary\": \"Madeleine West says she has had to relive the horrible experience of her childhood abuse from her neighbour, Peter White, a long time ago. \"\\n  }', '{\\n    \"startOffset\": 304,\\n    \"endOffset\": 320,\\n    \"chapterSummary\": \"Peter White was known to invite kids over to watch VHS movies. \"\\n  }', '{\\n    \"startOffset\": 320,\\n    \"endOffset\": 336,\\n    \"chapterSummary\": \"Madeleine West says she told her parents about the abuse. She says, her parents were very young and she remembers the toilet being full of blood after the abuse. \"\\n  }', '{\\n    \"startOffset\": 336,\\n    \"endOffset\": 352,\\n    \"chapterSummary\": \"Madeleine West\\'s childhood friend, Amanda Lee, who grew up in Woodend, says that she also suffered abuse from Peter White. \"\\n  }', '{\\n    \"startOffset\": 352,\\n    \"endOffset\": 360,\\n    \"chapterSummary\": \"Amanda Lee says the abuse happened every weekend for years.  \"\\n  }']\n",
      "\n",
      "\n",
      "hereh are you chapters:\n",
      "\n",
      "[{'startOffset': '240', 'endOffset': '256', 'chapterSummary': 'A man named Peter White, a plumber in a small town Woodend, was a pedophile who used his respectable facade to abuse children.'}, {'startOffset': '256', 'endOffset': '272', 'chapterSummary': 'Madeleine West, an Australian actor who became famous for being in the TV show Neighbors,  has now come forward to help police put Peter White behind bars.'}, {'startOffset': '272', 'endOffset': '288', 'chapterSummary': 'The detective in charge of the case, Scott Tuddenham, is not your average detective, he is a former professional fighter. He is a specialist in catching sex offenders.'}, {'startOffset': '288', 'endOffset': '304', 'chapterSummary': 'Madeleine West says she has had to relive the horrible experience of her childhood abuse from her neighbour, Peter White, a long time ago.'}, {'startOffset': '304', 'endOffset': '320', 'chapterSummary': 'Peter White was known to invite kids over to watch VHS movies.'}, {'startOffset': '320', 'endOffset': '336', 'chapterSummary': 'Madeleine West says she told her parents about the abuse. She says, her parents were very young and she remembers the toilet being full of blood after the abuse.'}, {'startOffset': '336', 'endOffset': '352', 'chapterSummary': \"Madeleine West's childhood friend, Amanda Lee, who grew up in Woodend, says that she also suffered abuse from Peter White.\"}, {'startOffset': '352', 'endOffset': '360', 'chapterSummary': 'Amanda Lee says the abuse happened every weekend for years.'}]\n",
      "{'start': 360, 'end': 480}\n",
      "getting summaries..\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"```json\\n[\\n  {\\n    \\\"startOffset\\\": 360,\\n    \\\"endOffset\\\": 376,\\n    \\\"chapterSummary\\\": \\\"Donald Trump is facing 91 indictments and 4 criminal trials. These are related to the attempts to overturn the results of 2020 election, election interference in Georgia, falsifying business records, and mishandling classified documents.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 376,\\n    \\\"endOffset\\\": 392,\\n    \\\"chapterSummary\\\": \\\"Donald Trump\\'s legal team argues that his actions are not a threat to American democracy. They argue that it is vital to maintain the safety of all Americans in the face of threats.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 392,\\n    \\\"endOffset\\\": 408,\\n    \\\"chapterSummary\\\": \\\"Donald Trump is running for presidency in 2024. The US constitution does not prohibit a felon from running for president.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 408,\\n    \\\"endOffset\\\": 424,\\n    \\\"chapterSummary\\\": \\\"Some argue that Joe Biden\\'s age will be a challenge in the upcoming election. Others suggest that his experience in government will be a benefit.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 424,\\n    \\\"endOffset\\\": 440,\\n    \\\"chapterSummary\\\": \\\"The US has a close partnership with NATO and EU, but there are concerns that Trump would potentially disrupt those partnerships.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 440,\\n    \\\"endOffset\\\": 456,\\n    \\\"chapterSummary\\\": \\\"Donald Trump\\'s supporters believe he will be able to win the 2024 election. The world is watching to see what happens with the US election.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 456,\\n    \\\"endOffset\\\": 472,\\n    \\\"chapterSummary\\\": \\\"Michael Cohen, Trump\\'s former lawyer and friend, speaks about his relationship with Trump.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 472,\\n    \\\"endOffset\\\": 480,\\n    \\\"chapterSummary\\\": \\\"The January 6th riot at the US Capitol building was a pivotal moment in American political history. The riot was a direct result of Trump\\'s rhetoric.\\\"\\n  }\\n]\\n```\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.162247255\n",
      "    severity: HARM_SEVERITY_LOW\n",
      "    severity_score: 0.223207697\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.191327676\n",
      "    severity: HARM_SEVERITY_LOW\n",
      "    severity_score: 0.24292329\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: LOW\n",
      "    probability_score: 0.524425149\n",
      "    severity: HARM_SEVERITY_MEDIUM\n",
      "    severity_score: 0.404448658\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: LOW\n",
      "    probability_score: 0.334806889\n",
      "    severity: HARM_SEVERITY_LOW\n",
      "    severity_score: 0.38815406\n",
      "  }\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 851419\n",
      "  candidates_token_count: 536\n",
      "  total_token_count: 851955\n",
      "}\n",
      "\n",
      "['{\\n    \"startOffset\": 360,\\n    \"endOffset\": 376,\\n    \"chapterSummary\": \"Donald Trump is facing 91 indictments and 4 criminal trials. These are related to the attempts to overturn the results of 2020 election, election interference in Georgia, falsifying business records, and mishandling classified documents.\"\\n  }', '{\\n    \"startOffset\": 376,\\n    \"endOffset\": 392,\\n    \"chapterSummary\": \"Donald Trump\\'s legal team argues that his actions are not a threat to American democracy. They argue that it is vital to maintain the safety of all Americans in the face of threats.\"\\n  }', '{\\n    \"startOffset\": 392,\\n    \"endOffset\": 408,\\n    \"chapterSummary\": \"Donald Trump is running for presidency in 2024. The US constitution does not prohibit a felon from running for president.\"\\n  }', '{\\n    \"startOffset\": 408,\\n    \"endOffset\": 424,\\n    \"chapterSummary\": \"Some argue that Joe Biden\\'s age will be a challenge in the upcoming election. Others suggest that his experience in government will be a benefit.\"\\n  }', '{\\n    \"startOffset\": 424,\\n    \"endOffset\": 440,\\n    \"chapterSummary\": \"The US has a close partnership with NATO and EU, but there are concerns that Trump would potentially disrupt those partnerships.\"\\n  }', '{\\n    \"startOffset\": 440,\\n    \"endOffset\": 456,\\n    \"chapterSummary\": \"Donald Trump\\'s supporters believe he will be able to win the 2024 election. The world is watching to see what happens with the US election.\"\\n  }', '{\\n    \"startOffset\": 456,\\n    \"endOffset\": 472,\\n    \"chapterSummary\": \"Michael Cohen, Trump\\'s former lawyer and friend, speaks about his relationship with Trump.\"\\n  }', '{\\n    \"startOffset\": 472,\\n    \"endOffset\": 480,\\n    \"chapterSummary\": \"The January 6th riot at the US Capitol building was a pivotal moment in American political history. The riot was a direct result of Trump\\'s rhetoric.\"\\n  }']\n",
      "\n",
      "\n",
      "hereh are you chapters:\n",
      "\n",
      "[{'startOffset': '360', 'endOffset': '376', 'chapterSummary': 'Donald Trump is facing 91 indictments and 4 criminal trials. These are related to the attempts to overturn the results of 2020 election, election interference in Georgia, falsifying business records, and mishandling classified documents.'}, {'startOffset': '376', 'endOffset': '392', 'chapterSummary': \"Donald Trump's legal team argues that his actions are not a threat to American democracy. They argue that it is vital to maintain the safety of all Americans in the face of threats.\"}, {'startOffset': '392', 'endOffset': '408', 'chapterSummary': 'Donald Trump is running for presidency in 2024. The US constitution does not prohibit a felon from running for president.'}, {'startOffset': '408', 'endOffset': '424', 'chapterSummary': \"Some argue that Joe Biden's age will be a challenge in the upcoming election. Others suggest that his experience in government will be a benefit.\"}, {'startOffset': '424', 'endOffset': '440', 'chapterSummary': 'The US has a close partnership with NATO and EU, but there are concerns that Trump would potentially disrupt those partnerships.'}, {'startOffset': '440', 'endOffset': '456', 'chapterSummary': \"Donald Trump's supporters believe he will be able to win the 2024 election. The world is watching to see what happens with the US election.\"}, {'startOffset': '456', 'endOffset': '472', 'chapterSummary': \"Michael Cohen, Trump's former lawyer and friend, speaks about his relationship with Trump.\"}, {'startOffset': '472', 'endOffset': '480', 'chapterSummary': \"The January 6th riot at the US Capitol building was a pivotal moment in American political history. The riot was a direct result of Trump's rhetoric.\"}]\n",
      "{'start': 480, 'end': 600}\n",
      "getting summaries..\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"```json\\n[\\n  {\\n    \\\"startOffset\\\": 480,\\n    \\\"endOffset\\\": 496,\\n    \\\"chapterSummary\\\": \\\"A woman is interviewed and describes a man that molested her and other children in the past.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 496,\\n    \\\"endOffset\\\": 512,\\n    \\\"chapterSummary\\\": \\\"The man in question was a respected plumber in the small town of Woodend.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 512,\\n    \\\"endOffset\\\": 528,\\n    \\\"chapterSummary\\\": \\\"The woman in question is Madeleine West, an Australian actress who is famous for acting in various TV shows and movies.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 528,\\n    \\\"endOffset\\\": 544,\\n    \\\"chapterSummary\\\": \\\"Madeleine West shares that it took a lot of courage to confront the man in question in 2017.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 544,\\n    \\\"endOffset\\\": 560,\\n    \\\"chapterSummary\\\": \\\"Madeleine West\\'s case was unique, as it involved two women from the same town who had been abused by the same man, and both came forward at different times with their accounts.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 560,\\n    \\\"endOffset\\\": 576,\\n    \\\"chapterSummary\\\": \\\"A detective named Scott Tuddenham is described as a former professional fighter and boxing coach, who made it a mission to protect children.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 576,\\n    \\\"endOffset\\\": 592,\\n    \\\"chapterSummary\\\": \\\"The detective had a difficult time gathering evidence and had to deal with a lot of offenders, but his work proved fruitful in the end. He was very determined to put the offender behind bars.\\\"\\n  },\\n  {\\n    \\\"startOffset\\\": 592,\\n    \\\"endOffset\\\": 600,\\n    \\\"chapterSummary\\\": \\\"The detective used a wire to get the offender to confess his crimes.\\\"\\n  }\\n]\\n```\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.16721867\n",
      "    severity: HARM_SEVERITY_LOW\n",
      "    severity_score: 0.228328541\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.194520772\n",
      "    severity: HARM_SEVERITY_LOW\n",
      "    severity_score: 0.231788054\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: LOW\n",
      "    probability_score: 0.537071705\n",
      "    severity: HARM_SEVERITY_MEDIUM\n",
      "    severity_score: 0.405801922\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: LOW\n",
      "    probability_score: 0.361502767\n",
      "    severity: HARM_SEVERITY_MEDIUM\n",
      "    severity_score: 0.402803183\n",
      "  }\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 851419\n",
      "  candidates_token_count: 485\n",
      "  total_token_count: 851904\n",
      "}\n",
      "\n",
      "['{\\n    \"startOffset\": 480,\\n    \"endOffset\": 496,\\n    \"chapterSummary\": \"A woman is interviewed and describes a man that molested her and other children in the past.\"\\n  }', '{\\n    \"startOffset\": 496,\\n    \"endOffset\": 512,\\n    \"chapterSummary\": \"The man in question was a respected plumber in the small town of Woodend.\"\\n  }', '{\\n    \"startOffset\": 512,\\n    \"endOffset\": 528,\\n    \"chapterSummary\": \"The woman in question is Madeleine West, an Australian actress who is famous for acting in various TV shows and movies.\"\\n  }', '{\\n    \"startOffset\": 528,\\n    \"endOffset\": 544,\\n    \"chapterSummary\": \"Madeleine West shares that it took a lot of courage to confront the man in question in 2017.\"\\n  }', '{\\n    \"startOffset\": 544,\\n    \"endOffset\": 560,\\n    \"chapterSummary\": \"Madeleine West\\'s case was unique, as it involved two women from the same town who had been abused by the same man, and both came forward at different times with their accounts.\"\\n  }', '{\\n    \"startOffset\": 560,\\n    \"endOffset\": 576,\\n    \"chapterSummary\": \"A detective named Scott Tuddenham is described as a former professional fighter and boxing coach, who made it a mission to protect children.\"\\n  }', '{\\n    \"startOffset\": 576,\\n    \"endOffset\": 592,\\n    \"chapterSummary\": \"The detective had a difficult time gathering evidence and had to deal with a lot of offenders, but his work proved fruitful in the end. He was very determined to put the offender behind bars.\"\\n  }', '{\\n    \"startOffset\": 592,\\n    \"endOffset\": 600,\\n    \"chapterSummary\": \"The detective used a wire to get the offender to confess his crimes.\"\\n  }']\n",
      "\n",
      "\n",
      "hereh are you chapters:\n",
      "\n",
      "[{'startOffset': '480', 'endOffset': '496', 'chapterSummary': 'A woman is interviewed and describes a man that molested her and other children in the past.'}, {'startOffset': '496', 'endOffset': '512', 'chapterSummary': 'The man in question was a respected plumber in the small town of Woodend.'}, {'startOffset': '512', 'endOffset': '528', 'chapterSummary': 'The woman in question is Madeleine West, an Australian actress who is famous for acting in various TV shows and movies.'}, {'startOffset': '528', 'endOffset': '544', 'chapterSummary': 'Madeleine West shares that it took a lot of courage to confront the man in question in 2017.'}, {'startOffset': '544', 'endOffset': '560', 'chapterSummary': \"Madeleine West's case was unique, as it involved two women from the same town who had been abused by the same man, and both came forward at different times with their accounts.\"}, {'startOffset': '560', 'endOffset': '576', 'chapterSummary': 'A detective named Scott Tuddenham is described as a former professional fighter and boxing coach, who made it a mission to protect children.'}, {'startOffset': '576', 'endOffset': '592', 'chapterSummary': 'The detective had a difficult time gathering evidence and had to deal with a lot of offenders, but his work proved fruitful in the end. He was very determined to put the offender behind bars.'}, {'startOffset': '592', 'endOffset': '600', 'chapterSummary': 'The detective used a wire to get the offender to confess his crimes.'}]\n"
     ]
    }
   ],
   "source": [
    "video_chapters=[]\n",
    "segments_to_process=120\n",
    "intervals=16\n",
    "video_duration=10*60\n",
    "prev=0\n",
    "import time\n",
    "\n",
    "        \n",
    "        \n",
    "video_file = \"gs://github-repo/embeddings/getting_started_embeddings/UCF-101-subset/BrushingTeeth/v_BrushingTeeth_g01_c02.mp4\"\n",
    "video_file=\"gs://raw_nine_files/60MI23_33_A_HBB.mp4\"\n",
    "video_file=\"gs://raw_nine_files/60MI24_1_A_HBB.mp4\"\n",
    "\n",
    "#video_file=\"gs://github-repo/embeddings/getting_started_embeddings/UCF-101-subset/BrushingTeeth/v_BrushingTeeth_g01_c02.mp4\"\n",
    "startOffset=0\n",
    "endOffset=120\n",
    "intervals=16\n",
    "\n",
    "\n",
    "for val in range (segments_to_process,video_duration+segments_to_process,segments_to_process):\n",
    "                offset={'start':prev, 'end':val}\n",
    "                prev=val    \n",
    "                print(offset)\n",
    "                 \n",
    "                print('getting summaries..')\n",
    "                \n",
    "                chapters=get_video_summarycontent(video_file=video_file,startOffset=offset['start'],endOffset=offset['end'],intervals=intervals)\n",
    "               \n",
    "                for chapter in chapters:\n",
    "                    video_chapters.append(\n",
    "                        VideoChapter(\n",
    "                            embedding=[1,2,3],\n",
    "                            #self.get_summarycontent_embedding_from_text_embedding_model(text=chapter[\"chapterSummary\"]).text_embedding,                           \n",
    "                            start_offset_sec=chapter[\"startOffset\"],\n",
    "                            end_offset_sec=chapter[\"endOffset\"],\n",
    "                            summary=chapter[\"chapterSummary\"]\n",
    "                        )\n",
    "                    )\n",
    "                print(\"hereh are you chapters:\")\n",
    "                print()\n",
    "                print(chapters)\n",
    "                time.sleep(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9bd4d469-34dc-4869-9eaa-337adbad2ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "\n",
    "class VideoChapter:\n",
    "    \"\"\"Chapters generated from video with offset times.\"\"\"\n",
    "\n",
    "    start_offset_sec: int\n",
    "    end_offset_sec: int\n",
    "    embedding: List[float]\n",
    "    summary: str\n",
    "\n",
    "    def __init__(\n",
    "        self, start_offset_sec: int, end_offset_sec: int, embedding: List[float], summary: str\n",
    "    ):\n",
    "        \"\"\"Creates a `VideoEmbedding` object.\n",
    "\n",
    "        Args:\n",
    "            start_offset_sec: Start time offset (in seconds) of generated embeddings.\n",
    "            end_offset_sec: End time offset (in seconds) of generated embeddings.\n",
    "            embedding: Generated embedding for interval.\n",
    "        \"\"\"\n",
    "        self.start_offset_sec = start_offset_sec\n",
    "        self.end_offset_sec = end_offset_sec\n",
    "        self.embedding = embedding\n",
    "        self.summary=summary\n",
    "        \n",
    "\n",
    "def get_video_summarycontent( text: str = None, video_file: str = None,startOffset: int=0, endOffset: int=120, intervals: int=16):\n",
    "        \n",
    "         '''\n",
    "         Gimini Features for Video as per:https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/video-understanding\n",
    "         gemini-1.5-flash, Gemini 1.5 Pro: \n",
    "         With audio: ~50 minutes\n",
    "         Without audio: 60 minutes\n",
    "         Maximum videos per prompt: 10\n",
    "         \n",
    "         Gemini 1.0 Pro Vision:\n",
    "         Maximum video length: 2 minutes\n",
    "         The maximum videos per prompt: 1\n",
    "         Audio in the video is ignored.\n",
    "         \n",
    "         Gimini feature for Part as per:https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#sample-requests\n",
    "        '''\n",
    "        \n",
    "\n",
    " \n",
    "         generative_multimodal_model= GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "         # Please only capture key events and highlights.\n",
    "        \n",
    "         video_description_prompt=f\"\"\"You are an assistant tasked with summarizing videos for retrieval.\\\n",
    "         These summaries will be embedded and used to retrieve the raw video.\\\n",
    "        Chapterize the video content by grouping the video content into chapters \\\n",
    "        with intervals of {intervals} seconds and providing a concise detail for each chapter that is well optimized for retrieval.\\\n",
    "        If there is a famous person like politician, celebrity or athlete, indicate their name and describe what they are famous for.\\\n",
    "        Describe important scenes in the video concisely.\\\n",
    "        If you are not sure about any info, please do not make it up. \\\n",
    "        Only consider video from {startOffset} seconds to {endOffset} seconds. Ignore analyzing the rest of video.\\\n",
    "        If it is the last chapter, set the endOffset to {endOffset} instead.\\ \n",
    "        If a chapter includes prohibited content, set chapterSummary to \"\".\\\n",
    "        For result, follow JSON schema.<JSONSchema>{json.dumps(schema)}</JSONSchema>\"\n",
    "        \"\"\"\n",
    "                   \n",
    "         #generation_config= GenerationConfig(temperature=1, top_k=40,top_p=0.95,max_output_tokens=8192) \n",
    "         generation_config=GenerationConfig(temperature=1, top_k=40,top_p=0.95,max_output_tokens=8192)#, response_mime_type='application/json',\n",
    "\t         # response_schema=json.loads(schema))  \n",
    "         #for video, BLOCK_NONE gives error. So, have to set it to BLOCK_ONLY_HIGH\n",
    "         safety_settings=  {\n",
    "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    }\n",
    "         stream=False\n",
    "        \n",
    "        \n",
    "         # Load the saved video as a Gemini Part Object\n",
    "          \n",
    "         contents=[GenerativeModelPart.from_uri(video_file,mime_type=\"video/mp4\"),\n",
    "                   video_description_prompt,]\n",
    "        \n",
    "        \n",
    "         model_response = generative_multimodal_model.generate_content(\n",
    "            contents,\n",
    "            generation_config=generation_config,\n",
    "            stream=stream,\n",
    "            safety_settings=safety_settings, )\n",
    "        \n",
    "        \n",
    "         response_list = []\n",
    "         print(model_response)\n",
    "        \n",
    "         if str(model_response.prompt_feedback).strip()!='block_reason: PROHIBITED_CONTENT':\n",
    "             response=model_response.text\n",
    "   \n",
    "             chapters=[]\n",
    "             chapters_text=re.findall(r'\\{[^{}]*\\}',response )\n",
    "             print(chapters_text)\n",
    "             print('\\n')\n",
    "             for chapter in chapters_text:\n",
    "                         if 'startOffset' in chapter:\n",
    "                             chapter=chapter.replace('{','').replace('}','').strip()\n",
    "                             chapters.append(\n",
    "                                 {\n",
    "                                    \"startOffset\":chapter.split(',')[0].replace('\"startOffset\":','').replace(\"{\",'').strip(),\n",
    "                                    \"endOffset\":chapter.split(',')[1].replace('\"endOffset\":','').strip(),\n",
    "                                     \"chapterSummary\": ('[ST]'+chapter[chapter.index('\"chapterSummary\":'): len(chapter)-1].replace('\"chapterSummary\":','').replace(\"}\",'').strip()).replace('[ST]\"','')\n",
    "\n",
    "                                 }\n",
    "                             )\n",
    "         else:\n",
    "               chapters.append(\n",
    "                                 {\n",
    "                                    \"startOffset\":str(startOffset),\n",
    "                                    \"endOffset\":str(endOffset),\n",
    "                                     \"chapterSummary\": '***PROHIBITED_CONTENT***'\n",
    "\n",
    "                                 }\n",
    "               )\n",
    "         return chapters\n",
    "\n",
    "#def get_video_summarycontent( text: str = None, video_file: str = None):\n",
    "# def get_video_summarycontent1( text: str = None, video_file: str = None,startOffset: int=0, endOffset: int=120, intervals: int=16):\n",
    "#          '''\n",
    "#          Gimini Features for Video as per:https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/video-understanding\n",
    "#          gemini-1.5-flash, Gemini 1.5 Pro: \n",
    "#          With audio: ~50 minutes\n",
    "#          Without audio: 60 minutes\n",
    "#          Maximum videos per prompt: 10\n",
    "         \n",
    "#          Gemini 1.0 Pro Vision:\n",
    "#          Maximum video length: 2 minutes\n",
    "#          The maximum videos per prompt: 1\n",
    "#          Audio in the video is ignored.\n",
    "         \n",
    "#          Gimini feature for Part as per:https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#sample-requests\n",
    "#         '''\n",
    "        \n",
    "\n",
    " \n",
    "#          generative_multimodal_model= GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "#          # Please only capture key events and highlights.\n",
    "        \n",
    "#          video_description_prompt=f\"\"\"You are an assistant tasked with summarizing videos for retrieval.\\\n",
    "#          These summaries will be embedded and used to retrieve the raw video.\\\n",
    "#         Chapterize the video content by grouping the video content into chapters \\\n",
    "#         with intervals of {intervals} seconds and providing a concise detail for each chapter that is well optimized for retrieval.\\\n",
    "#         If there is a famous person like politician, celebrity or athlete, indicate their name and describe what they are famous for.\\\n",
    "#         Describe important scenes in the video concisely.\\\n",
    "#         If you are not sure about any info, please do not make it up. \\\n",
    "#         Only consider video from {startOffset} seconds to {endOffset} seconds. Ignore analyzing the rest of video.\\\n",
    "#         Return the result as per given schema:\\\n",
    "#         {schema}.\\\n",
    "#         If it is the last chapter, set the endOffset to {endOffset} instead.\\  \n",
    "#         \"\"\"\n",
    "                   \n",
    "#          generation_config= GenerationConfig(temperature=1, top_k=40,top_p=0.95,max_output_tokens=8192) \n",
    "         \n",
    "#         #for video, BLOCK_NONE gives error. So, have to set it to BLOCK_ONLY_HIGH\n",
    "#          safety_settings=  {\n",
    "#                     HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "#                     HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "#                     HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "#                     HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "#                     }\n",
    "#          stream=True\n",
    "        \n",
    "#          # Load the saved video as a Gemini Part Object\n",
    "          \n",
    "#          contents=[GenerativeModelPart.from_uri(video_file,mime_type=\"video/mp4\"),\n",
    "#                    video_description_prompt,]\n",
    "        \n",
    "        \n",
    "#          res = generative_multimodal_model.generate_content(\n",
    "#             contents,\n",
    "#             generation_config=generation_config,\n",
    "#             stream=stream,\n",
    "#             safety_settings=safety_settings, )\n",
    "        \n",
    "        \n",
    "#          response_list = []\n",
    "\n",
    "#          for chunk in res:\n",
    "#             try:\n",
    "#                 response_list.append(chunk.text)\n",
    "#             except Exception as e:\n",
    "#                 print(\n",
    "#                     \"Exception occurred while calling gemini. Something is wrong. Lower the safety thresholds [safety_settings: BLOCK_NONE ] if not already done. -----\",\n",
    "#                     e,\n",
    "#                 )\n",
    "#                 response_list.append(\"****Exception occurred***:\"+e)\n",
    "#                 continue\n",
    "                \n",
    "#          response = ''.join(response_list)\n",
    "#          response=response.replace('''{\\n  \"description\": \"A list of chapters\",\\n  \"type\": \"array\",\\n  \"items\": {\\n\\t\"type\":\"object\",\\n\\t\"properties\": {\\n\\t\\t\"startOffset\": {\\n\\t\\t\\t\"type\":\"integer\"\\n\\t\\t},\\n\\t\\t\"endOffset\": {\\n\\t\\t\\t\"type\":\"integer\"\\n\\t\\t},\\n\\t\\t\"chapterSummary\": {\\n\\t\\t\\t\"type\":\"string\"\\n\\t\\t}\\n\\t},\\n\\t\"required\": [\"startOffset\",\"endOffset\" ]\\n  }\\n},\\n  ''','')\n",
    "#          response=response[response.index('\"items\"'):len(response)-1]\n",
    "\n",
    "#          chapters=[]\n",
    "#          chapters_text=re.findall(r'\\{[^{}]*\\}',response )\n",
    "#          print(chapters_text)\n",
    "#          print('\\n')\n",
    "#          for chapter in chapters_text:\n",
    "#                      chapter=chapter.replace('{','').replace('}','').strip()\n",
    "#                      chapters.append(\n",
    "#                          {\n",
    "#                             \"startOffset\":chapter.split(',')[0].replace('\"startOffset\":','').replace(\"{\",'').strip(),\n",
    "#                             \"endOffset\":chapter.split(',')[1].replace('\"endOffset\":','').strip(),\n",
    "#                              \"chapterSummary\": ('[ST]'+chapter[chapter.index('\"chapterSummary\":'): len(chapter)-1].replace('\"chapterSummary\":','').replace(\"}\",'').strip()).replace('[ST]\"','')\n",
    "                        \n",
    "#                          }\n",
    "#                      )\n",
    "#          return chapters\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f53c0ad8-89c2-4d2a-a996-bbe955ab7cc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "video_file=\"gs://raw_nine_files/60MI23_33_A_HBB.mp4\"\n",
    "def get_video_summarycontent( video_file: str = None,startOffset: int=0, endOffset: int=120, intervals: int=16):\n",
    "        \n",
    "         '''\n",
    "         Gimini Features for Video as per:https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/video-understanding\n",
    "         gemini-1.5-flash, Gemini 1.5 Pro: \n",
    "         With audio: ~50 minutes\n",
    "         Without audio: 60 minutes\n",
    "         Maximum videos per prompt: 10\n",
    "         \n",
    "         Gemini 1.0 Pro Vision:\n",
    "         Maximum video length: 2 minutes\n",
    "         The maximum videos per prompt: 1\n",
    "         Audio in the video is ignored.\n",
    "         \n",
    "         Gimini feature for Part as per:https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#sample-requests\n",
    "        '''\n",
    "        \n",
    "\n",
    " \n",
    "         generative_multimodal_model= GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "         # Please only capture key events and highlights.\n",
    "        \n",
    "         video_description_prompt=f\"\"\"You are an assistant tasked with summarizing videos for retrieval.\\\n",
    "         These summaries will be embedded and used to retrieve the raw video.\\\n",
    "        Chapterize the video content by grouping the video content into chapters \\\n",
    "        with intervals of {intervals} seconds and providing a concise summary for each chapter that is well optimized for retrieval.\\\n",
    "        If there is a famous person like politician, celebrity or athlete, indicate their name and describe what they are famous for.\\\n",
    "        If you are not sure about any info, please do not make it up. \\\n",
    "        Only consider video from {startOffset} seconds to {endOffset} seconds. Ignore analyzing the rest of video.\\\n",
    "        Return the result in the JSON format with keys as follows : \"startOffset\",\"endOffset\", \"chapterSummary\".\\\n",
    "        If it is the last chapter, set the endOffset to {endOffset} instead.\\\n",
    "       \"\"\"\n",
    "\n",
    "        \n",
    "         generation_config= GenerationConfig(temperature=1, top_k=40,top_p=0.95,max_output_tokens=8192) \n",
    "         \n",
    "        #for video, BLOCK_NONE gives error. So, have to set it to BLOCK_ONLY_HIGH\n",
    "         safety_settings=  {\n",
    "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    }\n",
    "         stream=True\n",
    "        \n",
    "         # Load the saved video as a Gemini Part Object\n",
    "          \n",
    "         contents=[GenerativeModelPart.from_uri(video_file,mime_type=\"video/mp4\"),\n",
    "                   video_description_prompt,]\n",
    "        \n",
    "        \n",
    "         response = generative_multimodal_model.generate_content(\n",
    "            contents,\n",
    "            generation_config=generation_config,\n",
    "            stream=stream,\n",
    "            safety_settings=safety_settings, )\n",
    "        \n",
    "        \n",
    "         response_list = []\n",
    "\n",
    "         for chunk in response:\n",
    "            try:\n",
    "                response_list.append(chunk.text)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    \"Exception occurred while calling gemini. Something is wrong. Lower the safety thresholds [safety_settings: BLOCK_NONE ] if not already done. -----\",\n",
    "                    e,\n",
    "                )\n",
    "                response_list.append(\"Exception occurred\")\n",
    "                continue\n",
    "         response = \"\".join(response_list)\n",
    "        \n",
    "         chapters_text=re.findall(r\"\\{.*?\\}\", response.replace('\\n',''))\n",
    "         chapters=[]\n",
    "         for chapter in chapters_text:\n",
    "            chapters.append(yaml.safe_load(chapter))\n",
    " \n",
    "         return response,chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190401dc-00a4-4d0e-927d-b41ed0a54c05",
   "metadata": {},
   "source": [
    "### Defining encoding functions\n",
    "Create an EmbeddingPredictionClient which encapsulates the logic to call the embedding API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2909bb5d-edfb-4921-ba30-450df70aa1b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'google.cloud.aiplatform_v1beta1.types.content' from '/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform_v1beta1/types/content.py'>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part ,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory \n",
    ")\n",
    "\n",
    "from google.cloud.aiplatform_v1beta1.types import (\n",
    "    content as gapic_content_types,\n",
    ")\n",
    "gapic_content_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "90dc1b9d-a545-41d4-9a4a-912228ecfc77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HarmBlockMethod',\n",
       " 'HarmBlockThreshold',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__base__',\n",
       " '__bases__',\n",
       " '__basicsize__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dictoffset__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__flags__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__instancecheck__',\n",
       " '__itemsize__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__mro__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__prepare__',\n",
       " '__qualname__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__ror__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasscheck__',\n",
       " '__subclasses__',\n",
       " '__subclasshook__',\n",
       " '__text_signature__',\n",
       " '__weakrefoffset__',\n",
       " 'copy_from',\n",
       " 'deserialize',\n",
       " 'from_json',\n",
       " 'meta',\n",
       " 'mro',\n",
       " 'pb',\n",
       " 'serialize',\n",
       " 'to_dict',\n",
       " 'to_json',\n",
       " 'wrap']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(gapic_content_types.SafetySetting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a2ad50c-4171-4375-ad84-977710db7a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import time\n",
    "import typing\n",
    "import math\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.protobuf import struct_pb2\n",
    "\n",
    "#libraries to generate image summaries\n",
    "from vertexai.vision_models import Video\n",
    "from vertexai.vision_models import VideoSegmentConfig\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.vision_models import Image as vision_model_Image\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part as GenerativeModelPart,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    "    model_response.prompt_feedback.block_reason.value\n",
    ")\n",
    "from typing import Any, Dict, List, Literal, Optional, Union\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "text_embedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@latest\")\n",
    "#multimodal_embedding_model = MultiModalEmbeddingModel.from_pretrained(\n",
    " #   \"multimodalembedding@001\"\n",
    "#)\n",
    "intervals=120\n",
    "max_duration=120#math.ceil(2719.04)#\n",
    "\n",
    "\n",
    "class VideoEmbedding:\n",
    "    \"\"\"Embeddings generated from video with offset times.\"\"\"\n",
    "\n",
    "    __module__ = \"vertexai.vision_models\"\n",
    "\n",
    "    start_offset_sec: int\n",
    "    end_offset_sec: int\n",
    "    embedding: List[float]\n",
    "\n",
    "    def __init__(\n",
    "        self, start_offset_sec: int, end_offset_sec: int, embedding: List[float]\n",
    "    ):\n",
    "        \"\"\"Creates a `VideoEmbedding` object.\n",
    "\n",
    "        Args:\n",
    "            start_offset_sec: Start time offset (in seconds) of generated embeddings.\n",
    "            end_offset_sec: End time offset (in seconds) of generated embeddings.\n",
    "            embedding: Generated embedding for interval.\n",
    "        \"\"\"\n",
    "        self.start_offset_sec = start_offset_sec\n",
    "        self.end_offset_sec = end_offset_sec\n",
    "        self.embedding = embedding\n",
    "        \n",
    "class EmbeddingResponse(typing.NamedTuple):\n",
    "    text_embedding: typing.Sequence[float]\n",
    "    video_embedding: typing.Sequence[VideoEmbedding]\n",
    "       \n",
    "        \n",
    "def load_video_bytes(video_uri: str) -> bytes:\n",
    "    \"\"\"Load image bytes from a remote or local URI.\"\"\"\n",
    "    video_bytes = None\n",
    "    if video_uri.startswith(\"http://\") or video_uri.startswith(\"https://\") or video_uri.startswith(\"gs://\"):\n",
    "        video_uri=video_uri.replace(\"gs://\", \"https://storage.googleapis.com/\").replace(\n",
    "        \" \", \"%20\")\n",
    "            \n",
    "        response = requests.get(video_uri, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            video_bytes = response.content\n",
    "    else:\n",
    "        video_bytes = open(video_uri, \"rb\").read()\n",
    "        \n",
    "\n",
    "    return video_bytes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_video_duration(video_uri):\n",
    "  try:\n",
    "    \n",
    "    if video_uri.startswith(\"http://\") or video_uri.startswith(\"https://\") or video_uri.startswith(\"gs://\"):\n",
    "        video_uri=video_uri.replace(\"gs://\", \"https://storage.googleapis.com/\").replace(\n",
    "        \" \", \"%20\")\n",
    "        \n",
    "    clip = VideoFileClip(video_uri)\n",
    "    duration = clip.duration\n",
    "    clip.close()  # Release resources\n",
    "    return duration\n",
    "  except OSError as e:\n",
    "    if \"moov atom not found\" in str(e):\n",
    "      print(\"Error: The video file seems to be corrupted or incomplete.\")\n",
    "      #To Do: fix this\n",
    "      #fix the issue using \n",
    "      ##!MP4Box -inter 0  'drive/MyDrive/Colab Notebooks/60MI23_33_A_HBB.mp4'\n",
    "      #for now\n",
    "      return max_duration\n",
    "    else:\n",
    "      print(f\"Error reading video file: {e}\")\n",
    "    return None\n",
    "\n",
    "    \n",
    "class EmbeddingPredictionClient:\n",
    "    \"\"\"Wrapper around Prediction Service Client.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        project: str,\n",
    "        location: str = \"us-central1\",\n",
    "        api_regional_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "    ):\n",
    "        client_options = {\"api_endpoint\": api_regional_endpoint}\n",
    "        # Initialize client that will be used to create and send requests.\n",
    "        # This client only needs to be created once, and can be reused for multiple requests.\n",
    "        self.client = aiplatform.gapic.PredictionServiceClient(\n",
    "            client_options=client_options\n",
    "        )\n",
    "        self.location = location\n",
    "        self.project = project\n",
    "\n",
    "    \n",
    "    def get_embedding(self, text: str = None, video_file: str = None  ):\n",
    "        if not text and not video_file:\n",
    "            raise ValueError(\"At least one of text or video_file must be specified.\")\n",
    "\n",
    " \n",
    "        # Load video file\n",
    "        video_bytes = None\n",
    "        if video_file:           \n",
    "            video_bytes = load_video_bytes(video_file)\n",
    "\n",
    "        instance ={}\n",
    "        if text:\n",
    "            instance[\"text\"] = text\n",
    "\n",
    "        if video_bytes:             \n",
    "                     \n",
    "            encoded_content = base64.b64encode(video_bytes).decode(\"utf-8\")\n",
    "            instance[\"video\"] = {\n",
    "                    \"bytesBase64Encoded\": encoded_content # pylint: disable=protected-access\n",
    "                }  # pylint: disable=protected-access\n",
    "            #get video duration\n",
    "            #as the files are incomplete, for now set it fix\n",
    "            video_duration=math.ceil(get_video_duration(video_file))\n",
    "\n",
    "\n",
    "        endpoint = (\n",
    "           f\"projects/{self.project}/locations/{self.location}\"\n",
    "           \"/publishers/google/models/multimodalembedding@001\"\n",
    "        )\n",
    "\n",
    "        #response =self.client.predict(endpoint=endpoint, instances=instances)\n",
    "\n",
    "        text_embedding = None\n",
    "        if text:\n",
    "            instances = [instance]\n",
    "            response =self.client.predict(endpoint=endpoint, instances=instances)\n",
    "            text_emb_value = response.predictions[0][\"textEmbedding\"]\n",
    "            text_embedding = [v for v in text_emb_value]\n",
    "\n",
    "         \n",
    "        video_embedding = None\n",
    "        if video_bytes:\n",
    "            video_embeddings = []  \n",
    "            prev=0\n",
    "            #iterate over the file and get embeddings of the whole file\n",
    "            for val in range (intervals,video_duration+intervals,intervals):\n",
    "                offset={'start':prev, 'end':val}\n",
    "                prev=val    \n",
    "                print(offset)\n",
    "                video_segments=VideoSegmentConfig(start_offset_sec=offset['start'],end_offset_sec=offset['end'])\n",
    "\n",
    "                if video_segments:\n",
    "                    instance[\"video\"][\"videoSegmentConfig\"] = {\n",
    "                            \"startOffsetSec\": video_segments.start_offset_sec,\n",
    "                            \"endOffsetSec\": video_segments.end_offset_sec,\n",
    "                            \"intervalSec\": video_segments.interval_sec,\n",
    "                        }\n",
    "                \n",
    "                instances = [instance]\n",
    "                response =self.client.predict(endpoint=endpoint, instances=instances)\n",
    "                for video_embedding in response.predictions[0].get(\"videoEmbeddings\", []):\n",
    "                    video_embeddings.append(\n",
    "                        VideoEmbedding(\n",
    "                            embedding=video_embedding[\"embedding\"],\n",
    "                            start_offset_sec=video_embedding[\"startOffsetSec\"],\n",
    "                            end_offset_sec=video_embedding[\"endOffsetSec\"],\n",
    "                        )\n",
    "                    )\n",
    "                # video_embeddings.append(\n",
    "                #         VideoEmbedding(\n",
    "                #             embedding=[1,2,3],\n",
    "                #             start_offset_sec=video_segments.start_offset_sec,\n",
    "                #             end_offset_sec=video_segments.end_offset_sec,\n",
    "                #         )\n",
    "                #     )\n",
    "\n",
    "                \n",
    "        return EmbeddingResponse (text_embedding=text_embedding, video_embedding=video_embeddings)\n",
    " \n",
    "   \n",
    "   \n",
    "    def get_video_summarycontent(self, text: str = None, video_file: str = None):\n",
    "        \n",
    "         '''\n",
    "         Gimini Features for Video as per:https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/video-understanding\n",
    "         gemini-1.5-flash, Gemini 1.5 Pro: \n",
    "         With audio: ~50 minutes\n",
    "         Without audio: 60 minutes\n",
    "         Maximum videos per prompt: 10\n",
    "         \n",
    "         Gemini 1.0 Pro Vision:\n",
    "         Maximum video length: 2 minutes\n",
    "         The maximum videos per prompt: 1\n",
    "         Audio in the video is ignored.\n",
    "         \n",
    "         Gimini feature for Part as per:https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#sample-requests\n",
    "        '''\n",
    "        \n",
    "\n",
    " \n",
    "         generative_multimodal_model= GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "         # Please only capture key events and highlights.\n",
    "         video_description_prompt=\"\"\"You are an assistant tasked with summarizing videos for retrieval.\\\n",
    "         These summaries will be embedded and used to retrieve the raw video.\\\n",
    "        Chapterize the video content by grouping the video content into chapters \\\n",
    "        and providing a concise summary for each chapter that is well optimized for retrieval.\\\n",
    "        If there is a famous person like politician, celebrity or athlete, indicate their name and describe what they are famous for.\\\n",
    "        If you are not sure about any info, please do not make it up. \\\n",
    "        Return the result in the JSON format with keys as follows : \"timecode\", \"chapterSummary\"\n",
    "        \"\"\"\n",
    "\n",
    "         generation_config= GenerationConfig(temperature=1, max_output_tokens=8192,TopK=40,TopP=0.95) \n",
    "        \n",
    "         safety_settings=  {\n",
    "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    }\n",
    "         stream=True\n",
    "        \n",
    "         # Load the saved video as a Gemini Part Object\n",
    "        \n",
    "         video_for_gemini=GenerativeModelPart.from_uri(video_file,mimeType='video/mp4')\n",
    "   \n",
    "         model_input=[video_description_prompt, video_for_gemini]\n",
    "        \n",
    "       \n",
    "        \n",
    "         response = generative_multimodal_model.generate_content(\n",
    "            model_input,\n",
    "            generation_config=generation_config,\n",
    "            stream=stream,\n",
    "            safety_settings=safety_settings, )\n",
    "        \n",
    "        \n",
    "         response_list = []\n",
    "\n",
    "         for chunk in response:\n",
    "            try:\n",
    "                response_list.append(chunk.text)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    \"Exception occurred while calling gemini. Something is wrong. Lower the safety thresholds [safety_settings: BLOCK_NONE ] if not already done. -----\",\n",
    "                    e,\n",
    "                )\n",
    "                response_list.append(\"Exception occurred\")\n",
    "                continue\n",
    "         response = \"\".join(response_list)\n",
    " \n",
    "         return response\n",
    "\n",
    "    \n",
    "    def get_summarycontent_embedding_from_text_embedding_model(self, text: str, return_array: Optional[bool] = False,) -> list:\n",
    "        \"\"\"\n",
    "        Generates a numerical text embedding from a provided text input using a text embedding model.\n",
    "\n",
    "        Args:\n",
    "            text: The input text string to be embedded.\n",
    "            return_array: If True, returns the embedding as a NumPy array.\n",
    "                          If False, returns the embedding as a list. (Default: False)\n",
    "\n",
    "        Returns:\n",
    "            list or numpy.ndarray: A 768-dimensional vector representation of the input text.\n",
    "                                   The format (list or NumPy array) depends on the\n",
    "                                   value of the 'return_array' parameter.\n",
    "        \"\"\"\n",
    "\n",
    "        #the given text is maximum 2048 token. If more, it has to be chunked.\n",
    "        embeddings = text_embedding_model.get_embeddings([text])\n",
    "        text_embedding = [embedding.values for embedding in embeddings][0]\n",
    "\n",
    "        if return_array:\n",
    "            text_embedding = np.fromiter(text_embedding, dtype=float)\n",
    "\n",
    "        # returns 768 dimensional array\n",
    "        return EmbeddingResponse(\n",
    "            text_embedding=text_embedding, image_embedding=None\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728cf6b-baeb-476a-a061-68c748a8dc6e",
   "metadata": {},
   "source": [
    "### Create helper functions to process data in batches\n",
    "Datasets can be large, so it's recommended to load a batch of data at a time into memory using a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e6f9ef7-0279-48f4-a576-3868ec14a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Callable, Generator, List,Tuple\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#Number of API calls per second\n",
    "API_IMAGES_PER_SECOND = 2\n",
    "\n",
    "def generate_batches(\n",
    "    inputs: List[str], batch_size: int\n",
    ") -> Generator[List[str], None, None]:\n",
    "    \"\"\"\n",
    "    Generator function that takes a list of strings and a batch size, and yields batches of the specified size.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(inputs), batch_size):\n",
    "        yield inputs [i : i + batch_size] \n",
    "\n",
    "\n",
    "\n",
    "def encode_to_embeddings_chunked(\n",
    "    process_function: Callable[[List[str]], List[Optional[List[float]]]],\n",
    "    items: str,\n",
    "    batch_size: int = 1,\n",
    ") -> List[Optional[List[float]]]:\n",
    "    \"\"\"\n",
    "    Function that encodes a list of strings into embeddings using a process function.\n",
    "    It takes a list of strings and returns a list of optional lists of floats.\n",
    "    The data is processed in chunks to prevent out-of-memory errors.\n",
    "    \"\"\"\n",
    "    \n",
    "    embeddings_list: List[Optional[List[float]]] = []\n",
    "\n",
    "    # Prepare the batches using a generator\n",
    "    batches = generate_batches(items, batch_size)\n",
    "    \n",
    "   \n",
    "    seconds_per_job = batch_size / API_IMAGES_PER_SECOND\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for batch in tqdm(batches, total=len(items) // batch_size, position=0):\n",
    "            futures.append(executor.submit(process_function, batch))\n",
    "            time.sleep(seconds_per_job)\n",
    "\n",
    "        for future in futures:\n",
    "            embeddings_list.extend(future.result())\n",
    "    return embeddings_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70084d60-e64f-4acf-b41d-07295141df90",
   "metadata": {},
   "source": [
    "### Create functions that wrap embedding functions in try-except and retry logic\n",
    "This particular embedding model can only process 1 image at a time, so inputs are validated to be equal to a length of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc24f964-09eb-4641-a0ed-2a9fc05247aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from tenacity import retry, stop_after_attempt\n",
    "\n",
    "client = EmbeddingPredictionClient(project=PROJECT_ID)\n",
    "\n",
    "\n",
    "# Use a retry handler in case of failure\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_texts_to_embeddings_with_retry(text: List[str]) -> List[List[float]]:\n",
    "    assert len(text) == 1\n",
    "\n",
    "    try:\n",
    "        return [client.get_embedding(text=text[0], image_file=None).text_embedding]\n",
    "    except Exception:\n",
    "        raise RuntimeError(\"Error getting embedding.\")\n",
    "\n",
    "\n",
    "def encode_texts_to_embeddings(text: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_texts_to_embeddings_with_retry(text=text)\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(text))]\n",
    "\n",
    "\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_videos_to_embeddings_with_retry(video_uris: List[str] ) -> List[List[float]]:\n",
    "    assert len(video_uris) == 1\n",
    "\n",
    "    try:\n",
    "        return [\n",
    "            client.get_embedding(text=None, video_file=video_uris[0] ).video_embedding\n",
    "        ]\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        raise RuntimeError(\"Error getting embedding for video.\")\n",
    "\n",
    "\n",
    "def encode_videos_to_embeddings(video_uris: List[str] ) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        \n",
    "        return encode_videos_to_embeddings_with_retry(video_uris=video_uris )\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return [None for _ in range(len(video_uris))]\n",
    "    \n",
    "\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_videos_to_summarycontent_with_retry(video_uris: List[str]) -> List[List[float]]:\n",
    "    assert len(image_uris) == 1\n",
    "\n",
    "    try:\n",
    "        return [\n",
    "            client.get_video_summarycontent(text=None, video_file=video_uris[0])\n",
    "        ]\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        raise RuntimeError(\"Error getting summaries.\")\n",
    "\n",
    "\n",
    "def encode_videos_to_summarycontent(video_uris: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_videos_to_summarycontent_with_retry(video_uris=video_uris)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return [None for _ in range(len(video_uris))]\n",
    "    \n",
    "    \n",
    "# Use a retry handler in case of failure\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_summarycontent_to_embeddings_with_retry(text: List[str]) -> List[List[float]]:\n",
    "    assert len(text) == 1\n",
    "\n",
    "    try:\n",
    "        return [client.get_summarycontent_embedding_from_text_embedding_model(text=text[0]).text_embedding]\n",
    "    except Exception:\n",
    "        raise RuntimeError(\"Error getting embedding for summary content.\")\n",
    "\n",
    "\n",
    "def encode_summarycontent_to_embeddings(text: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_summarycontent_to_embeddings_with_retry(text=text)\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(text))]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e9287-4332-4ac5-8d6a-4b6f2a24f0ff",
   "metadata": {},
   "source": [
    "### Create and save the embeddings in JSONL format\n",
    "The data must be formatted in JSONL format, which means each embedding dictionary is written as an individual JSON object on its own line.\n",
    "\n",
    "See more information in the docs at Input data format and structure.\n",
    "\n",
    "Run the following code in the next available cells, to create a temporary file to store embeddings in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aeb8b57-7ab4-490d-8a98-01f71f45d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile, shutil\n",
    "\n",
    "# Create temporary file to write embeddings to\n",
    "videoembeddings_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=False)\n",
    "\n",
    "# Create temporary file to write summaries to\n",
    "videosummaries_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25a08f1-1e9a-4c97-a0eb-624ce9d75165",
   "metadata": {},
   "source": [
    "### embedding file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a898f97e-a4c3-49b5-afae-9bfa7e1a05d8",
   "metadata": {},
   "source": [
    "### Video Embeddings in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a0e2eed2-d8ff-4d1f-b802-fdf099777d33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SampleVideo/highway_vehicles.mp4']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_paths_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de986c74-1704-4dbb-bc76-6e4493b61755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad0c2e7537840658420d01422db2244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c89c746dc5949d89f6dc035aaa61637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 0, 'end': 120}\n",
      "[[<vertexai.vision_models.VideoEmbedding object at 0x7ff06eff4df0>]]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "BATCH_SIZE = 1# this can be changed\n",
    " \n",
    "           \n",
    "with open(videoembeddings_file.name, \"a\") as ef:     \n",
    "         for i in tqdm(range(0, len(video_paths), BATCH_SIZE)):#len(image_names)\n",
    "            video_names_chunk = video_names[i : i + BATCH_SIZE]\n",
    "            video_paths_chunk = video_paths[i : i + BATCH_SIZE]\n",
    "            \n",
    "            \n",
    "            embeddings=[]\n",
    "            video_summaries=[]\n",
    "            #comment to prevent extra costs\n",
    "            #********************************\n",
    "            embeddings = encode_to_embeddings_chunked(\n",
    "                    process_function=encode_videos_to_embeddings, items=video_paths_chunk)                 \n",
    "            #********************************\n",
    "\n",
    "            #comment to prevent extra costs\n",
    "            #********************************\n",
    "            #summaries = encode_to_embeddings_chunked(\n",
    "                #process_function=encode_videos_to_summarycontent, items=video_paths_chunk\n",
    "               #)\n",
    "\n",
    "            #********************************\n",
    "            #summaries=[' The image shows three people: Joe Biden, a young girl, and Hunter Biden. Joe Biden is smiling and wearing a dark suit. The young girl is smiling and wearing a white dress. Hunter Biden is smiling and wearing a dark suit. The background is a photo of the White House.','this is test']\n",
    "\n",
    "            #comment to prevent extra costs\n",
    "            #********************************\n",
    "            #summaries_embeddings = encode_to_embeddings_chunked(\n",
    "                 #process_function=encode_summarycontent_to_embeddings, items=summaries\n",
    "            #)\n",
    "            #summaries_embeddings=[[1,2],[1,2,3]]\n",
    "\n",
    "            #********************************\n",
    "\n",
    "            print(embeddings)\n",
    "\n",
    "            # Append to file\n",
    "            embeddings_formatted=[]\n",
    "            for id,path,embedding in zip(video_names_chunk,video_paths_chunk,embeddings):\n",
    "                for value in embedding:\n",
    "                    if value.embedding is not None:\n",
    "                        embeddings_formatted.append(  \n",
    "                            json.dumps(\n",
    "                                {\n",
    "                                    \"id\": str(id), \n",
    "                                    \"video path\":str(path),\n",
    "                                    \"embedding\": [str(value) for value in value.embedding],\n",
    "                                    \"start_offset_sec\": value.start_offset_sec,\n",
    "                                    \"end_offset_sec\": value.end_offset_sec \n",
    "                                }\n",
    "                            )\n",
    "                            + \"\\n\"\n",
    "\n",
    "                        )\n",
    "            ef.writelines(embeddings_formatted)\n",
    "        \n",
    " \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb182a-2199-4b47-b844-65df08836758",
   "metadata": {},
   "source": [
    "### Create bucket and push embeddings into the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e5e18b-8a1c-4d1a-8013-d5ebd1a173cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#set bucket info to create a bucket\n",
    "BUCKET_URI = f\"gs://artifacts-{PROJECT_ID}-unique\"  # @param {type:\"string\"}\n",
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2354d-42f3-4b45-a387-c9f225f9b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIQUE_FOLDER_NAME = \"embeddings_results_NinePOC\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58369a05-16b4-4f93-b792-03b389544a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings\n",
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/{UNIQUE_FOLDER_NAME}/\"\n",
    "! gsutil cp {embeddings_file.name} {EMBEDDINGS_INITIAL_URI}\n",
    "\n",
    "#summaries\n",
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/{UNIQUE_FOLDER_NAME}/\"\n",
    "! gsutil cp {summaries_file.name} {EMBEDDINGS_INITIAL_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4fae7267-4f5f-43e7-a0fe-c39b4e0b9d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'summaries_file.json'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the temp files in persistent disk\n",
    "import tempfile, shutil\n",
    " \n",
    "file_name = embeddings_file.name\n",
    "embeddings_file.close()\n",
    "shutil.copy(file_name, 'embeddings_file.json')\n",
    "\n",
    "file_name = summaries_file.name\n",
    "summaries_file.close()\n",
    "shutil.copy(file_name, 'summaries_file.json')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe4468d-d92f-45cb-a3d0-9de84d8344be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
