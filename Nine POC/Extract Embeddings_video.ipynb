{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a354f9-0984-4c94-9042-efb28db5f4be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.58.0)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.59.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (2.14.0)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.17.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.31.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.19.6)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (24.1)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.25.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.12.3)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.4)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.10.17)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.7.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.32.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.1)\n",
      "INFO: pip is looking at multiple versions of google-api-core[grpc] to determine which version is compatible with other requirements. This could take a while.\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.7)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.7.4)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
      "Downloading google_cloud_aiplatform-1.59.0-py2.py3-none-any.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-2.17.0-py2.py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: google-api-core, google-cloud-storage, google-cloud-aiplatform\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 1.34.1\n",
      "    Uninstalling google-api-core-1.34.1:\n",
      "      Successfully uninstalled google-api-core-1.34.1\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.14.0\n",
      "    Uninstalling google-cloud-storage-2.14.0:\n",
      "      Successfully uninstalled google-cloud-storage-2.14.0\n",
      "  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 1.58.0\n",
      "    Uninstalling google-cloud-aiplatform-1.58.0:\n",
      "      Successfully uninstalled google-cloud-aiplatform-1.58.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.19.1 which is incompatible.\n",
      "google-cloud-pubsub 2.21.4 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.48.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-api-core-2.11.1 google-cloud-aiplatform-1.59.0 google-cloud-storage-2.17.0\n",
      "Requirement already satisfied: google-cloud-vision in /opt/conda/lib/python3.10/site-packages (3.7.2)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2.11.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-vision) (2.31.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-vision) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-vision) (3.19.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.63.1)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.48.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (4.9)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "# Install the packages\n",
    "! pip3 install --upgrade google-cloud-aiplatform \\\n",
    "                         google-cloud-storage\n",
    "\n",
    "# Install the packages\n",
    "! pip install google-cloud-vision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895e40a3-1749-4b68-ac38-7e001f32a101",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-videointelligence in /opt/conda/lib/python3.10/site-packages (1.16.3)\n",
      "Collecting google-cloud-videointelligence\n",
      "  Downloading google_cloud_videointelligence-2.13.4-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2.11.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-videointelligence) (2.31.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-videointelligence) (1.24.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 (from google-cloud-videointelligence)\n",
      "  Downloading protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.63.1)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.48.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (4.9)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2024.7.4)\n",
      "Downloading google_cloud_videointelligence-2.13.4-py2.py3-none-any.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.0/245.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf, google-cloud-videointelligence\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: google-cloud-videointelligence\n",
      "    Found existing installation: google-cloud-videointelligence 1.16.3\n",
      "    Uninstalling google-cloud-videointelligence-1.16.3:\n",
      "      Successfully uninstalled google-cloud-videointelligence-1.16.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "apache-beam 2.46.0 requires grpcio!=1.48.0,<2,>=1.33.1, but you have grpcio 1.48.0 which is incompatible.\n",
      "apache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.11.1 which is incompatible.\n",
      "google-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-datastore 1.15.5 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-language 1.3.2 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-pubsub 2.21.4 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.48.0 which is incompatible.\n",
      "google-cloud-storage 2.17.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 2.11.1 which is incompatible.\n",
      "kfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.3 which is incompatible.\n",
      "kfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorboardx 2.6 requires protobuf<4,>=3.8.0, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-serving-api 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-cloud-videointelligence-2.13.4 protobuf-3.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-videointelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70639287-6593-462f-a952-cfa0605b29dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8162339b-0555-46c0-8271-a26fe9fe99a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set project info\n",
    "PROJECT = !gcloud config get-value project\n",
    "PROJECT_ID = PROJECT[0]\n",
    "REGION = \"us-central1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fb72555-1765-496b-ad6a-d8c7d3aff330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "video_directory = \"SampleVideo\"\n",
    "\n",
    "video_names=[]\n",
    "for file_name in os.listdir(video_directory):\n",
    "    if  not file_name.startswith('.'):\n",
    "        video_names.append(file_name)\n",
    "\n",
    "video_paths = [os.path.join(video_directory, video_name) for video_name in video_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07f4fb10-2294-4fef-b4ac-a9075d30663a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_paths=[\"gs://cloud-samples-data/vertex-ai-vision/highway_vehicles.mp4\"]\n",
    "video_paths=[\"gs://raw_nine_files/60MI23_33_A_HBB.mp4\"]\n",
    "video_names=['60MI23_33_A_HBB.mp4']\n",
    "\n",
    "#second sample\n",
    "video_paths=[\"gs://raw_nine_files/60MI24_1_A_HBB.mp4\"]\n",
    "video_names=['60MI24_1_A_HBB.mp4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6125a26-9f33-4c17-bd52-657233921201",
   "metadata": {},
   "source": [
    "### Define function to detect explicit images\n",
    "\n",
    "enable clound vision api before running this bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b070ae5-1f9e-430f-9fda-9e01bcee82b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.cloud.videointelligence.v1beta import SafeSearchAnnotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4839766e-611a-4f1b-b7eb-9f4ab6c03f41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for now the api is not active just to save costs. I set everything to true\n",
    "is_safe_values_cloud_vision=[True for i in range (len(video_paths))]\n",
    "is_safe_values_cloud_vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f555e1b5-65f5-4afb-a36b-d00a43d174f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter images by safety\n",
    "video_names = [\n",
    "    video_name\n",
    "    for video_name, is_safe in zip(video_names, is_safe_values_cloud_vision)\n",
    "    if is_safe\n",
    "]\n",
    "video_paths = [\n",
    "    video_path\n",
    "    for video_path, is_safe in zip(video_paths, is_safe_values_cloud_vision)\n",
    "    if is_safe\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190401dc-00a4-4d0e-927d-b41ed0a54c05",
   "metadata": {},
   "source": [
    "### Defining encoding functions\n",
    "Create an EmbeddingPredictionClient which encapsulates the logic to call the embedding API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82af3661-214e-4c4b-bcd4-10390c5441f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# client = EmbeddingPredictionClient(project=PROJECT_ID)\n",
    "\n",
    "# a=client.get_embedding(video_file= video_paths[0]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab017234-eed5-4282-ab56-11f3ff30959b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://raw_nine_files/60MI24_1_A_HBB.mp4'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a2ad50c-4171-4375-ad84-977710db7a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import time\n",
    "import typing\n",
    "import math\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.protobuf import struct_pb2\n",
    "\n",
    "#libraries to generate image summaries\n",
    "from vertexai.vision_models import Video\n",
    "from vertexai.vision_models import VideoSegmentConfig\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.vision_models import Image as vision_model_Image\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part as GenerativeModelPart,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n",
    "from typing import Any, Dict, List, Literal, Optional, Union\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "text_embedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@latest\")\n",
    "#multimodal_embedding_model = MultiModalEmbeddingModel.from_pretrained(\n",
    " #   \"multimodalembedding@001\"\n",
    "#)\n",
    "import requests\n",
    "from google.cloud import storage\n",
    "from google.cloud.aiplatform import initializer as aiplatform_initializer\n",
    "import datetime\n",
    "\n",
    "import yaml\n",
    "import re\n",
    "\n",
    "segments_to_process=120 #segments duration\n",
    "intervals=16#intervals\n",
    "video_start =0 #where from video to start\n",
    "\n",
    "#max_duration=120#math.ceil(2719.04)#\n",
    "\n",
    "schema = '''\n",
    "{\n",
    "  \"description\": \"A list of chapters\",\n",
    "  \"type\": \"array\",\n",
    "  \"items\": {\n",
    "\t\"type\":\"object\",\n",
    "\t\"properties\": {\n",
    "\t\t\"startOffset\": {\n",
    "\t\t\t\"type\":\"integer\"\n",
    "\t\t},\n",
    "\t\t\"endOffset\": {\n",
    "\t\t\t\"type\":\"integer\"\n",
    "\t\t},\n",
    "\t\t\"chapterSummary\": {\n",
    "\t\t\t\"type\":\"string\"\n",
    "\t\t}\n",
    "\t},\n",
    "\t\"required\": [\"startOffset\",\"endOffset\",\"chapterSummary\" ]\n",
    "  }\n",
    "}\n",
    "'''\n",
    "\n",
    "\n",
    "class VideoEmbedding:\n",
    "    \"\"\"Embeddings generated from video with offset times.\"\"\"\n",
    "\n",
    "    __module__ = \"vertexai.vision_models\"\n",
    "\n",
    "    start_offset_sec: int\n",
    "    end_offset_sec: int\n",
    "    embedding: List[float]\n",
    "\n",
    "    def __init__(\n",
    "        self, start_offset_sec: int, end_offset_sec: int, embedding: List[float]\n",
    "    ):\n",
    "        \"\"\"Creates a `VideoEmbedding` object.\n",
    "\n",
    "        Args:\n",
    "            start_offset_sec: Start time offset (in seconds) of generated embeddings.\n",
    "            end_offset_sec: End time offset (in seconds) of generated embeddings.\n",
    "            embedding: Generated embedding for interval.\n",
    "        \"\"\"\n",
    "        self.start_offset_sec = start_offset_sec\n",
    "        self.end_offset_sec = end_offset_sec\n",
    "        self.embedding = embedding\n",
    "        \n",
    "        \n",
    "class VideoChapter:\n",
    "    \"\"\"Chapters generated from video with offset times.\"\"\"\n",
    "\n",
    "    start_offset_sec: int\n",
    "    end_offset_sec: int\n",
    "    embedding: List[float]\n",
    "    summary: str\n",
    "\n",
    "    def __init__(\n",
    "        self, start_offset_sec: int, end_offset_sec: int, embedding: List[float], summary: str\n",
    "    ):\n",
    "        \"\"\"Creates a `VideoEmbedding` object.\n",
    "\n",
    "        Args:\n",
    "            start_offset_sec: Start time offset (in seconds) of generated embeddings.\n",
    "            end_offset_sec: End time offset (in seconds) of generated embeddings.\n",
    "            embedding: Generated embedding for interval.\n",
    "        \"\"\"\n",
    "        self.start_offset_sec = start_offset_sec\n",
    "        self.end_offset_sec = end_offset_sec\n",
    "        self.embedding = embedding\n",
    "        self.summary=summary\n",
    "        \n",
    "        \n",
    "class EmbeddingResponse(typing.NamedTuple):\n",
    "    text_embedding: typing.Sequence[float]\n",
    "    video_embedding: typing.Sequence[VideoEmbedding]\n",
    "    video_chapter: typing.Sequence[VideoChapter]\n",
    "       \n",
    "        \n",
    "def load_video_bytes(video_uri: str ) -> bytes:\n",
    "    \"\"\"Load image bytes from a remote or local URI.\"\"\"\n",
    "   \n",
    "    video_bytes = None\n",
    "    if video_uri.startswith(\"http://\") or video_uri.startswith(\"https://\") :\n",
    "        #reading from remote\n",
    "        video_uri=video_uri.replace(\" \", \"%20\")\n",
    "        response = requests.get(video_uri, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            video_bytes = response.content\n",
    "    elif   video_uri.startswith(\"gs://\"):\n",
    "           #reading from gcs\n",
    "            storage_client = storage.Client(\n",
    "                   credentials=aiplatform_initializer.global_config.credentials\n",
    "                      )\n",
    "            blob = storage.Blob.from_string(uri=video_uri, client=storage_client)\n",
    "            # Needed to populate `blob.content_type`\n",
    "            blob.reload()\n",
    "            blob.download_as_bytes()  \n",
    "            video_bytes=blob.download_as_bytes()\n",
    "           \n",
    "        \n",
    "    else:\n",
    "        #reading from local\n",
    "        video_bytes = open(video_uri, \"rb\").read()\n",
    "        \n",
    "\n",
    "    return video_bytes\n",
    "\n",
    "\n",
    "def generate_download_signed_url_v4(bucket_name, blob_name):\n",
    "    \"\"\"Generates a v4 signed URL for downloading a blob.\n",
    "\n",
    "    Note that this method requires a service account key file. You can not use\n",
    "    this if you are using Application Default Credentials from Google Compute\n",
    "    Engine or from the Google Cloud SDK.\n",
    "    \"\"\"\n",
    "    # bucket_name = 'your-bucket-name'\n",
    "    # blob_name = 'your-object-name'\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    \n",
    "    from google.auth.transport import requests\n",
    "    from google.auth import default, compute_engine\n",
    "    \n",
    "    credentials, _ = default()\n",
    "    \n",
    "    # then within your abstraction\n",
    "    auth_request = requests.Request()\n",
    "    credentials.refresh(auth_request)\n",
    "    \n",
    "    signing_credentials = compute_engine.IDTokenCredentials(\n",
    "        auth_request,\n",
    "        \"\",\n",
    "        service_account_email=credentials.service_account_email\n",
    "    )\n",
    " \n",
    "    print(signing_credentials)\n",
    "    url = blob.generate_signed_url(\n",
    "        version=\"v4\",\n",
    "        # This URL is valid for 15 minutes\n",
    "        expiration=datetime.timedelta(minutes=15),\n",
    "        # Allow GET requests using this URL.\n",
    "        method=\"GET\",\n",
    "         credentials=signing_credentials,\n",
    "    )\n",
    "    return url\n",
    "\n",
    "\n",
    "def get_video_duration(video_uri):\n",
    "  try:   \n",
    "    \n",
    "    if video_uri.startswith(\"http://\") or video_uri.startswith(\"https://\") :\n",
    "        video_uri=video_uri.replace(\" \", \"%20\")\n",
    "    elif video_uri.startswith(\"gs://\"):  \n",
    "        bucket_name='/'.join(video_paths[0].replace('gs://','').split('/')[:-1])\n",
    "        blob_name=video_uri.replace('gs://','').split('/')[-1]\n",
    "        video_uri= generate_download_signed_url_v4(bucket_name, blob_name)\n",
    "    else:\n",
    "        video_uri=video_uri\n",
    "        \n",
    "    clip = VideoFileClip(video_uri)\n",
    "    duration = clip.duration\n",
    "    clip.close()  # Release resources\n",
    "    return duration\n",
    "  except OSError as e:\n",
    "    if \"moov atom not found\" in str(e):\n",
    "      print(\"Error: The video file seems to be corrupted or incomplete.\")\n",
    "      #To Do: fix this\n",
    "      #fix the issue using \n",
    "      ##!MP4Box -inter 0  'drive/MyDrive/Colab Notebooks/60MI23_33_A_HBB.mp4'\n",
    "      #for now\n",
    "      return max_duration\n",
    "    else:\n",
    "      print(f\"Error reading video file: {e}\")\n",
    "    return max_duration\n",
    "\n",
    "    \n",
    "class EmbeddingPredictionClient:\n",
    "    \"\"\"Wrapper around Prediction Service Client.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        project: str,\n",
    "        location: str = \"us-central1\",\n",
    "        api_regional_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "    ):\n",
    "        client_options = {\"api_endpoint\": api_regional_endpoint}\n",
    "        # Initialize client that will be used to create and send requests.\n",
    "        # This client only needs to be created once, and can be reused for multiple requests.\n",
    "        self.client = aiplatform.gapic.PredictionServiceClient(\n",
    "            client_options=client_options\n",
    "        )\n",
    "        self.location = location\n",
    "        self.project = project\n",
    "        \n",
    "\n",
    "    \n",
    "    def get_embedding(self, text: str = None, video_file: str = None  ):\n",
    "        if not text and not video_file:\n",
    "            raise ValueError(\"At least one of text or video_file must be specified.\")\n",
    "\n",
    " \n",
    "        # Load video file\n",
    "        video_bytes = None\n",
    "        if (video_file) and (not video_file.startswith(\"gs://\")):             \n",
    "            video_bytes = load_video_bytes(video_file)\n",
    "\n",
    " \n",
    "        instance ={}\n",
    "        if text:\n",
    "            instance[\"text\"] = text\n",
    "\n",
    "        if (video_file) and ((video_bytes) or (video_file.startswith(\"gs://\"))):             \n",
    "            \n",
    "            if video_bytes:\n",
    "               encoded_content = base64.b64encode(video_bytes).decode(\"utf-8\")\n",
    "               instance[\"video\"] = {\n",
    "                    \"bytesBase64Encoded\": encoded_content # pylint: disable=protected-access\n",
    "                }#  # pylint: disable=protected-access\n",
    "               \n",
    "            if  (video_file.startswith(\"gs://\")):  \n",
    "                instance[\"video\"] = {\n",
    "                        \"gcsUri\": video_file  # pylint: disable=protected-access\n",
    "                    }          \n",
    "                \n",
    "            #get video duration\n",
    "            video_duration=2885#math.ceil(get_video_duration(video_file))\n",
    "     \n",
    "\n",
    "\n",
    "        endpoint = (\n",
    "           f\"projects/{self.project}/locations/{self.location}\"\n",
    "           \"/publishers/google/models/multimodalembedding@001\"\n",
    "        )\n",
    "        \n",
    "\n",
    "        #response =self.client.predict(endpoint=endpoint, instances=instances)\n",
    "\n",
    "        text_embedding = None\n",
    "        if text:\n",
    "            instances = [instance]\n",
    "            response =self.client.predict(endpoint=endpoint, instances=instances)\n",
    "            text_emb_value = response.predictions[0][\"textEmbedding\"]\n",
    "            text_embedding = [v for v in text_emb_value]\n",
    "\n",
    "        \n",
    "        video_embedding = None\n",
    "        if (video_file) and ((video_bytes) or (video_file.startswith(\"gs://\"))): \n",
    "            video_embeddings = [] \n",
    "            prev=video_start \n",
    "            #iterate over the file and get embeddings of the whole file      \n",
    "            for val in range (segments_to_process,video_duration+segments_to_process,segments_to_process):\n",
    "                offset={'start':prev, 'end':val}\n",
    "                prev=val    \n",
    "                print(offset)\n",
    "                print('getting Multimodal Embeddings..')\n",
    "                video_segments=VideoSegmentConfig(start_offset_sec=offset['start'],end_offset_sec=offset['end'])\n",
    "\n",
    "                if video_segments:\n",
    "                    instance[\"video\"][\"videoSegmentConfig\"] = {\n",
    "                            \"startOffsetSec\": video_segments.start_offset_sec,\n",
    "                            \"endOffsetSec\": video_segments.end_offset_sec,\n",
    "                            \"intervalSec\": video_segments.interval_sec,\n",
    "                        }\n",
    "                \n",
    "                instances = [instance]\n",
    "                try:\n",
    "                    response =self.client.predict(endpoint=endpoint, instances=instances)\n",
    "                    for video_embedding in response.predictions[0].get(\"videoEmbeddings\", []):\n",
    "                        video_embeddings.append(\n",
    "                            VideoEmbedding(\n",
    "                                embedding=video_embedding[\"embedding\"],                           \n",
    "                                start_offset_sec=video_embedding[\"startOffsetSec\"],\n",
    "                                end_offset_sec=video_embedding[\"endOffsetSec\"],\n",
    "                            )\n",
    "                        )\n",
    "                    print('Done! Multimodal Embedding from' +str(video_segments.start_offset_sec)+'-'+str( video_segments.end_offset_sec) )\n",
    "                except Exception as e :\n",
    "                       print('Error in Response Multimodal Embedding from' +str(video_segments.start_offset_sec)+'-'+str( video_segments.end_offset_sec)+str(e))\n",
    "                       video_embeddings.append(\n",
    "                            VideoEmbedding(\n",
    "                                embedding=None,                           \n",
    "                                start_offset_sec=video_segments.start_offset_sec,\n",
    "                                end_offset_sec= video_segments.end_offset_sec,\n",
    "                            )\n",
    "                        )\n",
    "                    \n",
    "\n",
    "#                 video_embeddings.append(\n",
    "#                             VideoEmbedding(\n",
    "#                                 embedding=[1,2,3],\n",
    "#                                 start_offset_sec=offset['start'],\n",
    "#                                 end_offset_sec=offset['end'],\n",
    "#                             )\n",
    "#                         )              \n",
    "\n",
    "                \n",
    "        return EmbeddingResponse (text_embedding=text_embedding, video_embedding=video_embeddings, video_chapter=[])\n",
    " \n",
    "   \n",
    "   \n",
    "    def get_video_summarycontent(self, text: str = None, video_file: str = None ):\n",
    "        \n",
    "         '''\n",
    "         Gimini Features for Video as per:https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/video-understanding\n",
    "         gemini-1.5-flash, Gemini 1.5 Pro: \n",
    "         With audio: ~50 minutes\n",
    "         Without audio: 60 minutes\n",
    "         Maximum videos per prompt: 10\n",
    "         \n",
    "         Gemini 1.0 Pro Vision:\n",
    "         Maximum video length: 2 minutes\n",
    "         The maximum videos per prompt: 1\n",
    "         Audio in the video is ignored.\n",
    "         \n",
    "         Gimini feature for Part as per:https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#sample-requests\n",
    "        '''\n",
    "                \n",
    "         generative_multimodal_model= GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "         #generation_config= GenerationConfig(temperature=1, top_k=40,top_p=0.95,max_output_tokens=8192) \n",
    "         generation_config=GenerationConfig(temperature=1, top_k=40,top_p=0.95,max_output_tokens=8192)#, response_mime_type='application/json',\n",
    "\t         # response_schema=json.loads(schema))  \n",
    "         #for video, BLOCK_NONE gives error. So, have to set it to BLOCK_ONLY_HIGH\n",
    "         safety_settings=  {\n",
    "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    }\n",
    "         stream=False\n",
    "        \n",
    "         video_duration=2885#math.ceil(get_video_duration(video_file))\n",
    "         chapters=[]  \n",
    "         video_chapters=[]\n",
    "         prev=video_start\n",
    "          \n",
    "         for val in range (segments_to_process,video_duration+segments_to_process,segments_to_process):\n",
    "                offset={'start':prev, 'end':val}\n",
    "                prev=val    \n",
    "                print(offset)\n",
    "                startOffset=offset['start']\n",
    "                endOffset=offset['end']\n",
    "                \n",
    "                video_description_prompt=f\"\"\"You are an assistant tasked with summarizing videos for retrieval.\\\n",
    "                     These summaries will be embedded and used to retrieve the raw video.\\\n",
    "                    Chapterize the video content by grouping the video content into chapters \\\n",
    "                    with intervals of {intervals} seconds and providing a concise detail for each chapter that is well optimized for retrieval.\\\n",
    "                    If there is a famous person like politician, celebrity or athlete, indicate their name and describe what they are famous for.\\\n",
    "                    Describe important scenes in the video concisely.\\\n",
    "                    If you are not sure about any info, please do not make it up. \\\n",
    "                    Only consider video from {startOffset} seconds to {endOffset} seconds. Ignore analyzing the rest of video.\\\n",
    "                    If it is the last chapter, set the endOffset to {endOffset} instead.\\ \n",
    "                    If a chapter includes prohibited content, set chapterSummary to \"\".\\\n",
    "                    For result, follow JSON schema.<JSONSchema>{json.dumps(schema)}</JSONSchema>\"\n",
    "                    \"\"\"   \n",
    "#                 video_chapters.append(\n",
    "#                         VideoChapter(\n",
    "#                             embedding=[],                           \n",
    "#                             start_offset_sec=startOffset,\n",
    "#                             end_offset_sec=endOffset,\n",
    "#                             summary='test'\n",
    "#                         )\n",
    "#                 )\n",
    "                \n",
    "                # Load the saved video as a Gemini Part Object          \n",
    "                contents=[GenerativeModelPart.from_uri(video_file,mime_type=\"video/mp4\"),\n",
    "                       video_description_prompt,]        \n",
    "        \n",
    "                model_response = generative_multimodal_model.generate_content(\n",
    "                                contents,\n",
    "                                generation_config=generation_config,\n",
    "                                stream=stream,\n",
    "                                safety_settings=safety_settings, )        \n",
    "        \n",
    "                response_list = []\n",
    "                print(model_response)\n",
    "        \n",
    "                if str(model_response.prompt_feedback).strip()!='block_reason: PROHIBITED_CONTENT':\n",
    "                     response=model_response.text\n",
    "                     chapters_text=re.findall(r'\\{[^{}]*\\}',response )\n",
    "                     print(chapters_text)\n",
    "                     print('\\n')\n",
    "                     for chapter in chapters_text:\n",
    "                                 if 'startOffset' in chapter:\n",
    "                                     chapter=chapter.replace('{','').replace('}','').strip()\n",
    "                                     chapters.append(\n",
    "                                         {\n",
    "                                            \"startOffset\":chapter.split(',')[0].replace('\"startOffset\":','').replace(\"{\",'').strip(),\n",
    "                                            \"endOffset\":chapter.split(',')[1].replace('\"endOffset\":','').strip(),\n",
    "                                             \"chapterSummary\": ('[ST]'+chapter[chapter.index('\"chapterSummary\":'): len(chapter)-1].replace('\"chapterSummary\":','').replace(\"}\",'').strip()).replace('[ST]\"','')\n",
    "\n",
    "                                         }\n",
    "                                     )\n",
    "                else:\n",
    "                       chapters.append(\n",
    "                                         {\n",
    "                                            \"startOffset\":str(startOffset),\n",
    "                                            \"endOffset\":str(endOffset),\n",
    "                                             \"chapterSummary\": '***PROHIBITED_CONTENT***'\n",
    "\n",
    "                                         } \n",
    "                                       )                \n",
    "          \n",
    "                \n",
    "                for chapter in chapters:\n",
    "                    try:\n",
    "                        if chapter[\"chapterSummary\"] !='***PROHIBITED_CONTENT***' and chapter[\"chapterSummary\"].strip()!=\"\":\n",
    "                             embedding=self.get_summarycontent_embedding_from_text_embedding_model(text=chapter[\"chapterSummary\"]).text_embedding\n",
    "                        else:\n",
    "                             embedding=None\n",
    "                    except:\n",
    "                        embedding=None\n",
    "                        \n",
    "                    video_chapters.append(\n",
    "                        VideoChapter(\n",
    "                            embedding=embedding,                          \n",
    "                            start_offset_sec=chapter[\"startOffset\"],\n",
    "                            end_offset_sec=chapter[\"endOffset\"],\n",
    "                            summary=chapter[\"chapterSummary\"]\n",
    "                             )\n",
    "                           )\n",
    "         \n",
    "         return EmbeddingResponse (text_embedding=[], video_embedding=[], video_chapter=video_chapters)\n",
    "    \n",
    "    def get_summarycontent_embedding_from_text_embedding_model(self, text: str, return_array: Optional[bool] = False,) -> list:\n",
    "        \"\"\"\n",
    "        Generates a numerical text embedding from a provided text input using a text embedding model.\n",
    "\n",
    "        Args:\n",
    "            text: The input text string to be embedded.\n",
    "            return_array: If True, returns the embedding as a NumPy array.\n",
    "                          If False, returns the embedding as a list. (Default: False)\n",
    "\n",
    "        Returns:\n",
    "            list or numpy.ndarray: A 768-dimensional vector representation of the input text.\n",
    "                                   The format (list or NumPy array) depends on the\n",
    "                                   value of the 'return_array' parameter.\n",
    "        \"\"\"\n",
    "\n",
    "        #the given text is maximum 2048 token. If more, it has to be chunked.\n",
    "        embeddings = text_embedding_model.get_embeddings([text])\n",
    "        text_embedding = [embedding.values for embedding in embeddings][0]\n",
    "\n",
    "        if return_array:\n",
    "            text_embedding = np.fromiter(text_embedding, dtype=float)\n",
    "\n",
    "        # returns 768 dimensional array\n",
    "        return EmbeddingResponse(\n",
    "            text_embedding=text_embedding, video_embedding=None, video_chapter=None\n",
    "        )   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728cf6b-baeb-476a-a061-68c748a8dc6e",
   "metadata": {},
   "source": [
    "### Create helper functions to process data in batches\n",
    "Datasets can be large, so it's recommended to load a batch of data at a time into memory using a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e6f9ef7-0279-48f4-a576-3868ec14a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Callable, Generator, List,Tuple\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#Number of API calls per second\n",
    "API_IMAGES_PER_SECOND = 2\n",
    "\n",
    "def generate_batches(\n",
    "    inputs: List[str], batch_size: int\n",
    ") -> Generator[List[str], None, None]:\n",
    "    \"\"\"\n",
    "    Generator function that takes a list of strings and a batch size, and yields batches of the specified size.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(inputs), batch_size):\n",
    "        yield inputs [i : i + batch_size] \n",
    "\n",
    "\n",
    "\n",
    "def encode_to_embeddings_chunked(\n",
    "    process_function: Callable[[List[str]], List[Optional[List[float]]]],\n",
    "    items: str,\n",
    "    batch_size: int = 1,\n",
    ") -> List[Optional[List[float]]]:\n",
    "    \"\"\"\n",
    "    Function that encodes a list of strings into embeddings using a process function.\n",
    "    It takes a list of strings and returns a list of optional lists of floats.\n",
    "    The data is processed in chunks to prevent out-of-memory errors.\n",
    "    \"\"\"\n",
    "    \n",
    "    embeddings_list: List[Optional[List[float]]] = []\n",
    "\n",
    "    # Prepare the batches using a generator\n",
    "    batches = generate_batches(items, batch_size)\n",
    "    \n",
    "   \n",
    "    seconds_per_job = batch_size / API_IMAGES_PER_SECOND\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for batch in tqdm(batches, total=len(items) // batch_size, position=0):\n",
    "            futures.append(executor.submit(process_function, batch))\n",
    "            time.sleep(seconds_per_job)\n",
    "\n",
    "        for future in futures:\n",
    "            embeddings_list.extend(future.result())\n",
    "    return embeddings_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70084d60-e64f-4acf-b41d-07295141df90",
   "metadata": {},
   "source": [
    "### Create functions that wrap embedding functions in try-except and retry logic\n",
    "This particular embedding model can only process 1 image at a time, so inputs are validated to be equal to a length of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc24f964-09eb-4641-a0ed-2a9fc05247aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from tenacity import retry, stop_after_attempt\n",
    "\n",
    "client = EmbeddingPredictionClient(project=PROJECT_ID)\n",
    "\n",
    "\n",
    "# Use a retry handler in case of failure\n",
    "@retry(reraise=True, stop=stop_after_attempt(0))\n",
    "def encode_texts_to_embeddings_with_retry(text: List[str]) -> List[List[float]]:\n",
    "    assert len(text) == 1\n",
    "\n",
    "    try:\n",
    "        return [client.get_embedding(text=text[0], image_file=None).text_embedding]\n",
    "    except Exception:\n",
    "        raise RuntimeError(\"Error getting embedding.\")\n",
    "\n",
    "\n",
    "def encode_texts_to_embeddings(text: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_texts_to_embeddings_with_retry(text=text)\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(text))]\n",
    "\n",
    "\n",
    "@retry(reraise=True, stop=stop_after_attempt(0))\n",
    "def encode_videos_to_embeddings_with_retry(video_uris: List[str] ) -> List[List[float]]:\n",
    "    assert len(video_uris) == 1\n",
    "\n",
    "    try:\n",
    "        embeddings=client.get_embedding(text=None, video_file=video_uris[0] )\n",
    "        return [embeddings.video_embedding],[embeddings.video_chapter] \n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        raise RuntimeError(\"Error getting embedding for video.\")\n",
    "\n",
    "\n",
    "def encode_videos_to_embeddings(video_uris: List[str] ) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        \n",
    "        return encode_videos_to_embeddings_with_retry(video_uris=video_uris )\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return [None for _ in range(len(video_uris))]\n",
    "    \n",
    "\n",
    "@retry(reraise=True, stop=stop_after_attempt(0))\n",
    "def encode_videos_to_summarycontent_with_retry(video_uris: List[str]) -> List[List[float]]:\n",
    "    assert len(video_uris) == 1\n",
    "\n",
    "    try:\n",
    "        return [\n",
    "            client.get_video_summarycontent(text=None, video_file=video_uris[0]).video_chapter\n",
    "        ]\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        raise RuntimeError(\"Error getting summaries.\")\n",
    "\n",
    "\n",
    "def encode_videos_to_summarycontent(video_uris: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_videos_to_summarycontent_with_retry(video_uris=video_uris)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return [None for _ in range(len(video_uris))]\n",
    "    \n",
    "    \n",
    "# Use a retry handler in case of failure\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_summarycontent_to_embeddings_with_retry(text: List[str]) -> List[List[float]]:\n",
    "    assert len(text) == 1\n",
    "\n",
    "    try:\n",
    "        return [client.get_summarycontent_embedding_from_text_embedding_model(text=text[0]).text_embedding]\n",
    "    except Exception:\n",
    "        raise RuntimeError(\"Error getting embedding for summary content.\")\n",
    "\n",
    "\n",
    "def encode_summarycontent_to_embeddings(text: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_summarycontent_to_embeddings_with_retry(text=text)\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(text))]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e9287-4332-4ac5-8d6a-4b6f2a24f0ff",
   "metadata": {},
   "source": [
    "### Create and save the embeddings in JSONL format\n",
    "The data must be formatted in JSONL format, which means each embedding dictionary is written as an individual JSON object on its own line.\n",
    "\n",
    "See more information in the docs at Input data format and structure.\n",
    "\n",
    "Run the following code in the next available cells, to create a temporary file to store embeddings in JSON format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25a08f1-1e9a-4c97-a0eb-624ce9d75165",
   "metadata": {},
   "source": [
    "### embedding file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a898f97e-a4c3-49b5-afae-9bfa7e1a05d8",
   "metadata": {},
   "source": [
    "### Video Embeddings in Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de986c74-1704-4dbb-bc76-6e4493b61755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ddde309da6c4fbca4971f24abae4d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36df007209f48bf80df3e303669db82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 0, 'end': 120}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from0-120\n",
      "{'start': 120, 'end': 240}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from120-240\n",
      "{'start': 240, 'end': 360}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from240-360\n",
      "{'start': 360, 'end': 480}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from360-480\n",
      "{'start': 480, 'end': 600}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from480-600\n",
      "{'start': 600, 'end': 720}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from600-720\n",
      "{'start': 720, 'end': 840}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from720-840\n",
      "{'start': 840, 'end': 960}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from840-960\n",
      "{'start': 960, 'end': 1080}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from960-1080\n",
      "{'start': 1080, 'end': 1200}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from1080-1200\n",
      "{'start': 1200, 'end': 1320}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from1200-1320\n",
      "{'start': 1320, 'end': 1440}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from1320-1440\n",
      "{'start': 1440, 'end': 1560}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from1440-1560\n",
      "{'start': 1560, 'end': 1680}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from1560-1680\n",
      "{'start': 1680, 'end': 1800}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from1680-1800\n",
      "{'start': 1800, 'end': 1920}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from1800-1920\n",
      "{'start': 1920, 'end': 2040}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from1920-2040\n",
      "{'start': 2040, 'end': 2160}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from2040-2160\n",
      "{'start': 2160, 'end': 2280}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from2160-2280\n",
      "{'start': 2280, 'end': 2400}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from2280-2400\n",
      "{'start': 2400, 'end': 2520}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from2400-2520\n",
      "{'start': 2520, 'end': 2640}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from2520-2640\n",
      "{'start': 2640, 'end': 2760}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from2640-2760\n",
      "{'start': 2760, 'end': 2880}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from2760-2880\n",
      "{'start': 2880, 'end': 3000}\n",
      "getting Multimodal Embeddings..\n",
      "Done! Multimodal Embedding from2880-3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'videoembeddings_file.json'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import operator\n",
    "import tempfile, shutil\n",
    "\n",
    "\n",
    "# Create temporary file to write embeddings to\n",
    "videoembeddings_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=False)\n",
    "\n",
    "BATCH_SIZE = 1# this can be changed\n",
    " \n",
    "           \n",
    "with open(videoembeddings_file.name, \"a\") as ef :     \n",
    "         for i in tqdm(range(0, len(video_paths), BATCH_SIZE)):#len(image_names)\n",
    "            video_names_chunk = video_names[i : i + BATCH_SIZE]\n",
    "            video_paths_chunk = video_paths[i : i + BATCH_SIZE]\n",
    "            \n",
    "            \n",
    "            embeddings=[]\n",
    "            video_summaries=[]\n",
    "            #comment to prevent extra costs\n",
    "            #********************************\n",
    "            video_embeddings,_ = encode_to_embeddings_chunked(\n",
    "                   process_function=encode_videos_to_embeddings, items=video_paths_chunk)                 \n",
    "            #********************************\n",
    "\n",
    "           # Append to file\n",
    "            video_embeddings_formatted=[]\n",
    "            for id,path,embedding in zip(video_names_chunk,video_paths_chunk,video_embeddings):\n",
    "                embedding=sorted(embedding, key=operator.attrgetter('start_offset_sec'))\n",
    "             \n",
    "                for ValEmbedding in embedding:\n",
    "                    video_embeddings_formatted.append(  \n",
    "                                json.dumps(\n",
    "                                    {\n",
    "                                        \"id\": str(id), \n",
    "                                        \"video path\":str(path),                                       \n",
    "                                        \"video_embedding\": [str(value) for value in ValEmbedding.embedding] if not ValEmbedding.embedding is None else None,                                        \n",
    "                                        \"start_offset_sec_embedding\": ValEmbedding.start_offset_sec,\n",
    "                                        \"end_offset_sec_embedding\": ValEmbedding.end_offset_sec \n",
    "                                    }\n",
    "                                )\n",
    "                                + \"\\n\"\n",
    "\n",
    "                            )\n",
    "              \n",
    "            ef.writelines(video_embeddings_formatted)\n",
    "            \n",
    "embedding_file_name = videoembeddings_file.name\n",
    "videoembeddings_file.close()\n",
    "shutil.copy(embedding_file_name, 'videoembeddings_file.json')\n",
    "           \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc59029-38de-4924-98e4-d3b5ba965fcc",
   "metadata": {},
   "source": [
    "### video summaries in Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4ea0f2ce-4e6c-4d27-bafd-c6c60ed527ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75b7020f1624edda649142bb59d449a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ea94ecd0cf4737987d831f00b41f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 0, 'end': 120}\n",
      "{'start': 120, 'end': 240}\n",
      "{'start': 240, 'end': 360}\n",
      "{'start': 360, 'end': 480}\n",
      "{'start': 480, 'end': 600}\n",
      "{'start': 600, 'end': 720}\n",
      "{'start': 720, 'end': 840}\n",
      "{'start': 840, 'end': 960}\n",
      "{'start': 960, 'end': 1080}\n",
      "{'start': 1080, 'end': 1200}\n",
      "{'start': 1200, 'end': 1320}\n",
      "{'start': 1320, 'end': 1440}\n",
      "{'start': 1440, 'end': 1560}\n",
      "{'start': 1560, 'end': 1680}\n",
      "{'start': 1680, 'end': 1800}\n",
      "{'start': 1800, 'end': 1920}\n",
      "{'start': 1920, 'end': 2040}\n",
      "{'start': 2040, 'end': 2160}\n",
      "{'start': 2160, 'end': 2280}\n",
      "{'start': 2280, 'end': 2400}\n",
      "{'start': 2400, 'end': 2520}\n",
      "{'start': 2520, 'end': 2640}\n",
      "{'start': 2640, 'end': 2760}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'videosummaries_file.json'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import operator\n",
    "import tempfile, shutil\n",
    " \n",
    "# Create temporary file to write summaries to\n",
    "videosummaries_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=False)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 1# this can be changed\n",
    " \n",
    "           \n",
    "with  open(videosummaries_file.name, \"a\") as sf:     \n",
    "         for i in tqdm(range(0, len(video_paths), BATCH_SIZE)):#len(image_names)\n",
    "            video_names_chunk = video_names[i : i + BATCH_SIZE]\n",
    "            video_paths_chunk = video_paths[i : i + BATCH_SIZE]\n",
    "            \n",
    "            #comment to prevent extra costs\n",
    "            #********************************\n",
    "            video_chapters = encode_to_embeddings_chunked(\n",
    "                process_function=encode_videos_to_summarycontent, items=video_paths_chunk\n",
    "               )\n",
    "            \n",
    "            # Append to file\n",
    "            video_chapters_formatted=[]\n",
    "            for id,path,embedding in zip(video_names_chunk,video_paths_chunk,video_chapters):\n",
    "                embedding=sorted(embedding, key=operator.attrgetter('start_offset_sec'))\n",
    "             \n",
    "                for ValChapter in embedding:\n",
    "                    video_chapters_formatted.append(  \n",
    "                                json.dumps(\n",
    "                                    {\n",
    "                                        \"id\": str(id), \n",
    "                                        \"video path\":str(path),  \n",
    "                                         \"chapter_summary\":ValChapter.summary,\n",
    "                                        \"chapter_embedding\": [str(value) for value in ValEmbedding.embedding] if not ValChapter.embedding is None else None,                                        \n",
    "                                        \"start_offset_sec_chapter\": ValChapter.start_offset_sec,\n",
    "                                        \"end_offset_sec_chapter\": ValChapter.end_offset_sec \n",
    "                                    }\n",
    "                                )\n",
    "                                + \"\\n\"\n",
    "\n",
    "                            )\n",
    "              \n",
    "            sf.writelines(video_chapters_formatted)\n",
    "           \n",
    "            \n",
    "summaries_file_name = videosummaries_file.name\n",
    "videosummaries_file.close()\n",
    "shutil.copy(summaries_file_name, 'videosummaries_file.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb182a-2199-4b47-b844-65df08836758",
   "metadata": {},
   "source": [
    "### Create bucket and push embeddings into the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e5e18b-8a1c-4d1a-8013-d5ebd1a173cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#set bucket info to create a bucket\n",
    "BUCKET_URI = f\"gs://artifacts-{PROJECT_ID}-unique\"  # @param {type:\"string\"}\n",
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2354d-42f3-4b45-a387-c9f225f9b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIQUE_FOLDER_NAME = \"embeddings_results_NinePOC\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58369a05-16b4-4f93-b792-03b389544a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings\n",
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/{UNIQUE_FOLDER_NAME}/\"\n",
    "! gsutil cp {embeddings_file.name} {EMBEDDINGS_INITIAL_URI}\n",
    "\n",
    "#summaries\n",
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/{UNIQUE_FOLDER_NAME}/\"\n",
    "! gsutil cp {summaries_file.name} {EMBEDDINGS_INITIAL_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4fae7267-4f5f-43e7-a0fe-c39b4e0b9d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'videoembeddings_file.json'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the temp files in persistent disk\n",
    "import tempfile, shutil\n",
    " \n",
    "file_name = videoembeddings_file.name\n",
    "videoembeddings_file.close()\n",
    "shutil.copy(file_name, 'videoembeddings_file.json')\n",
    "\n",
    "# file_name = summaries_file.name\n",
    "# summaries_file.close()\n",
    "# shutil.copy(file_name, 'summaries_file.json')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe4468d-d92f-45cb-a3d0-9de84d8344be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
