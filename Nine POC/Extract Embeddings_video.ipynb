{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a354f9-0984-4c94-9042-efb28db5f4be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.58.0)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.59.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (2.14.0)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.17.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.31.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.19.6)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (24.1)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.25.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.12.3)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.4)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.10.17)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.7.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.32.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.1)\n",
      "INFO: pip is looking at multiple versions of google-api-core[grpc] to determine which version is compatible with other requirements. This could take a while.\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.7)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.7.4)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
      "Downloading google_cloud_aiplatform-1.59.0-py2.py3-none-any.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-2.17.0-py2.py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: google-api-core, google-cloud-storage, google-cloud-aiplatform\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 1.34.1\n",
      "    Uninstalling google-api-core-1.34.1:\n",
      "      Successfully uninstalled google-api-core-1.34.1\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.14.0\n",
      "    Uninstalling google-cloud-storage-2.14.0:\n",
      "      Successfully uninstalled google-cloud-storage-2.14.0\n",
      "  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 1.58.0\n",
      "    Uninstalling google-cloud-aiplatform-1.58.0:\n",
      "      Successfully uninstalled google-cloud-aiplatform-1.58.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.19.1 which is incompatible.\n",
      "google-cloud-pubsub 2.21.4 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.48.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-api-core-2.11.1 google-cloud-aiplatform-1.59.0 google-cloud-storage-2.17.0\n",
      "Requirement already satisfied: google-cloud-vision in /opt/conda/lib/python3.10/site-packages (3.7.2)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2.11.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-vision) (2.31.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-vision) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-vision) (3.19.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.63.1)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.48.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (4.9)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "# Install the packages\n",
    "! pip3 install --upgrade google-cloud-aiplatform \\\n",
    "                         google-cloud-storage\n",
    "\n",
    "# Install the packages\n",
    "! pip install google-cloud-vision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895e40a3-1749-4b68-ac38-7e001f32a101",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-videointelligence in /opt/conda/lib/python3.10/site-packages (1.16.3)\n",
      "Collecting google-cloud-videointelligence\n",
      "  Downloading google_cloud_videointelligence-2.13.4-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2.11.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-videointelligence) (2.31.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-videointelligence) (1.24.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 (from google-cloud-videointelligence)\n",
      "  Downloading protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.63.1)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.48.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (4.9)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2024.7.4)\n",
      "Downloading google_cloud_videointelligence-2.13.4-py2.py3-none-any.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.0/245.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf, google-cloud-videointelligence\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: google-cloud-videointelligence\n",
      "    Found existing installation: google-cloud-videointelligence 1.16.3\n",
      "    Uninstalling google-cloud-videointelligence-1.16.3:\n",
      "      Successfully uninstalled google-cloud-videointelligence-1.16.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "apache-beam 2.46.0 requires grpcio!=1.48.0,<2,>=1.33.1, but you have grpcio 1.48.0 which is incompatible.\n",
      "apache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.11.1 which is incompatible.\n",
      "google-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-datastore 1.15.5 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-language 1.3.2 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-pubsub 2.21.4 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.48.0 which is incompatible.\n",
      "google-cloud-storage 2.17.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 2.11.1 which is incompatible.\n",
      "kfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.3 which is incompatible.\n",
      "kfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorboardx 2.6 requires protobuf<4,>=3.8.0, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-serving-api 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-cloud-videointelligence-2.13.4 protobuf-3.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-videointelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70639287-6593-462f-a952-cfa0605b29dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8162339b-0555-46c0-8271-a26fe9fe99a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set project info\n",
    "PROJECT = !gcloud config get-value project\n",
    "PROJECT_ID = PROJECT[0]\n",
    "REGION = \"us-central1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fb72555-1765-496b-ad6a-d8c7d3aff330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "video_directory = \"SampleVideo\"\n",
    "\n",
    "video_names=[]\n",
    "for file_name in os.listdir(video_directory):\n",
    "    if  not file_name.startswith('.'):\n",
    "        video_names.append(file_name)\n",
    "\n",
    "video_paths = [os.path.join(video_directory, video_name) for video_name in video_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "07f4fb10-2294-4fef-b4ac-a9075d30663a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_paths=[\"gs://cloud-samples-data/vertex-ai-vision/highway_vehicles.mp4\"]\n",
    "video_paths=[\"gs://raw_nine_files/60MI23_33_A_HBB.mp4\"]\n",
    "video_names=['60MI23_33_A_HBB.mp4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6125a26-9f33-4c17-bd52-657233921201",
   "metadata": {},
   "source": [
    "### Define function to detect explicit images\n",
    "\n",
    "enable clound vision api before running this bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b070ae5-1f9e-430f-9fda-9e01bcee82b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.cloud.videointelligence.v1beta import SafeSearchAnnotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4839766e-611a-4f1b-b7eb-9f4ab6c03f41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for now the api is not active just to save costs. I set everything to true\n",
    "is_safe_values_cloud_vision=[True for i in range (len(video_paths))]\n",
    "is_safe_values_cloud_vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f555e1b5-65f5-4afb-a36b-d00a43d174f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter images by safety\n",
    "video_names = [\n",
    "    video_name\n",
    "    for video_name, is_safe in zip(video_names, is_safe_values_cloud_vision)\n",
    "    if is_safe\n",
    "]\n",
    "video_paths = [\n",
    "    video_path\n",
    "    for video_path, is_safe in zip(video_paths, is_safe_values_cloud_vision)\n",
    "    if is_safe\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190401dc-00a4-4d0e-927d-b41ed0a54c05",
   "metadata": {},
   "source": [
    "### Defining encoding functions\n",
    "Create an EmbeddingPredictionClient which encapsulates the logic to call the embedding API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9a2ad50c-4171-4375-ad84-977710db7a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import time\n",
    "import typing\n",
    "import math\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.protobuf import struct_pb2\n",
    "\n",
    "#libraries to generate image summaries\n",
    "from vertexai.vision_models import Video\n",
    "from vertexai.vision_models import VideoSegmentConfig\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.vision_models import Image as vision_model_Image\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part as GenerativeModelPart,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n",
    "from typing import Any, Dict, List, Literal, Optional, Union\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "text_embedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@latest\")\n",
    "#multimodal_embedding_model = MultiModalEmbeddingModel.from_pretrained(\n",
    " #   \"multimodalembedding@001\"\n",
    "#)\n",
    "import requests\n",
    "from google.cloud import storage\n",
    "from google.cloud.aiplatform import initializer as aiplatform_initializer\n",
    "import datetime\n",
    "\n",
    "import yaml\n",
    "import re\n",
    "\n",
    "segments_to_process=120\n",
    "intervals=16\n",
    "#max_duration=120#math.ceil(2719.04)#\n",
    "\n",
    "\n",
    "class VideoEmbedding:\n",
    "    \"\"\"Embeddings generated from video with offset times.\"\"\"\n",
    "\n",
    "    __module__ = \"vertexai.vision_models\"\n",
    "\n",
    "    start_offset_sec: int\n",
    "    end_offset_sec: int\n",
    "    embedding: List[float]\n",
    "\n",
    "    def __init__(\n",
    "        self, start_offset_sec: int, end_offset_sec: int, embedding: List[float]\n",
    "    ):\n",
    "        \"\"\"Creates a `VideoEmbedding` object.\n",
    "\n",
    "        Args:\n",
    "            start_offset_sec: Start time offset (in seconds) of generated embeddings.\n",
    "            end_offset_sec: End time offset (in seconds) of generated embeddings.\n",
    "            embedding: Generated embedding for interval.\n",
    "        \"\"\"\n",
    "        self.start_offset_sec = start_offset_sec\n",
    "        self.end_offset_sec = end_offset_sec\n",
    "        self.embedding = embedding\n",
    "        \n",
    "        \n",
    "class VideoChapter:\n",
    "    \"\"\"Chapters generated from video with offset times.\"\"\"\n",
    "\n",
    "    start_offset_sec: int\n",
    "    end_offset_sec: int\n",
    "    embedding: List[float]\n",
    "    summary: str\n",
    "\n",
    "    def __init__(\n",
    "        self, start_offset_sec: int, end_offset_sec: int, embedding: List[float], summary: str\n",
    "    ):\n",
    "        \"\"\"Creates a `VideoEmbedding` object.\n",
    "\n",
    "        Args:\n",
    "            start_offset_sec: Start time offset (in seconds) of generated embeddings.\n",
    "            end_offset_sec: End time offset (in seconds) of generated embeddings.\n",
    "            embedding: Generated embedding for interval.\n",
    "        \"\"\"\n",
    "        self.start_offset_sec = start_offset_sec\n",
    "        self.end_offset_sec = end_offset_sec\n",
    "        self.embedding = embedding\n",
    "        self.summary=summary\n",
    "        \n",
    "        \n",
    "class EmbeddingResponse(typing.NamedTuple):\n",
    "    text_embedding: typing.Sequence[float]\n",
    "    video_embedding: typing.Sequence[VideoEmbedding]\n",
    "    video_chapter: typing.Sequence[VideoChapter]\n",
    "       \n",
    "        \n",
    "def load_video_bytes(video_uri: str ) -> bytes:\n",
    "    \"\"\"Load image bytes from a remote or local URI.\"\"\"\n",
    "   \n",
    "    video_bytes = None\n",
    "    if video_uri.startswith(\"http://\") or video_uri.startswith(\"https://\") :\n",
    "        #reading from remote\n",
    "        video_uri=video_uri.replace(\" \", \"%20\")\n",
    "        response = requests.get(video_uri, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            video_bytes = response.content\n",
    "    elif   video_uri.startswith(\"gs://\"):\n",
    "           #reading from gcs\n",
    "            storage_client = storage.Client(\n",
    "                   credentials=aiplatform_initializer.global_config.credentials\n",
    "                      )\n",
    "            blob = storage.Blob.from_string(uri=video_uri, client=storage_client)\n",
    "            # Needed to populate `blob.content_type`\n",
    "            blob.reload()\n",
    "            blob.download_as_bytes()  \n",
    "            video_bytes=blob.download_as_bytes()\n",
    "           \n",
    "        \n",
    "    else:\n",
    "        #reading from local\n",
    "        video_bytes = open(video_uri, \"rb\").read()\n",
    "        \n",
    "\n",
    "    return video_bytes\n",
    "\n",
    "\n",
    "def generate_download_signed_url_v4(bucket_name, blob_name):\n",
    "    \"\"\"Generates a v4 signed URL for downloading a blob.\n",
    "\n",
    "    Note that this method requires a service account key file. You can not use\n",
    "    this if you are using Application Default Credentials from Google Compute\n",
    "    Engine or from the Google Cloud SDK.\n",
    "    \"\"\"\n",
    "    # bucket_name = 'your-bucket-name'\n",
    "    # blob_name = 'your-object-name'\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    \n",
    "    from google.auth.transport import requests\n",
    "    from google.auth import default, compute_engine\n",
    "    \n",
    "    credentials, _ = default()\n",
    "    \n",
    "    # then within your abstraction\n",
    "    auth_request = requests.Request()\n",
    "    credentials.refresh(auth_request)\n",
    "    \n",
    "    signing_credentials = compute_engine.IDTokenCredentials(\n",
    "        auth_request,\n",
    "        \"\",\n",
    "        service_account_email=credentials.service_account_email\n",
    "    )\n",
    " \n",
    "    print(signing_credentials)\n",
    "    url = blob.generate_signed_url(\n",
    "        version=\"v4\",\n",
    "        # This URL is valid for 15 minutes\n",
    "        expiration=datetime.timedelta(minutes=15),\n",
    "        # Allow GET requests using this URL.\n",
    "        method=\"GET\",\n",
    "         credentials=signing_credentials,\n",
    "    )\n",
    "    return url\n",
    "\n",
    "\n",
    "def get_video_duration(video_uri):\n",
    "  try:   \n",
    "    \n",
    "    if video_uri.startswith(\"http://\") or video_uri.startswith(\"https://\") :\n",
    "        video_uri=video_uri.replace(\" \", \"%20\")\n",
    "    elif video_uri.startswith(\"gs://\"):  \n",
    "        bucket_name='/'.join(video_paths[0].replace('gs://','').split('/')[:-1])\n",
    "        blob_name=video_uri.replace('gs://','').split('/')[-1]\n",
    "        video_uri= generate_download_signed_url_v4(bucket_name, blob_name)\n",
    "    else:\n",
    "        video_uri=video_uri\n",
    "        \n",
    "    clip = VideoFileClip(video_uri)\n",
    "    duration = clip.duration\n",
    "    clip.close()  # Release resources\n",
    "    return duration\n",
    "  except OSError as e:\n",
    "    if \"moov atom not found\" in str(e):\n",
    "      print(\"Error: The video file seems to be corrupted or incomplete.\")\n",
    "      #To Do: fix this\n",
    "      #fix the issue using \n",
    "      ##!MP4Box -inter 0  'drive/MyDrive/Colab Notebooks/60MI23_33_A_HBB.mp4'\n",
    "      #for now\n",
    "      return max_duration\n",
    "    else:\n",
    "      print(f\"Error reading video file: {e}\")\n",
    "    return max_duration\n",
    "\n",
    "    \n",
    "class EmbeddingPredictionClient:\n",
    "    \"\"\"Wrapper around Prediction Service Client.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        project: str,\n",
    "        location: str = \"us-central1\",\n",
    "        api_regional_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "    ):\n",
    "        client_options = {\"api_endpoint\": api_regional_endpoint}\n",
    "        # Initialize client that will be used to create and send requests.\n",
    "        # This client only needs to be created once, and can be reused for multiple requests.\n",
    "        self.client = aiplatform.gapic.PredictionServiceClient(\n",
    "            client_options=client_options\n",
    "        )\n",
    "        self.location = location\n",
    "        self.project = project\n",
    "        \n",
    "\n",
    "    \n",
    "    def get_embedding(self, text: str = None, video_file: str = None  ):\n",
    "        if not text and not video_file:\n",
    "            raise ValueError(\"At least one of text or video_file must be specified.\")\n",
    "\n",
    " \n",
    "        # Load video file\n",
    "        video_bytes = None\n",
    "        if (video_file) and (not video_file.startswith(\"gs://\")):             \n",
    "            video_bytes = load_video_bytes(video_file)\n",
    "\n",
    " \n",
    "        instance ={}\n",
    "        if text:\n",
    "            instance[\"text\"] = text\n",
    "\n",
    "        if (video_file) and ((video_bytes) or (video_file.startswith(\"gs://\"))):             \n",
    "            \n",
    "            if video_bytes:\n",
    "               encoded_content = base64.b64encode(video_bytes).decode(\"utf-8\")\n",
    "               instance[\"video\"] = {\n",
    "                    \"bytesBase64Encoded\": encoded_content # pylint: disable=protected-access\n",
    "                }#  # pylint: disable=protected-access\n",
    "               \n",
    "            if  (video_file.startswith(\"gs://\")):  \n",
    "                instance[\"video\"] = {\n",
    "                        \"gcsUri\": video_file  # pylint: disable=protected-access\n",
    "                    }          \n",
    "                \n",
    "            #get video duration\n",
    "            video_duration=math.ceil(get_video_duration(video_file))\n",
    "     \n",
    "\n",
    "\n",
    "        endpoint = (\n",
    "           f\"projects/{self.project}/locations/{self.location}\"\n",
    "           \"/publishers/google/models/multimodalembedding@001\"\n",
    "        )\n",
    "        \n",
    "        print(endpoint)\n",
    "\n",
    "        #response =self.client.predict(endpoint=endpoint, instances=instances)\n",
    "\n",
    "        text_embedding = None\n",
    "        if text:\n",
    "            instances = [instance]\n",
    "            response =self.client.predict(endpoint=endpoint, instances=instances)\n",
    "            text_emb_value = response.predictions[0][\"textEmbedding\"]\n",
    "            text_embedding = [v for v in text_emb_value]\n",
    "\n",
    "        #video_duration=4*60\n",
    "        \n",
    "        video_embedding = None\n",
    "        if (video_file) and ((video_bytes) or (video_file.startswith(\"gs://\"))): \n",
    "            video_embeddings = []  \n",
    "            video_chapters=[]\n",
    "            prev=0\n",
    "            #iterate over the file and get embeddings of the whole file\n",
    "            \n",
    "            \n",
    "            for val in range (segments_to_process,video_duration+segments_to_process,segments_to_process):\n",
    "                offset={'start':prev, 'end':val}\n",
    "                prev=val    \n",
    "                print(offset)\n",
    "                print('getting Multimodal Embeddings..')\n",
    "                video_segments=VideoSegmentConfig(start_offset_sec=offset['start'],end_offset_sec=offset['end'])\n",
    "\n",
    "                if video_segments:\n",
    "                    instance[\"video\"][\"videoSegmentConfig\"] = {\n",
    "                            \"startOffsetSec\": video_segments.start_offset_sec,\n",
    "                            \"endOffsetSec\": video_segments.end_offset_sec,\n",
    "                            \"intervalSec\": video_segments.interval_sec,\n",
    "                        }\n",
    "                \n",
    "                instances = [instance]\n",
    "                response =self.client.predict(endpoint=endpoint, instances=instances)\n",
    "                for video_embedding in response.predictions[0].get(\"videoEmbeddings\", []):\n",
    "                    video_embeddings.append(\n",
    "                        VideoEmbedding(\n",
    "                            embedding=video_embedding[\"embedding\"],                           \n",
    "                            start_offset_sec=video_embedding[\"startOffsetSec\"],\n",
    "                            end_offset_sec=video_embedding[\"endOffsetSec\"],\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "\n",
    "                print('getting summaries..')\n",
    "                \n",
    "                chapters=self.get_video_summarycontent(video_file=video_file,startOffset=offset['start'],endOffset=offset['end'],intervals=intervals)\n",
    "                \n",
    "                for chapter in chapters:\n",
    "                    video_chapters.append(\n",
    "                        VideoChapter(\n",
    "                            embedding=self.get_summarycontent_embedding_from_text_embedding_model\n",
    "                            (text=chapter[\"chapterSummary\"]).text_embedding,                           \n",
    "                            start_offset_sec=chapter[\"startOffset\"],\n",
    "                            end_offset_sec=chapter[\"endOffset\"],\n",
    "                            summary=chapter[\"chapterSummary\"]\n",
    "                        )\n",
    "                    )\n",
    "                    \n",
    "                    video_embeddings.append(\n",
    "                            VideoEmbedding(\n",
    "                                embedding=[1,2,3],\n",
    "                                start_offset_sec=video_segments.start_offset_sec,\n",
    "                                end_offset_sec=video_segments.end_offset_sec,\n",
    "                            )\n",
    "                        )\n",
    "                # video_chapters.append(\n",
    "                #         VideoChapter(\n",
    "                #             embedding=[],                           \n",
    "                #             start_offset_sec=video_segments.start_offset_sec,\n",
    "                #             end_offset_sec=video_segments.start_offset_sec,\n",
    "                #             summary='test'\n",
    "                #         )\n",
    "                # )\n",
    "\n",
    "                \n",
    "        return EmbeddingResponse (text_embedding=text_embedding, video_embedding=video_embeddings, video_chapter=video_chapters)\n",
    " \n",
    "   \n",
    "   \n",
    "    def get_video_summarycontent(self, text: str = None, video_file: str = None,startOffset: int=0, endOffset: int=120, intervals: int=16):\n",
    "        \n",
    "         '''\n",
    "         Gimini Features for Video as per:https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/video-understanding\n",
    "         gemini-1.5-flash, Gemini 1.5 Pro: \n",
    "         With audio: ~50 minutes\n",
    "         Without audio: 60 minutes\n",
    "         Maximum videos per prompt: 10\n",
    "         \n",
    "         Gemini 1.0 Pro Vision:\n",
    "         Maximum video length: 2 minutes\n",
    "         The maximum videos per prompt: 1\n",
    "         Audio in the video is ignored.\n",
    "         \n",
    "         Gimini feature for Part as per:https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#sample-requests\n",
    "        '''\n",
    "        \n",
    "\n",
    " \n",
    "         generative_multimodal_model= GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "         # Please only capture key events and highlights.\n",
    "        \n",
    "         video_description_prompt=f\"\"\"You are an assistant tasked with summarizing videos for retrieval.\\\n",
    "         These summaries will be embedded and used to retrieve the raw video.\\\n",
    "        Chapterize the video content by grouping the video content into chapters \\\n",
    "        with intervals of {intervals} seconds and providing a concise detail for each chapter that is well optimized for retrieval.\\\n",
    "        If there is a famous person like politician, celebrity or athlete, indicate their name and describe what they are famous for.\\\n",
    "        Describe important scenes in the video concisely.\\\n",
    "        If you are not sure about any info, please do not make it up. \\\n",
    "        Only consider video from {startOffset} seconds to {endOffset} seconds. Ignore analyzing the rest of video.\\\n",
    "        For each chapter, put the result within {'{}'} with keys as follows : \"startOffset\",\"endOffset\", \"chapterSummary\".\\\n",
    "        Do not add any ',' between chapters.\\\n",
    "        If it is the last chapter, set the endOffset to {endOffset} instead.\n",
    "       \"\"\"\n",
    "\n",
    "        \n",
    "         generation_config= GenerationConfig(temperature=1, top_k=40,top_p=0.95,max_output_tokens=8192) \n",
    "         \n",
    "        #for video, BLOCK_NONE gives error. So, have to set it to BLOCK_ONLY_HIGH\n",
    "         safety_settings=  {\n",
    "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    }\n",
    "         stream=True\n",
    "        \n",
    "         # Load the saved video as a Gemini Part Object\n",
    "          \n",
    "         contents=[GenerativeModelPart.from_uri(video_file,mime_type=\"video/mp4\"),\n",
    "                   video_description_prompt,]\n",
    "        \n",
    "        \n",
    "         response = generative_multimodal_model.generate_content(\n",
    "            contents,\n",
    "            generation_config=generation_config,\n",
    "            stream=stream,\n",
    "            safety_settings=safety_settings, )\n",
    "        \n",
    "        \n",
    "         response_list = []\n",
    "\n",
    "         for chunk in response:\n",
    "            try:\n",
    "                response_list.append(chunk.text)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    \"Exception occurred while calling gemini. Something is wrong. Lower the safety thresholds [safety_settings: BLOCK_NONE ] if not already done. -----\",\n",
    "                    e,\n",
    "                )\n",
    "                response_list.append(\"Exception occurred\")\n",
    "                continue\n",
    "         response = ''.join(response_list)\n",
    "        \n",
    "         chapters=[]\n",
    "         chapters_text=re.findall(r\"\\{.*?\\}\", response)\n",
    "         print(chapters_text)\n",
    "         for chapter in chapters_text:\n",
    "             chapter=chapter.replace('{','').replace('}','').strip()\n",
    "             chapters.append(\n",
    "                 {\n",
    "                    \"startOffset\":chapter.split(',')[0].replace('startOffset','').replace('\"',\"\").replace(':','').strip(),\n",
    "                    \"endOffset\":chapter.split(',')[1].replace('endOffset','').replace('\"',\"\").replace(':','').strip(),\n",
    "                    \"chapterSummary\":chapter[chapter.index('chapterSummary'): len(chapter)-1]\\\n",
    "                     .replace('\"chapterSummary\":','')\\\n",
    "                     .replace('\"chapterSummary\" :','')\\\n",
    "                     .replace(\"'chapterSummary' :\",'')\\\n",
    "                     .replace(\"'chapterSummary':\",'')\\\n",
    "                }\n",
    "             )\n",
    "\n",
    "         # response=response.replace('```json\\n[\\n ','').replace('\\n]\\n```','')\n",
    "         # chapters_text=re.findall(r\"\\{.*?\\}\", response)\n",
    "         # print(chapters_text)\n",
    "         # print()\n",
    "         # for chapter in chapters_text:\n",
    "         #    chapters.append(yaml.safe_load(chapter))\n",
    "            \n",
    "#          chapter=''\n",
    "#          for char in response:\n",
    "#             chapter=chapter+char\n",
    "#             if \"}\" in char:\n",
    "#                 #item.replace(\"{\",'')\n",
    "#                 chapter =chapter.replace(',\\n  {','\\n  {')\n",
    "#                 print(chapter)\n",
    "#                 chapters.append(yaml.safe_load(chapter))\n",
    "\n",
    "#                 chapter=''\n",
    "                    \n",
    " \n",
    "         return chapters\n",
    "\n",
    "    \n",
    "    def get_summarycontent_embedding_from_text_embedding_model(self, text: str, return_array: Optional[bool] = False,) -> list:\n",
    "        \"\"\"\n",
    "        Generates a numerical text embedding from a provided text input using a text embedding model.\n",
    "\n",
    "        Args:\n",
    "            text: The input text string to be embedded.\n",
    "            return_array: If True, returns the embedding as a NumPy array.\n",
    "                          If False, returns the embedding as a list. (Default: False)\n",
    "\n",
    "        Returns:\n",
    "            list or numpy.ndarray: A 768-dimensional vector representation of the input text.\n",
    "                                   The format (list or NumPy array) depends on the\n",
    "                                   value of the 'return_array' parameter.\n",
    "        \"\"\"\n",
    "\n",
    "        #the given text is maximum 2048 token. If more, it has to be chunked.\n",
    "        embeddings = text_embedding_model.get_embeddings([text])\n",
    "        text_embedding = [embedding.values for embedding in embeddings][0]\n",
    "\n",
    "        if return_array:\n",
    "            text_embedding = np.fromiter(text_embedding, dtype=float)\n",
    "\n",
    "        # returns 768 dimensional array\n",
    "        return EmbeddingResponse(\n",
    "            text_embedding=text_embedding, video_embedding=None, video_chapter=None\n",
    "        )   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728cf6b-baeb-476a-a061-68c748a8dc6e",
   "metadata": {},
   "source": [
    "### Create helper functions to process data in batches\n",
    "Datasets can be large, so it's recommended to load a batch of data at a time into memory using a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1e6f9ef7-0279-48f4-a576-3868ec14a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Callable, Generator, List,Tuple\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#Number of API calls per second\n",
    "API_IMAGES_PER_SECOND = 2\n",
    "\n",
    "def generate_batches(\n",
    "    inputs: List[str], batch_size: int\n",
    ") -> Generator[List[str], None, None]:\n",
    "    \"\"\"\n",
    "    Generator function that takes a list of strings and a batch size, and yields batches of the specified size.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(inputs), batch_size):\n",
    "        yield inputs [i : i + batch_size] \n",
    "\n",
    "\n",
    "\n",
    "def encode_to_embeddings_chunked(\n",
    "    process_function: Callable[[List[str]], List[Optional[List[float]]]],\n",
    "    items: str,\n",
    "    batch_size: int = 1,\n",
    ") -> List[Optional[List[float]]]:\n",
    "    \"\"\"\n",
    "    Function that encodes a list of strings into embeddings using a process function.\n",
    "    It takes a list of strings and returns a list of optional lists of floats.\n",
    "    The data is processed in chunks to prevent out-of-memory errors.\n",
    "    \"\"\"\n",
    "    \n",
    "    embeddings_list: List[Optional[List[float]]] = []\n",
    "\n",
    "    # Prepare the batches using a generator\n",
    "    batches = generate_batches(items, batch_size)\n",
    "    \n",
    "   \n",
    "    seconds_per_job = batch_size / API_IMAGES_PER_SECOND\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for batch in tqdm(batches, total=len(items) // batch_size, position=0):\n",
    "            futures.append(executor.submit(process_function, batch))\n",
    "            time.sleep(seconds_per_job)\n",
    "\n",
    "        for future in futures:\n",
    "            embeddings_list.extend(future.result())\n",
    "    return embeddings_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70084d60-e64f-4acf-b41d-07295141df90",
   "metadata": {},
   "source": [
    "### Create functions that wrap embedding functions in try-except and retry logic\n",
    "This particular embedding model can only process 1 image at a time, so inputs are validated to be equal to a length of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cc24f964-09eb-4641-a0ed-2a9fc05247aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from tenacity import retry, stop_after_attempt\n",
    "\n",
    "client = EmbeddingPredictionClient(project=PROJECT_ID)\n",
    "\n",
    "\n",
    "# Use a retry handler in case of failure\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_texts_to_embeddings_with_retry(text: List[str]) -> List[List[float]]:\n",
    "    assert len(text) == 1\n",
    "\n",
    "    try:\n",
    "        return [client.get_embedding(text=text[0], image_file=None).text_embedding]\n",
    "    except Exception:\n",
    "        raise RuntimeError(\"Error getting embedding.\")\n",
    "\n",
    "\n",
    "def encode_texts_to_embeddings(text: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_texts_to_embeddings_with_retry(text=text)\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(text))]\n",
    "\n",
    "\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_videos_to_embeddings_with_retry(video_uris: List[str] ) -> List[List[float]]:\n",
    "    assert len(video_uris) == 1\n",
    "\n",
    "    try:\n",
    "        embeddings=client.get_embedding(text=None, video_file=video_uris[0] )\n",
    "        return [embeddings.video_embedding],[embeddings.video_chapter] \n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        raise RuntimeError(\"Error getting embedding for video.\")\n",
    "\n",
    "\n",
    "def encode_videos_to_embeddings(video_uris: List[str] ) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        \n",
    "        return encode_videos_to_embeddings_with_retry(video_uris=video_uris )\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return [None for _ in range(len(video_uris))]\n",
    "    \n",
    "\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_videos_to_summarycontent_with_retry(video_uris: List[str]) -> List[List[float]]:\n",
    "    assert len(image_uris) == 1\n",
    "\n",
    "    try:\n",
    "        return [\n",
    "            client.get_video_summarycontent(text=None, video_file=video_uris[0])\n",
    "        ]\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        raise RuntimeError(\"Error getting summaries.\")\n",
    "\n",
    "\n",
    "def encode_videos_to_summarycontent(video_uris: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_videos_to_summarycontent_with_retry(video_uris=video_uris)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return [None for _ in range(len(video_uris))]\n",
    "    \n",
    "    \n",
    "# Use a retry handler in case of failure\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_summarycontent_to_embeddings_with_retry(text: List[str]) -> List[List[float]]:\n",
    "    assert len(text) == 1\n",
    "\n",
    "    try:\n",
    "        return [client.get_summarycontent_embedding_from_text_embedding_model(text=text[0]).text_embedding]\n",
    "    except Exception:\n",
    "        raise RuntimeError(\"Error getting embedding for summary content.\")\n",
    "\n",
    "\n",
    "def encode_summarycontent_to_embeddings(text: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_summarycontent_to_embeddings_with_retry(text=text)\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(text))]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e9287-4332-4ac5-8d6a-4b6f2a24f0ff",
   "metadata": {},
   "source": [
    "### Create and save the embeddings in JSONL format\n",
    "The data must be formatted in JSONL format, which means each embedding dictionary is written as an individual JSON object on its own line.\n",
    "\n",
    "See more information in the docs at Input data format and structure.\n",
    "\n",
    "Run the following code in the next available cells, to create a temporary file to store embeddings in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2aeb8b57-7ab4-490d-8a98-01f71f45d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile, shutil\n",
    "\n",
    "# Create temporary file to write embeddings to\n",
    "videoembeddings_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=False)\n",
    "\n",
    "# Create temporary file to write summaries to\n",
    "videosummaries_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25a08f1-1e9a-4c97-a0eb-624ce9d75165",
   "metadata": {},
   "source": [
    "### embedding file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a898f97e-a4c3-49b5-afae-9bfa7e1a05d8",
   "metadata": {},
   "source": [
    "### Video Embeddings in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "de986c74-1704-4dbb-bc76-6e4493b61755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5e7ab05cf74b719d38a0d6c34ab0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efdcc9d655da49c79151987fdd65877f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<google.auth.compute_engine.credentials.IDTokenCredentials object at 0x7f5350b75a20>\n",
      "projects/nine-quality-test/locations/us-central1/publishers/google/models/multimodalembedding@001\n",
      "{'start': 0, 'end': 120}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{ \"startOffset\": 0, \"endOffset\": 16, \"chapterSummary\": \"Black and white photo of a woman. The woman has dark hair and looks intensely at the camera\" }', '{ \"startOffset\": 16, \"endOffset\": 32, \"chapterSummary\": \"A woman speaking on camera about her experience with the police, the police were looking for evidence and she says it was scary. \" }', '{ \"startOffset\": 32, \"endOffset\": 48, \"chapterSummary\": \"A woman speaking on camera about her thoughts on the disappearance of her sister and the police investigation \" }', '{ \"startOffset\": 48, \"endOffset\": 64, \"chapterSummary\": \"A woman speaking on camera about her thoughts on the disappearance of her sister and the police investigation. \" }', '{ \"startOffset\": 64, \"endOffset\": 80, \"chapterSummary\": \"A woman speaking on camera about her thoughts on the disappearance of her sister and the police investigation. \" }', '{ \"startOffset\": 80, \"endOffset\": 96, \"chapterSummary\": \"A woman speaking on camera about her thoughts on the disappearance of her sister and the police investigation. \" }', '{ \"startOffset\": 96, \"endOffset\": 112, \"chapterSummary\": \"A man speaking on camera about the police investigation into a missing person. They are hopeful that the investigation will be successful. \" }', '{ \"startOffset\": 112, \"endOffset\": 120, \"chapterSummary\": \"A woman speaking on camera about her thoughts on the disappearance of her sister and the police investigation. \" }']\n",
      "{'start': 120, 'end': 240}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{ \"startOffset\": 120, \"endOffset\": 136, \"chapterSummary\": \"A woman reveals she does not believe a word that comes out of her ex-husband\\'s mouth.\" }', '{ \"startOffset\": 136, \"endOffset\": 152, \"chapterSummary\": \"The discovery of the missing woman\\'s possessions scared the sister.\" }', '{ \"startOffset\": 152, \"endOffset\": 168, \"chapterSummary\": \"The police are investigating a new suspect for the disappearance.\" }', '{ \"startOffset\": 168, \"endOffset\": 184, \"chapterSummary\": \"A man in a green shirt is questioned about the disappearance of the missing woman.\" }', '{ \"startOffset\": 184, \"endOffset\": 200, \"chapterSummary\": \"A woman in a black jacket reveals the suspect\\'s alibi did not check out.\" }', '{ \"startOffset\": 200, \"endOffset\": 216, \"chapterSummary\": \"A woman in a black jacket reveals that the initial police did not check out the alibi.\" }', '{ \"startOffset\": 216, \"endOffset\": 232, \"chapterSummary\": \"The suspect\\'s alibi did not match the phone records.\" }', '{ \"startOffset\": 232, \"endOffset\": 240, \"chapterSummary\": \"The case remains unsolved.\" }']\n",
      "{'start': 240, 'end': 360}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{ \"startOffset\": 240, \"endOffset\": 256, \"chapterSummary\": \"A man with glasses is shown opening the trunk of a silver car.\" }', '{ \"startOffset\": 256, \"endOffset\": 272, \"chapterSummary\": \"A woman with long blonde hair is shown turning the pages of a photo album. It seems to be a photo album of a young woman.\" }', '{ \"startOffset\": 272, \"endOffset\": 288, \"chapterSummary\": \"A woman with blonde hair is shown talking to another woman about a man named Zoron. She is concerned about his whereabouts after his wife went missing.\" }', '{ \"startOffset\": 288, \"endOffset\": 304, \"chapterSummary\": \"A man in a white shirt and a tie is shown walking on a sidewalk. He appears to be anxious.\" }', '{ \"startOffset\": 304, \"endOffset\": 320, \"chapterSummary\": \"A woman is shown speaking about a man. She says that he changed his story multiple times and it was hard to verify his whereabouts.\" }', '{ \"startOffset\": 320, \"endOffset\": 336, \"chapterSummary\": \"A man with a beard and glasses is shown looking at a photo album. He is recounting a story about how a woman he encountered at the Edge Restaurant was trying to establish a timeline. \" }', '{ \"startOffset\": 336, \"endOffset\": 352, \"chapterSummary\": \"A woman with long blonde hair is shown speaking. She says that the police did not care about the woman who went missing. \" }', '{ \"startOffset\": 352, \"endOffset\": 360, \"chapterSummary\": \"A man with glasses is shown speaking. He is shown how Scientology was a big part of the case.\" }']\n",
      "{'start': 360, 'end': 480}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{ \"startOffset\": 360, \"endOffset\": 376, \"chapterSummary\": \"The details of the night of the murder that were never found out before, a 10 p.m. booking with a man named Boyan.\"}', '{ \"startOffset\": 376, \"endOffset\": 392, \"chapterSummary\": \"The man\\'s whereabouts were never verified by the initial batch of police that investigated.\"}', '{ \"startOffset\": 392, \"endOffset\": 408, \"chapterSummary\": \"A new piece of evidence, a tip from crime stoppers about a man in a photo.\"}', '{ \"startOffset\": 408, \"endOffset\": 424, \"chapterSummary\": \"This tip off was given anonymously, Detective Chief Inspector Stewart Bell has been investigating for the last 3 years.\"}', '{ \"startOffset\": 424, \"endOffset\": 440, \"chapterSummary\": \"The detective chief inspector wants more details, is asking for someone to come forward and provide the information.\"}', '{ \"startOffset\": 440, \"endOffset\": 456, \"chapterSummary\": \"The details that are being investigated now are the details that were never found out before.\"}', '{ \"startOffset\": 456, \"endOffset\": 472, \"chapterSummary\": \" The details that were never found out before.\"}', '{ \"startOffset\": 472, \"endOffset\": 480, \"chapterSummary\": \"The details that were never found out before.\"}']\n",
      "{'start': 480, 'end': 600}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{ \"startOffset\": 480, \"endOffset\": 496, \"chapterSummary\": \"Suellen Simpson, the sister of the missing woman, Reveil Belmaine, has spent 30 years seeking answers to her sister\\'s disappearance. \" }', '{ \"startOffset\": 496, \"endOffset\": 512, \"chapterSummary\": \"Reveils\\'s disappearance was a challenging case. Police have uncovered new clues and a new person of interest in the case.\" }', '{ \"startOffset\": 512, \"endOffset\": 528, \"chapterSummary\": \"Police are asking for more details from those who knew Reveil to help solve the case.\" }', '{ \"startOffset\": 528, \"endOffset\": 544, \"chapterSummary\": \"Zoran Stanojevic, the former husband of Reveil\\'s boss, Jane King, is now a person of interest.\" }', '{ \"startOffset\": 544, \"endOffset\": 560, \"chapterSummary\": \"Zoran has changed his story over time, making him a person of interest in the case.\" }', '{ \"startOffset\": 560, \"endOffset\": 576, \"chapterSummary\": \"Jane King is a witness in the case. She says she did not use the word \\\\\"murdered\\\\\" when she spoke to police.\" }', '{ \"startOffset\": 576, \"endOffset\": 592, \"chapterSummary\": \"Adam Owen was the manager at the Edge Restaurant where Jane and Zoran were dining the night Reveil went missing.\" }', '{ \"startOffset\": 592, \"endOffset\": 600, \"chapterSummary\": \"Jane King believes there was a degree of panic in the call.\" }']\n",
      "{'start': 600, 'end': 720}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{ \"startOffset\":600, \"endOffset\":616, \"chapterSummary\": \"A man tells the reporter that he had everything to do with the situation.\" }', '{ \"startOffset\":616, \"endOffset\":632, \"chapterSummary\": \"A woman is interviewed, and she expresses that she is feeling overwhelmed with sadness because of what happened.\" }', '{ \"startOffset\":632, \"endOffset\":648, \"chapterSummary\": \"A man tells the reporter about how he is trying to get more information to establish a timeline of what happened to a missing person.\" }', '{ \"startOffset\":648, \"endOffset\":664, \"chapterSummary\": \"The woman explains that she doesn\\'t know why he would lie about what happened.\" }', '{ \"startOffset\":664, \"endOffset\":680, \"chapterSummary\": \"The man explains that they are trying to establish a timeline of what happened.\" }', '{ \"startOffset\":680, \"endOffset\":696, \"chapterSummary\": \"A woman explains that she was exhausted from her pregnancy.\" }', '{ \"startOffset\":696, \"endOffset\":712, \"chapterSummary\": \"A woman shares her thoughts on how the initial investigation handled the situation.\" }', '{ \"startOffset\":712, \"endOffset\":720, \"chapterSummary\": \"A woman explains how the event and its aftermath have affected her.\"}']\n",
      "{'start': 720, 'end': 840}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{ \"startOffset\": 720, \"endOffset\": 736, \"chapterSummary\": \"A person is interviewing Jane King,  Revel\\'s boss, regarding her actions after hearing that Revel is missing. Jane tells the reporter that she did not believe that Gavin Semo was involved in her disappearance.\" }', '{ \"startOffset\": 736, \"endOffset\": 752, \"chapterSummary\": \"Jane King, Revel\\'s boss, shares her perspective on the initial police investigation in the Revel Belmaine case. \" }', '{ \"startOffset\": 752, \"endOffset\": 768, \"chapterSummary\": \"The reporter asked Jane King why she did not think Gavin Semo was involved in Revel\\'s disappearance. \" }', '{ \"startOffset\": 768, \"endOffset\": 784, \"chapterSummary\": \"Jane King explains why she did not suspect Gavin Semo in Revel\\'s disappearance. \" }', '{ \"startOffset\": 784, \"endOffset\": 800, \"chapterSummary\": \"Jane King discusses the fact that her husband, Zoran, was a co-owner of a business that would have given him reason to arrange a flight for Revel and Boyan.\" }', '{ \"startOffset\": 800, \"endOffset\": 816, \"chapterSummary\": \"Jane King was surprised that Zoran had arranged for Boyan to leave Australia the next day.\" }', '{ \"startOffset\": 816, \"endOffset\": 840, \"chapterSummary\": \"Jane King discusses how Zoran had not been honest about the events of that night. She also says that the police did not seem to care about the case at the time. \" }']\n",
      "{'start': 840, 'end': 960}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{ \"startOffset\": 840, \"endOffset\": 856, \"chapterSummary\": \"A woman with long brown hair speaks about how she will not let go of her son’s death and the truth. She expresses how his death consumed her.\" }', '{ \"startOffset\": 856, \"endOffset\": 872, \"chapterSummary\": \"A man speaks about how the death of a person who jumped in front of a speeding car is never a good thing.\" }', '{ \"startOffset\": 872, \"endOffset\": 888, \"chapterSummary\": \"A woman with long brown hair speaks about how the death of her son was his own fault. She expresses how her son would not have wanted to die.\" }', '{ \"startOffset\": 888, \"endOffset\": 904, \"chapterSummary\": \"A man with a beard speaks about how his statement about the incident is not true and just his personal opinion.\" }', '{ \"startOffset\": 904, \"endOffset\": 920, \"chapterSummary\": \"A woman with long blond hair speaks about how the police did not care about the business she was in when her sister disappeared.\" }', '{ \"startOffset\": 920, \"endOffset\": 936, \"chapterSummary\": \"The man with a beard states that he never used the word \"murdered\" in the statement and what he did say is the truth.\" }', '{ \"startOffset\": 936, \"endOffset\": 952, \"chapterSummary\": \"A woman speaks about how she thinks it is important to be able to account for one’s whereabouts. She also speaks about how the clients were people she knew.\" }', '{ \"startOffset\": 952, \"endOffset\": 960, \"chapterSummary\": \"A man with a beard speaks about a police investigation of murder and the timeline of the investigation.\" }']\n",
      "{'start': 960, 'end': 1080}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{ \"startOffset\": 960, \"endOffset\": 976, \"chapterSummary\": \"A woman in a striped shirt talks about the case\" }', '{ \"startOffset\": 976, \"endOffset\": 992, \"chapterSummary\": \"The woman with a black top, talks about her and her husband, discussing about the missing person and her possessions\" }', '{ \"startOffset\": 992, \"endOffset\": 1008, \"chapterSummary\": \"A man in a green polo shirt and brown jacket talks about the missing person\" }', '{ \"startOffset\": 1008, \"endOffset\": 1024, \"chapterSummary\": \"A man in a green polo shirt and brown jacket talks about the missing person\" }', '{ \"startOffset\": 1024, \"endOffset\": 1040, \"chapterSummary\": \"A man in a green polo shirt and brown jacket talks about the missing person\" }', '{ \"startOffset\": 1040, \"endOffset\": 1056, \"chapterSummary\": \"A woman in a black top and black jacket talks about her thought and disbelief\" }', '{ \"startOffset\": 1056, \"endOffset\": 1072, \"chapterSummary\": \"A man in a black jacket and white shirt talks about the evidence for the case\" }', '{ \"startOffset\": 1072, \"endOffset\": 1080, \"chapterSummary\": \"A woman in a black top and black jacket talks about the details of the case\" }']\n",
      "{'start': 1080, 'end': 1200}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{ \"startOffset\": 1080, \"endOffset\": 1104, \"chapterSummary\": \"The family of a woman who was hit and killed by a car, Melissa Oates, believes Melissa\\'s death was not an accident. Melissa Oates\\'s boyfriend, Jari Wise was found dead at the scene by the side of the road.\" }', '{ \"startOffset\": 1104, \"endOffset\": 1128, \"chapterSummary\": \"Melissa Oates is now pushing for a coronial inquiry after the original inquiry was denied in the Supreme Court of Tasmania.\" }', '{ \"startOffset\": 1128, \"endOffset\": 1152, \"chapterSummary\": \"The family believes that Melissa Oates\\' death was due to domestic violence, and they want justice for their son.\" }', '{ \"startOffset\": 1152, \"endOffset\": 1176, \"chapterSummary\": \"They want the truth to be revealed. \" }', '{ \"startOffset\": 1176, \"endOffset\": 1200, \"chapterSummary\": \"This story, the hit and run death of Jari Wise is a story that is still being investigated by Tasmanian police.\" }']\n",
      "{'start': 1200, 'end': 1320}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{ \"startOffset\":1200, \"endOffset\":1216, \"chapterSummary\": \"A man and a woman are walking down a city street. \" }', '{ \"startOffset\":1216, \"endOffset\":1232, \"chapterSummary\": \"The man in the video is Zoran Stanojevic, he ran an escort agency with his wife Jane.\" }', '{ \"startOffset\":1232, \"endOffset\":1248, \"chapterSummary\": \"Jane King, Zoran\\'s wife, is talking about the night her sister Revel went missing.\" }', '{ \"startOffset\":1248, \"endOffset\":1264, \"chapterSummary\": \"Revel was a part-time escort and an aspiring model who went missing on November 5th, 1994.\" }', '{ \"startOffset\":1264, \"endOffset\":1280, \"chapterSummary\": \"Jane King says that her husband Zoran told the police he stayed home with her on the night Revel went missing but that wasn\\'t true. She says that her husband was out driving other escorts to and from jobs that night. \" }', '{ \"startOffset\":1280, \"endOffset\":1296, \"chapterSummary\": \"The police have recovered new evidence in the case. They are investigating Zoran Stanojevic because his alibi doesn\\'t add up. \" }', '{ \"startOffset\":1296, \"endOffset\":1312, \"chapterSummary\": \"The police are looking into phone calls made by Zoran, which seem to be very critical to his alibi.\" }', '{ \"startOffset\":1312, \"endOffset\":1320, \"chapterSummary\": \"A man named Boyan is mentioned as someone that Zoran knew and may have been associated with Revel. \" }']\n",
      "{'start': 1320, 'end': 1440}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{ \"startOffset\":1320, \"endOffset\":1336, \"chapterSummary\": \"Suellen Simpson, Revelle Belmaine\\'s sister, describes how they reacted to the news of her sister\\'s disappearance.\" }', '{ \"startOffset\":1336, \"endOffset\":1352, \"chapterSummary\": \"Suellen says that she does not believe a word that comes out of Zoron\\'s mouth.\" }', '{ \"startOffset\":1352, \"endOffset\":1368, \"chapterSummary\": \"The police had found Revelle\\'s belongings that scared her family.\" }', '{ \"startOffset\":1368, \"endOffset\":1384, \"chapterSummary\": \"Suellen Simpson says that she felt like she would break into million pieces when she heard her sister was missing.\" }', '{ \"startOffset\":1384, \"endOffset\":1400, \"chapterSummary\": \"Suellen Simpson and a reporter talk about the investigation surrounding Revelle Belmaine\\'s disappearance.\" }', '{ \"startOffset\":1400, \"endOffset\":1416, \"chapterSummary\": \"Suellen Simpson thinks that the police had not investigated properly at the time of her sister\\'s disappearance.\" }', '{ \"startOffset\":1416, \"endOffset\":1432, \"chapterSummary\": \"The journalist asks Suellen about how she feels after 30 years wondering what happened to her sister.\" }', '{ \"startOffset\":1432, \"endOffset\":1440, \"chapterSummary\": \"Suellen Simpson shares her thoughts about how she feels when they still try to figure out what happened to her sister.\" }']\n",
      "{'start': 1440, 'end': 1560}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{ \"startOffset\": 1440, \"endOffset\": 1456, \"chapterSummary\": \"The 2021 Crime Stoppers tip mentioned a man in a photo seen with a woman and her possessions.\" }', '{ \"startOffset\": 1456, \"endOffset\": 1472, \"chapterSummary\": \"Police are looking for more detail about the person seen in the tip photo and if they can identify them.\" }', '{ \"startOffset\": 1472, \"endOffset\": 1488, \"chapterSummary\": \"The woman who provided the tip was skeptical that the man from the photo is involved and believes they are simply brushing it off.\" }', '{ \"startOffset\": 1488, \"endOffset\": 1504, \"chapterSummary\": \"The woman believes they are brushing the situation off because they don\\'t care much about escorts.\" }', '{ \"startOffset\": 1504, \"endOffset\": 1520, \"chapterSummary\": \"The detective believes the situation needs to be investigated further, even if the tip was anonymous.\" }', '{ \"startOffset\": 1520, \"endOffset\": 1536, \"chapterSummary\": \"The woman is trying to find the person responsible and it is crucial because they will never get a fourth investigation on this.\" }', '{ \"startOffset\": 1536, \"endOffset\": 1560, \"chapterSummary\": \"The woman believes it\\'s time to speak with police if they know anything about the case, and that they need to reach out to the Reveal team.\" }']\n",
      "{'start': 1560, 'end': 1680}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{ \"startOffset\": 1560, \"endOffset\": 1576, \"chapterSummary\": \"A woman, Suellen Simpson, is talking about how difficult it was to lose her sister, Revel.\" }', '{ \"startOffset\": 1576, \"endOffset\": 1592, \"chapterSummary\": \"The police discovered Revel\\'s possessions the day after her disappearance.\" }', '{ \"startOffset\": 1592, \"endOffset\": 1608, \"chapterSummary\": \"Suellen Simpson speaks about how the police discovered Revel\\'s possessions so quickly after her disappearance.\" }', '{ \"startOffset\": 1608, \"endOffset\": 1624, \"chapterSummary\": \"Suellen Simpson speaks about how the police investigation was difficult.\" }', '{ \"startOffset\": 1624, \"endOffset\": 1640, \"chapterSummary\": \"Suellen Simpson talks about how she and her family had to cope with the disappearance of Revel.\" }', '{ \"startOffset\": 1640, \"endOffset\": 1656, \"chapterSummary\": \"Suellen Simpson describes the shock she experienced when learning her sister, Revel, was missing.\" }', '{ \"startOffset\": 1656, \"endOffset\": 1672, \"chapterSummary\": \"Suellen Simpson speaks about the man her husband, Zoran, was working with.\" }', '{ \"startOffset\": 1672, \"endOffset\": 1680, \"chapterSummary\": \"Suellen Simpson discusses why Zoran might have lied to the police about his whereabouts.\" }']\n",
      "{'start': 1680, 'end': 1800}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{ \"startOffset\": 1680, \"endOffset\": 1712, \"chapterSummary\": \"Jane King, who owned the escort agency with her then-husband, Zoran, feels that the police investigation was inadequate. She feels that the police did not care enough about her sister\\'s disappearance, or how her sister was killed.  She feels the police were biased against her sister because of her profession.\" }', '{ \"startOffset\": 1712, \"endOffset\": 1744, \"chapterSummary\": \"Jane King tells a story of how she thought her husband was out driving an escort to a job. She explains that it was a common occurrence, but that the police later realized that he was lying.\" }', '{ \"startOffset\": 1744, \"endOffset\": 1776, \"chapterSummary\": \"The investigation changed focus from Zoran to a man named Boyan, someone Zoran knew, and who he helped arrange a flight out of Australia. The police are looking for Boyan.\" }', '{ \"startOffset\": 1776, \"endOffset\": 1800, \"chapterSummary\": \"There is a discussion about the restaurant where Jane was dining the night her sister disappeared.  The restaurant\\'s manager, Adam Owen, confirms that Jane was at the restaurant. The interviewee is adamant that Jane never used the word \\'murdered\\' during her conversation with the police.\" }']\n",
      "{'start': 1800, 'end': 1920}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{ \"startOffset\":1800, \"endOffset\":1816, \"chapterSummary\": \"A woman discusses with an interviewer the reasons why she contacted the restaurant before calling the police.\" }', '{ \"startOffset\":1816, \"endOffset\":1832, \"chapterSummary\": \"The woman expresses that she did not think the person would be angry for being contacted.\" }', '{ \"startOffset\":1832, \"endOffset\":1848, \"chapterSummary\": \"The woman explains that she felt it was important to be able to account for their whereabouts.\" }', '{ \"startOffset\":1848, \"endOffset\":1864, \"chapterSummary\": \"The woman discusses that the police did not find her missing sister\\'s belongings at the location of her disappearance.\" }', '{ \"startOffset\":1864, \"endOffset\":1880, \"chapterSummary\": \"The woman discusses how she felt upon learning her sister was missing.\" }', '{ \"startOffset\":1880, \"endOffset\":1896, \"chapterSummary\": \"The woman discusses the details that exposed new suspects in her sister\\'s case.\" }', '{ \"startOffset\":1896, \"endOffset\":1912, \"chapterSummary\": \"A man discusses with an interviewer the information that a suspect could be involved in the disappearance of the woman. \" }', '{ \"startOffset\":1912, \"endOffset\":1920, \"chapterSummary\": \"A man tells an interviewer the reason why police are asking people to come forward, and he states that they do not want people to contact them anonymously.\" }']\n",
      "{'start': 1920, 'end': 2040}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{ \"startOffset\": 1920, \"endOffset\": 1936, \"chapterSummary\": \"Suellen Simpson, the older sister of Revel Balmain, talked about her feelings after she was told that her sister was missing.\" }', '{ \"startOffset\": 1936, \"endOffset\": 1952, \"chapterSummary\": \"Suellen Simpson was told that her sister\\'s possessions were found. She felt like she was going to break into a million pieces.\" }', '{ \"startOffset\": 1952, \"endOffset\": 1968, \"chapterSummary\": \"Suellen Simpson talked about her grief and uncertainty about her sister\\'s disappearance.\" }', '{ \"startOffset\": 1968, \"endOffset\": 1984, \"chapterSummary\": \"The police talked about new evidence that could connect Zoran Stanoyevic with Revel Balmain\\'s disappearance.\" }', '{ \"startOffset\": 1984, \"endOffset\": 2000, \"chapterSummary\": \"The new evidence came in the form of phone records. It\\'s unknown if Zoran Stanoyevic\\'s story is consistent with phone records.\" }', '{ \"startOffset\": 2000, \"endOffset\": 2016, \"chapterSummary\": \"Suellen Simpson talked about the details that she was told about her sister\\'s belongings being found.\" }', '{ \"startOffset\": 2016, \"endOffset\": 2032, \"chapterSummary\": \"The police talked about their investigation into Revel Balmain\\'s case.\" }', '{ \"startOffset\": 2032, \"endOffset\": 2040, \"chapterSummary\": \"Suellen Simpson talked about the outcome of her sister\\'s case and what she is hoping for.\" }']\n",
      "{'start': 2040, 'end': 2160}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{ \"startOffset\": 2040, \"endOffset\": 2056, \"chapterSummary\": \"Suellen Simpson, the sister of the missing woman Revel Belmain, is still looking for answers.\" }', '{ \"startOffset\": 2056, \"endOffset\": 2102, \"chapterSummary\": \"Suellen wants to see the person who murdered Revel, and wants to see that person put in jail for the rest of their life.\" }', '{ \"startOffset\": 2102, \"endOffset\": 2128, \"chapterSummary\": \"Suellen thinks the initial police investigation was not conducted seriously and  doesn\\'t think they took the case seriously because they didn\\'t care much about escorts, or working girls as she refers to them.\" }', '{ \"startOffset\": 2128, \"endOffset\": 2144, \"chapterSummary\": \"Suellen believes that the police did not conduct the initial investigation properly and that her sister\\'s disappearance was an important thing to investigate.\" }', '{ \"startOffset\": 2144, \"endOffset\": 2160, \"chapterSummary\": \"The police have now uncovered information about Zoran\\'s friend, Boyan Provalovic and are appealing for more details.\" }']\n",
      "{'start': 2160, 'end': 2280}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{ \"startOffset\" : 2160, \"endOffset\" : 2176, \"chapterSummary\" : \"A woman who is the mother of a man who passed away is interviewed about the details of the accident that caused his death.  \"}', '{ \"startOffset\" : 2176, \"endOffset\" : 2192, \"chapterSummary\" : \"The woman states that she and her boyfriend were at a restaurant that night, and that she does not think her boyfriend would have jumped in front of a car and that is not where he would have been.\" }', '{ \"startOffset\" : 2192, \"endOffset\" : 2208, \"chapterSummary\" : \"She says that she is racked with guilt that she did not call her boyfriend to come home that night. \" }', '{ \"startOffset\" : 2208, \"endOffset\" : 2224, \"chapterSummary\" : \"The man, who is the mother\\'s boyfriend, died when a car hit him.  He was driving at a very high rate of speed.\" }', '{ \"startOffset\" : 2224, \"endOffset\" : 2240, \"chapterSummary\" : \"The woman says that the accident was a devastating decision and that it consumes her, and she cannot let go of the memory.  \"}', '{ \"startOffset\" : 2240, \"endOffset\" : 2256, \"chapterSummary\" : \"She says that it is important to call her boyfriend\\'s family and let them know that she and her boyfriend were at the restaurant together at the time.  \"}', '{ \"startOffset\" : 2256, \"endOffset\" : 2280, \"chapterSummary\" : \"The woman says that she doesn\\'t think that the police cared about escorts, prostitutes or working girls, whatever you want to call them.\" }']\n",
      "substring not found\n",
      "<google.auth.compute_engine.credentials.IDTokenCredentials object at 0x7f5350a36e60>\n",
      "projects/nine-quality-test/locations/us-central1/publishers/google/models/multimodalembedding@001\n",
      "{'start': 0, 'end': 120}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 47\u001b[0m, in \u001b[0;36mencode_to_embeddings_chunked\u001b[0;34m(process_function, items, batch_size)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m futures:\n\u001b[0;32m---> 47\u001b[0m         embeddings_list\u001b[38;5;241m.\u001b[39mextend(\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings_list\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m video_summaries\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#comment to prevent extra costs\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#********************************\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m video_embeddings,video_chapters \u001b[38;5;241m=\u001b[39m \u001b[43mencode_to_embeddings_chunked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m       \u001b[49m\u001b[43mprocess_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_videos_to_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvideo_paths_chunk\u001b[49m\u001b[43m)\u001b[49m                 \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#********************************\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#comment to prevent extra costs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Append to file\u001b[39;00m\n\u001b[1;32m     39\u001b[0m embeddings_formatted\u001b[38;5;241m=\u001b[39m[]\n",
      "Cell \u001b[0;32mIn[133], line 40\u001b[0m, in \u001b[0;36mencode_to_embeddings_chunked\u001b[0;34m(process_function, items, batch_size)\u001b[0m\n\u001b[1;32m     35\u001b[0m batches \u001b[38;5;241m=\u001b[39m generate_batches(items, batch_size)\n\u001b[1;32m     38\u001b[0m seconds_per_job \u001b[38;5;241m=\u001b[39m batch_size \u001b[38;5;241m/\u001b[39m API_IMAGES_PER_SECOND\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m     41\u001b[0m     futures \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(batches, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(items) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:649\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "BATCH_SIZE = 1# this can be changed\n",
    " \n",
    "           \n",
    "with open(videoembeddings_file.name, \"a\") as ef:     \n",
    "         for i in tqdm(range(0, len(video_paths), BATCH_SIZE)):#len(image_names)\n",
    "            video_names_chunk = video_names[i : i + BATCH_SIZE]\n",
    "            video_paths_chunk = video_paths[i : i + BATCH_SIZE]\n",
    "            \n",
    "            \n",
    "            embeddings=[]\n",
    "            video_summaries=[]\n",
    "            #comment to prevent extra costs\n",
    "            #********************************\n",
    "            video_embeddings,video_chapters = encode_to_embeddings_chunked(\n",
    "                   process_function=encode_videos_to_embeddings, items=video_paths_chunk)                 \n",
    "            #********************************\n",
    "\n",
    "            #comment to prevent extra costs\n",
    "            #********************************\n",
    "            #summaries = encode_to_embeddings_chunked(\n",
    "                #process_function=encode_videos_to_summarycontent, items=video_paths_chunk\n",
    "               #)\n",
    "\n",
    "            #********************************\n",
    "            #summaries=[' The image shows three people: Joe Biden, a young girl, and Hunter Biden. Joe Biden is smiling and wearing a dark suit. The young girl is smiling and wearing a white dress. Hunter Biden is smiling and wearing a dark suit. The background is a photo of the White House.','this is test']\n",
    "\n",
    "            #comment to prevent extra costs\n",
    "            #********************************\n",
    "            #summaries_embeddings = encode_to_embeddings_chunked(\n",
    "                 #process_function=encode_summarycontent_to_embeddings, items=summaries\n",
    "            #)\n",
    "            #summaries_embeddings=[[1,2],[1,2,3]]\n",
    "\n",
    "            #********************************\n",
    "\n",
    "            # Append to file\n",
    "            embeddings_formatted=[]\n",
    "            for id,path,embedding,chapter in zip(video_names_chunk,video_paths_chunk,video_embeddings,video_chapters):\n",
    "                embedding=sorted(embedding, key=operator.attrgetter('start_offset_sec'))\n",
    "                chapter=sorted(chapter, key=operator.attrgetter('start_offset_sec'))\n",
    "                for ValEmbedding,ValChapter in zip(embedding,chapter):\n",
    "                    if ValChapter.start_offset_sec==ValEmbedding.start_offset_sec:\n",
    "                    \n",
    "                        if (ValEmbedding.embedding is not None) or (ValChapter.embedding is not None) :\n",
    "                            embeddings_formatted.append(  \n",
    "                                json.dumps(\n",
    "                                    {\n",
    "                                        \"id\": str(id), \n",
    "                                        \"video path\":str(path),\n",
    "                                        \"video_summary\":ValChapter.summary,\n",
    "                                        \"video_embedding\": [str(value) for value in ValEmbedding.embedding] if not ValEmbedding.embedding is None else None,\n",
    "                                        \"summary_embedding\": [str(value) for value in ValChapter.embedding] if not ValChapter.embedding is None else None,\n",
    "                                        \"start_offset_sec_embedding\": ValEmbedding.start_offset_sec,\n",
    "                                        \"end_offset_sec_embedding\": ValEmbedding.end_offset_sec ,\n",
    "                                        \"start_offset_sec_chapter\": ValChapter.start_offset_sec,\n",
    "                                        \"end_offset_sec_chapter\": ValChapter.end_offset_sec \n",
    "\n",
    "                                    }\n",
    "                                )\n",
    "                                + \"\\n\"\n",
    "\n",
    "                            )\n",
    "                    else:\n",
    "                        print('Something went wrong when chapterizing the video. The chapters are not inline with video segments.')\n",
    "                        raise\n",
    "            ef.writelines(embeddings_formatted)\n",
    "        \n",
    " \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb182a-2199-4b47-b844-65df08836758",
   "metadata": {},
   "source": [
    "### Create bucket and push embeddings into the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e5e18b-8a1c-4d1a-8013-d5ebd1a173cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#set bucket info to create a bucket\n",
    "BUCKET_URI = f\"gs://artifacts-{PROJECT_ID}-unique\"  # @param {type:\"string\"}\n",
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2354d-42f3-4b45-a387-c9f225f9b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIQUE_FOLDER_NAME = \"embeddings_results_NinePOC\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58369a05-16b4-4f93-b792-03b389544a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings\n",
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/{UNIQUE_FOLDER_NAME}/\"\n",
    "! gsutil cp {embeddings_file.name} {EMBEDDINGS_INITIAL_URI}\n",
    "\n",
    "#summaries\n",
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/{UNIQUE_FOLDER_NAME}/\"\n",
    "! gsutil cp {summaries_file.name} {EMBEDDINGS_INITIAL_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4fae7267-4f5f-43e7-a0fe-c39b4e0b9d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'videoembeddings_file.json'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the temp files in persistent disk\n",
    "import tempfile, shutil\n",
    " \n",
    "file_name = videoembeddings_file.name\n",
    "videoembeddings_file.close()\n",
    "shutil.copy(file_name, 'videoembeddings_file.json')\n",
    "\n",
    "# file_name = summaries_file.name\n",
    "# summaries_file.close()\n",
    "# shutil.copy(file_name, 'summaries_file.json')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe4468d-d92f-45cb-a3d0-9de84d8344be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
