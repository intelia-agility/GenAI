{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a354f9-0984-4c94-9042-efb28db5f4be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.58.0)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.59.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (2.14.0)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.17.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.31.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.19.6)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (24.1)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.25.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.12.3)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.4)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.10.17)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.7.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.32.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.1)\n",
      "INFO: pip is looking at multiple versions of google-api-core[grpc] to determine which version is compatible with other requirements. This could take a while.\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.7)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.7.4)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
      "Downloading google_cloud_aiplatform-1.59.0-py2.py3-none-any.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-2.17.0-py2.py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: google-api-core, google-cloud-storage, google-cloud-aiplatform\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 1.34.1\n",
      "    Uninstalling google-api-core-1.34.1:\n",
      "      Successfully uninstalled google-api-core-1.34.1\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.14.0\n",
      "    Uninstalling google-cloud-storage-2.14.0:\n",
      "      Successfully uninstalled google-cloud-storage-2.14.0\n",
      "  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 1.58.0\n",
      "    Uninstalling google-cloud-aiplatform-1.58.0:\n",
      "      Successfully uninstalled google-cloud-aiplatform-1.58.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.19.1 which is incompatible.\n",
      "google-cloud-pubsub 2.21.4 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.48.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-api-core-2.11.1 google-cloud-aiplatform-1.59.0 google-cloud-storage-2.17.0\n",
      "Requirement already satisfied: google-cloud-vision in /opt/conda/lib/python3.10/site-packages (3.7.2)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2.11.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-vision) (2.31.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-vision) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-vision) (3.19.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.63.1)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.48.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (4.9)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "# Install the packages\n",
    "! pip3 install --upgrade google-cloud-aiplatform \\\n",
    "                         google-cloud-storage\n",
    "\n",
    "# Install the packages\n",
    "! pip install google-cloud-vision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895e40a3-1749-4b68-ac38-7e001f32a101",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-videointelligence in /opt/conda/lib/python3.10/site-packages (1.16.3)\n",
      "Collecting google-cloud-videointelligence\n",
      "  Downloading google_cloud_videointelligence-2.13.4-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2.11.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-videointelligence) (2.31.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-videointelligence) (1.24.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 (from google-cloud-videointelligence)\n",
      "  Downloading protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.63.1)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.48.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (4.9)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2024.7.4)\n",
      "Downloading google_cloud_videointelligence-2.13.4-py2.py3-none-any.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.0/245.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf, google-cloud-videointelligence\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: google-cloud-videointelligence\n",
      "    Found existing installation: google-cloud-videointelligence 1.16.3\n",
      "    Uninstalling google-cloud-videointelligence-1.16.3:\n",
      "      Successfully uninstalled google-cloud-videointelligence-1.16.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "apache-beam 2.46.0 requires grpcio!=1.48.0,<2,>=1.33.1, but you have grpcio 1.48.0 which is incompatible.\n",
      "apache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.11.1 which is incompatible.\n",
      "google-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-datastore 1.15.5 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-language 1.3.2 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-pubsub 2.21.4 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.48.0 which is incompatible.\n",
      "google-cloud-storage 2.17.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 2.11.1 which is incompatible.\n",
      "kfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.3 which is incompatible.\n",
      "kfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorboardx 2.6 requires protobuf<4,>=3.8.0, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-serving-api 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-cloud-videointelligence-2.13.4 protobuf-3.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-videointelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70639287-6593-462f-a952-cfa0605b29dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8162339b-0555-46c0-8271-a26fe9fe99a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set project info\n",
    "PROJECT = !gcloud config get-value project\n",
    "PROJECT_ID = PROJECT[0]\n",
    "REGION = \"us-central1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fb72555-1765-496b-ad6a-d8c7d3aff330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "video_directory = \"SampleVideo\"\n",
    "\n",
    "video_names=[]\n",
    "for file_name in os.listdir(video_directory):\n",
    "    if  not file_name.startswith('.'):\n",
    "        video_names.append(file_name)\n",
    "\n",
    "video_paths = [os.path.join(video_directory, video_name) for video_name in video_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07f4fb10-2294-4fef-b4ac-a9075d30663a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_paths=[\"gs://cloud-samples-data/vertex-ai-vision/highway_vehicles.mp4\"]\n",
    "video_paths=[\"gs://raw_nine_files/60MI23_33_A_HBB.mp4\"]\n",
    "video_names=['60MI23_33_A_HBB.mp4']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6125a26-9f33-4c17-bd52-657233921201",
   "metadata": {},
   "source": [
    "### Define function to detect explicit images\n",
    "\n",
    "enable clound vision api before running this bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b070ae5-1f9e-430f-9fda-9e01bcee82b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.cloud.videointelligence.v1beta import SafeSearchAnnotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4839766e-611a-4f1b-b7eb-9f4ab6c03f41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for now the api is not active just to save costs. I set everything to true\n",
    "is_safe_values_cloud_vision=[True for i in range (len(video_paths))]\n",
    "is_safe_values_cloud_vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f555e1b5-65f5-4afb-a36b-d00a43d174f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter images by safety\n",
    "video_names = [\n",
    "    video_name\n",
    "    for video_name, is_safe in zip(video_names, is_safe_values_cloud_vision)\n",
    "    if is_safe\n",
    "]\n",
    "video_paths = [\n",
    "    video_path\n",
    "    for video_path, is_safe in zip(video_paths, is_safe_values_cloud_vision)\n",
    "    if is_safe\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190401dc-00a4-4d0e-927d-b41ed0a54c05",
   "metadata": {},
   "source": [
    "### Defining encoding functions\n",
    "Create an EmbeddingPredictionClient which encapsulates the logic to call the embedding API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c28009b4-80bf-4e6c-b378-1dc927224a24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n"
     ]
    }
   ],
   "source": [
    "c=['{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n      \"startOffset\": 0,\\n      \"endOffset\": 16,\\n      \"chapterSummary\": \"A black-and-white photo of a young blonde woman, with a 60 Minutes logo in the bottom left corner\"\\n    }', '{\\n      \"startOffset\": 16,\\n      \"endOffset\": 32,\\n      \"chapterSummary\": \"A woman in a black blazer sits in a dark room, talking about her sister, Revel Belmaine, who was a model and dancer. The woman expresses her fear and worry about her sister, who disappeared in 1994.\"\\n    }', '{\\n      \"startOffset\": 32,\\n      \"endOffset\": 48,\\n      \"chapterSummary\": \"A police officer shines a UV light on a wall, revealing a red handprint. An investigator discusses the possibility of Revel\\'s death and the investigation into her disappearance.\"\\n    }', '{\\n      \"startOffset\": 48,\\n      \"endOffset\": 64,\\n      \"chapterSummary\": \"A woman discusses the evidence against her ex-husband, Zoran Stanoyevic. The woman believes that he was involved in Revel\\'s disappearance.\"\\n    }', '{\\n      \"startOffset\": 64,\\n      \"endOffset\": 80,\\n      \"chapterSummary\": \"The woman in a black blazer describes her ex-husband\\'s changing story and how it raises suspicion. She describes her ex-husband as way too obvious and feels he is not being honest with the police.\"\\n    }', '{\\n      \"startOffset\": 80,\\n      \"endOffset\": 96,\\n      \"chapterSummary\": \"The woman shares her experience of the day after her sister disappeared and how it affected her.\"\\n    }', '{\\n      \"startOffset\": 96,\\n      \"endOffset\": 112,\\n      \"chapterSummary\": \"The woman discusses how the initial police investigation failed to find any credible evidence against her ex-husband. The case was brushed off and not thoroughly investigated.  \"\\n    }', '{\\n      \"startOffset\": 112,\\n      \"endOffset\": 120,\\n      \"chapterSummary\": \"A police officer stands in the background. The woman hopes that police will find answers about her sister\\'s disappearance.\"\\n    }']\n",
    "\n",
    "for x in c:\n",
    "    if 'startOffset' in x:\n",
    "        print('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82af3661-214e-4c4b-bcd4-10390c5441f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/nine-quality-test/locations/us-central1/publishers/google/models/multimodalembedding@001\n",
      "{'start': 0, 'end': 120}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n      \"startOffset\": 0,\\n      \"endOffset\": 16,\\n      \"chapterSummary\": \"A black and white picture of a young woman with blonde hair\"\\n    }', '{\\n      \"startOffset\": 16,\\n      \"endOffset\": 32,\\n      \"chapterSummary\": \"Police in SWAT gear enter a building.  A woman talks about being scared after her sister disappeared.\"\\n    }', '{\\n      \"startOffset\": 32,\\n      \"endOffset\": 48,\\n      \"chapterSummary\": \"Police investigate a missing persons case.  The woman\\'s sister talks about her sister working as an escort.\"\\n    }', '{\\n      \"startOffset\": 48,\\n      \"endOffset\": 64,\\n      \"chapterSummary\": \"A man in a red jacket tells a reporter he has nothing to say.  The woman\\'s sister talks about the night her sister went missing.\"\\n    }', '{\\n      \"startOffset\": 64,\\n      \"endOffset\": 80,\\n      \"chapterSummary\": \"A man tells the reporter that he worked with the missing woman.  He says he has no thoughts on the missing person case.\"\\n    }', '{\\n      \"startOffset\": 80,\\n      \"endOffset\": 96,\\n      \"chapterSummary\": \"Police investigate the missing person case.  The woman\\'s sister talks about new evidence in the case.\"\\n    }', '{\\n      \"startOffset\": 96,\\n      \"endOffset\": 112,\\n      \"chapterSummary\": \"A man with a backpack walks away from a reporter.  The woman\\'s sister talks about her sister\\'s last client.\"\\n    }', '{\\n      \"startOffset\": 112,\\n      \"endOffset\": 120,\\n      \"chapterSummary\": \"The woman\\'s sister talks about the night her sister disappeared.\"\\n    }']\n",
      "\n",
      "\n",
      "[{'startOffset': '0', 'endOffset': '16', 'chapterSummary': 'A black and white picture of a young woman with blonde hair'}, {'startOffset': '16', 'endOffset': '32', 'chapterSummary': 'Police in SWAT gear enter a building.  A woman talks about being scared after her sister disappeared.'}, {'startOffset': '32', 'endOffset': '48', 'chapterSummary': \"Police investigate a missing persons case.  The woman's sister talks about her sister working as an escort.\"}, {'startOffset': '48', 'endOffset': '64', 'chapterSummary': \"A man in a red jacket tells a reporter he has nothing to say.  The woman's sister talks about the night her sister went missing.\"}, {'startOffset': '64', 'endOffset': '80', 'chapterSummary': 'A man tells the reporter that he worked with the missing woman.  He says he has no thoughts on the missing person case.'}, {'startOffset': '80', 'endOffset': '96', 'chapterSummary': \"Police investigate the missing person case.  The woman's sister talks about new evidence in the case.\"}, {'startOffset': '96', 'endOffset': '112', 'chapterSummary': \"A man with a backpack walks away from a reporter.  The woman's sister talks about her sister's last client.\"}, {'startOffset': '112', 'endOffset': '120', 'chapterSummary': \"The woman's sister talks about the night her sister disappeared.\"}]\n",
      "{'start': 120, 'end': 240}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{\\n      \"startOffset\": 120,\\n      \"endOffset\": 136,\\n      \"chapterSummary\": \"The case remains unsolved after nearly 30 years. The missing woman was last seen with her client. The victim\\'s family fears the worst.\"\\n    }', '{\\n      \"startOffset\": 136,\\n      \"endOffset\": 152,\\n      \"chapterSummary\": \"The victim\\'s sister says she believes that her ex-husband lied about the night her sister disappeared. The police are now investigating that lead.\"\\n    }', '{\\n      \"startOffset\": 152,\\n      \"endOffset\": 168,\\n      \"chapterSummary\": \"The police are looking into the ex-husband\\'s alibi and have a new person of interest in the case. The police have new clues and a new person of interest.\"\\n    }', '{\\n      \"startOffset\": 168,\\n      \"endOffset\": 184,\\n      \"chapterSummary\": \"The victim\\'s sister says that she never thought that the ex-husband was involved. The sister feels like the police didn\\'t take the case seriously enough.\"\\n    }', '{\\n      \"startOffset\": 184,\\n      \"endOffset\": 200,\\n      \"chapterSummary\": \"The sister says that the ex-husband changed his story about the night the victim disappeared.  The sister is looking for answers. New details about the night the victim disappeared.\"\\n    }', '{\\n      \"startOffset\": 200,\\n      \"endOffset\": 216,\\n      \"chapterSummary\": \"The victim\\'s sister says that she is still searching for answers. The victim\\'s sister says that she believes that she did everything that she could to find her sister. \"\\n    }', '{\\n      \"startOffset\": 216,\\n      \"endOffset\": 232,\\n      \"chapterSummary\": \"The victim\\'s sister says that her family and friends need to know what happened. The police are now looking into new information that has come to light.\"\\n    }', '{\\n      \"startOffset\": 232,\\n      \"endOffset\": 240,\\n      \"chapterSummary\": \"The police are investigating the ex-husband\\'s alibi, which has changed several times. The victim\\'s sister says that she doesn\\'t think that her ex-husband would come looking for her.\"\\n    }']\n",
      "\n",
      "\n",
      "[{'startOffset': '120', 'endOffset': '136', 'chapterSummary': \"The case remains unsolved after nearly 30 years. The missing woman was last seen with her client. The victim's family fears the worst.\"}, {'startOffset': '136', 'endOffset': '152', 'chapterSummary': \"The victim's sister says she believes that her ex-husband lied about the night her sister disappeared. The police are now investigating that lead.\"}, {'startOffset': '152', 'endOffset': '168', 'chapterSummary': \"The police are looking into the ex-husband's alibi and have a new person of interest in the case. The police have new clues and a new person of interest.\"}, {'startOffset': '168', 'endOffset': '184', 'chapterSummary': \"The victim's sister says that she never thought that the ex-husband was involved. The sister feels like the police didn't take the case seriously enough.\"}, {'startOffset': '184', 'endOffset': '200', 'chapterSummary': 'The sister says that the ex-husband changed his story about the night the victim disappeared.  The sister is looking for answers. New details about the night the victim disappeared.'}, {'startOffset': '200', 'endOffset': '216', 'chapterSummary': \"The victim's sister says that she is still searching for answers. The victim's sister says that she believes that she did everything that she could to find her sister.\"}, {'startOffset': '216', 'endOffset': '232', 'chapterSummary': \"The victim's sister says that her family and friends need to know what happened. The police are now looking into new information that has come to light.\"}, {'startOffset': '232', 'endOffset': '240', 'chapterSummary': \"The police are investigating the ex-husband's alibi, which has changed several times. The victim's sister says that she doesn't think that her ex-husband would come looking for her.\"}]\n",
      "{'start': 240, 'end': 360}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{\\n    \"startOffset\": 240,\\n    \"endOffset\": 256,\\n    \"chapterSummary\": \"Zoran claimed he was not working the night Revel went missing. He said he was at home with a heavily pregnant Jane\"\\n  }', '{\\n    \"startOffset\": 256,\\n    \"endOffset\": 272,\\n    \"chapterSummary\": \"Zoran, who ran an escort agency with Jane, arranged a ticket for a client to leave Australia the next day.\"\\n  }', '{\\n    \"startOffset\": 272,\\n    \"endOffset\": 288,\\n    \"chapterSummary\": \"Jane\\'s sister says Zoran knew the client well enough to book them a flight.\"\\n  }', '{\\n    \"startOffset\": 288,\\n    \"endOffset\": 304,\\n    \"chapterSummary\": \"Zoran admitted he wasn\\'t home that night. He told the police he was out driving another escort to and from jobs. But phone calls critical to his alibi were never made.\"\\n  }', '{\\n    \"startOffset\": 304,\\n    \"endOffset\": 320,\\n    \"chapterSummary\": \"Jane\\'s ex-husband, Zoran, who owned the escort agency with her, is under intense pressure to explain his whereabouts the night 22-year-old Revel disappeared.\"\\n  }', '{\\n    \"startOffset\": 320,\\n    \"endOffset\": 336,\\n    \"chapterSummary\": \"Jane claims her ex-husband had nothing to do with Revel\\'s disappearance. But she has startling information about what Zoran did for him, the day after Revel disappeared.\"\\n  }', '{\\n    \"startOffset\": 336,\\n    \"endOffset\": 352,\\n    \"chapterSummary\": \"Zoran arranged a ticket for a client to leave Australia the day after Revel went missing. This client is now a person of interest.\"\\n  }', '{\\n    \"startOffset\": 352,\\n    \"endOffset\": 360,\\n    \"chapterSummary\": \"The family and investigators are hoping someone will come forward and help solve the mystery of Revel\\'s disappearance.\"\\n  }']\n",
      "\n",
      "\n",
      "[{'startOffset': '240', 'endOffset': '256', 'chapterSummary': 'Zoran claimed he was not working the night Revel went missing. He said he was at home with a heavily pregnant Jane'}, {'startOffset': '256', 'endOffset': '272', 'chapterSummary': 'Zoran, who ran an escort agency with Jane, arranged a ticket for a client to leave Australia the next day.'}, {'startOffset': '272', 'endOffset': '288', 'chapterSummary': \"Jane's sister says Zoran knew the client well enough to book them a flight.\"}, {'startOffset': '288', 'endOffset': '304', 'chapterSummary': \"Zoran admitted he wasn't home that night. He told the police he was out driving another escort to and from jobs. But phone calls critical to his alibi were never made.\"}, {'startOffset': '304', 'endOffset': '320', 'chapterSummary': \"Jane's ex-husband, Zoran, who owned the escort agency with her, is under intense pressure to explain his whereabouts the night 22-year-old Revel disappeared.\"}, {'startOffset': '320', 'endOffset': '336', 'chapterSummary': \"Jane claims her ex-husband had nothing to do with Revel's disappearance. But she has startling information about what Zoran did for him, the day after Revel disappeared.\"}, {'startOffset': '336', 'endOffset': '352', 'chapterSummary': 'Zoran arranged a ticket for a client to leave Australia the day after Revel went missing. This client is now a person of interest.'}, {'startOffset': '352', 'endOffset': '360', 'chapterSummary': \"The family and investigators are hoping someone will come forward and help solve the mystery of Revel's disappearance.\"}]\n",
      "{'start': 360, 'end': 480}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"integer\"\\n      }', '{\\n        \"type\": \"string\"\\n      }', '{\\n  \"startOffset\": 360,\\n  \"endOffset\": 376,\\n  \"chapterSummary\": \"A discussion about a statement made about a man called Boyan Provalovic.  Zoran, a man in the video, is said to have booked a flight for Boyan to Thailand and this is what Jane, Zoran\\'s ex-wife, says about it.\"\\n}', '{\\n  \"startOffset\": 376,\\n  \"endOffset\": 392,\\n  \"chapterSummary\": \"A discussion about whether Zoran would have done something like that. Jane, Zoran\\'s ex-wife, says that she doesn\\'t believe he would have and that the incident was not like her to have handled in such a way.\"\\n}', '{\\n  \"startOffset\": 392,\\n  \"endOffset\": 408,\\n  \"chapterSummary\": \"A man called Adam Owen is the maitre d\\' of The Edge restaurant and a discussion about the phone call made to Adam. He claims that the statement made was not true.\"\\n}', '{\\n  \"startOffset\": 408,\\n  \"endOffset\": 424,\\n  \"chapterSummary\": \"The person in the video with the beard and glasses is Adam Owen. He is asked whether he remembers the words used to him when he was called to confirm a booking at his restaurant.\"\\n}', '{\\n  \"startOffset\": 424,\\n  \"endOffset\": 440,\\n  \"chapterSummary\": \"The discussion continues about Adam Owen and a booking for a man called Boyan Provalovic, Zoran\\'s friend and Revelle Belmain\\'s last client, at the Edge restaurant. They are asking him to confirm his statement made.\"\\n}', '{\\n  \"startOffset\": 440,\\n  \"endOffset\": 456,\\n  \"chapterSummary\": \"Zoran is being discussed in the video and the discussion about whether he would be angry at Jane for asking questions about his actions in relation to Revelle Belmain\\'s disappearance.\"\\n}', '{\\n  \"startOffset\": 456,\\n  \"endOffset\": 472,\\n  \"chapterSummary\": \"Zoran is a person of interest in this case and he is being investigated. The police are asking people who know him to come forward and speak to them and also to help them with their investigation.\"\\n}', '{\\n  \"startOffset\": 472,\\n  \"endOffset\": 480,\\n  \"chapterSummary\": \"A discussion about Zoran\\'s recent arrest and charges in relation to cannabis. They are not related to the case of the disappearance of Revelle Belmain.\"\\n}']\n",
      "\n",
      "\n",
      "[{'startOffset': '360', 'endOffset': '376', 'chapterSummary': \"A discussion about a statement made about a man called Boyan Provalovic.  Zoran, a man in the video, is said to have booked a flight for Boyan to Thailand and this is what Jane, Zoran's ex-wife, says about it.\"}, {'startOffset': '376', 'endOffset': '392', 'chapterSummary': \"A discussion about whether Zoran would have done something like that. Jane, Zoran's ex-wife, says that she doesn't believe he would have and that the incident was not like her to have handled in such a way.\"}, {'startOffset': '392', 'endOffset': '408', 'chapterSummary': \"A man called Adam Owen is the maitre d' of The Edge restaurant and a discussion about the phone call made to Adam. He claims that the statement made was not true.\"}, {'startOffset': '408', 'endOffset': '424', 'chapterSummary': 'The person in the video with the beard and glasses is Adam Owen. He is asked whether he remembers the words used to him when he was called to confirm a booking at his restaurant.'}, {'startOffset': '424', 'endOffset': '440', 'chapterSummary': \"The discussion continues about Adam Owen and a booking for a man called Boyan Provalovic, Zoran's friend and Revelle Belmain's last client, at the Edge restaurant. They are asking him to confirm his statement made.\"}, {'startOffset': '440', 'endOffset': '456', 'chapterSummary': \"Zoran is being discussed in the video and the discussion about whether he would be angry at Jane for asking questions about his actions in relation to Revelle Belmain's disappearance.\"}, {'startOffset': '456', 'endOffset': '472', 'chapterSummary': 'Zoran is a person of interest in this case and he is being investigated. The police are asking people who know him to come forward and speak to them and also to help them with their investigation.'}, {'startOffset': '472', 'endOffset': '480', 'chapterSummary': \"A discussion about Zoran's recent arrest and charges in relation to cannabis. They are not related to the case of the disappearance of Revelle Belmain.\"}]\n",
      "{'start': 480, 'end': 600}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n"
     ]
    }
   ],
   "source": [
    "client = EmbeddingPredictionClient(project=PROJECT_ID)\n",
    "\n",
    "a=client.get_embedding(video_file= video_paths[0]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a2ad50c-4171-4375-ad84-977710db7a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import time\n",
    "import typing\n",
    "import math\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.protobuf import struct_pb2\n",
    "\n",
    "#libraries to generate image summaries\n",
    "from vertexai.vision_models import Video\n",
    "from vertexai.vision_models import VideoSegmentConfig\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.vision_models import Image as vision_model_Image\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part as GenerativeModelPart,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n",
    "from typing import Any, Dict, List, Literal, Optional, Union\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "text_embedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@latest\")\n",
    "#multimodal_embedding_model = MultiModalEmbeddingModel.from_pretrained(\n",
    " #   \"multimodalembedding@001\"\n",
    "#)\n",
    "import requests\n",
    "from google.cloud import storage\n",
    "from google.cloud.aiplatform import initializer as aiplatform_initializer\n",
    "import datetime\n",
    "\n",
    "import yaml\n",
    "import re\n",
    "\n",
    "segments_to_process=120\n",
    "intervals=16\n",
    "#max_duration=120#math.ceil(2719.04)#\n",
    "\n",
    "schema = '''\n",
    "{\n",
    "  \"description\": \"A list of chapters\",\n",
    "  \"type\": \"array\",\n",
    "  \"items\": {\n",
    "\t\"type\":\"object\",\n",
    "\t\"properties\": {\n",
    "\t\t\"startOffset\": {\n",
    "\t\t\t\"type\":\"integer\"\n",
    "\t\t},\n",
    "\t\t\"endOffset\": {\n",
    "\t\t\t\"type\":\"integer\"\n",
    "\t\t},\n",
    "\t\t\"chapterSummary\": {\n",
    "\t\t\t\"type\":\"string\"\n",
    "\t\t}\n",
    "\t},\n",
    "\t\"required\": [\"startOffset\",\"endOffset\" ]\n",
    "  }\n",
    "}\n",
    "'''\n",
    "\n",
    "\n",
    "class VideoEmbedding:\n",
    "    \"\"\"Embeddings generated from video with offset times.\"\"\"\n",
    "\n",
    "    __module__ = \"vertexai.vision_models\"\n",
    "\n",
    "    start_offset_sec: int\n",
    "    end_offset_sec: int\n",
    "    embedding: List[float]\n",
    "\n",
    "    def __init__(\n",
    "        self, start_offset_sec: int, end_offset_sec: int, embedding: List[float]\n",
    "    ):\n",
    "        \"\"\"Creates a `VideoEmbedding` object.\n",
    "\n",
    "        Args:\n",
    "            start_offset_sec: Start time offset (in seconds) of generated embeddings.\n",
    "            end_offset_sec: End time offset (in seconds) of generated embeddings.\n",
    "            embedding: Generated embedding for interval.\n",
    "        \"\"\"\n",
    "        self.start_offset_sec = start_offset_sec\n",
    "        self.end_offset_sec = end_offset_sec\n",
    "        self.embedding = embedding\n",
    "        \n",
    "        \n",
    "class VideoChapter:\n",
    "    \"\"\"Chapters generated from video with offset times.\"\"\"\n",
    "\n",
    "    start_offset_sec: int\n",
    "    end_offset_sec: int\n",
    "    embedding: List[float]\n",
    "    summary: str\n",
    "\n",
    "    def __init__(\n",
    "        self, start_offset_sec: int, end_offset_sec: int, embedding: List[float], summary: str\n",
    "    ):\n",
    "        \"\"\"Creates a `VideoEmbedding` object.\n",
    "\n",
    "        Args:\n",
    "            start_offset_sec: Start time offset (in seconds) of generated embeddings.\n",
    "            end_offset_sec: End time offset (in seconds) of generated embeddings.\n",
    "            embedding: Generated embedding for interval.\n",
    "        \"\"\"\n",
    "        self.start_offset_sec = start_offset_sec\n",
    "        self.end_offset_sec = end_offset_sec\n",
    "        self.embedding = embedding\n",
    "        self.summary=summary\n",
    "        \n",
    "        \n",
    "class EmbeddingResponse(typing.NamedTuple):\n",
    "    text_embedding: typing.Sequence[float]\n",
    "    video_embedding: typing.Sequence[VideoEmbedding]\n",
    "    video_chapter: typing.Sequence[VideoChapter]\n",
    "       \n",
    "        \n",
    "def load_video_bytes(video_uri: str ) -> bytes:\n",
    "    \"\"\"Load image bytes from a remote or local URI.\"\"\"\n",
    "   \n",
    "    video_bytes = None\n",
    "    if video_uri.startswith(\"http://\") or video_uri.startswith(\"https://\") :\n",
    "        #reading from remote\n",
    "        video_uri=video_uri.replace(\" \", \"%20\")\n",
    "        response = requests.get(video_uri, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            video_bytes = response.content\n",
    "    elif   video_uri.startswith(\"gs://\"):\n",
    "           #reading from gcs\n",
    "            storage_client = storage.Client(\n",
    "                   credentials=aiplatform_initializer.global_config.credentials\n",
    "                      )\n",
    "            blob = storage.Blob.from_string(uri=video_uri, client=storage_client)\n",
    "            # Needed to populate `blob.content_type`\n",
    "            blob.reload()\n",
    "            blob.download_as_bytes()  \n",
    "            video_bytes=blob.download_as_bytes()\n",
    "           \n",
    "        \n",
    "    else:\n",
    "        #reading from local\n",
    "        video_bytes = open(video_uri, \"rb\").read()\n",
    "        \n",
    "\n",
    "    return video_bytes\n",
    "\n",
    "\n",
    "def generate_download_signed_url_v4(bucket_name, blob_name):\n",
    "    \"\"\"Generates a v4 signed URL for downloading a blob.\n",
    "\n",
    "    Note that this method requires a service account key file. You can not use\n",
    "    this if you are using Application Default Credentials from Google Compute\n",
    "    Engine or from the Google Cloud SDK.\n",
    "    \"\"\"\n",
    "    # bucket_name = 'your-bucket-name'\n",
    "    # blob_name = 'your-object-name'\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    \n",
    "    from google.auth.transport import requests\n",
    "    from google.auth import default, compute_engine\n",
    "    \n",
    "    credentials, _ = default()\n",
    "    \n",
    "    # then within your abstraction\n",
    "    auth_request = requests.Request()\n",
    "    credentials.refresh(auth_request)\n",
    "    \n",
    "    signing_credentials = compute_engine.IDTokenCredentials(\n",
    "        auth_request,\n",
    "        \"\",\n",
    "        service_account_email=credentials.service_account_email\n",
    "    )\n",
    " \n",
    "    print(signing_credentials)\n",
    "    url = blob.generate_signed_url(\n",
    "        version=\"v4\",\n",
    "        # This URL is valid for 15 minutes\n",
    "        expiration=datetime.timedelta(minutes=15),\n",
    "        # Allow GET requests using this URL.\n",
    "        method=\"GET\",\n",
    "         credentials=signing_credentials,\n",
    "    )\n",
    "    return url\n",
    "\n",
    "\n",
    "def get_video_duration(video_uri):\n",
    "  try:   \n",
    "    \n",
    "    if video_uri.startswith(\"http://\") or video_uri.startswith(\"https://\") :\n",
    "        video_uri=video_uri.replace(\" \", \"%20\")\n",
    "    elif video_uri.startswith(\"gs://\"):  \n",
    "        bucket_name='/'.join(video_paths[0].replace('gs://','').split('/')[:-1])\n",
    "        blob_name=video_uri.replace('gs://','').split('/')[-1]\n",
    "        video_uri= generate_download_signed_url_v4(bucket_name, blob_name)\n",
    "    else:\n",
    "        video_uri=video_uri\n",
    "        \n",
    "    clip = VideoFileClip(video_uri)\n",
    "    duration = clip.duration\n",
    "    clip.close()  # Release resources\n",
    "    return duration\n",
    "  except OSError as e:\n",
    "    if \"moov atom not found\" in str(e):\n",
    "      print(\"Error: The video file seems to be corrupted or incomplete.\")\n",
    "      #To Do: fix this\n",
    "      #fix the issue using \n",
    "      ##!MP4Box -inter 0  'drive/MyDrive/Colab Notebooks/60MI23_33_A_HBB.mp4'\n",
    "      #for now\n",
    "      return max_duration\n",
    "    else:\n",
    "      print(f\"Error reading video file: {e}\")\n",
    "    return max_duration\n",
    "\n",
    "    \n",
    "class EmbeddingPredictionClient:\n",
    "    \"\"\"Wrapper around Prediction Service Client.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        project: str,\n",
    "        location: str = \"us-central1\",\n",
    "        api_regional_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "    ):\n",
    "        client_options = {\"api_endpoint\": api_regional_endpoint}\n",
    "        # Initialize client that will be used to create and send requests.\n",
    "        # This client only needs to be created once, and can be reused for multiple requests.\n",
    "        self.client = aiplatform.gapic.PredictionServiceClient(\n",
    "            client_options=client_options\n",
    "        )\n",
    "        self.location = location\n",
    "        self.project = project\n",
    "        \n",
    "\n",
    "    \n",
    "    def get_embedding(self, text: str = None, video_file: str = None  ):\n",
    "        if not text and not video_file:\n",
    "            raise ValueError(\"At least one of text or video_file must be specified.\")\n",
    "\n",
    " \n",
    "        # Load video file\n",
    "        video_bytes = None\n",
    "        if (video_file) and (not video_file.startswith(\"gs://\")):             \n",
    "            video_bytes = load_video_bytes(video_file)\n",
    "\n",
    " \n",
    "        instance ={}\n",
    "        if text:\n",
    "            instance[\"text\"] = text\n",
    "\n",
    "        if (video_file) and ((video_bytes) or (video_file.startswith(\"gs://\"))):             \n",
    "            \n",
    "            if video_bytes:\n",
    "               encoded_content = base64.b64encode(video_bytes).decode(\"utf-8\")\n",
    "               instance[\"video\"] = {\n",
    "                    \"bytesBase64Encoded\": encoded_content # pylint: disable=protected-access\n",
    "                }#  # pylint: disable=protected-access\n",
    "               \n",
    "            if  (video_file.startswith(\"gs://\")):  \n",
    "                instance[\"video\"] = {\n",
    "                        \"gcsUri\": video_file  # pylint: disable=protected-access\n",
    "                    }          \n",
    "                \n",
    "            #get video duration\n",
    "            video_duration=10*60#math.ceil(get_video_duration(video_file))\n",
    "     \n",
    "\n",
    "\n",
    "        endpoint = (\n",
    "           f\"projects/{self.project}/locations/{self.location}\"\n",
    "           \"/publishers/google/models/multimodalembedding@001\"\n",
    "        )\n",
    "        \n",
    "        print(endpoint)\n",
    "\n",
    "        #response =self.client.predict(endpoint=endpoint, instances=instances)\n",
    "\n",
    "        text_embedding = None\n",
    "        if text:\n",
    "            instances = [instance]\n",
    "            response =self.client.predict(endpoint=endpoint, instances=instances)\n",
    "            text_emb_value = response.predictions[0][\"textEmbedding\"]\n",
    "            text_embedding = [v for v in text_emb_value]\n",
    "\n",
    "        #video_duration=4*60\n",
    "        \n",
    "        video_embedding = None\n",
    "        if (video_file) and ((video_bytes) or (video_file.startswith(\"gs://\"))): \n",
    "            video_embeddings = []  \n",
    "            video_chapters=[]\n",
    "            prev=0\n",
    "            #iterate over the file and get embeddings of the whole file\n",
    "            \n",
    "            \n",
    "            for val in range (segments_to_process,video_duration+segments_to_process,segments_to_process):\n",
    "                offset={'start':prev, 'end':val}\n",
    "                prev=val    \n",
    "                print(offset)\n",
    "                print('getting Multimodal Embeddings..')\n",
    "#                 video_segments=VideoSegmentConfig(start_offset_sec=offset['start'],end_offset_sec=offset['end'])\n",
    "\n",
    "#                 if video_segments:\n",
    "#                     instance[\"video\"][\"videoSegmentConfig\"] = {\n",
    "#                             \"startOffsetSec\": video_segments.start_offset_sec,\n",
    "#                             \"endOffsetSec\": video_segments.end_offset_sec,\n",
    "#                             \"intervalSec\": video_segments.interval_sec,\n",
    "#                         }\n",
    "                \n",
    "#                 instances = [instance]\n",
    "                # response =self.client.predict(endpoint=endpoint, instances=instances)\n",
    "                # for video_embedding in response.predictions[0].get(\"videoEmbeddings\", []):\n",
    "                #     video_embeddings.append(\n",
    "                #         VideoEmbedding(\n",
    "                #             embedding=video_embedding[\"embedding\"],                           \n",
    "                #             start_offset_sec=video_embedding[\"startOffsetSec\"],\n",
    "                #             end_offset_sec=video_embedding[\"endOffsetSec\"],\n",
    "                #         )\n",
    "                #     )\n",
    "\n",
    "\n",
    "                print('getting summaries..')\n",
    "                \n",
    "                chapters=self.get_video_summarycontent(video_file=video_file,startOffset=offset['start'],endOffset=offset['end'],intervals=intervals)\n",
    "               \n",
    "                print(chapters)\n",
    "                  #self.get_summarycontent_embedding_from_text_embedding_model(text=chapter[\"chapterSummary\"]).text_embedding,                           \n",
    "                    \n",
    "                for chapter in chapters:\n",
    "                    video_chapters.append(\n",
    "                        VideoChapter(\n",
    "                            embedding=[1,2,3],                          \n",
    "                            start_offset_sec=chapter[\"startOffset\"],\n",
    "                            end_offset_sec=chapter[\"endOffset\"],\n",
    "                            summary=chapter[\"chapterSummary\"]\n",
    "                        )\n",
    "                    )\n",
    "                    \n",
    "                    video_embeddings.append(\n",
    "                            VideoEmbedding(\n",
    "                                embedding=[1,2,3],\n",
    "                                start_offset_sec=chapter[\"startOffset\"],\n",
    "                                end_offset_sec=chapter[\"endOffset\"],\n",
    "                            )\n",
    "                        )\n",
    "                # video_chapters.append(\n",
    "                #         VideoChapter(\n",
    "                #             embedding=[],                           \n",
    "                #             start_offset_sec=video_segments.start_offset_sec,\n",
    "                #             end_offset_sec=video_segments.start_offset_sec,\n",
    "                #             summary='test'\n",
    "                #         )\n",
    "                # )\n",
    "\n",
    "                \n",
    "        return EmbeddingResponse (text_embedding=text_embedding, video_embedding=video_embeddings, video_chapter=video_chapters)\n",
    " \n",
    "   \n",
    "   \n",
    "    def get_video_summarycontent(self, text: str = None, video_file: str = None,startOffset: int=0, endOffset: int=120, intervals: int=16):\n",
    "        \n",
    "         '''\n",
    "         Gimini Features for Video as per:https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/video-understanding\n",
    "         gemini-1.5-flash, Gemini 1.5 Pro: \n",
    "         With audio: ~50 minutes\n",
    "         Without audio: 60 minutes\n",
    "         Maximum videos per prompt: 10\n",
    "         \n",
    "         Gemini 1.0 Pro Vision:\n",
    "         Maximum video length: 2 minutes\n",
    "         The maximum videos per prompt: 1\n",
    "         Audio in the video is ignored.\n",
    "         \n",
    "         Gimini feature for Part as per:https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#sample-requests\n",
    "        '''\n",
    "        \n",
    "\n",
    " \n",
    "         generative_multimodal_model= GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "         # Please only capture key events and highlights.\n",
    "        \n",
    "         video_description_prompt=f\"\"\"You are an assistant tasked with summarizing videos for retrieval.\\\n",
    "         These summaries will be embedded and used to retrieve the raw video.\\\n",
    "        Chapterize the video content by grouping the video content into chapters \\\n",
    "        with intervals of {intervals} seconds and providing a concise detail for each chapter that is well optimized for retrieval.\\\n",
    "        If there is a famous person like politician, celebrity or athlete, indicate their name and describe what they are famous for.\\\n",
    "        Describe important scenes in the video concisely.\\\n",
    "        If you are not sure about any info, please do not make it up. \\\n",
    "        Only consider video from {startOffset} seconds to {endOffset} seconds. Ignore analyzing the rest of video.\\\n",
    "        Return the result as per given schema:\\\n",
    "        {schema}.\\\n",
    "        If it is the last chapter, set the endOffset to {endOffset} instead.\\  \n",
    "        \"\"\"\n",
    "                   \n",
    "         generation_config= GenerationConfig(temperature=1, top_k=40,top_p=0.95,max_output_tokens=8192) \n",
    "         \n",
    "        #for video, BLOCK_NONE gives error. So, have to set it to BLOCK_ONLY_HIGH\n",
    "         safety_settings=  {\n",
    "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    }\n",
    "         stream=True\n",
    "        \n",
    "         # Load the saved video as a Gemini Part Object\n",
    "          \n",
    "         contents=[GenerativeModelPart.from_uri(video_file,mime_type=\"video/mp4\"),\n",
    "                   video_description_prompt,]\n",
    "        \n",
    "        \n",
    "         response = generative_multimodal_model.generate_content(\n",
    "            contents,\n",
    "            generation_config=generation_config,\n",
    "            stream=stream,\n",
    "            safety_settings=safety_settings, )\n",
    "        \n",
    "        \n",
    "         response_list = []\n",
    "\n",
    "         for chunk in response:\n",
    "            try:\n",
    "                response_list.append(chunk.text)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    \"Exception occurred while calling gemini. Something is wrong. Lower the safety thresholds [safety_settings: BLOCK_NONE ] if not already done. -----\",\n",
    "                    e,\n",
    "                )\n",
    "                response_list.append(\"****Exception occurred***:\"+e)\n",
    "                continue\n",
    "\n",
    "         response = ''.join(response_list)\n",
    "         response=response.replace('''{\\n  \"description\": \"A list of chapters\",\\n  \"type\": \"array\",\\n  \"items\": {\\n\\t\"type\":\"object\",\\n\\t\"properties\": {\\n\\t\\t\"startOffset\": {\\n\\t\\t\\t\"type\":\"integer\"\\n\\t\\t},\\n\\t\\t\"endOffset\": {\\n\\t\\t\\t\"type\":\"integer\"\\n\\t\\t},\\n\\t\\t\"chapterSummary\": {\\n\\t\\t\\t\"type\":\"string\"\\n\\t\\t}\\n\\t},\\n\\t\"required\": [\"startOffset\",\"endOffset\" ]\\n  }\\n},\\n  ''','')\n",
    "         response=response[response.index('\"items\"'):len(response)-1]\n",
    "\n",
    "         chapters=[]\n",
    "         chapters_text=re.findall(r'\\{[^{}]*\\}',response )\n",
    "         print(chapters_text)\n",
    "         print('\\n')\n",
    "         for chapter in chapters_text:\n",
    "                     if 'startOffset' in chapter:\n",
    "                         chapter=chapter.replace('{','').replace('}','').strip()\n",
    "                         chapters.append(\n",
    "                             {\n",
    "                                \"startOffset\":chapter.split(',')[0].replace('\"startOffset\":','').replace(\"{\",'').strip(),\n",
    "                                \"endOffset\":chapter.split(',')[1].replace('\"endOffset\":','').strip(),\n",
    "                                 \"chapterSummary\": ('[ST]'+chapter[chapter.index('\"chapterSummary\":'): len(chapter)-1].replace('\"chapterSummary\":','').replace(\"}\",'').strip()).replace('[ST]\"','')\n",
    "\n",
    "                             }\n",
    "                         )\n",
    "             \n",
    " \n",
    "         return chapters\n",
    "\n",
    "    \n",
    "    def get_summarycontent_embedding_from_text_embedding_model(self, text: str, return_array: Optional[bool] = False,) -> list:\n",
    "        \"\"\"\n",
    "        Generates a numerical text embedding from a provided text input using a text embedding model.\n",
    "\n",
    "        Args:\n",
    "            text: The input text string to be embedded.\n",
    "            return_array: If True, returns the embedding as a NumPy array.\n",
    "                          If False, returns the embedding as a list. (Default: False)\n",
    "\n",
    "        Returns:\n",
    "            list or numpy.ndarray: A 768-dimensional vector representation of the input text.\n",
    "                                   The format (list or NumPy array) depends on the\n",
    "                                   value of the 'return_array' parameter.\n",
    "        \"\"\"\n",
    "\n",
    "        #the given text is maximum 2048 token. If more, it has to be chunked.\n",
    "        embeddings = text_embedding_model.get_embeddings([text])\n",
    "        text_embedding = [embedding.values for embedding in embeddings][0]\n",
    "\n",
    "        if return_array:\n",
    "            text_embedding = np.fromiter(text_embedding, dtype=float)\n",
    "\n",
    "        # returns 768 dimensional array\n",
    "        return EmbeddingResponse(\n",
    "            text_embedding=text_embedding, video_embedding=None, video_chapter=None\n",
    "        )   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728cf6b-baeb-476a-a061-68c748a8dc6e",
   "metadata": {},
   "source": [
    "### Create helper functions to process data in batches\n",
    "Datasets can be large, so it's recommended to load a batch of data at a time into memory using a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e6f9ef7-0279-48f4-a576-3868ec14a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Callable, Generator, List,Tuple\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#Number of API calls per second\n",
    "API_IMAGES_PER_SECOND = 2\n",
    "\n",
    "def generate_batches(\n",
    "    inputs: List[str], batch_size: int\n",
    ") -> Generator[List[str], None, None]:\n",
    "    \"\"\"\n",
    "    Generator function that takes a list of strings and a batch size, and yields batches of the specified size.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(inputs), batch_size):\n",
    "        yield inputs [i : i + batch_size] \n",
    "\n",
    "\n",
    "\n",
    "def encode_to_embeddings_chunked(\n",
    "    process_function: Callable[[List[str]], List[Optional[List[float]]]],\n",
    "    items: str,\n",
    "    batch_size: int = 1,\n",
    ") -> List[Optional[List[float]]]:\n",
    "    \"\"\"\n",
    "    Function that encodes a list of strings into embeddings using a process function.\n",
    "    It takes a list of strings and returns a list of optional lists of floats.\n",
    "    The data is processed in chunks to prevent out-of-memory errors.\n",
    "    \"\"\"\n",
    "    \n",
    "    embeddings_list: List[Optional[List[float]]] = []\n",
    "\n",
    "    # Prepare the batches using a generator\n",
    "    batches = generate_batches(items, batch_size)\n",
    "    \n",
    "   \n",
    "    seconds_per_job = batch_size / API_IMAGES_PER_SECOND\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for batch in tqdm(batches, total=len(items) // batch_size, position=0):\n",
    "            futures.append(executor.submit(process_function, batch))\n",
    "            time.sleep(seconds_per_job)\n",
    "\n",
    "        for future in futures:\n",
    "            embeddings_list.extend(future.result())\n",
    "    return embeddings_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70084d60-e64f-4acf-b41d-07295141df90",
   "metadata": {},
   "source": [
    "### Create functions that wrap embedding functions in try-except and retry logic\n",
    "This particular embedding model can only process 1 image at a time, so inputs are validated to be equal to a length of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc24f964-09eb-4641-a0ed-2a9fc05247aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from tenacity import retry, stop_after_attempt\n",
    "\n",
    "client = EmbeddingPredictionClient(project=PROJECT_ID)\n",
    "\n",
    "\n",
    "# Use a retry handler in case of failure\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_texts_to_embeddings_with_retry(text: List[str]) -> List[List[float]]:\n",
    "    assert len(text) == 1\n",
    "\n",
    "    try:\n",
    "        return [client.get_embedding(text=text[0], image_file=None).text_embedding]\n",
    "    except Exception:\n",
    "        raise RuntimeError(\"Error getting embedding.\")\n",
    "\n",
    "\n",
    "def encode_texts_to_embeddings(text: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_texts_to_embeddings_with_retry(text=text)\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(text))]\n",
    "\n",
    "\n",
    "@retry(reraise=True, stop=stop_after_attempt(0))\n",
    "def encode_videos_to_embeddings_with_retry(video_uris: List[str] ) -> List[List[float]]:\n",
    "    assert len(video_uris) == 1\n",
    "\n",
    "    try:\n",
    "        embeddings=client.get_embedding(text=None, video_file=video_uris[0] )\n",
    "        return [embeddings.video_embedding],[embeddings.video_chapter] \n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        raise RuntimeError(\"Error getting embedding for video.\")\n",
    "\n",
    "\n",
    "def encode_videos_to_embeddings(video_uris: List[str] ) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        \n",
    "        return encode_videos_to_embeddings_with_retry(video_uris=video_uris )\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return [None for _ in range(len(video_uris))]\n",
    "    \n",
    "\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_videos_to_summarycontent_with_retry(video_uris: List[str]) -> List[List[float]]:\n",
    "    assert len(image_uris) == 1\n",
    "\n",
    "    try:\n",
    "        return [\n",
    "            client.get_video_summarycontent(text=None, video_file=video_uris[0])\n",
    "        ]\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        raise RuntimeError(\"Error getting summaries.\")\n",
    "\n",
    "\n",
    "def encode_videos_to_summarycontent(video_uris: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_videos_to_summarycontent_with_retry(video_uris=video_uris)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return [None for _ in range(len(video_uris))]\n",
    "    \n",
    "    \n",
    "# Use a retry handler in case of failure\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_summarycontent_to_embeddings_with_retry(text: List[str]) -> List[List[float]]:\n",
    "    assert len(text) == 1\n",
    "\n",
    "    try:\n",
    "        return [client.get_summarycontent_embedding_from_text_embedding_model(text=text[0]).text_embedding]\n",
    "    except Exception:\n",
    "        raise RuntimeError(\"Error getting embedding for summary content.\")\n",
    "\n",
    "\n",
    "def encode_summarycontent_to_embeddings(text: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_summarycontent_to_embeddings_with_retry(text=text)\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(text))]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e9287-4332-4ac5-8d6a-4b6f2a24f0ff",
   "metadata": {},
   "source": [
    "### Create and save the embeddings in JSONL format\n",
    "The data must be formatted in JSONL format, which means each embedding dictionary is written as an individual JSON object on its own line.\n",
    "\n",
    "See more information in the docs at Input data format and structure.\n",
    "\n",
    "Run the following code in the next available cells, to create a temporary file to store embeddings in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2aeb8b57-7ab4-490d-8a98-01f71f45d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile, shutil\n",
    "\n",
    "# Create temporary file to write embeddings to\n",
    "videoembeddings_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=False)\n",
    "\n",
    "# Create temporary file to write summaries to\n",
    "videosummaries_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25a08f1-1e9a-4c97-a0eb-624ce9d75165",
   "metadata": {},
   "source": [
    "### embedding file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a898f97e-a4c3-49b5-afae-9bfa7e1a05d8",
   "metadata": {},
   "source": [
    "### Video Embeddings in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de986c74-1704-4dbb-bc76-6e4493b61755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4465a638d9c841e4a1d3b9238df76cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace6b2b560a74ca6b3db82ef8a89be8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/nine-quality-test/locations/us-central1/publishers/google/models/multimodalembedding@001\n",
      "{'start': 0, 'end': 120}\n",
      "getting Multimodal Embeddings..\n",
      "getting summaries..\n",
      "['{\\n\\t\\t\\t\"type\":\"integer\"\\n\\t\\t}', '{\\n\\t\\t\\t\"type\":\"integer\"\\n\\t\\t}', '{\\n\\t\\t\\t\"type\":\"string\"\\n\\t\\t}', '{\\n  \"startOffset\": 0,\\n  \"endOffset\": 16,\\n  \"chapterSummary\": \"A woman speaks about a missing person, and her family is trying to piece together what happened to her.\"\\n}', '{\\n  \"startOffset\": 16,\\n  \"endOffset\": 32,\\n  \"chapterSummary\": \"A woman, who lost her sister, is recounting the events leading up to the disappearance of her sister. The 60 Minutes logo is displayed.\"\\n}', '{\\n  \"startOffset\": 32,\\n  \"endOffset\": 48,\\n  \"chapterSummary\": \"The 60 Minutes logo is displayed.  A woman describes the investigation into her sister\\'s disappearance.  There is a focus on how a person of interest is changing his story.\"\\n}', '{\\n  \"startOffset\": 48,\\n  \"endOffset\": 64,\\n  \"chapterSummary\": \"The woman\\'s statement about the investigation is shown, as is the police\\'s investigation and its impact on the family.\"\\n}', '{\\n  \"startOffset\": 64,\\n  \"endOffset\": 80,\\n  \"chapterSummary\": \"A description of the events leading up to the disappearance and its aftermath.  A person of interest is shown, and their interaction with police.\"\\n}', '{\\n  \"startOffset\": 80,\\n  \"endOffset\": 96,\\n  \"chapterSummary\": \"The 60 Minutes logo is displayed. A discussion about a person of interest who is now being brought back into the investigation.\"\\n}', '{\\n  \"startOffset\": 96,\\n  \"endOffset\": 112,\\n  \"chapterSummary\": \"The 60 Minutes logo is displayed.  A woman expresses her feelings about the police and how the investigation has impacted her. \"\\n}', '{\\n  \"startOffset\": 112,\\n  \"endOffset\": 120,\\n  \"chapterSummary\": \"The 60 Minutes logo is displayed.  The woman describes the impact of the investigation on her life.\"\\n}']\n",
      "\n",
      "\n",
      "list index out of range\n",
      "Error getting embedding for video.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m video_summaries\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#comment to prevent extra costs\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#********************************\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m video_embeddings,video_chapters \u001b[38;5;241m=\u001b[39m encode_to_embeddings_chunked(\n\u001b[1;32m     17\u001b[0m        process_function\u001b[38;5;241m=\u001b[39mencode_videos_to_embeddings, items\u001b[38;5;241m=\u001b[39mvideo_paths_chunk)                 \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#********************************\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#comment to prevent extra costs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Append to file\u001b[39;00m\n\u001b[1;32m     39\u001b[0m embeddings_formatted\u001b[38;5;241m=\u001b[39m[]\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "BATCH_SIZE = 1# this can be changed\n",
    " \n",
    "           \n",
    "with open(videoembeddings_file.name, \"a\") as ef:     \n",
    "         for i in tqdm(range(0, len(video_paths), BATCH_SIZE)):#len(image_names)\n",
    "            video_names_chunk = video_names[i : i + BATCH_SIZE]\n",
    "            video_paths_chunk = video_paths[i : i + BATCH_SIZE]\n",
    "            \n",
    "            \n",
    "            embeddings=[]\n",
    "            video_summaries=[]\n",
    "            #comment to prevent extra costs\n",
    "            #********************************\n",
    "            video_embeddings,video_chapters = encode_to_embeddings_chunked(\n",
    "                   process_function=encode_videos_to_embeddings, items=video_paths_chunk)                 \n",
    "            #********************************\n",
    "\n",
    "            #comment to prevent extra costs\n",
    "            #********************************\n",
    "            #summaries = encode_to_embeddings_chunked(\n",
    "                #process_function=encode_videos_to_summarycontent, items=video_paths_chunk\n",
    "               #)\n",
    "\n",
    "            #********************************\n",
    "            #summaries=[' The image shows three people: Joe Biden, a young girl, and Hunter Biden. Joe Biden is smiling and wearing a dark suit. The young girl is smiling and wearing a white dress. Hunter Biden is smiling and wearing a dark suit. The background is a photo of the White House.','this is test']\n",
    "\n",
    "            #comment to prevent extra costs\n",
    "            #********************************\n",
    "            #summaries_embeddings = encode_to_embeddings_chunked(\n",
    "                 #process_function=encode_summarycontent_to_embeddings, items=summaries\n",
    "            #)\n",
    "            #summaries_embeddings=[[1,2],[1,2,3]]\n",
    "\n",
    "            #********************************\n",
    "\n",
    "            # Append to file\n",
    "            embeddings_formatted=[]\n",
    "            for id,path,embedding,chapter in zip(video_names_chunk,video_paths_chunk,video_embeddings,video_chapters):\n",
    "                embedding=sorted(embedding, key=operator.attrgetter('start_offset_sec'))\n",
    "                chapter=sorted(chapter, key=operator.attrgetter('start_offset_sec'))\n",
    "                for ValEmbedding,ValChapter in zip(embedding,chapter):\n",
    "                    if ValChapter.start_offset_sec==ValEmbedding.start_offset_sec:\n",
    "                    \n",
    "                        if (ValEmbedding.embedding is not None) or (ValChapter.embedding is not None) :\n",
    "                            embeddings_formatted.append(  \n",
    "                                json.dumps(\n",
    "                                    {\n",
    "                                        \"id\": str(id), \n",
    "                                        \"video path\":str(path),\n",
    "                                        \"video_summary\":ValChapter.summary,\n",
    "                                        \"video_embedding\": [str(value) for value in ValEmbedding.embedding] if not ValEmbedding.embedding is None else None,\n",
    "                                        \"summary_embedding\": [str(value) for value in ValChapter.embedding] if not ValChapter.embedding is None else None,\n",
    "                                        \"start_offset_sec_embedding\": ValEmbedding.start_offset_sec,\n",
    "                                        \"end_offset_sec_embedding\": ValEmbedding.end_offset_sec ,\n",
    "                                        \"start_offset_sec_chapter\": ValChapter.start_offset_sec,\n",
    "                                        \"end_offset_sec_chapter\": ValChapter.end_offset_sec \n",
    "\n",
    "                                    }\n",
    "                                )\n",
    "                                + \"\\n\"\n",
    "\n",
    "                            )\n",
    "                    else:\n",
    "                        print('Something went wrong when chapterizing the video. The chapters are not inline with video segments.')\n",
    "                        raise\n",
    "            ef.writelines(embeddings_formatted)\n",
    "        \n",
    " \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb182a-2199-4b47-b844-65df08836758",
   "metadata": {},
   "source": [
    "### Create bucket and push embeddings into the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e5e18b-8a1c-4d1a-8013-d5ebd1a173cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#set bucket info to create a bucket\n",
    "BUCKET_URI = f\"gs://artifacts-{PROJECT_ID}-unique\"  # @param {type:\"string\"}\n",
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2354d-42f3-4b45-a387-c9f225f9b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIQUE_FOLDER_NAME = \"embeddings_results_NinePOC\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58369a05-16b4-4f93-b792-03b389544a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings\n",
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/{UNIQUE_FOLDER_NAME}/\"\n",
    "! gsutil cp {embeddings_file.name} {EMBEDDINGS_INITIAL_URI}\n",
    "\n",
    "#summaries\n",
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/{UNIQUE_FOLDER_NAME}/\"\n",
    "! gsutil cp {summaries_file.name} {EMBEDDINGS_INITIAL_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4fae7267-4f5f-43e7-a0fe-c39b4e0b9d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'videoembeddings_file.json'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the temp files in persistent disk\n",
    "import tempfile, shutil\n",
    " \n",
    "file_name = videoembeddings_file.name\n",
    "videoembeddings_file.close()\n",
    "shutil.copy(file_name, 'videoembeddings_file.json')\n",
    "\n",
    "# file_name = summaries_file.name\n",
    "# summaries_file.close()\n",
    "# shutil.copy(file_name, 'summaries_file.json')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe4468d-d92f-45cb-a3d0-9de84d8344be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
