{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8162339b-0555-46c0-8271-a26fe9fe99a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set project info\n",
    "PROJECT = !gcloud config get-value project\n",
    "PROJECT_ID = PROJECT[0]\n",
    "REGION ='us-cental1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eafa47e-3ad7-4e31-bcdf-7a976cf232f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "url = \"http://metadata.google.internal/computeMetadata/v1/project/project-id\"\n",
    "req = urllib.request.Request(url)\n",
    "req.add_header(\"Metadata-Flavor\", \"Google\")\n",
    "project_id = urllib.request.urlopen(req).read().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc77f6b7-aaf0-46fa-8545-29d1a2e23802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "def list_blobs(bucket_name):\n",
    "    \"\"\"Lists all the blobs in the bucket.\"\"\"\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    paths=[]\n",
    "    names=[]\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Note: Client.list_blobs requires at least package version 1.17.0.\n",
    "    blobs = storage_client.list_blobs(bucket_name,match_glob=[\"**/*.png\"])\n",
    " \n",
    "    # Note: The call returns a response only when the iterator is consumed.\n",
    "    for blob in blobs:    \n",
    "        paths.append('gs://' + blob.id[:-(len(str(blob.generation)) + 1)])\n",
    "        names.append(blob.name)\n",
    "    return paths,names\n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b63a65-47c9-4f33-bec0-56306b8f6cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_paths,image_names=list_blobs('raw_nine_files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6125a26-9f33-4c17-bd52-657233921201",
   "metadata": {},
   "source": [
    "### Define function to detect explicit images\n",
    "\n",
    "enable clound vision api before running this bit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190401dc-00a4-4d0e-927d-b41ed0a54c05",
   "metadata": {},
   "source": [
    "### Defining encoding functions\n",
    "Create an EmbeddingPredictionClient which encapsulates the logic to call the embedding API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2ad50c-4171-4375-ad84-977710db7a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import time\n",
    "import typing\n",
    "import copy\n",
    "from typing import List, Optional\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.protobuf import struct_pb2\n",
    "\n",
    "#libraries to generate image summaries\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.vision_models import Image as vision_model_Image\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n",
    "\n",
    "text_embedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@latest\")\n",
    "#multimodal_embedding_model = MultiModalEmbeddingModel.from_pretrained(\n",
    " #   \"multimodalembedding@001\"\n",
    "#)\n",
    "\n",
    "\n",
    "class EmbeddingResponse(typing.NamedTuple):\n",
    "    text_embedding: typing.Sequence[float]\n",
    "    image_embedding: typing.Sequence[float]\n",
    "\n",
    "\n",
    "import requests\n",
    "def get_public_url_from_gcs(gcs_uri: str) -> str:\n",
    "    return gcs_uri.replace(\"gs://\", \"https://storage.googleapis.com/\").replace(\n",
    "        \" \", \"%20\"\n",
    "    )\n",
    "\n",
    "def load_image_bytes(image_uri: str) -> bytes:\n",
    "    \"\"\"Load image bytes from a remote or local URI.\"\"\"\n",
    "    image_bytes = None\n",
    "    image_uri= get_public_url_from_gcs(image_uri)\n",
    "    if image_uri.startswith(\"http://\") or image_uri.startswith(\"https://\"):\n",
    "        response = requests.get(image_uri, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            image_bytes = response.content\n",
    "    else:\n",
    "        image_bytes = open(image_uri, \"rb\").read()\n",
    "    return image_bytes\n",
    "\n",
    "\n",
    "class EmbeddingPredictionClient:\n",
    "    \"\"\"Wrapper around Prediction Service Client.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        project: str,\n",
    "        location: str = \"us-central1\",\n",
    "        api_regional_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "    ):\n",
    "        client_options = {\"api_endpoint\": api_regional_endpoint}\n",
    "        # Initialize client that will be used to create and send requests.\n",
    "        # This client only needs to be created once, and can be reused for multiple requests.\n",
    "        self.client = aiplatform.gapic.PredictionServiceClient(\n",
    "            client_options=client_options\n",
    "        )\n",
    "        self.location = location\n",
    "        self.project = project\n",
    "\n",
    "    def get_embedding(self, text: str = None, image_file: str = None):\n",
    "        if not text and not image_file:\n",
    "            raise ValueError(\"At least one of text or image_file must be specified.\")\n",
    "\n",
    "        # Load image file\n",
    "        image_bytes = None\n",
    "        if image_file:\n",
    "            if not (image_file.startswith(\"gs://\")): \n",
    "                image_bytes = load_image_bytes(image_file)\n",
    "\n",
    "        instance = struct_pb2.Struct()\n",
    "        if text:\n",
    "            instance.fields[\"text\"].string_value = text\n",
    "\n",
    "        if image_bytes:\n",
    "            encoded_content = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "            image_struct = instance.fields[\"image\"].struct_value\n",
    "            image_struct.fields[\"bytesBase64Encoded\"].string_value = encoded_content\n",
    "\n",
    "        if image_file:\n",
    "            if (image_file.startswith(\"gs://\")): \n",
    "                  instance[\"image\"] = {\n",
    "                        \"gcsUri\": image_file  # pylint: disable=protected-access\n",
    "                    }       \n",
    "        \n",
    "        instances = [instance]\n",
    "        \n",
    "        endpoint = (\n",
    "           f\"projects/{self.project}/locations/{self.location}\"\n",
    "           \"/publishers/google/models/multimodalembedding@001\"\n",
    "        )\n",
    "        response = self.client.predict(endpoint=endpoint, instances=instances)\n",
    "        text_embedding = None\n",
    "        if text:\n",
    "            text_emb_value = response.predictions[0][\"textEmbedding\"]\n",
    "            text_embedding = [v for v in text_emb_value]\n",
    "\n",
    "        image_embedding = None\n",
    "        if image_bytes or image_file:\n",
    "            image_emb_value = response.predictions[0][\"imageEmbedding\"]\n",
    "            image_embedding = [v for v in image_emb_value]\n",
    "\n",
    "        return EmbeddingResponse(\n",
    "            text_embedding=text_embedding, image_embedding=image_embedding\n",
    "        )\n",
    "\n",
    "    def get_image_summarycontent(self, text: str = None, image_file: str = None):\n",
    "        \n",
    "        generative_multimodal_model= GenerativeModel(\"gemini-pro-vision\")\n",
    "        \n",
    "        image_description_prompt=\"\"\"You are an assistant tasked with summarizing images for retrieval. \\\n",
    "        These summaries will be embedded and used to retrieve the raw image. \\\n",
    "        Give a concise summary of the image that is well optimized for retrieval.\\\n",
    "        If there is a famous person like politician, celebrity or athlete, indicate their name and describe what they are famous for.\\\n",
    "        If you are not sure about any info, please do not make it up.\"\"\"\n",
    "        \n",
    "        generation_config= GenerationConfig(temperature=0.2, max_output_tokens=2048) \n",
    "        \n",
    "        safety_settings=  {\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        }\n",
    "        stream=True\n",
    "        \n",
    "        # Load the saved image as a Gemini Image Object\n",
    "        #image_for_gemini= Image.load_from_file(image_file)\n",
    "        image_for_gemini = Part.from_uri(image_file, \"image/jpeg\")\n",
    "\n",
    "        model_input=[image_description_prompt, image_for_gemini]\n",
    "        \n",
    "        response = generative_multimodal_model.generate_content(\n",
    "        model_input,\n",
    "        generation_config=generation_config,\n",
    "        stream=stream,\n",
    "        safety_settings=safety_settings, )\n",
    "        \n",
    "        \n",
    "        response_list = []\n",
    "\n",
    "        for chunk in response:\n",
    "            try:\n",
    "                response_list.append(chunk.text)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    \"Exception occurred while calling gemini. Something is wrong. Lower the safety thresholds [safety_settings: BLOCK_NONE ] if not already done. -----\",\n",
    "                    e,\n",
    "                )\n",
    "                response_list.append(\"Exception occurred\")\n",
    "                continue\n",
    "        response = \"\".join(response_list)\n",
    " \n",
    "        return response\n",
    "\n",
    "    def get_summarycontent_embedding_from_text_embedding_model(self, text: str, return_array: Optional[bool] = False,) -> list:\n",
    "        \"\"\"\n",
    "        Generates a numerical text embedding from a provided text input using a text embedding model.\n",
    "\n",
    "        Args:\n",
    "            text: The input text string to be embedded.\n",
    "            return_array: If True, returns the embedding as a NumPy array.\n",
    "                          If False, returns the embedding as a list. (Default: False)\n",
    "\n",
    "        Returns:\n",
    "            list or numpy.ndarray: A 768-dimensional vector representation of the input text.\n",
    "                                   The format (list or NumPy array) depends on the\n",
    "                                   value of the 'return_array' parameter.\n",
    "        \"\"\"\n",
    "\n",
    "        #the given text is maximum 2048 token. If more, it has to be chunked.\n",
    "        embeddings = text_embedding_model.get_embeddings([text])\n",
    "        text_embedding = [embedding.values for embedding in embeddings][0]\n",
    "\n",
    "        if return_array:\n",
    "            text_embedding = np.fromiter(text_embedding, dtype=float)\n",
    "\n",
    "        # returns 768 dimensional array\n",
    "        return EmbeddingResponse(\n",
    "            text_embedding=text_embedding, image_embedding=None\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728cf6b-baeb-476a-a061-68c748a8dc6e",
   "metadata": {},
   "source": [
    "### Create helper functions to process data in batches\n",
    "Datasets can be large, so it's recommended to load a batch of data at a time into memory using a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f9ef7-0279-48f4-a576-3868ec14a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Callable, Generator, List\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#Number of API calls per second\n",
    "API_IMAGES_PER_SECOND = 2\n",
    "\n",
    "def generate_batches(\n",
    "    inputs: List[str], batch_size: int\n",
    ") -> Generator[List[str], None, None]:\n",
    "    \"\"\"\n",
    "    Generator function that takes a list of strings and a batch size, and yields batches of the specified size.\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(0, len(inputs), batch_size):\n",
    "        yield inputs[i : i + batch_size]\n",
    "\n",
    "\n",
    "\n",
    "def encode_to_embeddings_chunked(\n",
    "    process_function: Callable[[List[str]], List[Optional[List[float]]]],\n",
    "    items: List[str],\n",
    "    batch_size: int = 1,\n",
    ") -> List[Optional[List[float]]]:\n",
    "    \"\"\"\n",
    "    Function that encodes a list of strings into embeddings using a process function.\n",
    "    It takes a list of strings and returns a list of optional lists of floats.\n",
    "    The data is processed in chunks to prevent out-of-memory errors.\n",
    "    \"\"\"\n",
    "\n",
    "    embeddings_list: List[Optional[List[float]]] = []\n",
    "\n",
    "    # Prepare the batches using a generator\n",
    "    batches = generate_batches(items, batch_size)\n",
    "\n",
    "    seconds_per_job = batch_size / API_IMAGES_PER_SECOND\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for batch in tqdm(batches, total=len(items) // batch_size, position=0):\n",
    "            futures.append(executor.submit(process_function, batch))\n",
    "            time.sleep(seconds_per_job)\n",
    "\n",
    "        for future in futures:\n",
    "            embeddings_list.extend(future.result())\n",
    "    return embeddings_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70084d60-e64f-4acf-b41d-07295141df90",
   "metadata": {},
   "source": [
    "### Create functions that wrap embedding functions in try-except and retry logic\n",
    "This particular embedding model can only process 1 image at a time, so inputs are validated to be equal to a length of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc24f964-09eb-4641-a0ed-2a9fc05247aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from tenacity import retry, stop_after_attempt\n",
    "\n",
    "client = EmbeddingPredictionClient(project=PROJECT_ID)\n",
    "\n",
    "\n",
    "# Use a retry handler in case of failure\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_texts_to_embeddings_with_retry(text: List[str]) -> List[List[float]]:\n",
    "    assert len(text) == 1\n",
    "\n",
    "    try:\n",
    "        return [client.get_embedding(text=text[0], image_file=None).text_embedding]\n",
    "    except Exception:\n",
    "        raise RuntimeError(\"Error getting embedding.\")\n",
    "\n",
    "\n",
    "def encode_texts_to_embeddings(text: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_texts_to_embeddings_with_retry(text=text)\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(text))]\n",
    "\n",
    "\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_images_to_embeddings_with_retry(image_uris: List[str]) -> List[List[float]]:\n",
    "    assert len(image_uris) == 1\n",
    "\n",
    "    try:\n",
    "        return [\n",
    "            client.get_embedding(text=None, image_file=image_uris[0]).image_embedding\n",
    "        ]\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        raise RuntimeError(\"Error getting embedding for image.\")\n",
    "\n",
    "\n",
    "def encode_images_to_embeddings(image_uris: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_images_to_embeddings_with_retry(image_uris=image_uris)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return [None for _ in range(len(image_uris))]\n",
    "    \n",
    "\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_images_to_summarycontent_with_retry(image_uris: List[str]) -> List[List[float]]:\n",
    "    assert len(image_uris) == 1\n",
    "\n",
    "    try:\n",
    "        return [\n",
    "            client.get_image_summarycontent(text=None, image_file=image_uris[0])\n",
    "        ]\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        raise RuntimeError(\"Error getting summaries.\")\n",
    "\n",
    "\n",
    "def encode_images_to_summarycontent(image_uris: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_images_to_summarycontent_with_retry(image_uris=image_uris)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return [None for _ in range(len(image_uris))]\n",
    "    \n",
    "    \n",
    "# Use a retry handler in case of failure\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_summarycontent_to_embeddings_with_retry(text: List[str]) -> List[List[float]]:\n",
    "    assert len(text) == 1\n",
    "\n",
    "    try:\n",
    "        return [client.get_summarycontent_embedding_from_text_embedding_model(text=text[0]).text_embedding]\n",
    "    except Exception:\n",
    "        raise RuntimeError(\"Error getting embedding for summary content.\")\n",
    "\n",
    "\n",
    "def encode_summarycontent_to_embeddings(text: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_summarycontent_to_embeddings_with_retry(text=text)\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(text))]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e9287-4332-4ac5-8d6a-4b6f2a24f0ff",
   "metadata": {},
   "source": [
    "### Create and save the embeddings in JSONL format\n",
    "The data must be formatted in JSONL format, which means each embedding dictionary is written as an individual JSON object on its own line.\n",
    "\n",
    "See more information in the docs at Input data format and structure.\n",
    "\n",
    "Run the following code in the next available cells, to create a temporary file to store embeddings in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2aeb8b57-7ab4-490d-8a98-01f71f45d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile, shutil\n",
    "\n",
    "# Create temporary file to write embeddings to\n",
    "embeddings_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=False)\n",
    "\n",
    "# Create temporary file to write summaries to\n",
    "summaries_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8f28b9a3-a032-4fc4-9b16-de51a625d9c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(embeddings_file.name, \"a\") as ef:\n",
    "     ef.writelines('this is only a test22222')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25a08f1-1e9a-4c97-a0eb-624ce9d75165",
   "metadata": {},
   "source": [
    "### embedding file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de986c74-1704-4dbb-bc76-6e4493b61755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "BATCH_SIZE = 1# this can be changed\n",
    "\n",
    "with open(embeddings_file.name, \"a\") as ef, open(summaries_file.name, \"a\") as sf:\n",
    "     for i in tqdm(range(0, len(image_names), BATCH_SIZE)):#len(image_names)\n",
    "        image_names_chunk = image_names[i : i + BATCH_SIZE]\n",
    "        image_paths_chunk = image_paths[i : i + BATCH_SIZE]\n",
    "        embeddings=[]\n",
    "        image_summaries=[]\n",
    "        #comment to prevent extra costs\n",
    "        #********************************\n",
    "        embeddings = encode_to_embeddings_chunked(\n",
    "            process_function=encode_images_to_embeddings, items=image_paths_chunk\n",
    "        )\n",
    "        #embeddings=[[1,2],[1,2]]\n",
    "        #********************************\n",
    "\n",
    "        #comment to prevent extra costs\n",
    "        #********************************\n",
    "        summaries = encode_to_embeddings_chunked(\n",
    "            process_function=encode_images_to_summarycontent, items=image_paths_chunk\n",
    "           )\n",
    "        #summaries=['1'+str(i),'2'+str(i)]\n",
    "        #********************************\n",
    "        #summaries=[' The image shows three people: Joe Biden, a young girl, and Hunter Biden. Joe Biden is smiling and wearing a dark suit. The young girl is smiling and wearing a white dress. Hunter Biden is smiling and wearing a dark suit. The background is a photo of the White House.','this is test']\n",
    "   \n",
    "        #comment to prevent extra costs\n",
    "        #********************************\n",
    "        summaries_embeddings = encode_to_embeddings_chunked(\n",
    "             process_function=encode_summarycontent_to_embeddings, items=summaries\n",
    "        )\n",
    "        #summaries_embeddings=[[1,2],[1,2,3]]\n",
    "        \n",
    "        #********************************\n",
    "        \n",
    "        #print(embeddings)\n",
    "        #print('-----')\n",
    "        print(summaries)\n",
    "        #print('-----')\n",
    "        #print(summaries_embeddings)\n",
    "        # Append to file\n",
    "        embeddings_formatted = [\n",
    "            json.dumps(\n",
    "                {\n",
    "                    \"id\": str(id),\n",
    "                    \"embedding\": [str(value) for value in embedding],\n",
    "                }\n",
    "            )\n",
    "            + \"\\n\"\n",
    "            for id, embedding in zip(image_names_chunk, embeddings)\n",
    "            if embedding is not None\n",
    "        ]\n",
    "        ef.writelines(embeddings_formatted)\n",
    "        \n",
    "        \n",
    "        summaries_formatted = [\n",
    "            json.dumps(\n",
    "                {\n",
    "                    \"id\": str(id),\n",
    "                    \"image path\": image_path,\n",
    "                    \"summary\":  summary,\n",
    "                    \"summary embedding\": [str(value) for value in summaries_embedding],\n",
    "                    \"image embedding\": [str(value) for value in embedding],\n",
    "                }\n",
    "            )\n",
    "            + \"\\n\"\n",
    "            for id, summary,summaries_embedding,embedding,image_path in zip(image_names_chunk, summaries,summaries_embeddings,embeddings,image_paths_chunk)\n",
    "            if summaries is not None\n",
    "        ]\n",
    "        sf.writelines(summaries_formatted)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb182a-2199-4b47-b844-65df08836758",
   "metadata": {},
   "source": [
    "### Create bucket and push embeddings into the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e5e18b-8a1c-4d1a-8013-d5ebd1a173cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#set bucket info to create a bucket\n",
    "BUCKET_URI = f\"gs://artifacts-{PROJECT_ID}-unique\"  # @param {type:\"string\"}\n",
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8ff2354d-42f3-4b45-a387-c9f225f9b1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///var/tmp/tmp90h66ik0.json [Content-Type=application/json]...\n",
      "/ [1 files][   19.0 B/   19.0 B]                                                \n",
      "Operation completed over 1 objects/19.0 B.                                       \n"
     ]
    }
   ],
   "source": [
    "UNIQUE_FOLDER_NAME = \"multimodal_embeddings\"\n",
    "BUCKET_URI = f\"gs://artifacts-nine-quality-test-embeddings\"\n",
    "#embeddings\n",
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/{UNIQUE_FOLDER_NAME}/\"\n",
    "! gsutil cp {embeddings_file.name} {EMBEDDINGS_INITIAL_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0b1f16dc-f1b5-401a-9013-538073b17d61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp=embeddings_file\n",
    "client = storage.Client()\n",
    "BUCKET_URI = f\"artifacts-nine-quality-test-embeddings\"\n",
    "#embeddings\n",
    "EMBEDDINGS_INITIAL_URI = f\"{UNIQUE_FOLDER_NAME}/\"\n",
    "\n",
    "if 1==1:\n",
    "        # Extract name to the temp file\n",
    "        temp_file = \"\".join([str(temp.name)])\n",
    "        # Save image to temp file            \n",
    "        # Uploading the temp image file to the bucket\n",
    "        dest_filename = f\"{UNIQUE_FOLDER_NAME}/embeddingtest.json\"\n",
    "        dest_bucket_name =  f\"artifacts-nine-quality-test-embeddings\"\n",
    "        dest_bucket = client.get_bucket(BUCKET_URI)\n",
    "        dest_blob = dest_bucket.blob(dest_filename)\n",
    "        dest_blob.upload_from_filename(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58369a05-16b4-4f93-b792-03b389544a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings\n",
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/{UNIQUE_FOLDER_NAME}/\"\n",
    "! gsutil cp {embeddings_file.name} {EMBEDDINGS_INITIAL_URI}\n",
    "\n",
    "#summaries\n",
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/{UNIQUE_FOLDER_NAME}/\"\n",
    "! gsutil cp {summaries_file.name} {EMBEDDINGS_INITIAL_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fae7267-4f5f-43e7-a0fe-c39b4e0b9d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#save the temp files in persistent disk\n",
    "import tempfile, shutil\n",
    " \n",
    "file_name = embeddings_file.name\n",
    "embeddings_file.close()\n",
    "shutil.copy(file_name, 'embeddings_file.json')\n",
    "\n",
    "file_name = summaries_file.name\n",
    "summaries_file.close()\n",
    "shutil.copy(file_name, 'summaries_file.json')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe4468d-d92f-45cb-a3d0-9de84d8344be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
