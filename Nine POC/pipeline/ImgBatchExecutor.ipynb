{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eafa47e-3ad7-4e31-bcdf-7a976cf232f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from google.cloud import storage\n",
    "import copy\n",
    "import numpy as np\n",
    "import requests\n",
    "from tenacity import retry, stop_after_attempt\n",
    "\n",
    "import base64\n",
    "import time\n",
    "import typing\n",
    "import copy\n",
    "import requests\n",
    "from typing import List, Optional\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.protobuf import struct_pb2\n",
    "\n",
    "#libraries to generate image summaries\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.vision_models import Image as vision_model_Image\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n",
    "import tempfile, shutil\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Callable, Generator, List, Optional\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "#Number of API calls per second\n",
    "API_IMAGES_PER_SECOND = 2\n",
    "#Number of files to be processed in a batch\n",
    "BATCH_SIZE = 1# this can be changed\n",
    "#source bucket to get data from\n",
    "SOURCE_BUCKET_NAME='raw_nine_files'\n",
    "#MM embeddings folder name\n",
    "MM_UNIQUE_FOLDER_NAME = \"multimodal_embeddings\"\n",
    "#Content embeddings folder name\n",
    "CNT_UNIQUE_FOLDER_NAME = \"content_embeddings\"\n",
    "#Destination bucket name\n",
    "DESTINATION_BUCKET_URI = f\"artifacts-nine-quality-test-embeddings\" \n",
    "    \n",
    "text_embedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@latest\")\n",
    "#multimodal_embedding_model = MultiModalEmbeddingModel.from_pretrained(\n",
    " #   \"multimodalembedding@001\"\n",
    "#)\n",
    "\n",
    "\n",
    "url = \"http://metadata.google.internal/computeMetadata/v1/project/project-id\"\n",
    "req = urllib.request.Request(url)\n",
    "req.add_header(\"Metadata-Flavor\", \"Google\")\n",
    "PROJECT_ID = urllib.request.urlopen(req).read().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a2ad50c-4171-4375-ad84-977710db7a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EmbeddingResponse(typing.NamedTuple):\n",
    "    text_embedding: typing.Sequence[float]\n",
    "    image_embedding: typing.Sequence[float]\n",
    " \n",
    "class EmbeddingPredictionClient:\n",
    "    \"\"\"Wrapper around Prediction Service Client.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        project: str,\n",
    "        location: str = \"us-central1\",\n",
    "        api_regional_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "    ):\n",
    "        client_options = {\"api_endpoint\": api_regional_endpoint}\n",
    "        # Initialize client that will be used to create and send requests.\n",
    "        # This client only needs to be created once, and can be reused for multiple requests.\n",
    "        self.client = aiplatform.gapic.PredictionServiceClient(\n",
    "            client_options=client_options\n",
    "        )\n",
    "        self.location = location\n",
    "        self.project = project\n",
    "\n",
    "    def get_embedding(self, text: str = None, image_file: str = None):\n",
    "        if not text and not image_file:\n",
    "            raise ValueError(\"At least one of text or image_file must be specified.\")\n",
    "\n",
    "\n",
    "        instance = struct_pb2.Struct()\n",
    "        if text:\n",
    "            instance.fields[\"text\"].string_value = text        \n",
    "        \n",
    "        if image_file:\n",
    "            if (image_file.startswith(\"gs://\")): \n",
    "                  instance[\"image\"] = {\n",
    "                        \"gcsUri\": image_file  # pylint: disable=protected-access\n",
    "                    }       \n",
    "        \n",
    "        instances = [instance]\n",
    "        \n",
    "        endpoint = (\n",
    "           f\"projects/{self.project}/locations/{self.location}\"\n",
    "           \"/publishers/google/models/multimodalembedding@001\"\n",
    "        )\n",
    "        response = self.client.predict(endpoint=endpoint, instances=instances)\n",
    "        text_embedding = None\n",
    "        if text:\n",
    "            text_emb_value = response.predictions[0][\"textEmbedding\"]\n",
    "            text_embedding = [v for v in text_emb_value]\n",
    "\n",
    "        image_embedding = None\n",
    "        if image_file:\n",
    "            image_emb_value = response.predictions[0][\"imageEmbedding\"]\n",
    "            image_embedding = [v for v in image_emb_value]\n",
    "\n",
    "        return EmbeddingResponse(\n",
    "            text_embedding=text_embedding, image_embedding=image_embedding\n",
    "        )\n",
    "\n",
    "    def get_image_summarycontent(self, text: str = None, image_file: str = None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Generates summary content for the image.\n",
    "\n",
    "        Args:\n",
    "            image_file: The input image url to summarize its content.\n",
    "\n",
    "        Returns:\n",
    "            string: string value including the content description of the provided image.\n",
    "        \"\"\"            \n",
    "        \n",
    "        generative_multimodal_model= GenerativeModel(\"gemini-pro-vision\")\n",
    "        \n",
    "        image_description_prompt=\"\"\"You are an assistant tasked with summarizing images for retrieval. \\\n",
    "        These summaries will be embedded and used to retrieve the raw image. \\\n",
    "        Give a concise summary of the image that is well optimized for retrieval.\\\n",
    "        If there is a famous person like politician, celebrity or athlete, indicate their name and describe what they are famous for.\\\n",
    "        If you are not sure about any info, please do not make it up.\"\"\"\n",
    "        \n",
    "        generation_config= GenerationConfig(temperature=0.2, max_output_tokens=2048) \n",
    "        \n",
    "        safety_settings=  {\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        }\n",
    "        stream=True\n",
    "        \n",
    "        # Load the saved image as a Gemini Image Object\n",
    "        #image_for_gemini= Image.load_from_file(image_file)\n",
    "        image_for_gemini = Part.from_uri(image_file, \"image/jpeg\")\n",
    "\n",
    "        model_input=[image_description_prompt, image_for_gemini]\n",
    "        \n",
    "        response = generative_multimodal_model.generate_content(\n",
    "        model_input,\n",
    "        generation_config=generation_config,\n",
    "        stream=stream,\n",
    "        safety_settings=safety_settings, )\n",
    "        \n",
    "        \n",
    "        response_list = []\n",
    "\n",
    "        for chunk in response:\n",
    "            try:\n",
    "                response_list.append(chunk.text)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    \"Exception occurred while calling gemini. Something is wrong. Lower the safety thresholds [safety_settings: BLOCK_NONE ] if not already done. -----\",\n",
    "                    e,\n",
    "                )\n",
    "                response_list.append(\"Exception occurred\")\n",
    "                continue\n",
    "        response = \"\".join(response_list)\n",
    " \n",
    "        return response\n",
    "\n",
    "    def get_summarycontent_embedding_from_text_embedding_model(self, text: str, return_array: Optional[bool] = False,) -> list:\n",
    "        \"\"\"\n",
    "        Generates a numerical text embedding from a provided text input using a text embedding model.\n",
    "\n",
    "        Args:\n",
    "            text: The input text string to be embedded.\n",
    "            return_array: If True, returns the embedding as a NumPy array.\n",
    "                          If False, returns the embedding as a list. (Default: False)\n",
    "\n",
    "        Returns:\n",
    "            list or numpy.ndarray: A 768-dimensional vector representation of the input text.\n",
    "                                   The format (list or NumPy array) depends on the\n",
    "                                   value of the 'return_array' parameter.\n",
    "        \"\"\"\n",
    "\n",
    "        #the given text is maximum 2048 token. If more, it has to be chunked.\n",
    "        embeddings = text_embedding_model.get_embeddings([text])\n",
    "        text_embedding = [embedding.values for embedding in embeddings][0]\n",
    "\n",
    "        if return_array:\n",
    "            text_embedding = np.fromiter(text_embedding, dtype=float)\n",
    "\n",
    "        # returns 768 dimensional array\n",
    "        return EmbeddingResponse(\n",
    "            text_embedding=text_embedding, image_embedding=None\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e6f9ef7-0279-48f4-a576-3868ec14a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_batches(\n",
    "    inputs: List[str], batch_size: int\n",
    ") -> Generator[List[str], None, None]:\n",
    "    \"\"\"\n",
    "    Generator function that takes a list of strings and a batch size, and yields batches of the specified size.\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(0, len(inputs), batch_size):\n",
    "        yield inputs[i : i + batch_size]\n",
    "\n",
    "\n",
    "\n",
    "def encode_to_embeddings_chunked(\n",
    "    process_function: Callable[[List[str]], List[Optional[List[float]]]],\n",
    "    items: List[str],\n",
    "    batch_size: int = 1,\n",
    ") -> List[Optional[List[float]]]:\n",
    "    \"\"\"\n",
    "    Function that encodes a list of strings into embeddings using a process function.\n",
    "    It takes a list of strings and returns a list of optional lists of floats.\n",
    "    The data is processed in chunks to prevent out-of-memory errors.\n",
    "    \"\"\"\n",
    "\n",
    "    embeddings_list: List[Optional[List[float]]] = []\n",
    "\n",
    "    # Prepare the batches using a generator\n",
    "    batches = generate_batches(items, batch_size)\n",
    "\n",
    "    seconds_per_job = batch_size / API_IMAGES_PER_SECOND\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for batch in tqdm(batches, total=len(items) // batch_size, position=0):\n",
    "            futures.append(executor.submit(process_function, batch))\n",
    "            time.sleep(seconds_per_job)\n",
    "\n",
    "        for future in futures:\n",
    "            embeddings_list.extend(future.result())\n",
    "    return embeddings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc24f964-09eb-4641-a0ed-2a9fc05247aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = EmbeddingPredictionClient(project=PROJECT_ID)\n",
    "\n",
    "\n",
    "# Use a retry handler in case of failure\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_texts_to_embeddings_with_retry(text: List[str]) -> List[List[float]]:\n",
    "    assert len(text) == 1\n",
    "\n",
    "    try:\n",
    "        return [client.get_embedding(text=text[0], image_file=None).text_embedding]\n",
    "    except Exception:\n",
    "        raise RuntimeError(\"Error getting embedding.\")\n",
    "\n",
    "\n",
    "def encode_texts_to_embeddings(text: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_texts_to_embeddings_with_retry(text=text)\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(text))]\n",
    "\n",
    "\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_images_to_embeddings_with_retry(image_uris: List[str]) -> List[List[float]]:\n",
    "    assert len(image_uris) == 1\n",
    "\n",
    "    try:\n",
    "        return [\n",
    "            client.get_embedding(text=None, image_file=image_uris[0]).image_embedding\n",
    "        ]\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        raise RuntimeError(\"Error getting embedding for image.\")\n",
    "\n",
    "\n",
    "def encode_images_to_embeddings(image_uris: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_images_to_embeddings_with_retry(image_uris=image_uris)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return [None for _ in range(len(image_uris))]\n",
    "    \n",
    "\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_images_to_summarycontent_with_retry(image_uris: List[str]) -> List[List[float]]:\n",
    "    assert len(image_uris) == 1\n",
    "\n",
    "    try:\n",
    "        return [\n",
    "            client.get_image_summarycontent(text=None, image_file=image_uris[0])\n",
    "        ]\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        raise RuntimeError(\"Error getting summaries.\")\n",
    "\n",
    "\n",
    "def encode_images_to_summarycontent(image_uris: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_images_to_summarycontent_with_retry(image_uris=image_uris)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return [None for _ in range(len(image_uris))]\n",
    "    \n",
    "    \n",
    "# Use a retry handler in case of failure\n",
    "@retry(reraise=True, stop=stop_after_attempt(3))\n",
    "def encode_summarycontent_to_embeddings_with_retry(text: List[str]) -> List[List[float]]:\n",
    "    assert len(text) == 1\n",
    "\n",
    "    try:\n",
    "        return [client.get_summarycontent_embedding_from_text_embedding_model(text=text[0]).text_embedding]\n",
    "    except Exception:\n",
    "        raise RuntimeError(\"Error getting embedding for summary content.\")\n",
    "\n",
    "\n",
    "def encode_summarycontent_to_embeddings(text: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        return encode_summarycontent_to_embeddings_with_retry(text=text)\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(text))]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de986c74-1704-4dbb-bc76-6e4493b61755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_blobs(bucket_name: str):\n",
    "    \"\"\"Lists all the blobs in the bucket. \n",
    "   \n",
    "        Args:\n",
    "            bucket_name: name of the source gcs bucket to read files from\n",
    "\n",
    "        Returns:\n",
    "            list paths: list of paths to the gcs objects\n",
    "            list names: list of names of the gcs objects\n",
    "    \"\"\"\n",
    "        \n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    paths=[]\n",
    "    names=[]\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Note: Client.list_blobs requires at least package version 1.17.0.\n",
    "    blobs = storage_client.list_blobs(bucket_name,match_glob=[\"**/*.png\"])\n",
    " \n",
    "    # Note: The call returns a response only when the iterator is consumed.\n",
    "    for blob in blobs:    \n",
    "        paths.append('gs://' + blob.id[:-(len(str(blob.generation)) + 1)])\n",
    "        names.append(blob.name)\n",
    "    return paths,names\n",
    "   \n",
    "def upload_embeddings_to_gcs(embeddings_file: tempfile, file_pre_fix:str, folder_name:str, dest_bucket_name:str ):\n",
    "    temp=embeddings_file\n",
    "    client = storage.Client()\n",
    "    now=datetime.strptime(str(datetime.now()),\n",
    "                               '%Y-%m-%d %H:%M:%S.%f')\n",
    "    # Extract name to the temp file\n",
    "    temp_file = \"\".join([str(temp.name)])\n",
    "    # Uploading the temp image file to the bucket\n",
    "    dest_filename = f\"{folder_name}/\"+file_pre_fix+datetime.strftime(now, '%Y%m%d%H%M%S')+\".json\" \n",
    "    dest_bucket = client.get_bucket(dest_bucket_name)\n",
    "    dest_blob = dest_bucket.blob(dest_filename)\n",
    "    dest_blob.upload_from_filename(temp_file)\n",
    "        \n",
    "\n",
    "def Generate_Batch_Image_Embeddings():\n",
    "    \n",
    "    #get the list of images from the bucket\n",
    "    image_paths,image_names=list_blobs(SOURCE_BUCKET_NAME)\n",
    "    \n",
    "    # Create temporary file to write embeddings to\n",
    "    embeddings_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=False)\n",
    "    # Create temporary file to write summaries to\n",
    "    summaries_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=False) \n",
    "\n",
    "    with open(embeddings_file.name, \"a\") as ef, open(summaries_file.name, \"a\") as sf:\n",
    "         for i in tqdm(range(0, len(image_names), BATCH_SIZE)):#len(image_names)\n",
    "            image_names_chunk = image_names[i : i + BATCH_SIZE]\n",
    "            image_paths_chunk = image_paths[i : i + BATCH_SIZE]\n",
    "            embeddings=[]\n",
    "            image_summaries=[]\n",
    "\n",
    "            #********************************\n",
    "            embeddings = encode_to_embeddings_chunked(\n",
    "                process_function=encode_images_to_embeddings, items=image_paths_chunk\n",
    "            )\n",
    "\n",
    "            #********************************\n",
    "            summaries = encode_to_embeddings_chunked(\n",
    "                process_function=encode_images_to_summarycontent, items=image_paths_chunk\n",
    "               )\n",
    " \n",
    "            #********************************\n",
    "\n",
    "            summaries_embeddings = encode_to_embeddings_chunked(\n",
    "                 process_function=encode_summarycontent_to_embeddings, items=summaries\n",
    "            )\n",
    "\n",
    "            #********************************\n",
    "\n",
    "            # Append to file\n",
    "            embeddings_formatted = [\n",
    "                json.dumps(\n",
    "                    {\n",
    "                        \"id\": str(id),\n",
    "                        \"embedding\": [str(value) for value in embedding],\n",
    "                    }\n",
    "                )\n",
    "                + \"\\n\"\n",
    "                for id, embedding in zip(image_names_chunk, embeddings)\n",
    "                if embedding is not None\n",
    "            ]\n",
    "            ef.writelines(embeddings_formatted)\n",
    "\n",
    "\n",
    "            summaries_formatted = [\n",
    "                json.dumps(\n",
    "                    {\n",
    "                        \"id\": str(id),\n",
    "                        \"image path\": image_path,\n",
    "                        \"summary\":  summary,\n",
    "                        \"summary embedding\": [str(value) for value in summaries_embedding],\n",
    "                        \"image embedding\": [str(value) for value in embedding],\n",
    "                    }\n",
    "                )\n",
    "                + \"\\n\"\n",
    "                for id, summary,summaries_embedding,embedding,image_path in zip(image_names_chunk, summaries,summaries_embeddings,embeddings,image_paths_chunk)\n",
    "                if summaries is not None\n",
    "            ]\n",
    "            sf.writelines(summaries_formatted)\n",
    "\n",
    "    #push files into destination buckets\n",
    "    upload_embeddings_to_gcs(embeddings_file, 'multimodal', MM_UNIQUE_FOLDER_NAME, DESTINATION_BUCKET_URI )\n",
    "    upload_embeddings_to_gcs(summaries_file, 'content', CNT_UNIQUE_FOLDER_NAME, DESTINATION_BUCKET_URI )\n",
    "      \n",
    "    #to do : move the processed files into processed folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6cec35-a025-4472-bb3f-31ee89b670ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20893349ff6e4dc1bffeeafa1a6f191a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1073b3f16768444bb3b78d8e5a41cc11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b53ef0f07e4669afb3c11f15378541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5894049f3684b028f8f73d42ee7ff80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Generate_Batch_Image_Embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e217e4-6bc8-4861-9d46-6b891ee3072d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
